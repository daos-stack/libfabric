From e5f9667f61b731dd7678688c5b1c0e9b76aa941e Mon Sep 17 00:00:00 2001
From: Sean Hefty <sean.hefty@intel.com>
Date: Tue, 18 Jul 2023 15:41:44 -0700
Subject: [PATCH 2/3] prov/tcp: Add locking to trywait path for potential data
 race

Problems reported by thread sanitizer.  There is no locking
around checking the CQ or EQ for being empty.  It's unclear if
the locking is technically needed, but safer to add given the
code is not in a fast path (prior to the app making a blocking
call).

Note that with the change, the lock used by the CQ and cntr
signaling fd is not technically needed, as the progress
lock protects the entire operation.  Removal of the lock is
deferred for subsequent patches, as the EQ locking requires
further investigation (in order to remove).

Signed-off-by: Sean Hefty <sean.hefty@intel.com>
---
 prov/tcp/src/xnet_progress.c | 42 +++++++++++++++++++++---------------
 1 file changed, 25 insertions(+), 17 deletions(-)

diff --git a/prov/tcp/src/xnet_progress.c b/prov/tcp/src/xnet_progress.c
index c09a85fd6..8906bfe6d 100644
--- a/prov/tcp/src/xnet_progress.c
+++ b/prov/tcp/src/xnet_progress.c
@@ -1352,50 +1352,58 @@ static void xnet_reset_wait(struct util_wait *wait)
  */
 int xnet_trywait(struct fid_fabric *fabric_fid, struct fid **fid, int count)
 {
-	struct util_cq *cq;
+	struct xnet_cq *cq;
 	struct xnet_eq *eq;
 	struct util_cntr *cntr;
 	struct util_wait *wait;
-	int ret, i;
+	int ret = 0, i;
 
-	for (i = 0; i < count; i++) {
+	for (i = 0; i < count && !ret; i++) {
 		switch (fid[i]->fclass) {
 		case FI_CLASS_CQ:
-			cq = container_of(fid[i], struct util_cq, cq_fid.fid);
-			if (!ofi_cirque_isempty(cq->cirq))
-				return -FI_EAGAIN;
-
-			xnet_reset_wait(cq->wait);
+			cq = container_of(fid[i], struct xnet_cq,
+					  util_cq.cq_fid.fid);
+			ofi_genlock_lock(xnet_cq2_progress(cq)->active_lock);
+			if (ofi_cirque_isempty(cq->util_cq.cirq))
+				xnet_reset_wait(cq->util_cq.wait);
+			else
+				ret = -FI_EAGAIN;
+			ofi_genlock_unlock(xnet_cq2_progress(cq)->active_lock);
 			break;
 		case FI_CLASS_EQ:
 			eq = container_of(fid[i], struct xnet_eq,
 					  util_eq.eq_fid.fid);
+			ofi_mutex_lock(&eq->util_eq.lock);
 			if (!slist_empty(&eq->util_eq.list))
-				return -FI_EAGAIN;
-
-			xnet_reset_wait(eq->util_eq.wait);
+				ret = -FI_EAGAIN;
+			ofi_mutex_unlock(&eq->util_eq.lock);
+			if (!ret)
+				xnet_reset_wait(eq->util_eq.wait);
 			break;
 		case FI_CLASS_CNTR:
 			/* The user must read the counter before and after
 			 * fi_trywait and compare the results to ensure that no
 			 * events were lost.
 			 */
-			cntr = container_of(fid[i], struct util_cntr, cntr_fid.fid);
+			cntr = container_of(fid[i], struct util_cntr,
+					    cntr_fid.fid);
+			ofi_genlock_lock(xnet_cntr2_progress(cntr)->active_lock);
 			xnet_reset_wait(cntr->wait);
+			ofi_genlock_unlock(xnet_cntr2_progress(cntr)->active_lock);
 			break;
 		case FI_CLASS_WAIT:
-			wait = container_of(fid[i], struct util_wait, wait_fid.fid);
+			wait = container_of(fid[i], struct util_wait,
+					    wait_fid.fid);
 			ret = wait->wait_try(wait);
-			if (ret)
-				return ret;
 			break;
 		default:
-			return -FI_ENOSYS;
+			ret = -FI_ENOSYS;
+			break;
 		}
 
 	}
 
-	return 0;
+	return ret;
 }
 
 /* We can't hold the progress lock around waiting, or we
-- 
2.40.1

