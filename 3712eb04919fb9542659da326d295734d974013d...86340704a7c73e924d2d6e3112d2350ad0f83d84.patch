diff --git a/AUTHORS b/AUTHORS
index c3a53a3..3b9bc47 100644
--- a/AUTHORS
+++ b/AUTHORS
@@ -3,10 +3,13 @@ aingerson <aingerson@gmail.com>
 aingerson <alexia.ingerson@intel.com>
 Ajay Kulkarni <ajaykulk@cisco.com>
 aleksandra.justa <ajusta@gklab-125-155.igk.intel.com>
+Alex McKinley <alex.mckinley@intel.com>
+Alex McKinley <alex@mckpals.com>
 Amith Abraham <aabraham@cray.com>
 Ana Guerrero López <ana@ekaia.org>
 Anatoliy Rozanov <anatoliy.rozanov@intel.com>
 Andrew Friedley <andrew.friedley@intel.com>
+Andrey Lobanov <andrey.lobanov@intel.com>
 Arun C Ilango <arun.ilango@intel.com>
 arun ilango <a-ilango@users.noreply.github.com>
 Arun Ilango <arun.ilango@intel.com>
@@ -20,6 +23,7 @@ Ben Turrubiates <bturrubi@cisco.com>
 Brian Li <brian14708@gmail.com>
 Chang Hyun Park <heartinpiece@gmail.com>
 Charles J Archer <charles.j.archer@intel.com>
+Chenwei Zhang <chenwz@amazon.com>
 Chen Zhao <soniczhao@gmail.com>
 Chris Dolan <chrisdolan@google.com>
 Chuck Fossen <chuckf@cray.com>
@@ -27,8 +31,10 @@ Coni Gehler <cgehler@cray.com>
 Dardo D Kleiner <dkleiner@cmf.nrl.navy.mil>
 Dave Goodell <dgoodell@cisco.com>
 David Noel <david.noel19@gmail.com>
+Dipti Kothari <dkothar@amazon.com>
 Dmitry Durnov <dmitry.durnov@intel.com>
 Dmitry Gladkov <dmitry.gladkov@intel.com>
+Doug Oucharek <dougso@me.com>
 Erik Paulson <epaulson10@gmail.com>
 Erik Paulson <erik.r.paulson@intel.com>
 Evan Harvey <e1.0harvey@gmail.com>
@@ -43,6 +49,7 @@ Gilles Gouaillardet <gilles.gouaillardet@iferc.org>
 Gilles Gouaillardet <gilles@rist.or.jp>
 Hefty <sean.hefty@intel.com>
 Holger Hoffstätte <holger@applied-asynchrony.com>
+Honggang Li <honli@redhat.com>
 Howard Pritchard <howardp@lanl.gov>
 Ignacio Hernandez <ignacio.hernandez@intel.com>
 Ira Weiny <ira.weiny@intel.com>
@@ -61,6 +68,7 @@ Jerome Berryhill <Jerome.Berryhill@Intel.com>
 Jerome Boyd Berryhill <JeromeBerryhill@Intel.com>
 Jerome Soumagne <jsoumagne@hdfgroup.org>
 Jianxin Xiong <jianxin.xiong@intel.com>
+Jie Zhang <zhngaj@amazon.com>
 Jim Snow <jim.m.snow@intel.com>
 Jithin Jose <jithin.jose@intel.com>
 Joe Doyle <joseph.doyle@intel.com>
@@ -87,6 +95,7 @@ Mikhail Khalilov <miharulidze@gmail.com>
 Mikhail Khalilov <mikhail.khalilov@intel.com>
 Mohan Gandhi <mohgan@amazon.com>
 Neil Spruit <neil.r.spruit@intel.com>
+nikhilnanal <nikhilnanal1@gmail.com>
 Nikita Gusev <nikita.gusev@intel.com>
 Oblomov, Sergey <hoopoepg@gmail.com>
 Oblomov, Sergey <sergey.oblomov@intel.com>
@@ -97,6 +106,7 @@ Patrick McCormick <patrick.m.mccormick@intel.com>
 Paul Coffman <pcoffman@anl.gov>
 Pavan Balaji <balaji@anl.gov>
 Peter Gottesman <pgottesm@cisco.com>
+Phil Carns <carns@mcs.anl.gov>
 Pierre Roux <piroux@cisco.com>
 Prankur Gupta <prankgup@cisco.com>
 Raghu Raja <craghun@amazon.com>
@@ -104,6 +114,7 @@ Raghu Raja <rajachan@users.noreply.github.com>
 Reese Faucette <rfaucett@cisco.com>
 Richard Halkyard <rhalkyard@cray.com>
 Robert Wespetal <wesper@amazon.com>
+Rohit Zambre <rzambre@uci.edu>
 Sannikov, Alexander <alexander.sannikov@intel.com>
 Sayantan Sur <sayantan.sur@intel.com>
 Sean Hefty <sean.hefty@intel.com>
@@ -132,6 +143,7 @@ William Zhang <wilzhang@amazon.com>
 Xuyang Wang <xuywang@cisco.com>
 Yohann Burette <yohann.burette@intel.com>
 yohann <yohann.burette@intel.com>
+Yulu Jia <yulu.jia@intel.com>
 Zach Tiffany <ztiffany@cray.com>
 Zach <ztiffany@cray.com>
 ztaylor <ztaylor@twitter.com>
diff --git a/Makefile.am b/Makefile.am
index fff7c2c..1a6e119 100644
--- a/Makefile.am
+++ b/Makefile.am
@@ -67,7 +67,8 @@ common_srcs =				\
 	prov/util/src/util_shm.c	\
 	prov/util/src/util_mem_monitor.c\
 	prov/util/src/util_mem_hooks.c	\
-	prov/util/src/util_mr_cache.c
+	prov/util/src/util_mr_cache.c	\
+	prov/util/src/util_coll.c
 
 
 if MACOS
@@ -126,6 +127,7 @@ src_libfabric_la_SOURCES =			\
 	include/ofi_indexer.h			\
 	include/ofi_iov.h			\
 	include/ofi_list.h			\
+	include/ofi_bitmask.h			\
 	include/shared/ofi_str.h		\
 	include/ofi_lock.h			\
 	include/ofi_mem.h			\
@@ -142,6 +144,7 @@ src_libfabric_la_SOURCES =			\
 	include/ofi_mr.h			\
 	include/ofi_net.h			\
 	include/ofi_perf.h			\
+	include/ofi_coll.h			\
 	include/fasthash.h			\
 	include/rbtree.h			\
 	include/uthash.h			\
@@ -172,7 +175,7 @@ src_libfabric_la_LIBADD =
 src_libfabric_la_DEPENDENCIES = libfabric.map
 
 if !EMBEDDED
-src_libfabric_la_LDFLAGS += -version-info 12:0:11
+src_libfabric_la_LDFLAGS += -version-info 13:0:12
 endif
 src_libfabric_la_LDFLAGS += -export-dynamic \
 			   $(libfabric_version_script)
@@ -180,6 +183,7 @@ rdmainclude_HEADERS += \
 	$(top_srcdir)/include/rdma/fabric.h \
 	$(top_srcdir)/include/rdma/fi_atomic.h \
 	$(top_srcdir)/include/rdma/fi_cm.h \
+	$(top_srcdir)/include/rdma/fi_collective.h \
 	$(top_srcdir)/include/rdma/fi_domain.h \
 	$(top_srcdir)/include/rdma/fi_eq.h \
 	$(top_srcdir)/include/rdma/fi_rma.h \
@@ -400,7 +404,6 @@ include prov/rxm/Makefile.include
 include prov/mrail/Makefile.include
 include prov/rxd/Makefile.include
 include prov/bgq/Makefile.include
-include prov/mlx/Makefile.include
 include prov/shm/Makefile.include
 include prov/tcp/Makefile.include
 include prov/rstream/Makefile.include
diff --git a/NEWS.md b/NEWS.md
index c87126a..738eb97 100644
--- a/NEWS.md
+++ b/NEWS.md
@@ -5,6 +5,81 @@ This file contains the main features as well as overviews of specific
 bug fixes (and other actions) for each version of Libfabric since
 version 1.0.
 
+v1.9.0, Fri Nov 22, 2019
+========================
+
+## Core
+
+## EFA
+
+## GNI
+
+## MRail
+
+## PSM2
+
+## RxD
+
+## RxM
+
+## SHM
+
+## TCP
+
+## Verbs
+
+
+v1.8.1, Mon Sep 30, 2019
+========================
+
+## Core
+
+- Limit default size of memory registration cache
+- Verify that correct entry is removed from MR cache
+
+## EFA
+
+- Fixes to fi_cancel() when used with multi-recv buffers
+- Fixes to registered memory handling after a fork()
+- Fixes to the long message flow-control protocol
+- Use FI_AV_TABLE as the preferred AV type
+- Fixes to the bufpool allocation handlers
+- Fixes to RTS handler
+- Fix to use correct arch detection preprocessor macro
+- Expose fid_nic information
+- Fix memory leaks
+
+## PSM2
+
+- Fix incorrect value of max_order_raw_size
+- Report page aligned max_msg_size
+- Always enable the lock accessed by the disconnection thread
+- Fix race condition with progress thread and FI_THREAD_DOMAIN
+- Avoid a potential deadlock in disconnection protocol
+
+## RxD
+- Fix default AV count with environment variable FI_OFI_RXD_MAX_PEERS
+
+## RxM
+
+- Fix connection handle shutdown/CQ processing race
+- Fix RMA ordering bits for FI_ATOMIC
+
+## SHM
+- Add correct reporting of FI_MR_BASIC
+- Add correct reporting and proper support of FI_DIRECTED_RECV
+
+## Verbs
+
+- Allow zero length memory registrations
+- Improve connection scale up by removing synchronous calls in fi_getinfo
+- Fix missing serialization to event channel during CM ID migration
+- Protect XRC EQ processing from EP API connect/accept calls
+- Fix XRC connection tag to EP return value in error case
+- return EAGAIN to user if an unhandled rdmacm event is received
+- handle IPv6 link local addresses correctly
+
+
 v1.8.0, Fri Jun 28, 2019
 ========================
 
diff --git a/configure.ac b/configure.ac
index 8d19361..e46fb02 100644
--- a/configure.ac
+++ b/configure.ac
@@ -6,7 +6,7 @@ dnl
 dnl Process this file with autoconf to produce a configure script.
 
 AC_PREREQ([2.60])
-AC_INIT([libfabric], [1.9.0a1], [ofiwg@lists.openfabrics.org])
+AC_INIT([libfabric], [1.9.0rc1], [ofiwg@lists.openfabrics.org])
 AC_CONFIG_SRCDIR([src/fabric.c])
 AC_CONFIG_AUX_DIR(config)
 AC_CONFIG_MACRO_DIR(config)
@@ -464,7 +464,6 @@ FI_PROVIDER_SETUP([efa])
 dnl The usnic provider must be setup after the verbs provider.  See
 dnl prov/usnic/configure.m4 for details.
 FI_PROVIDER_SETUP([usnic])
-FI_PROVIDER_SETUP([mlx])
 FI_PROVIDER_SETUP([gni])
 FI_PROVIDER_SETUP([udp])
 FI_PROVIDER_SETUP([tcp])
diff --git a/contrib/cray/Jenkinsfile.verbs b/contrib/cray/Jenkinsfile.verbs
index 7ace8f1..3e0b1c7 100644
--- a/contrib/cray/Jenkinsfile.verbs
+++ b/contrib/cray/Jenkinsfile.verbs
@@ -30,7 +30,7 @@ pipeline {
             steps {
                 // creating git short hash
                 script {
-                    GIT_SHORT_COMMIT = sh(returnStdout: true, script: "git log -n 1 --pretty=format:'%h'").trim()
+                    GIT_DESCRIPTION = sh(returnStdout: true, script: "git describe --tags").trim()
                     LIBFABRIC_INSTALL = pwd tmp: true
                 }
 
@@ -67,7 +67,7 @@ pipeline {
                 LIBFABRIC_INSTALL_PATH = "$LIBFABRIC_INSTALL"
                 SFT_BIN = "${SFT_INSTALL_PATH + '/bin'}"
                 SFT_MAX_JOB_TIME = '3'
-                SFT_NUM_JOBS = '4'
+                SFT_NUM_JOBS = '6'
                 SFT_PROVIDER = 'verbs;ofi_rxm'
                 SFT_BASELINE_DIR = "contrib/cray"
                 SFT_BASELINE_RESULTS_FILE = 'sft_test_results_baseline.txt'
@@ -325,7 +325,7 @@ pipeline {
                 }
             }
             environment {
-                LIBFABRIC_INSTALL_PATH="${LIBFABRIC_BUILD_PATH + '/' + GIT_SHORT_COMMIT}"
+                LIBFABRIC_INSTALL_PATH="${LIBFABRIC_BUILD_PATH + '/' + GIT_DESCRIPTION}"
             }
             steps {
                 sh './autogen.sh'
@@ -360,7 +360,7 @@ pipeline {
                     steps {
                         dir (env.TAG_DIRECTORY) {
                             sh "rm -f nightly || true"
-                            sh "ln -s ../$GIT_SHORT_COMMIT nightly"
+                            sh "ln -s ../$GIT_DESCRIPTION nightly"
                         }
                     }
                 }
@@ -371,7 +371,7 @@ pipeline {
                     steps {
                         dir (env.TAG_DIRECTORY) {
                             sh "rm -f $BRANCH_NAME || true"
-                            sh "ln -s ../$GIT_SHORT_COMMIT $BRANCH_NAME"
+                            sh "ln -s ../$GIT_DESCRIPTION $BRANCH_NAME"
                         }
                     }
                 }
@@ -409,7 +409,7 @@ pipeline {
         FABTEST_PATH = "${WORKSPACE + '/installs/fabtests'}"
         LIBFABRIC_BUILD_PATH = "${ROOT_BUILD_PATH + '/libfabric'}"
         OMB_BUILD_PATH = "${ROOT_BUILD_PATH + '/osu-micro-benchmarks/5.4.2/libexec/osu-micro-benchmarks/mpi'}"
-        MPICH_PATH = "${ROOT_BUILD_PATH + '/mpich/3.3b3'}"
+        MPICH_PATH = "${ROOT_BUILD_PATH + '/mpich/3.3'}"
         SFT_INSTALL_PATH = "${ROOT_BUILD_PATH + '/libfabric-sft/stable'}"
         BATS_INSTALL_PATH = "${ROOT_BUILD_PATH + '/bats/stable/bin'}"
     }
diff --git a/contrib/cray/python/parse_results.py b/contrib/cray/python/parse_results.py
index f83a812..d24ac1a 100755
--- a/contrib/cray/python/parse_results.py
+++ b/contrib/cray/python/parse_results.py
@@ -86,6 +86,8 @@ def fabtests_testcase_parser(log, classname_prefix):
                 result = 'pass'
             elif data[1] == 'Notrun':
                 result = 'skip'
+            elif data[1] == 'Excluded':
+                result = 'skip'
             else:
                 result = 'fail'
         elif line.startswith('  time:'):
diff --git a/contrib/intel/jenkins/Jenkinsfile b/contrib/intel/jenkins/Jenkinsfile
new file mode 100644
index 0000000..ecacc8b
--- /dev/null
+++ b/contrib/intel/jenkins/Jenkinsfile
@@ -0,0 +1,252 @@
+
+pipeline {
+    agent any
+    options {timestamps()}
+    /*triggers {
+        pollSCM('H/2 * * * *')
+    } */
+    stages {
+        stage ('fetch-opa-psm2')  {
+             steps {
+                 withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin']) { 
+                     dir('opa-psm2-lib') {
+
+                        checkout changelog: false, poll: false, scm: [$class: 'GitSCM', \
+                        branches: [[name: '*/master']], \
+                        doGenerateSubmoduleConfigurations: false, extensions: [], submoduleCfg: [], \
+                        userRemoteConfigs: [[url: 'https://github.com/intel/opa-psm2.git']]]                        
+                      }
+                 }
+             }
+        }
+        
+        stage ('build-libfabric') {
+            steps {
+                withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin']) { 
+                sh """
+                  python3.7 contrib/intel/jenkins/build.py 'libfabric'
+                  python3.7 contrib/intel/jenkins/build.py 'libfabric' --ofi_build_mode='dbg'
+                  python3.7 contrib/intel/jenkins/build.py 'libfabric' --ofi_build_mode='dl'
+                  echo "libfabric build completed"  
+                 """
+                }
+            }
+        }
+        stage('build-fabtests') {
+            steps {
+                withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin']) { 
+                sh """
+                python3.7 contrib/intel/jenkins/build.py 'fabtests'
+                python3.7 contrib/intel/jenkins/build.py 'fabtests' --ofi_build_mode='dbg'
+                python3.7 contrib/intel/jenkins/build.py 'fabtests' --ofi_build_mode='dl'              
+                echo 'fabtests build completed' 
+                """
+                }
+            }
+        }
+        
+        stage ('build-shmem') {
+            steps {
+              withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin']) {
+                sh """
+                python3.7  contrib/intel/jenkins/build.py 'shmem'
+                echo 'shmem benchmarks built successfully'
+                """
+                }
+              }
+          }
+  
+        stage ('build OMPI_bm') {
+              steps {
+              withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin']) {
+                  sh """
+                  python3.7 contrib/intel/jenkins/build.py 'ompi_benchmarks' 
+                  python3.7 contrib/intel/jenkins/build.py 'ompi_benchmarks' --ofi_build_mode='dbg' 
+                  python3.7 contrib/intel/jenkins/build.py 'ompi_benchmarks' --ofi_build_mode='dl'
+                  echo 'mpi benchmarks with ompi - built successfully'
+                 """
+                }
+              }
+          }
+    
+    stage('build IMPI_bm') {
+        steps {
+          withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin']) {
+                sh """
+                python3.7 contrib/intel/jenkins/build.py 'impi_benchmarks'
+                python3.7 contrib/intel/jenkins/build.py 'impi_benchmarks' --ofi_build_mode='dbg'
+                python3.7 contrib/intel/jenkins/build.py 'impi_benchmarks' --ofi_build_mode='dl'
+                echo 'mpi benchmarks with impi - built successfully'
+                """
+            }
+          }
+      }  
+    
+    stage('build MPICH_bm') {
+        steps {
+          withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin']) {
+                sh """
+                python3.7 contrib/intel/jenkins/build.py 'mpich_benchmarks'
+                python3.7 contrib/intel/jenkins/build.py 'mpich_benchmarks' --ofi_build_mode='dbg'
+                python3.7 contrib/intel/jenkins/build.py 'mpich_benchmarks' --ofi_build_mode='dl'
+                echo "mpi benchmarks with mpich - built successfully"
+                """
+              }
+            }
+        }
+   stage('parallel-tests') {
+            parallel {
+                stage('eth-test') {
+                     agent {node {label 'eth'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin/:$PYTHONPATH'])
+                        {
+                          sh """
+                            env
+                            (
+                                cd  ${env.WORKSPACE}/contrib/intel/jenkins/ 
+                                python3.7 runtests.py --prov=tcp
+                                python3.7 runtests.py --prov=udp 
+                                python3.7 runtests.py --prov=sockets               
+                            )                              
+                          """
+                        }
+                     }
+                 }
+                 stage('hfi1-test') {
+                     agent {node {label 'hfi1'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin:$PYTHONPATH']) {
+                          sh """
+                            env
+                            (
+                                cd ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=psm2
+                                python3.7 runtests.py --prov=verbs                   
+                            )
+                          """
+                        } 
+                     }       
+       
+                 }
+                 stage('mlx5-test') {
+                     agent {node {label 'mlx5'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin:$PYTHONPATH']) {
+                          sh """
+                            env
+                            (                            
+                                cd ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=verbs                   
+                            )  
+                          """
+                        } 
+                     }       
+       
+                 }
+                 stage('eth-test-dbg') {
+                     agent {node {label 'eth'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin/:$PYTHONPATH'])
+                        {
+                          sh """
+                            env
+                            ( 
+                                cd  ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=tcp --ofi_build_mode='dbg'
+                                python3.7 runtests.py --prov=udp --ofi_build_mode='dbg'
+                                python3.7 runtests.py --prov=sockets --ofi_build_mode='dbg'               
+                            )  
+                          """
+                        } 
+                     }       
+       
+                 }
+                 stage('hfi1-test-dbg') {
+                     agent {node {label 'hfi1'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin:$PYTHONPATH']) {
+                          sh """
+                            env 
+                            (
+                                cd ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=psm2 --ofi_build_mode='dbg'
+                                python3.7 runtests.py --prov=verbs --ofi_build_mode='dbg'                   
+                            ) 
+                         """
+                        } 
+                     }       
+       
+                 }
+                 stage('mlx5-test-dbg') {
+                     agent {node {label 'mlx5'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin:$PYTHONPATH']) {
+                          sh """
+                            env
+                            (
+                                cd ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=verbs --ofi_build_mode='dbg'                   
+                            ) 
+                          """
+                        } 
+                     }       
+       
+                 }
+                 stage('eth-test-dl') {
+                     agent {node {label 'eth'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin/:$PYTHONPATH'])
+                        {
+                          sh """
+                            env
+                            (
+                                cd  ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=tcp --ofi_build_mode='dl'
+                                python3.7 runtests.py --prov=udp --ofi_build_mode='dl'
+                                python3.7 runtests.py --prov=sockets --ofi_build_mode='dl'               
+                            )  
+                        """
+                        } 
+                     }       
+       
+                 }
+                 
+                 stage('hfi1-test-dl') {
+                     agent {node {label 'hfi1'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin:$PYTHONPATH']) {
+                          sh """
+                            env
+                            ( 
+                                cd ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=psm2 --ofi_build_mode='dl'
+                                python3.7 runtests.py --prov=verbs --ofi_build_mode='dl'                   
+                            ) 
+                         """
+                        } 
+                     }       
+       
+                 }
+                 
+                 stage('mlx5-test-dl') {
+                     agent {node {label 'mlx5'}}
+                     steps{
+                        withEnv(['PATH+EXTRA=/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/bin:$PYTHONPATH']) {
+                          sh """
+                            env
+                            (                           
+                                cd ${env.WORKSPACE}/contrib/intel/jenkins/
+                                python3.7 runtests.py --prov=verbs --ofi_build_mode='dl'                   
+                            )  
+                         """
+                        } 
+                     }       
+       
+                 }   
+    
+            } 
+   }        
+
+  }
+}
diff --git a/contrib/intel/jenkins/build.py b/contrib/intel/jenkins/build.py
new file mode 100755
index 0000000..dbd902e
--- /dev/null
+++ b/contrib/intel/jenkins/build.py
@@ -0,0 +1,190 @@
+import os
+import sys
+
+# add jenkins config location to PATH 
+sys.path.append(os.environ['CI_SITE_CONFIG'])
+
+import ci_site_config
+import argparse
+import subprocess
+import shlex
+import common
+import re
+
+def build_libfabric(libfab_install_path, mode):
+
+        if (os.path.exists(libfab_install_path) != True):
+            os.makedirs(libfab_install_path)  
+
+        config_cmd = ['./configure', '--prefix={}'.format(libfab_install_path)]
+        enable_prov_val = 'yes'
+
+        if (mode == 'dbg'):
+            config_cmd.append('--enable-debug')                     
+        elif (mode == 'dl'):
+            enable_prov_val='dl'
+                   
+        for prov in common.enabled_prov_list:
+            config_cmd.append('--enable-{}={}'.format(prov, enable_prov_val))
+        for prov in common.disabled_prov_list:
+             config_cmd.append('--enable-{}=no'.format(prov))
+       
+        config_cmd.append('--with-psm2-src={}/opa-psm2-lib'.format(workspace))   
+  
+           
+        common.run_command(['./autogen.sh'])
+        common.run_command(shlex.split(" ".join(config_cmd)))
+        common.run_command(['make','clean'])
+        common.run_command(['make'])
+        common.run_command(['make','install'])
+
+
+def build_fabtests(libfab_install_path, mode):
+       
+    os.chdir('{}/fabtests'.format(workspace))
+    if (mode == 'dbg'):   
+        config_cmd = ['./configure', '--enable-debug', '--prefix={}' \
+                      .format(libfab_install_path),'--with-libfabric={}' \
+                      .format(libfab_install_path)] 
+    else:
+        config_cmd = ['./configure', '--prefix={}'.format(libfab_install_path),
+                '--with-libfabric={}'.format(libfab_install_path)]
+
+
+    common.run_command(['./autogen.sh'])
+    common.run_command(config_cmd)
+    common.run_command(['make','clean'])
+    common.run_command(['make'])
+    common.run_command(['make', 'install'])
+
+
+def build_mpi(mpi, mpisrc, mpi_install_path, libfab_install_path,  ofi_build_mode):
+   
+    build_mpi_path ="/mpibuilddir/{}-build-dir/{}/{}/{}".format(mpi, branchname, buildno, ofi_build_mode)
+    if (os.path.exists(build_mpi_path) == False):
+        os.makedirs(build_mpi_path)
+
+    os.chdir(build_mpi_path)
+    cmd = ["{}/configure".format(mpisrc),
+                    "--disable-oshmem", "--prefix={}".format(mpi_install_path),
+                    "--with-libfabric={}".format(libfab_install_path)]
+
+    if (mpi == 'ompi'):
+        cmd.append("--enable-mpi-fortran=no")
+    elif (mpi == 'mpich'):
+        cmd.append("--enable-fortran=no")
+
+        
+    configure_cmd = shlex.split(" ".join(cmd))
+    common.run_command(configure_cmd)
+    common.run_command(["make", "clean"])
+    common.run_command(["make", "install", "-j32"])
+
+
+def build_stress_bm(mpi, mpi_install_path, libfab_install_path):
+    
+    stress_install_path = "{}/stress".format(mpi_install_path)
+    if (os.path.exists(stress_install_path) == False):
+        os.makedirs(stress_install_path)
+     
+    if (mpi == 'impi'):
+        os.environ['LD_LIBRARY_PATH'] = "{}/lib".format(libfab_install_path)
+        mpicc_path = "{}/intel64/bin/mpicc".format(ci_site_config.impi_root) 
+    else:
+        os.environ['LD_LIBRARY_PATH'] = ""
+        mpicc_path = "{}/bin/mpicc".format(mpi_install_path)
+
+    cmd=" ".join([mpicc_path, '-lz', "{}/mpi_stress/mpi_stress.c" \
+                 .format(ci_site_config.benchmarks['wfr-mpi-tests']),\
+                  '-o', "{}/mpi_stress".format(stress_install_path)])
+
+    runcmd = shlex.split(cmd)
+    common.run_command(runcmd)
+ 
+
+def build_osu_bm(mpi, mpi_install_path, libfab_install_path):
+    
+    osu_install_path = "{}/osu".format(mpi_install_path)
+    if (os.path.exists(osu_install_path) == False):
+        os.makedirs(osu_install_path)
+    os.chdir(osu_install_path)
+    
+    if (mpi == 'impi'):
+        os.environ['CC']="{}/intel64/bin/mpicc".format(ci_site_config.impi_root)
+        os.environ['CXX']="{}/intel64/bin/mpicxx".format(ci_site_config.impi_root)
+        os.environ['LD_LIBRARY_PATH'] = "{}/lib".format(libfab_install_path)
+
+    else: 
+        os.environ['CC']="{}/bin/mpicc".format(mpi_install_path)
+        os.environ['CXX']="{}/bin/mpicxx".format(mpi_install_path)
+        os.environ['LD_LIBRARY_PATH']=""
+
+    
+    os.environ['CFLAGS']="-I{}/util/".format(ci_site_config.benchmarks['osu'])
+    cmd = " ".join(["{}/configure".format(ci_site_config.benchmarks['osu']),
+                    "--prefix={}".format(osu_install_path)])
+   
+    configure_cmd = shlex.split(cmd) 
+    
+    common.run_command(configure_cmd)
+    common.run_command(["make", "-j4"])
+    common.run_command(["make", "install"])
+
+
+if __name__ == "__main__":
+#read environment variables
+    branchname = os.environ['BRANCH_NAME']
+    buildno = os.environ['BUILD_NUMBER']
+    workspace = os.environ['WORKSPACE']
+
+
+
+    parser = argparse.ArgumentParser()
+    parser.add_argument("build_item", help="build libfabric or fabtests",
+                         choices=['libfabric','fabtests', 'impi_benchmarks', \
+                        'ompi_benchmarks', 'mpich_benchmarks', 'shmem'])
+    parser.add_argument("--ofi_build_mode", help="select buildmode debug or dl", \
+                        choices=['dbg','dl'])
+
+    args = parser.parse_args()
+    build_item = args.build_item
+
+    if (args.ofi_build_mode):
+        ofi_build_mode = args.ofi_build_mode
+    else:
+        ofi_build_mode = 'reg'
+
+
+
+    install_path = "{installdir}/{brname}/{bno}/{bmode}" \
+                     .format(installdir=ci_site_config.install_dir,
+                            brname=branchname, bno=buildno,bmode=ofi_build_mode)
+
+    p = re.compile('mpi*')
+
+    if (build_item == 'libfabric'):
+        build_libfabric(install_path, ofi_build_mode)
+
+    elif (build_item == 'fabtests'):
+        build_fabtests(install_path, ofi_build_mode)
+   #if the build_item contains the string 'mpi'   
+    elif (p.search(build_item)):
+        mpi = build_item[:-11] #extract the mpitype from '*mpi*_benchmarks' build_item
+        mpi_install_path = "{}/{}".format(install_path, mpi) 
+    
+        if (os.path.exists(mpi_install_path) == False):
+            os.makedirs(mpi_install_path) 
+        if (mpi != 'impi'):
+            mpisrc = ci_site_config.mpich_src if mpi == 'mpich' \
+                     else ci_site_config.ompi_src
+            # only need to build ompi or mpich, impi is available as binary
+            build_mpi(mpi, mpisrc, mpi_install_path, install_path, ofi_build_mode)
+                           
+        # run stress and osu benchmarks for all mpitypes
+        build_stress_bm(mpi, mpi_install_path, install_path)
+        build_osu_bm(mpi, mpi_install_path, install_path)
+    else:
+        pass
+        #todo: build-shmem here
+
+
diff --git a/contrib/intel/jenkins/common.py b/contrib/intel/jenkins/common.py
new file mode 100755
index 0000000..2d45da8
--- /dev/null
+++ b/contrib/intel/jenkins/common.py
@@ -0,0 +1,57 @@
+import collections
+import ci_site_config
+import subprocess
+import sys
+
+def get_node_name(host, interface):
+   # This is the pattern we follow in SFS team cluster
+   return "%s-%s" % (host, interface)
+
+def run_command(command):
+    print(command)
+    p = subprocess.Popen(command, stdout=subprocess.PIPE, text=True)
+    print(p.returncode)
+    while True:
+        out = p.stdout.read(1)
+        if (out == "" and p.poll() != None):
+            break
+        if (out != ""):
+            sys.stdout.write(out)
+            sys.stdout.flush()
+    if (p.returncode != 0):
+        print("exiting with " + str(p.poll()))
+        sys.exit(p.returncode)
+
+
+Prov = collections.namedtuple('Prov', 'core util')
+prov_list = [
+
+   Prov("psm2", None),
+   Prov("verbs", None),
+   Prov("verbs", "rxd"),
+   Prov("verbs", "rxm"),
+   Prov("sockets", None),
+   Prov("tcp", None),
+   Prov("udp", None),
+   Prov("udp", "rxd"),
+   Prov("shm", None),
+]
+enabled_prov_list = [
+    "psm2",
+    "verbs",
+    "tcp",
+    "sockets",
+    "udp",
+    "shm"
+]
+disabled_prov_list = [
+    'usnic',
+    'psm',
+    'efa',
+    'perf',
+    'rstream',
+    'hook_debug',
+    'bgq'
+    'mrail'
+]
+     
diff --git a/contrib/intel/jenkins/run.py b/contrib/intel/jenkins/run.py
new file mode 100755
index 0000000..b4de450
--- /dev/null
+++ b/contrib/intel/jenkins/run.py
@@ -0,0 +1,91 @@
+import tests
+import subprocess
+import sys
+import argparse
+import os
+import common
+
+sys.path.append(os.environ['CI_SITE_CONFIG'])
+import ci_site_config
+
+fab = os.environ['FABRIC']#args.fabric
+brname = os.environ['BRANCH_NAME']#args.branchname
+bno = os.environ['BUILD_NUMBER']#args.buildno
+
+
+#run fi_info test
+def fi_info_test(core, hosts, mode,util=None):
+    
+    fi_info_test = tests.FiInfoTest(branchname=brname,buildno=bno,\
+                    testname="fi_info", core_prov=core, fabric=fab,\
+                         hosts=hosts, ofi_build_mode=mode, util_prov=util)
+    print("running fi_info test for {}-{}-{}".format(core, util, fab))
+    fi_info_test.execute_cmd()
+        
+
+#runfabtests
+def fabtests(core, hosts, mode, util=None):
+       
+       runfabtest = tests.Fabtest(branchname=brname,buildno=bno,\
+                    testname="runfabtests", core_prov=core, fabric=fab,\
+                         hosts=hosts, ofi_build_mode=mode, util_prov=util)
+
+       if (runfabtest.execute_condn):
+            print("running fabtests for {}-{}-{}".format(core, util, fab))
+            runfabtest.execute_cmd()
+       else:
+            print("skipping {} as execute condition fails"\
+                  .format(runfabtest.testname))
+       print("----------------------------------------------------------------------------------------\n")
+    
+
+#imb-tests
+def intel_mpi_benchmark(core, hosts, mpi, mode, util=None):
+
+    imb_test = tests.MpiTestIMB(branchname=brname,buildno=bno,\
+               testname="IntelMPIbenchmark",core_prov=core, fabric=fab,\
+               hosts=hosts, mpitype=mpi, ofi_build_mode=mode, util_prov=util)
+    
+    if (imb_test.execute_condn == True  and imb_test.mpi_gen_execute_condn == True):
+        print("running imb-test for {}-{}-{}-{}".format(core, util, fab, mpi))
+        imb_test.execute_cmd()
+    else:
+        print("skipping {} as execute condition fails"\
+                    .format(imb_test.testname))
+    print("----------------------------------------------------------------------------------------\n")
+    
+#mpi_stress benchmark tests
+def mpistress_benchmark(core, hosts, mpi, mode, util=None):
+
+    stress_test = tests.MpiTestStress(branchname=brname,buildno=bno,\
+                  testname="stress",core_prov=core, fabric=fab, mpitype=mpi,\
+                  hosts=hosts, ofi_build_mode=mode, util_prov=util)
+ 
+    if (stress_test.execute_condn == True and stress_test.mpi_gen_execute_condn == True):
+        print("running mpistress-test for {}-{}-{}-{}".format(core, util, fab, mpi))
+        stress_test.execute_cmd()
+    else:
+        print("skipping {} as execute condition fails" \
+                    .format(stress_test.testname))
+    print("----------------------------------------------------------------------------------------\n")
+
+#osu benchmark tests    
+def osu_benchmark(core, hosts, mpi, mode, util=None):
+
+    osu_test = tests.MpiTestOSU(branchname=brname, buildno=bno, \
+               testname="osu-benchmarks",core_prov=core, fabric=fab, mpitype=mpi, \
+               hosts=hosts, ofi_build_mode=mode, util_prov=util)
+    
+    if (osu_test.execute_condn == True and osu_test.mpi_gen_execute_condn == True):
+        print("running osu-test for {}-{}-{}-{}".format(core, util, fab, mpi))
+        osu_test.execute_cmd()
+    else:
+        print("skipping {} as execute condition fails" \
+                .format(osu_test.testname))
+    print("----------------------------------------------------------------------------------------\n")
+
+
+if __name__ == "__main__":
+    pass
+
+
diff --git a/contrib/intel/jenkins/runtests.py b/contrib/intel/jenkins/runtests.py
new file mode 100755
index 0000000..edd0351
--- /dev/null
+++ b/contrib/intel/jenkins/runtests.py
@@ -0,0 +1,62 @@
+import argparse
+import os
+import sys
+sys.path.append(os.environ['CI_SITE_CONFIG'])
+import ci_site_config
+import run
+import common
+
+parser = argparse.ArgumentParser()
+parser.add_argument("--prov", help="core provider", choices=["psm2", "verbs", \
+                     "tcp", "udp", "sockets", "shm"])
+parser.add_argument("--ofi_build_mode", help="specify the build configuration", \
+                     choices = ["dbg", "dl"])
+
+args = parser.parse_args()
+args_prov = args.prov
+
+
+if (args.ofi_build_mode):
+    ofi_build_mode = args.ofi_build_mode
+else:
+    ofi_build_mode='reg'
+
+node = (os.environ['NODE_NAME']).split('-')[0]
+hosts = [node]
+mpilist = ['impi', 'mpich', 'ompi']
+
+#this script is executed from /tmp
+#this is done since some mpi tests
+#look for a valid location before running
+# the test on the secondary host(client)
+# but jenkins only creates a valid path on 
+# the primary host (server/test node)
+
+os.chdir('/tmp/')
+
+if(args_prov):
+    for host in ci_site_config.node_map[node]:
+        hosts.append(host)
+
+    for prov in common.prov_list:
+        if (prov.core == args_prov):
+            if (prov.util == None):
+                run.fi_info_test(prov.core, hosts, ofi_build_mode)
+                run.fabtests(prov.core, hosts, ofi_build_mode)
+                for mpi in mpilist:
+                    run.intel_mpi_benchmark(prov.core, hosts, mpi, ofi_build_mode)   
+                    run.mpistress_benchmark(prov.core, hosts, mpi, ofi_build_mode)
+                    run.osu_benchmark(prov.core, hosts, mpi, ofi_build_mode)  
+            else:
+                run.fi_info_test(prov.core, hosts, ofi_build_mode, util=prov.util)
+                run.fabtests(prov.core, hosts, ofi_build_mode, util=prov.util)
+                for mpi in mpilist:
+                    run.intel_mpi_benchmark(prov.core, hosts, mpi, ofi_build_mode, \
+                                           util=prov.util,)
+                    run.mpistress_benchmark(prov.core, hosts, mpi, ofi_build_mode, \
+                                            util=prov.util)
+                    run.osu_benchmark(prov.core, hosts, mpi, ofi_build_mode, \
+                                             util=prov.util)
+else:
+    print("Error : Specify a core provider to run tests")
+    
diff --git a/contrib/intel/jenkins/tests.py b/contrib/intel/jenkins/tests.py
new file mode 100755
index 0000000..354710d
--- /dev/null
+++ b/contrib/intel/jenkins/tests.py
@@ -0,0 +1,347 @@
+import sys
+import os
+
+print(os.environ['CI_SITE_CONFIG'])
+sys.path.append(os.environ['CI_SITE_CONFIG']) # for adding path for ci_site_config
+
+import subprocess
+import re
+import ci_site_config
+import common
+import shlex
+
+class Test:
+    def __init__ (self, branchname, buildno, testname, core_prov, fabric,
+                  hosts, ofi_build_mode, util_prov=None):
+        self.branchname = branchname
+        self.buildno = buildno
+        self.testname = testname
+        self.core_prov = core_prov
+        self.util_prov = "ofi_{}".format(util_prov) if util_prov != None else "" 
+        self.fabric = fabric
+        self.hosts = hosts
+        self.ofi_build_mode = ofi_build_mode
+        if (len(hosts) == 2):
+            self.server = hosts[0]
+            self.client = hosts[1]
+       
+        self.nw_interface = ci_site_config.interface_map[self.fabric]
+        self.libfab_installpath = "{}/{}/{}/{}".format(ci_site_config.install_dir,
+                                  self.branchname, self.buildno, self.ofi_build_mode)
+ 
+        self.env = [("FI_VERBS_MR_CACHE_ENABLE", "1"),\
+                    ("FI_VERBS_INLINE_SIZE", "256")] \
+                    if self.core_prov == "verbs" else []
+class FiInfoTest(Test):
+    def __init__(self, branchname, buildno, testname, core_prov, fabric,
+                 hosts, ofi_build_mode, util_prov=None):
+
+        super().__init__(branchname, buildno, testname, core_prov, fabric,
+                     hosts, ofi_build_mode, util_prov)
+     
+        self.fi_info_testpath =  "{}/bin".format(self.libfab_installpath) 
+     
+    @property
+    def cmd(self):
+        return "{}/fi_info ".format(self.fi_info_testpath)
+
+    @property
+    def options(self):       
+        if (self.util_prov):
+            opts  = "-f -p {};{}".format(self.core_prov, self.util_prov)
+        else:
+            opts = "-f -p {}".format(self.core_prov)
+        
+        return opts 
+    
+    def execute_cmd(self):
+        command = self.cmd + self.options
+        outputcmd = shlex.split(command)
+        common.run_command(outputcmd)         
+     
+
+class Fabtest(Test):
+    
+    def __init__(self, branchname, buildno, testname, core_prov, fabric,
+                 hosts, ofi_build_mode, util_prov=None):
+        
+        super().__init__(branchname, buildno, testname, core_prov, fabric,
+                         hosts, ofi_build_mode, util_prov)
+        self.fabtestpath = "{}/bin".format(self.libfab_installpath) 
+        self.fabtestconfigpath = "{}/share/fabtests".format(self.libfab_installpath)
+    def get_exclude_file(self):
+        path = self.libfab_installpath
+        efile_path = "{}/share/fabtests/test_configs".format(path)
+
+        prov = self.util_prov if self.util_prov else self.core_prov
+        efile_old = "{path}/{prov}/{prov}.exclude".format(path=efile_path, 
+                      prov=prov)
+        
+        if self.util_prov:
+            efile = "{path}/{util_prov}/{core_prov}/exclude".format(path=efile_path,
+                      util_prov=self.util_prov, core_prov=self.core_prov)
+        else:
+            efile = "{path}/{prov}/exclude".format(path=efile_path,
+                      prov=self.core_prov)
+           
+        if os.path.isfile(efile):
+            return efile
+        elif os.path.isfile(efile_old):
+            return efile_old
+        else:
+            print("Exclude file: {} not found!".format(efile))
+            return None  
+
+    @property    
+    def cmd(self):    
+        return "{}/runfabtests.sh ".format(self.fabtestpath)
+     
+    @property
+    def options(self):
+        opts = "-T 300 -vvv -p {} -S ".format(self.fabtestpath)
+        if (self.core_prov == "verbs" and self.nw_interface):
+            opts = "{} -s {} ".format(opts, common.get_node_name(self.server, 
+                    self.nw_interface)) # include common.py
+            opts = "{} -c {} ".format(opts, common.get_node_name(self.client, 
+                    self.nw_interface)) # from common.py
+       
+        if (self.core_prov == "shm"):
+            opts = "{} -s {} ".format(opts, self.server)
+            opts = "{} -c {} ".format(opts, self.client)
+            opts += "-N "
+            
+        if not re.match(".*sockets|udp|tcp.*", self.core_prov):
+            opts = "{} -t all ".format(opts)
+
+        efile = self.get_exclude_file()
+        if efile:
+            opts = "{} -R ".format(opts)
+            opts = "{} -f {} ".format(opts, efile)  
+        
+        for key,val in self.env:
+            opts = "{options} -E {key}={value} ".format(options = opts, 
+                    key=key, value=val)
+    
+        if self.util_prov:
+            opts = "{options} {core};{util} ".format(options=opts, 
+                    core=self.core_prov, util=self.util_prov)
+        else:
+            opts = "{options} {core} ".format(options=opts,
+                    core=self.core_prov)
+        
+        if (self.core_prov == "shm"):
+            opts += "{} {} ".format(self.client, self.server)
+        else:
+            opts += "{} {} ".format(self.server, self.client)
+             
+        return opts
+   
+    @property
+    def execute_condn(self):
+        # fabtests works for shmem prov only for libfabric debug builds.
+        return True if (self.core_prov != 'shm' or \
+                        self.ofi_build_mode == 'dbg') else False
+
+    def execute_cmd(self):
+        curdir = os.getcwd()
+        os.chdir(self.fabtestconfigpath)
+        command = self.cmd + self.options
+        outputcmd = shlex.split(command)
+        common.run_command(outputcmd)
+        os.chdir(curdir) 
+
+class MpiTests(Test):
+    def __init__(self, branchname, buildno, testname, core_prov, fabric,
+                 mpitype, hosts, ofi_build_mode, util_prov=None):
+       
+        super().__init__(branchname, buildno, testname, core_prov, 
+                         fabric, hosts, ofi_build_mode, util_prov)
+        self.mpi = mpitype
+
+
+    @property
+    def cmd(self):
+        if (self.mpi == "impi" or self.mpi == "mpich"):
+            self.testpath = ci_site_config.mpi_testpath 
+            return "{}/run_{}.sh ".format(self.testpath,self.mpi)
+        elif(self.mpi =="ompi"):
+            self.testpath = "{}/ompi/bin".format(self.libfab_installpath)
+            return "{}/mpirun ".format(self.testpath)      
+    
+    @property
+    def options(self):
+        opts = [] 
+        if (self.mpi == "impi" or self.mpi == "mpich"):
+            opts = "-n {} -ppn {} -hosts {},{} ".format(self.n,self.ppn,
+                    self.server,self.client)
+                
+            if (self.mpi == "impi"):
+                opts = "{} -mpi_root={} ".format(opts, 
+                        ci_site_config.impi_root)
+            else:
+                opts = "{} -mpi_root={}/mpich".format(opts, 
+                        self.libfab_installpath)
+            
+            opts = "{} -libfabric_path={}/lib ".format(opts, 
+                    self.libfab_installpath)
+            
+            if self.util_prov:
+                opts = "{options} -prov {core};{util} ".format(options=opts, 
+                        core=self.core_prov, util=self.util_prov)
+            else:
+                opts = "{} -prov {} ".format(opts, self.core_prov)
+
+            for key, val in self.env:
+                opts = "{} -genv {} {} ".format(opts, key, val)
+            
+        elif (self.mpi == "ompi"):
+            opts = "-np {} ".format(self.n)
+            hosts = ",".join([":".join([host,str(self.ppn)]) \
+                    for host in self.hosts])
+            
+            opts = "{} --host {} ".format(opts, hosts)
+            
+            if self.util_prov:
+                opts = "{} --mca mtl_ofi_provider_include {};{} ".format(opts, 
+                        self.core_prov,self.util_prov)
+            else:
+                opts = "{} --mca mtl_ofi_provider_include {} ".format(opts, 
+                        self.core_prov)
+ 
+            opts += "--mca orte_base_help_aggregate 0 "
+            opts += "--mca mtl ofi --mca pml cm -tag-output "
+            for key,val in self.env:
+                opts = "{} -x {}={} ".format(opts,key,val)
+        return opts
+
+    @property
+    def mpi_gen_execute_condn(self):
+        #Skip MPI tests for udp, verbs(core) providers.
+        # we would still have MPI tests runnning for 
+        # verbs-rxd and verbs-rxm providers
+        return True if (self.core_prov != "udp" and \
+                        self.core_prov != "shm" and \
+                       (self.core_prov != "verbs" or \
+                       self.util_prov == "ofi_rxm" or \
+                       self.util_prov == "ofi_rxd")) else False
+
+class MpiTestIMB(MpiTests):
+
+    def __init__(self, branchname, buildno, testname, core_prov, fabric,
+                 mpitype, hosts, ofi_build_mode, util_prov=None):
+        super().__init__(branchname, buildno, testname, core_prov, fabric,
+                         mpitype, hosts, ofi_build_mode, util_prov)
+        self.additional_tests = [ 
+                                   "Biband",
+                                   "Uniband",
+                                   "PingPingAnySource",
+                                   "PingPingAnySource",
+                                   "PingPongSpecificSource",
+                                   "PingPongSpecificSource"
+        ]
+        self.n = 4
+        self.ppn = 2
+
+  
+    @property
+    def imb_cmd(self): 
+        return "{}/intel64/bin/IMB-MPI1 -include {}".format(ci_site_config.impi_root,
+                ','.join(self.additional_tests))
+    @property
+    def execute_condn(self):
+        return True if (self.mpi == "impi") else False
+        
+    def execute_cmd(self):
+        command = self.cmd + self.options + self.imb_cmd
+        outputcmd = shlex.split(command)
+        common.run_command(outputcmd) 
+
+        
+class MpiTestStress(MpiTests):
+     
+    def __init__(self, branchname, buildno, testname, core_prov, fabric, 
+                 mpitype, hosts, ofi_build_mode, util_prov=None):
+        super().__init__(branchname, buildno, testname, core_prov, fabric, 
+                         mpitype,  hosts, ofi_build_mode, util_prov)
+        
+         
+        if((self.core_prov == "verbs" or self.core_prov =="psm2")):
+            self.n = 16
+            self.ppn = 8
+        else:
+            self.n = 4
+            self.ppn = 2
+      
+    @property
+    def stress_cmd(self):
+        return "{}/{}/stress/mpi_stress -dcr".format(self.libfab_installpath, self.mpi)
+
+    @property
+    def execute_condn(self):
+        # Todo : run stress test for ompi with libfabirc-dbg builds if it works
+        # in Jenkins for buildbot these ompi did not build with libfabric-dbg 
+        return True if (self.mpi != 'ompi' or \
+                        self.ofi_build_mode != 'dbg') else  False
+    
+    def execute_cmd(self):
+        command = self.cmd + self.options + self.stress_cmd
+        outputcmd = shlex.split(command)
+        common.run_command(outputcmd) 
+
+         
+      
+class MpiTestOSU(MpiTests):
+
+    def __init__(self, branchname, buildno, testname, core_prov, fabric,
+                 mpitype, hosts, ofi_build_mode, util_prov=None):
+        super().__init__(branchname, buildno, testname, core_prov, fabric,
+                         mpitype, hosts, ofi_build_mode, util_prov)
+        
+        self.n = 4 
+        self.ppn = 2
+        self.two_proc_tests = {'osu_latency',
+                               'osu_bibw',
+                               'osu_latency_mt',
+                               'osu_bw','osu_get_latency',
+                               'osu_fop_latency',
+                               'osu_acc_latency',
+                               'osu_get_bw',
+                               'osu_put_latency',
+                               'osu_put_bw',
+                               'osu_put_bibw',
+                               'osu_cas_latency',
+                               'osu_get_acc_latency'
+                              }
+
+        self.osu_mpi_path = "{}/{}/osu/libexec/osu-micro-benchmarks/mpi/". \
+                            format(self.libfab_installpath,mpitype) 
+    
+    @property
+    def execute_condn(self): 
+        # sockets and psm2 have some issues with OSU benchmark testing.
+        return True if (self.mpi != "ompi" or \
+                       (self.core_prov != "sockets" and \
+                        self.core_prov != "psm2" and \
+                        self.ofi_build_mode!="dbg")) \
+                    else False
+    
+    def execute_cmd(self):
+        assert(self.osu_mpi_path)
+        p = re.compile('osu_put*')
+        for root, dirs, tests in os.walk(self.osu_mpi_path):
+            for test in tests:
+                if test in self.two_proc_tests:
+                    self.n=2
+                    self.ppn=1
+                else:
+                    self.n=4
+                    self.ppn=2
+                # for sockets provider skip 'osu_put' benchmark tests as they fail.
+                if(self.core_prov !='sockets' or p.search(test)== None):
+                    launcher = self.cmd + self.options
+                    osu_cmd = os.path.join(root, test)
+                    command = launcher + osu_cmd
+                    outputcmd = shlex.split(command)
+                    common.run_command(outputcmd) 
+
+
diff --git a/fabtests/Makefile.am b/fabtests/Makefile.am
index f8670cd..3593197 100644
--- a/fabtests/Makefile.am
+++ b/fabtests/Makefile.am
@@ -58,7 +58,8 @@ bin_PROGRAMS = \
 	unit/fi_getinfo_test \
 	unit/fi_resource_freeing \
 	ubertest/fi_ubertest	\
-	multinode/fi_multinode
+	multinode/fi_multinode	\
+	multinode/fi_multinode_coll
 
 dist_bin_SCRIPTS = \
 	scripts/runfabtests.sh \
@@ -83,17 +84,19 @@ nobase_dist_config_DATA = \
         test_configs/tcp/tcp.exclude \
         test_configs/verbs/all.test \
         test_configs/verbs/quick.test \
-	test_configs/verbs/exclude \
+	test_configs/verbs/verbs.exclude \
 	test_configs/usnic/all.test \
 	test_configs/usnic/quick.test \
 	test_configs/psm/all.test \
 	test_configs/psm2/all.test \
 	test_configs/psm2/verify.test \
 	test_configs/psm2/psm2.exclude \
-	test_configs/ofi_rxm/verbs/all.test \
-	test_configs/ofi_rxm/verbs/exclude \
-	test_configs/ofi_rxd/ofi_rxd.exclude \
+	test_configs/ofi_rxm/tcp.test \
+	test_configs/ofi_rxm/verbs.test \
+	test_configs/ofi_rxm/ofi_rxm.exclude \
 	test_configs/ofi_rxd/udp.test \
+	test_configs/ofi_rxd/verbs.test \
+	test_configs/ofi_rxd/ofi_rxd.exclude \
 	test_configs/shm/all.test \
 	test_configs/shm/shm.exclude \
 	test_configs/shm/quick.test \
@@ -341,7 +344,7 @@ ubertest_fi_ubertest_LDADD = libfabtests.la
 
 multinode_fi_multinode_SOURCES = \
 	multinode/src/harness.c \
-	multinode/src/pattern/full_mesh.c \
+	multinode/src/pattern.c \
 	multinode/include/pattern.h \
 	multinode/src/core.c \
 	multinode/include/core.h
@@ -352,6 +355,18 @@ multinode_fi_multinode_CFLAGS = \
 	$(AM_CFLAGS) \
 	-I$(srcdir)/multinode/include
 
+multinode_fi_multinode_coll_SOURCES = \
+	multinode/src/harness.c \
+	multinode/src/core_coll.c \
+	multinode/include/coll_test.h \
+	multinode/include/core.h
+
+multinode_fi_multinode_coll_LDADD = 	libfabtests.la
+
+multinode_fi_multinode_coll_CFLAGS = \
+	$(AM_CFLAGS) \
+	-I$(srcdir)/multinode/include
+
 real_man_pages = \
 	 man/man7/fabtests.7
 
diff --git a/fabtests/benchmarks/dgram_pingpong.c b/fabtests/benchmarks/dgram_pingpong.c
index bb18adf..4daba11 100644
--- a/fabtests/benchmarks/dgram_pingpong.c
+++ b/fabtests/benchmarks/dgram_pingpong.c
@@ -59,11 +59,7 @@ static int run(void)
 		for (i = 0; i < TEST_CNT; i++) {
 			if (!ft_use_size(i, opts.sizes_enabled))
 				continue;
-
 			opts.transfer_size = test_size[i].size;
-			if (opts.transfer_size > fi->ep_attr->max_msg_size)
-				continue;
-
 			init_test(&opts, test_name, sizeof(test_name));
 			ret = pingpong();
 			if (ret)
diff --git a/fabtests/common/shared.c b/fabtests/common/shared.c
index 44304ab..135ff5f 100644
--- a/fabtests/common/shared.c
+++ b/fabtests/common/shared.c
@@ -46,6 +46,7 @@
 #include <rdma/fi_rma.h>
 #include <rdma/fi_tagged.h>
 #include <rdma/fi_atomic.h>
+#include <rdma/fi_collective.h>
 
 #include <shared.h>
 
@@ -426,7 +427,7 @@ static int ft_alloc_msgs(void)
 	} else {
 		ft_set_tx_rx_sizes(&tx_size, &rx_size);
 		tx_mr_size = 0;
-		rx_mr_size = 0;		
+		rx_mr_size = 0;
 		buf_size = MAX(tx_size, FT_MAX_CTRL_MSG) + MAX(rx_size, FT_MAX_CTRL_MSG);
 	}
 
@@ -995,7 +996,8 @@ int ft_enable_ep(struct fid_ep *ep, struct fid_eq *eq, struct fid_av *av,
 	uint64_t flags;
 	int ret;
 
-	if (fi->ep_attr->type == FI_EP_MSG || fi->caps & FI_MULTICAST)
+	if (fi->ep_attr->type == FI_EP_MSG || fi->caps & FI_MULTICAST ||
+	    fi->caps & FI_COLLECTIVE)
 		FT_EP_BIND(ep, eq, 0);
 
 	FT_EP_BIND(ep, av, 0);
@@ -1143,7 +1145,7 @@ int ft_exchange_addresses_oob(struct fid_av *av_ptr, struct fid_ep *ep_ptr,
 
 	ret = ft_av_insert(av_ptr, buf, 1, remote_addr, 0, NULL);
 	if (ret)
-		return ret;	
+		return ret;
 
 	return 0;
 }
@@ -1855,7 +1857,7 @@ ssize_t ft_post_rma_inject(enum ft_rma_opcodes op, struct fid_ep *ep, size_t siz
 	switch (op) {
 	case FT_RMA_WRITE:
 		FT_POST(fi_inject_write, ft_progress, txcq, tx_seq, &tx_cq_cntr,
-			"fi_inject_write", ep, tx_buf, opts.transfer_size, 
+			"fi_inject_write", ep, tx_buf, opts.transfer_size,
 			remote_fi_addr, remote->addr, remote->key);
 		break;
 	case FT_RMA_WRITEDATA:
diff --git a/fabtests/configure.ac b/fabtests/configure.ac
index bd5a1fd..68b002f 100644
--- a/fabtests/configure.ac
+++ b/fabtests/configure.ac
@@ -5,7 +5,7 @@ dnl
 dnl Process this file with autoconf to produce a configure script.
 
 AC_PREREQ(2.57)
-AC_INIT([fabtests], [1.9.0a1], [ofiwg@lists.openfabrics.org])
+AC_INIT([fabtests], [1.9.0rc1], [ofiwg@lists.openfabrics.org])
 AC_CONFIG_AUX_DIR(config)
 AC_CONFIG_MACRO_DIR(config)
 AC_CONFIG_HEADERS(config.h)
diff --git a/fabtests/include/shared.h b/fabtests/include/shared.h
index a66428e..ee115dd 100644
--- a/fabtests/include/shared.h
+++ b/fabtests/include/shared.h
@@ -49,7 +49,7 @@ extern "C" {
 #endif
 
 #ifndef FT_FIVERSION
-#define FT_FIVERSION FI_VERSION(1,5)
+#define FT_FIVERSION FI_VERSION(1,9)
 #endif
 
 #include "ft_osd.h"
@@ -82,13 +82,6 @@ extern const unsigned int test_cnt;
 #define FT_ENABLE_ALL		(~0)
 #define FT_DEFAULT_SIZE		(1 << 0)
 
-static inline int ft_use_size(int index, int enable_flags)
-{
-	return (enable_flags == FT_ENABLE_ALL) ||
-		(enable_flags & test_size[index].enable_flags);
-}
-
-
 enum precision {
 	NANO = 1,
 	MICRO = 1000,
@@ -269,7 +262,7 @@ extern char default_port[8];
 	}
 
 #define FT_STR_LEN 32
-#define FT_MAX_CTRL_MSG 64
+#define FT_MAX_CTRL_MSG 256
 #define FT_MR_KEY 0xC0DE
 #define FT_TX_MR_KEY (FT_MR_KEY + 1)
 #define FT_RX_MR_KEY 0xFFFF
@@ -284,6 +277,13 @@ char *cnt_str(char str[FT_STR_LEN], long long cnt);
 int size_to_count(int size);
 size_t datatype_to_size(enum fi_datatype datatype);
 
+static inline int ft_use_size(int index, int enable_flags)
+{
+	return test_size[index].size <= fi->ep_attr->max_msg_size &&
+		((enable_flags == FT_ENABLE_ALL) ||
+		(enable_flags & test_size[index].enable_flags));
+}
+
 #define FT_PRINTERR(call, retv) \
 	do { fprintf(stderr, call "(): %s:%d, ret=%d (%s)\n", __FILE__, __LINE__, \
 			(int) (retv), fi_strerror((int) -(retv))); } while (0)
diff --git a/fabtests/man/fabtests.7.md b/fabtests/man/fabtests.7.md
index da2a8c9..ed16de3 100644
--- a/fabtests/man/fabtests.7.md
+++ b/fabtests/man/fabtests.7.md
@@ -212,6 +212,15 @@ testing scope is limited.
 *fi_resource_freeing*
 : Allocates and closes fabric resources to check for proper cleanup.
 
+# Multinode
+
+This test runs a series of tests over multiple formats and patterns to help
+validate at scale. The patterns are an all to all, one to all, all to one and
+a ring. The tests also run accross multiple capabilites, such as messages, rma,
+atomics, and tagged messages. Currently, there is no option to run these 
+capabilities and patterns independently, however the test is short enough to be
+all run at once.   
+
 # Ubertest
 
 This is a comprehensive latency, bandwidth, and functionality test that can
@@ -221,7 +230,7 @@ result, a full ubertest run can take a significant amount of time.  Because
 ubertest iterates over input variables, it relies on a test configuration
 file for control, rather than extensive command line options that are used
 by other fabtests.  A configuration file must be constructured for each
-provider.  Example test configurations are at /test_configs.
+provider.  Example test configurations are at test_configs.
 
 *fi_ubertest*
 : This test takes a configure file as input.  The file contains a list of
@@ -234,11 +243,94 @@ provider.  Example test configurations are at /test_configs.
 
 ### Config file options
 
-TODO: add all supported config options
+The following keys and respective key values may be used in the config file.
+
+*prov_name*
+: Identify the provider(s) to test.  E.g. udp, tcp, verbs,
+  ofi_rxm;verbs; ofi_rxd;udp.
+
+*test_type*
+: FT_TEST_LATENCY, FT_TEST_BANDWIDTH, FT_TEST_UNIT
+
+*test_class*
+: FT_CAP_MSG, FT_CAP_TAGGED, FT_CAP_RMA, FT_CAP_ATOMIC
+
+*class_function*
+: For FT_CAP_MSG and FT_CAP_TAGGED: FT_FUNC_SEND, FT_FUNC_SENDV, FT_FUNC_SENDMSG,
+  FT_FUNC_INJECT, FT_FUNC_INJECTDATA, FT_FUNC_SENDDATA
+
+  For FT_CAP_RMA: FT_FUNC_WRITE, FT_FUNC_WRITEV, FT_FUNC_WRITEMSG,
+  FT_FUNC_WRITEDATA, FT_FUNC_INJECT_WRITE, FT_FUNC_INJECT_WRITEDATA
+  FT_FUNC_READ, FT_FUNC_READV, FT_FUNC_READMSG
+
+  For FT_CAP_ATOMIC: FT_FUNC_ATOMIC, FT_FUNC_ATOMICV, FT_FUNC_ATOMICMSG,
+  FT_FUNC_INJECT_ATOMIC, FT_FUNC_FETCH_ATOMIC, FT_FUNC_FETCH_ATOMICV,
+  FT_FUNC_FETCH_ATOMICMSG, FT_FUNC_COMPARE_ATOMIC, FT_FUNC_COMPARE_ATOMICV,
+  FT_FUNC_COMPARE_ATOMICMSG
+
+*constant_caps - values OR'ed together*
+: FI_RMA, FI_MSG, FI_SEND, FI_RECV, FI_READ,
+  FI_WRITE, FI_REMOTE_READ, FI_REMOTE_WRITE, FI_TAGGED, FI_DIRECTED_RECV
+
+*mode - values OR'ed together*
+: FI_CONTEXT, FI_RX_CQ_DATA
+
+*ep_type*
+: FI_EP_MSG, FI_EP_DGRAM, FI_EP_RDM
+
+*comp_type*
+: FT_COMP_QUEUE, FT_COMP_CNTR, FT_COMP_ALL
+
+*av_type*
+: FI_AV_MAP, FI_AV_TABLE
+
+*eq_wait_obj*
+: FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_FD, FI_WAIT_MUTEX_COND
 
-- *threading*
-  Specify a list of threading levels. This is a hints only config: ubertest
-  doesn't spawn multiple threads to verify functionality.
+*cq_wait_obj*
+: FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_FD, FI_WAIT_MUTEX_COND
+
+*cntr_wait_obj*
+: FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_FD, FI_WAIT_MUTEX_COND
+
+*threading*
+: FI_THREAD_UNSPEC, FI_THREAD_SAFE, FI_THREAD_FID, FI_THREAD_DOMAIN,
+  FI_THREAD_COMPLETION, FI_THREAD_ENDPOINT
+
+*progress*
+: FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO, FI_PROGRESS_UNSPEC
+
+*mr_mode*
+: (Values OR'ed together) FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED,
+  FI_MR_PROV_KEY
+
+*op*
+: For FT_CAP_ATOMIC: FI_MIN, FI_MAX, FI_SUM, FI_PROD, FI_LOR, FI_LAND, FI_BOR,
+  FI_BAND, FI_LXOR, FI_BXOR, FI_ATOMIC_READ, FI_ATOMIC_WRITE, FI_CSWAP,
+  FI_CSWAP_NE, FI_CSWAP_LE, FI_CSWAP_LT, FI_CSWAP_GE, FI_CSWAP_GT, FI_MSWAP
+
+*datatype*
+: For FT_CAP_ATOMIC: FI_INT8, FI_UINT8, FI_INT16, FI_UINT16, FI_INT32,
+  FI_UINT32, FI_INT64, FI_UINT64, FI_FLOAT, FI_DOUBLE, FI_FLOAT_COMPLEX,
+  FI_DOUBLE_COMPLEX, FI_LONG_DOUBLE, FI_LONG_DOUBLE_COMPLE
+
+*msg_flags - values OR'ed together*
+: For FT_FUNC_XXXMSG: FI_REMOTE_CQ_DATA, FI_COMPLETION
+
+*rx_cq_bind_flags - values OR'ed together*
+: FI_SELECTIVE_COMPLETION
+
+*tx_cq_bind_flags - values OR'ed together*
+: FI_SELECTIVE_COMPLETION
+
+*rx_op_flags - values OR'ed together*
+: FI_COMPLETION
+
+*tx_op_flags - values OR'ed together*
+: FI_COMPLETION
+
+*test_flags - values OR'ed together*
+: FT_FLAG_QUICKTEST
 
 # HOW TO RUN TESTS
 
@@ -357,6 +449,14 @@ This will run "fi_rdm_atomic" for all atomic operations with
 	- 1024 bytes message size
 	- server node as 123.168.0.123
 
+## Run multinode tests
+
+	server and clients are invoked with the same command: 
+		fi_multinode -n <number of processes> -s <server_addr> 
+	
+	a process on the server must be started before any of the clients can be started 
+	succesfully. 
+
 ## Run fi_ubertest
 
 	run server: fi_ubertest
diff --git a/fabtests/man/man1/fi_multinode.1 b/fabtests/man/man1/fi_multinode.1
new file mode 100644
index 0000000..3f6ccf9
--- /dev/null
+++ b/fabtests/man/man1/fi_multinode.1
@@ -0,0 +1 @@
+.so man7/fabtests.7
diff --git a/fabtests/man/man7/fabtests.7 b/fabtests/man/man7/fabtests.7
index 26c9682..81fef18 100644
--- a/fabtests/man/man7/fabtests.7
+++ b/fabtests/man/man7/fabtests.7
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fabtests" "7" "2019\-07\-12" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fabtests" "7" "2019\-10\-25" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -307,6 +307,15 @@ Tests memory registration.
 Allocates and closes fabric resources to check for proper cleanup.
 .RS
 .RE
+.SH Multinode
+.PP
+This test runs a series of tests over multiple formats and patterns to
+help validate at scale.
+The patterns are an all to all, one to all, all to one and a ring.
+The tests also run accross multiple capabilites, such as messages, rma,
+atomics, and tagged messages.
+Currently, there is no option to run these capabilities and patterns
+independently, however the test is short enough to be all run at once.
 .SH Ubertest
 .PP
 This is a comprehensive latency, bandwidth, and functionality test that
@@ -318,7 +327,7 @@ Because ubertest iterates over input variables, it relies on a test
 configuration file for control, rather than extensive command line
 options that are used by other fabtests.
 A configuration file must be constructured for each provider.
-Example test configurations are at /test_configs.
+Example test configurations are at test_configs.
 .TP
 .B \f[I]fi_ubertest\f[]
 This test takes a configure file as input.
@@ -334,11 +343,143 @@ iterations of each test.
 .RE
 .SS Config file options
 .PP
-TODO: add all supported config options
-.IP \[bu] 2
-\f[I]threading\f[] Specify a list of threading levels.
-This is a hints only config: ubertest doesn\[aq]t spawn multiple threads
-to verify functionality.
+The following keys and respective key values may be used in the config
+file.
+.TP
+.B \f[I]prov_name\f[]
+Identify the provider(s) to test.
+E.g.
+udp, tcp, verbs, ofi_rxm;verbs; ofi_rxd;udp.
+.RS
+.RE
+.TP
+.B \f[I]test_type\f[]
+FT_TEST_LATENCY, FT_TEST_BANDWIDTH, FT_TEST_UNIT
+.RS
+.RE
+.TP
+.B \f[I]test_class\f[]
+FT_CAP_MSG, FT_CAP_TAGGED, FT_CAP_RMA, FT_CAP_ATOMIC
+.RS
+.RE
+.TP
+.B \f[I]class_function\f[]
+For FT_CAP_MSG and FT_CAP_TAGGED: FT_FUNC_SEND, FT_FUNC_SENDV,
+FT_FUNC_SENDMSG, FT_FUNC_INJECT, FT_FUNC_INJECTDATA, FT_FUNC_SENDDATA
+.RS
+.RE
+.PP
+For FT_CAP_RMA: FT_FUNC_WRITE, FT_FUNC_WRITEV, FT_FUNC_WRITEMSG,
+FT_FUNC_WRITEDATA, FT_FUNC_INJECT_WRITE, FT_FUNC_INJECT_WRITEDATA
+FT_FUNC_READ, FT_FUNC_READV, FT_FUNC_READMSG
+.PP
+For FT_CAP_ATOMIC: FT_FUNC_ATOMIC, FT_FUNC_ATOMICV, FT_FUNC_ATOMICMSG,
+FT_FUNC_INJECT_ATOMIC, FT_FUNC_FETCH_ATOMIC, FT_FUNC_FETCH_ATOMICV,
+FT_FUNC_FETCH_ATOMICMSG, FT_FUNC_COMPARE_ATOMIC,
+FT_FUNC_COMPARE_ATOMICV, FT_FUNC_COMPARE_ATOMICMSG
+.TP
+.B \f[I]constant_caps \- values OR\[aq]ed together\f[]
+FI_RMA, FI_MSG, FI_SEND, FI_RECV, FI_READ, FI_WRITE, FI_REMOTE_READ,
+FI_REMOTE_WRITE, FI_TAGGED, FI_DIRECTED_RECV
+.RS
+.RE
+.TP
+.B \f[I]mode \- values OR\[aq]ed together\f[]
+FI_CONTEXT, FI_RX_CQ_DATA
+.RS
+.RE
+.TP
+.B \f[I]ep_type\f[]
+FI_EP_MSG, FI_EP_DGRAM, FI_EP_RDM
+.RS
+.RE
+.TP
+.B \f[I]comp_type\f[]
+FT_COMP_QUEUE, FT_COMP_CNTR, FT_COMP_ALL
+.RS
+.RE
+.TP
+.B \f[I]av_type\f[]
+FI_AV_MAP, FI_AV_TABLE
+.RS
+.RE
+.TP
+.B \f[I]eq_wait_obj\f[]
+FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_FD, FI_WAIT_MUTEX_COND
+.RS
+.RE
+.TP
+.B \f[I]cq_wait_obj\f[]
+FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_FD, FI_WAIT_MUTEX_COND
+.RS
+.RE
+.TP
+.B \f[I]cntr_wait_obj\f[]
+FI_WAIT_NONE, FI_WAIT_UNSPEC, FI_WAIT_FD, FI_WAIT_MUTEX_COND
+.RS
+.RE
+.TP
+.B \f[I]threading\f[]
+FI_THREAD_UNSPEC, FI_THREAD_SAFE, FI_THREAD_FID, FI_THREAD_DOMAIN,
+FI_THREAD_COMPLETION, FI_THREAD_ENDPOINT
+.RS
+.RE
+.TP
+.B \f[I]progress\f[]
+FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO, FI_PROGRESS_UNSPEC
+.RS
+.RE
+.TP
+.B \f[I]mr_mode\f[]
+(Values OR\[aq]ed together) FI_MR_LOCAL, FI_MR_VIRT_ADDR,
+FI_MR_ALLOCATED, FI_MR_PROV_KEY
+.RS
+.RE
+.TP
+.B \f[I]op\f[]
+For FT_CAP_ATOMIC: FI_MIN, FI_MAX, FI_SUM, FI_PROD, FI_LOR, FI_LAND,
+FI_BOR, FI_BAND, FI_LXOR, FI_BXOR, FI_ATOMIC_READ, FI_ATOMIC_WRITE,
+FI_CSWAP, FI_CSWAP_NE, FI_CSWAP_LE, FI_CSWAP_LT, FI_CSWAP_GE,
+FI_CSWAP_GT, FI_MSWAP
+.RS
+.RE
+.TP
+.B \f[I]datatype\f[]
+For FT_CAP_ATOMIC: FI_INT8, FI_UINT8, FI_INT16, FI_UINT16, FI_INT32,
+FI_UINT32, FI_INT64, FI_UINT64, FI_FLOAT, FI_DOUBLE, FI_FLOAT_COMPLEX,
+FI_DOUBLE_COMPLEX, FI_LONG_DOUBLE, FI_LONG_DOUBLE_COMPLE
+.RS
+.RE
+.TP
+.B \f[I]msg_flags \- values OR\[aq]ed together\f[]
+For FT_FUNC_XXXMSG: FI_REMOTE_CQ_DATA, FI_COMPLETION
+.RS
+.RE
+.TP
+.B \f[I]rx_cq_bind_flags \- values OR\[aq]ed together\f[]
+FI_SELECTIVE_COMPLETION
+.RS
+.RE
+.TP
+.B \f[I]tx_cq_bind_flags \- values OR\[aq]ed together\f[]
+FI_SELECTIVE_COMPLETION
+.RS
+.RE
+.TP
+.B \f[I]rx_op_flags \- values OR\[aq]ed together\f[]
+FI_COMPLETION
+.RS
+.RE
+.TP
+.B \f[I]tx_op_flags \- values OR\[aq]ed together\f[]
+FI_COMPLETION
+.RS
+.RE
+.TP
+.B \f[I]test_flags \- values OR\[aq]ed together\f[]
+FT_FLAG_QUICKTEST
+.RS
+.RE
 .SH HOW TO RUN TESTS
 .IP "(1)" 4
 Fabtests requires that libfabric be installed on the system, and at
@@ -512,6 +653,17 @@ This will run "fi_rdm_atomic" for all atomic operations with
 \-\ server\ node\ as\ 123.168.0.123
 \f[]
 .fi
+.SS Run multinode tests
+.IP
+.nf
+\f[C]
+server\ and\ clients\ are\ invoked\ with\ the\ same\ command:\ 
+\ \ \ \ fi_multinode\ \-n\ <number\ of\ processes>\ \-s\ <server_addr>\ 
+
+a\ process\ on\ the\ server\ must\ be\ started\ before\ any\ of\ the\ clients\ can\ be\ started\ 
+succesfully.\ 
+\f[]
+.fi
 .SS Run fi_ubertest
 .IP
 .nf
diff --git a/fabtests/multinode/include/coll_test.h b/fabtests/multinode/include/coll_test.h
new file mode 100644
index 0000000..92eae06
--- /dev/null
+++ b/fabtests/multinode/include/coll_test.h
@@ -0,0 +1,45 @@
+/*
+ * Copyright (c) 2019-2019 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+#pragma once
+
+
+
+typedef int (*coll_test_setup_t)();
+typedef int (*coll_test_run_t)();
+typedef void (*coll_test_teardown_t)();
+
+struct coll_test {
+        char *name;
+        coll_test_setup_t setup;
+        coll_test_run_t run;
+        coll_test_teardown_t teardown;
+};
\ No newline at end of file
diff --git a/fabtests/multinode/include/core.h b/fabtests/multinode/include/core.h
index 526bf1a..d1bb11c 100644
--- a/fabtests/multinode/include/core.h
+++ b/fabtests/multinode/include/core.h
@@ -49,7 +49,9 @@ struct pm_job_info {
 	size_t		num_ranks;
 	int		sock;
 	int		*clients; //only valid for server
+
 	struct sockaddr_storage oob_server_addr;
+	size_t 		server_addr_len;
 	void		*names;
 	size_t		name_len;
 	fi_addr_t	*fi_addrs;
diff --git a/fabtests/multinode/include/pattern.h b/fabtests/multinode/include/pattern.h
index 0a1121c..43c36bf 100644
--- a/fabtests/multinode/include/pattern.h
+++ b/fabtests/multinode/include/pattern.h
@@ -35,16 +35,20 @@
 #include <stdlib.h>
 #include <stdbool.h>
 #include <errno.h>
-
 #include <rdma/fabric.h>
 
 /* Initial value for iterator position. */
 #define PATTERN_NO_CURRENT (-1)
 
+/* Number of patterns to test */
+extern const int NUM_TESTS;
+
 struct pattern_ops {
 	char *name;
 	int (*next_source)(int *cur);
 	int (*next_target) (int *cur);
 };
 
-extern struct pattern_ops full_mesh_ops;
+extern struct pattern_ops patterns[];
+
+
diff --git a/fabtests/multinode/src/core.c b/fabtests/multinode/src/core.c
index 558330f..17730c5 100644
--- a/fabtests/multinode/src/core.c
+++ b/fabtests/multinode/src/core.c
@@ -72,6 +72,9 @@ static int multinode_setup_fabric(int argc, char **argv)
 	tx_cq_cntr = 0;
 	rx_cq_cntr = 0;
 
+	if (pm_job.my_rank != 0)
+		pm_barrier();
+
 	ret = ft_getinfo(hints, &fi);
 	if (ret)
 		return ret;
@@ -104,6 +107,9 @@ static int multinode_setup_fabric(int argc, char **argv)
 		goto err;
 	}
 
+	if (pm_job.my_rank == 0)
+		pm_barrier();
+
 	ret = pm_allgather(my_name, pm_job.names, pm_job.name_len);
 	if (ret) {
 		FT_PRINTERR("error exchanging addresses\n", ret);
@@ -141,7 +147,7 @@ static int multinode_post_rx()
 			break;
 
 		ret = pattern->next_source(&state.cur_source);
-		if (ret == -ENODATA) {
+		if (ret == -FI_ENODATA) {
 			state.all_recvs_posted = true;
 			break;
 		} else if (ret < 0) {
@@ -152,7 +158,7 @@ static int multinode_post_rx()
 		assert(rx_ctx_arr[offset].state == OP_DONE);
 
 		ret = ft_post_rx_buf(ep, opts.transfer_size,
-				     &rx_ctx_arr[offset],
+				     &rx_ctx_arr[offset].context,
 				     rx_ctx_arr[offset].buf,
 				     rx_ctx_arr[offset].desc, 0);
 		if (ret)
@@ -176,7 +182,7 @@ static int multinode_post_tx()
 			break;
 
 		ret = pattern->next_target(&state.cur_target);
-		if (ret == -ENODATA) {
+		if (ret == -FI_ENODATA) {
 			state.all_sends_posted = true;
 			break;
 		} else if (ret < 0) {
@@ -190,7 +196,7 @@ static int multinode_post_tx()
 		dest = pm_job.fi_addrs[state.cur_target];
 		ret = ft_post_tx_buf(ep, dest, opts.transfer_size,
 				     NO_CQ_DATA,
-				     &tx_ctx_arr[offset],
+				     &tx_ctx_arr[offset].context,
 				     tx_ctx_arr[offset].buf,
 				     tx_ctx_arr[offset].desc, 0);
 		if (ret)
@@ -250,7 +256,6 @@ static int multinode_run_test()
 	for (iter = 0; iter < opts.iterations; iter++) {
 
 		multinode_init_state();
-
 		while (!state.all_completions_done ||
 				!state.all_recvs_posted ||
 				!state.all_sends_posted) {
@@ -265,32 +270,39 @@ static int multinode_run_test()
 			ret = multinode_wait_for_comp();
 			if (ret)
 				return ret;
+
+			pm_barrier();
 		}
 	}
-	pm_barrier();
 	return 0;
 }
 
 static void pm_job_free_res()
 {
-	if (pm_job.names)
-		free(pm_job.names);
 
-	if (pm_job.fi_addrs)
+	free(pm_job.names);
+
 	free(pm_job.fi_addrs);
 }
 
 int multinode_run_tests(int argc, char **argv)
 {
 	int ret = FI_SUCCESS;
+	int i;
 
 	ret = multinode_setup_fabric(argc, argv);
 	if (ret)
 		return ret;
 
-	pattern = &full_mesh_ops;
-
-	ret = multinode_run_test();
+	for (i = 0; i < NUM_TESTS && !ret; i++) {
+		printf("starting %s... ", patterns[i].name);
+		pattern = &patterns[i];
+		ret = multinode_run_test();
+		if (ret)
+			printf("failed\n");
+		else
+			printf("passed\n");
+	}
 
 	pm_job_free_res();
 	ft_free_res();
diff --git a/fabtests/multinode/src/core_coll.c b/fabtests/multinode/src/core_coll.c
new file mode 100644
index 0000000..fc05b03
--- /dev/null
+++ b/fabtests/multinode/src/core_coll.c
@@ -0,0 +1,428 @@
+/*
+ * Copyright (c) 2017-2019 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHWARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. const NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER const AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS const THE
+ * SOFTWARE.
+ */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <string.h>
+#include <unistd.h>
+#include <getopt.h>
+#include <limits.h>
+#include <stdarg.h>
+
+#include <rdma/fi_errno.h>
+#include <rdma/fi_domain.h>
+#include <rdma/fabric.h>
+#include <rdma/fi_endpoint.h>
+#include <rdma/fi_cm.h>
+#include <rdma/fi_trigger.h>
+#include <rdma/fi_collective.h>
+
+#include <core.h>
+#include <coll_test.h>
+#include <shared.h>
+#include <sys/socket.h>
+#include <netinet/in.h>
+#include <arpa/inet.h>
+#include <assert.h>
+
+struct fid_av_set *av_set;
+
+int no_setup()
+{
+	return FI_SUCCESS;
+}
+
+int no_run()
+{
+	return FI_SUCCESS;
+}
+
+void no_teardown()
+{
+}
+
+int coll_setup()
+{
+	int err;
+	struct fi_av_set_attr av_set_attr;
+
+	av_set_attr.count = pm_job.num_ranks;
+	av_set_attr.start_addr = 0;
+	av_set_attr.end_addr = pm_job.num_ranks-1;
+	av_set_attr.stride = 1;
+
+	err = fi_av_set(av, &av_set_attr, &av_set, NULL);
+	if (err) {
+		FT_DEBUG("av_set creation failed ret = %d\n", err);
+	}
+
+	return err;
+}
+
+void coll_teardown()
+{
+	free(av_set);
+}
+
+int join_test_run()
+{
+	int ret;
+	uint32_t event;
+	struct fi_cq_err_entry comp = {0};
+	fi_addr_t world_addr;
+	struct fid_mc *coll_mc;
+
+	ret = fi_av_set_addr(av_set, &world_addr);
+	if (ret) {
+		FT_DEBUG("failed to get collective addr = %d\n", ret);
+		return ret;
+	}
+
+	ret = fi_join_collective(ep, world_addr, av_set, 0, &coll_mc, NULL);
+	if (ret) {
+		FT_DEBUG("collective join failed ret = %d\n", ret);
+		return ret;
+	}
+
+	while (1) {
+		ret = fi_eq_read(eq, &event, NULL, 0, 0);
+		if (ret >= 0) {
+			FT_DEBUG("found eq entry ret %d\n", event);
+			if (event == FI_JOIN_COMPLETE) {
+				return FI_SUCCESS;
+			}
+		} else if(ret != -EAGAIN) {
+			return ret;
+		}
+
+		ret = fi_cq_read(rxcq, &comp, 1);
+		if(ret < 0 && ret != -EAGAIN) {
+			return ret;
+		}
+
+		ret = fi_cq_read(txcq, &comp, 1);
+		if(ret < 0 && ret != -EAGAIN) {
+			return ret;
+		}
+	}
+
+	fi_close(&coll_mc->fid);
+}
+
+int barrier_test_run()
+{
+	int ret;
+	uint32_t event;
+	struct fi_cq_err_entry comp = {0};
+	uint64_t done_flag;
+	fi_addr_t world_addr;
+	fi_addr_t barrier_addr;
+	struct fid_mc *coll_mc;
+
+	ret = fi_av_set_addr(av_set, &world_addr);
+	if (ret) {
+		FT_DEBUG("failed to get collective addr = %d\n", ret);
+		return ret;
+	}
+
+	ret = fi_join_collective(ep, world_addr, av_set, 0, &coll_mc, NULL);
+	if (ret) {
+		FT_DEBUG("collective join failed ret = %d\n", ret);
+		return ret;
+	}
+
+	while (1) {
+		ret = fi_eq_read(eq, &event, NULL, 0, 0);
+		if (ret >= 0) {
+			FT_DEBUG("found eq entry ret %d\n", event);
+			if (event == FI_JOIN_COMPLETE) {
+				barrier_addr = fi_mc_addr(coll_mc);
+				ret = fi_barrier(ep, barrier_addr, &done_flag);
+				if (ret) {
+					FT_DEBUG("collective barrier failed ret = %d\n", ret);
+					return ret;
+				}
+			}
+		} else if(ret != -EAGAIN) {
+			return ret;
+		}
+
+		ret = fi_cq_read(rxcq, &comp, 1);
+		if(ret < 0 && ret != -EAGAIN) {
+			return ret;
+		}
+
+		if(comp.op_context && comp.op_context == &done_flag) {
+			return FI_SUCCESS;
+		}
+
+		ret = fi_cq_read(txcq, &comp, 1);
+		if(ret < 0 && ret != -EAGAIN) {
+			return ret;
+		}
+
+		if(comp.op_context && comp.op_context == &done_flag) {
+			return FI_SUCCESS;
+		}
+	}
+
+	fi_close(&coll_mc->fid);
+}
+
+int sum_all_reduce_test_run()
+{
+	int ret;
+	uint32_t event;
+	struct fi_cq_err_entry comp = {0};
+	uint64_t done_flag;
+	fi_addr_t world_addr;
+	fi_addr_t allreduce_addr;
+	struct fid_mc *coll_mc;
+	uint64_t result = 0;
+	uint64_t expect_result = 0;
+	uint64_t data = pm_job.my_rank;
+	size_t count = 1;
+	uint64_t i;
+
+	for(i = 0; i < pm_job.num_ranks; i++) {
+		expect_result += i;
+	}
+
+	ret = fi_av_set_addr(av_set, &world_addr);
+	if (ret) {
+		FT_DEBUG("failed to get collective addr = %d\n", ret);
+		return ret;
+	}
+
+	ret = fi_join_collective(ep, world_addr, av_set, 0, &coll_mc, NULL);
+	if (ret) {
+		FT_DEBUG("collective join failed ret = %d\n", ret);
+		return ret;
+	}
+
+	while (1) {
+		ret = fi_eq_read(eq, &event, NULL, 0, 0);
+		if (ret >= 0) {
+			FT_DEBUG("found eq entry ret %d\n", event);
+			if (event == FI_JOIN_COMPLETE) {
+				allreduce_addr = fi_mc_addr(coll_mc);
+				ret = fi_allreduce(ep, &data, count, NULL, &result, NULL,
+						   allreduce_addr, FI_UINT64, FI_SUM, 0,
+						   &done_flag);
+				if (ret) {
+					FT_DEBUG("collective allreduce failed ret = %d\n", ret);
+					return ret;
+				}
+			}
+		} else if(ret != -EAGAIN) {
+			return ret;
+		}
+
+		ret = fi_cq_read(rxcq, &comp, 1);
+		if(ret < 0 && ret != -EAGAIN) {
+			return ret;
+		}
+
+		if(comp.op_context && comp.op_context == &done_flag) {
+			if(result == expect_result)
+				return FI_SUCCESS;
+			FT_DEBUG("allreduce failed; expect: %ld, actual: %ld\n", expect_result, result);
+
+			return FI_ENOEQ;
+		}
+
+		ret = fi_cq_read(txcq, &comp, 1);
+		if(ret < 0 && ret != -EAGAIN) {
+			return ret;
+		}
+
+		if(comp.op_context && comp.op_context == &done_flag) {
+			if(result == expect_result)
+				return FI_SUCCESS;
+			FT_DEBUG("allreduce failed; expect: %ld, actual: %ld\n", expect_result, result);
+
+			return FI_ENOEQ;
+		}
+	}
+
+	fi_close(&coll_mc->fid);
+}
+
+struct coll_test tests[] = {
+	{
+		.name = "join_test",
+		.setup = coll_setup,
+		.run = join_test_run,
+		.teardown = coll_teardown
+	},
+	{
+		.name = "barrier_test",
+		.setup = coll_setup,
+		.run = barrier_test_run,
+		.teardown = coll_teardown
+	},
+	{
+		.name = "sum_all_reduce_test",
+		.setup = coll_setup,
+		.run = sum_all_reduce_test_run,
+		.teardown = coll_teardown
+	},
+};
+
+const int NUM_TESTS = ARRAY_SIZE(tests);
+
+static inline
+int setup_hints()
+{
+	hints->ep_attr->type			= FI_EP_RDM;
+	hints->caps				= FI_MSG | FI_COLLECTIVE;
+	hints->mode				= FI_CONTEXT;
+	hints->domain_attr->control_progress	= FI_PROGRESS_MANUAL;
+	hints->domain_attr->data_progress	= FI_PROGRESS_MANUAL;
+	hints->fabric_attr->prov_name		= strdup("tcp");
+	return FI_SUCCESS;
+}
+
+static int multinode_setup_fabric(int argc, char **argv)
+{
+	char my_name[FT_MAX_CTRL_MSG];
+	size_t len;
+	int ret;
+
+	setup_hints();
+
+	ret = ft_getinfo(hints, &fi);
+	if (ret)
+		return ret;
+
+	ret = ft_open_fabric_res();
+	if (ret)
+		return ret;
+
+	opts.av_size = pm_job.num_ranks;
+
+	av_attr.type = FI_AV_TABLE;
+	ret = ft_alloc_active_res(fi);
+	if (ret)
+		return ret;
+
+	ret = ft_enable_ep(ep, eq, av, txcq, rxcq, txcntr, rxcntr);
+	if (ret)
+		return ret;
+
+	len = FT_MAX_CTRL_MSG;
+	ret = fi_getname(&ep->fid, (void *) my_name, &len);
+	if (ret) {
+		FT_PRINTERR("error determining local endpoint name\n", ret);
+		goto err;
+	}
+
+	pm_job.name_len = len;
+	pm_job.names = malloc(len * pm_job.num_ranks);
+	if (!pm_job.names) {
+		FT_ERR("error allocating memory for address exchange\n");
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	ret = pm_allgather(my_name, pm_job.names, pm_job.name_len);
+	if (ret) {
+		FT_PRINTERR("error exchanging addresses\n", ret);
+		goto err;
+	}
+
+	pm_job.fi_addrs = calloc(pm_job.num_ranks, sizeof(*pm_job.fi_addrs));
+	if (!pm_job.fi_addrs) {
+		FT_ERR("error allocating memory for av fi addrs\n");
+		ret = -FI_ENOMEM;
+		goto err;
+	}
+
+	ret = fi_av_insert(av, pm_job.names, pm_job.num_ranks,
+			   pm_job.fi_addrs, 0, NULL);
+	if (ret != pm_job.num_ranks) {
+		FT_ERR("unable to insert all addresses into AV table\n");
+		ret = -1;
+		goto err;
+	}
+	return 0;
+err:
+	ft_free_res();
+	return ft_exit_code(ret);
+}
+
+static void pm_job_free_res()
+{
+
+	free(pm_job.names);
+
+	free(pm_job.fi_addrs);
+}
+
+int multinode_run_tests(int argc, char **argv)
+{
+	int ret = FI_SUCCESS;
+	int i;
+
+	ret = multinode_setup_fabric(argc, argv);
+	if (ret)
+		return ret;
+
+	for (i = 0; i < NUM_TESTS && !ret; i++) {
+		FT_DEBUG("Running Test: %s \n", tests[i].name);
+
+		ret = tests[i].setup();
+		FT_DEBUG("Setup Complete...\n");
+		if (ret)
+			goto out;
+
+		ret = tests[i].run();
+		tests[i].teardown();
+		FT_DEBUG("Run Complete...\n");
+		if (ret)
+			goto out;
+
+
+		pm_barrier();
+		FT_DEBUG("Test Complete: %s \n", tests[i].name);
+	}
+
+out:
+	if (ret)
+		printf("failed\n");
+	else
+		printf("passed\n");
+
+	pm_job_free_res();
+	ft_free_res();
+	return ft_exit_code(ret);
+}
diff --git a/fabtests/multinode/src/harness.c b/fabtests/multinode/src/harness.c
index 1b3ca9f..b1b9551 100644
--- a/fabtests/multinode/src/harness.c
+++ b/fabtests/multinode/src/harness.c
@@ -80,7 +80,6 @@ static inline int socket_recv(int sock, void *buf, size_t len, int flags)
 }
 
 int pm_allgather(void *my_item, void *items, int item_size)
-
 {
 	int i, ret;
 	uint8_t *offset;
@@ -128,6 +127,26 @@ void pm_barrier()
 	pm_allgather(&ch, chs, 1);
 }
 
+static int pm_init_ranks()
+{
+	int ret;
+	int i;
+	size_t send_rank;
+
+	if (pm_job.clients) {
+		for(i = 0; i < pm_job.num_ranks-1; i++) {
+			send_rank = i + 1;
+			ret = socket_send(pm_job.clients[i], &send_rank, sizeof(send_rank), 0);
+			if (ret < 0)
+				return ret;
+		}
+	} else {
+		ret = socket_recv(pm_job.sock, &(pm_job.my_rank), sizeof(pm_job.my_rank), 0);
+	}
+
+	return ret;
+}
+
 static int server_connect()
 {
 	int new_sock;
@@ -141,7 +160,7 @@ static int server_connect()
 	if (!pm_job.clients)
 		return -FI_ENOMEM;
 
-	for (i = 0; i < pm_job.num_ranks-1; i++){
+	for (i = 0; i < pm_job.num_ranks-1; i++) {
 		new_sock = accept(pm_job.sock, NULL, NULL);
 		if (new_sock < 0) {
 			FT_ERR("error during server init\n");
@@ -165,7 +184,7 @@ static int pm_conn_setup()
 	int sock,  ret;
 	int optval = 1;
 
-	sock = socket(AF_INET, SOCK_STREAM, 0);
+	sock = socket(pm_job.oob_server_addr.ss_family, SOCK_STREAM, 0);
 	if (sock < 0)
 		return -1;
 
@@ -179,7 +198,7 @@ static int pm_conn_setup()
 	}
 
 	ret = bind(sock, (struct sockaddr *)&pm_job.oob_server_addr,
-		   sizeof(pm_job.oob_server_addr));
+		  pm_job.server_addr_len);
 	if (ret == 0) {
 		ret = server_connect();
 	} else {
@@ -188,7 +207,7 @@ static int pm_conn_setup()
 		opts.src_addr = NULL;
 		opts.src_port = 0;
 		ret = connect(pm_job.sock, (struct sockaddr *)&pm_job.oob_server_addr,
-			      sizeof(pm_job.oob_server_addr));
+			      pm_job.server_addr_len);
 	}
 	if (ret) {
 		FT_ERR("OOB conn failed - %s\n", strerror(errno));
@@ -218,15 +237,16 @@ int pm_get_oob_server_addr()
 	struct addrinfo *res;
 	struct sockaddr_in *in;
 	struct sockaddr_in6 *in6;
-        int ret;
+	int ret;
 
-        ret = getaddrinfo(opts.src_addr, NULL, NULL, &res);
-        if (ret) {
+	ret = getaddrinfo(opts.src_addr, NULL, NULL, &res);
+	if (ret) {
 		FT_ERR( "getaddrinfo failed\n");
-                return ret;
-        }
+		return ret;
+	}
 
 	memcpy(&pm_job.oob_server_addr, res->ai_addr, res->ai_addrlen);
+	pm_job.server_addr_len = res->ai_addrlen;
 
 	switch (pm_job.oob_server_addr.ss_family) {
 	case AF_INET:
@@ -244,7 +264,7 @@ int pm_get_oob_server_addr()
 	}
 
 	freeaddrinfo(res);
-        return ret;
+	return ret;
 }
 
 int main(int argc, char **argv)
@@ -261,16 +281,17 @@ int main(int argc, char **argv)
 	if (!hints)
 		return EXIT_FAILURE;
 
-	while ((c = getopt(argc, argv, "n:h" ADDR_OPTS INFO_OPTS)) != -1) {
+	while ((c = getopt(argc, argv, "n:h" CS_OPTS INFO_OPTS)) != -1) {
 		switch (c) {
 		default:
 			ft_parse_addr_opts(c, optarg, &opts);
 			ft_parseinfo(c, optarg, hints, &opts);
+			ft_parsecsopts(c, optarg, &opts);
 			break;
-		case '?':
 		case 'n':
 			pm_job.num_ranks = atoi(optarg);
 			break;
+		case '?':
 		case 'h':
 			ft_usage(argv[0], "A simple multinode test");
 			return EXIT_FAILURE;
@@ -282,8 +303,16 @@ int main(int argc, char **argv)
 		goto err1;
 
 	ret = pm_conn_setup();
-	if (ret)
+	if (ret) {
+		FT_ERR("connection setup failed\n");
 		goto err1;
+	}
+	
+	ret = pm_init_ranks();
+	if (ret < 0) {
+		FT_ERR("rank initialization failed\n");
+		goto err2;
+	}
 
 	FT_DEBUG("OOB job setup done\n");
 
diff --git a/fabtests/multinode/src/pattern.c b/fabtests/multinode/src/pattern.c
new file mode 100644
index 0000000..31ca177
--- /dev/null
+++ b/fabtests/multinode/src/pattern.c
@@ -0,0 +1,126 @@
+/*
+ * Copyright (c) 2017-2019 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+#include <pattern.h>
+#include <core.h>
+#include <shared.h>
+
+static int broadcast_gather_next(int *cur)
+{
+	int next;
+	if (pm_job.my_rank) 
+		return -FI_ENODATA;
+	next = *cur + 1;
+
+	if (next >= pm_job.num_ranks)
+		return -FI_ENODATA;
+	if (next == 0)
+		next = 1;
+
+	*cur = next;
+	
+	return 0;
+}
+
+static int broadcast_gather_current(int *cur)
+{
+	int next;
+	if (!pm_job.my_rank) 
+		return -FI_ENODATA;
+	
+	next = *cur + 1;
+
+	if (next > 0)			
+		return -FI_ENODATA;
+
+	*cur = next;
+	
+	return 0; 
+}
+
+static int ring_next(int *cur)
+{
+	if ((pm_job.my_rank == 0 && pm_job.num_ranks - 1 == *cur) ||
+		(pm_job.my_rank != 0 && pm_job.my_rank - 1   == *cur))
+		return -FI_ENODATA;
+		
+	if (pm_job.my_rank == 0)
+		*cur = pm_job.num_ranks - 1;
+	else 			
+		*cur = pm_job.my_rank - 1;
+	return 0; 
+}
+
+static int ring_current(int *cur)
+{
+	if ((pm_job.my_rank + 1) % pm_job.num_ranks == *cur) 
+		return -FI_ENODATA;
+	
+	*cur = (pm_job.my_rank + 1) % pm_job.num_ranks;
+	return 0; 
+	
+}
+
+static int mesh_next(int *cur)
+{
+	int next = *cur + 1;
+
+	if (next >= pm_job.num_ranks)
+		return -FI_ENODATA;
+
+	*cur = next;
+	return 0;
+}
+
+struct pattern_ops patterns[] = {
+	{
+		.name = "full_mesh",
+		.next_source = mesh_next,
+		.next_target = mesh_next,
+	},
+	{
+		.name = "ring",
+		.next_source = ring_next,
+		.next_target = ring_current,
+	},
+	{
+		.name = "gather",
+		.next_source = broadcast_gather_next,
+		.next_target = broadcast_gather_current,
+	},
+	{
+		.name = "broadcast",
+		.next_source = broadcast_gather_current,
+		.next_target = broadcast_gather_next,
+	},
+};
+
+const int NUM_TESTS = ARRAY_SIZE(patterns);
diff --git a/fabtests/multinode/src/pattern/full_mesh.c b/fabtests/multinode/src/pattern/full_mesh.c
deleted file mode 100644
index ead6ab6..0000000
--- a/fabtests/multinode/src/pattern/full_mesh.c
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Copyright (c) 2017-2019 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include <pattern.h>
-#include <core.h>
-
-static int pattern_next(int *cur)
-{
-	int next = *cur + 1;
-
-	if (next >= pm_job.num_ranks)
-		return -ENODATA;
-
-	*cur = next;
-	return 0;
-}
-
-
-struct pattern_ops full_mesh_ops = {
-	.name = "full_mesh",
-	.next_source = pattern_next,
-	.next_target = pattern_next,
-};
diff --git a/fabtests/scripts/runfabtests.sh b/fabtests/scripts/runfabtests.sh
index 030b321..8827028 100755
--- a/fabtests/scripts/runfabtests.sh
+++ b/fabtests/scripts/runfabtests.sh
@@ -46,6 +46,8 @@ trap cleanup_and_exit SIGINT
 #
 declare BIN_PATH
 declare PROV=""
+declare CORE=""
+declare UTIL=""
 declare TEST_TYPE="quick"
 declare SERVER="127.0.0.1"
 declare CLIENT="127.0.0.1"
@@ -197,6 +199,11 @@ complex_tests=(
 	"fi_ubertest"
 )
 
+multinode_tests=(
+	"fi_multinode"
+	"fi_multinode_coll"
+)
+
 function errcho {
 	>&2 echo $*
 }
@@ -298,12 +305,17 @@ function read_exclude_file {
 
 function auto_exclude {
 	local excl_file
+	local name=$UTIL
+
+	if [ -z $UTIL ]; then
+		name=$CORE
+	fi
 
-	excl_file="./fabtests/test_configs/${PROV}/${PROV}.exclude"
+	excl_file="./fabtests/test_configs/${name}/${name}.exclude"
 	if [[ ! -f "$excl_file" ]]; then
-		excl_file="./test_configs/${PROV}/${PROV}.exclude"
+		excl_file="./test_configs/${name}/${name}.exclude"
 		if [[ ! -f "$excl_file" ]]; then
-			excl_file="../test_configs/${PROV}/${PROV}.exclude"
+			excl_file="../test_configs/${name}/${name}.exclude"
 			if [[ ! -f "$excl_file" ]]; then
 				return
 			fi
@@ -443,9 +455,31 @@ function cs_test {
 	fi
 }
 
+function set_cfg_file {
+	local cfg_file
+	local parent=$UTIL
+	local name=$CORE
+
+	if [ -z $UTIL ]; then
+		parent=$CORE
+		name=$1
+	fi
+
+	cfg_file="${PWD}/fabtests/test_configs/${parent}/${name}.test"
+	if [[ ! -f "$cfg_file" ]]; then
+		cfg_file="${PWD}/test_configs/${parent}/${name}.test"
+		if [[ ! -f "$cfg_file" ]]; then
+			return
+		fi
+	fi
+
+	COMPLEX_CFG=${cfg_file}
+}
+
 function complex_test {
 	local test=$1
 	local config=$2
+	local path=${PROV/;/\/}
 	local test_exe="${test}"
 	local s_ret=0
 	local c_ret=0
@@ -454,6 +488,9 @@ function complex_test {
 	local test_time
 
 	is_excluded "$test" && return
+	if [[ -z "$COMPLEX_CFG" ]]; then
+		set_cfg_file $config
+	fi
 
 	start_time=$(date '+%s')
 
@@ -468,7 +505,7 @@ function complex_test {
 	s_pid=$!
 	sleep 1
 
-	c_cmd="${BIN_PATH}${test_exe} -p \"${PROV}\" -t $config $S_INTERFACE $opts"
+	c_cmd="${BIN_PATH}${test_exe} -u "${COMPLEX_CFG}" $S_INTERFACE $opts"
 	FI_LOG_LEVEL=error ${CLIENT_CMD} "${EXPORT_ENV} $c_cmd" &> $c_outp &
 	c_pid=$!
 
@@ -510,30 +547,97 @@ function complex_test {
 	fi
 }
 
+function multinode_test {
+	local test=$1
+	local s_ret=0
+	local c_ret=0
+	local num_procs=$2
+	local test_exe="${test} -n $num_procs -p \"${PROV}\"" 	
+	local start_time
+	local end_time
+	local test_time
+
+
+	is_excluded "$test" && return
+
+	start_time=$(date '+%s')
+
+	s_cmd="${BIN_PATH}${test_exe} ${S_ARGS} -s ${S_INTERFACE}"
+	${SERVER_CMD} "${EXPORT_ENV} $s_cmd" &> $s_outp &
+	s_pid=$!
+	sleep 1
+	
+	c_pid_arr=()	
+	for ((i=1; i<num_procs; i++))
+	do
+		c_cmd="${BIN_PATH}${test_exe} ${S_ARGS} -s ${S_INTERFACE}"
+		${CLIENT_CMD} "${EXPORT_ENV} $c_cmd" &> $c_outp & 
+		c_pid_arr+=($!)
+	done
+
+	for pid in ${c_pid_arr[*]}; do
+		wait $pid
+	done
+	
+
+	[[ c_ret -ne 0 ]] && kill -9 $s_pid 2> /dev/null
+
+	wait $s_pid
+	s_ret=$?
+	
+	end_time=$(date '+%s')
+	test_time=$(compute_duration "$start_time" "$end_time")
+
+	if [[ $STRICT_MODE -eq 0 && $s_ret -eq $FI_ENODATA && $c_ret -eq $FI_ENODATA ]] ||
+	   [[ $STRICT_MODE -eq 0 && $s_ret -eq $FI_ENOSYS && $c_ret -eq $FI_ENOSYS ]]; then
+		print_results "$test_exe" "Notrun" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+		skip_count+=1
+	elif [ $s_ret -ne 0 -o $c_ret -ne 0 ]; then
+		print_results "$test_exe" "Fail" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+		if [ $s_ret -eq 124 -o $c_ret -eq 124 ]; then
+			cleanup
+		fi
+		fail_count+=1
+	else
+		print_results "$test_exe" "Pass" "$test_time" "$s_outp" "$s_cmd" "$c_outp" "$c_cmd"
+		pass_count+=1
+	fi
+}
+
+function set_core_util {
+	prov_arr=$(echo $PROV | tr ";" " ")
+	CORE=""
+	UTIL=""
+	for p in $prov_arr; do
+		if [[ -z $CORE ]]; then
+			CORE=$p
+		else
+			UTIL=$p
+		fi
+	done
+}
+
 function main {
 	skip_count=0
 	pass_count=0
 	fail_count=0
-	local complex_cfg="quick"
+	local complex_type="quick"
 
+	set_core_util
 	set_excludes
 
 	if [[ $1 == "quick" ]]; then
 		local -r tests="unit functional short"
 	elif [[ $1 == "verify" ]]; then
 		local -r tests="complex"
-		complex_cfg=$1
+		complex_type=$1
 	else
 		local -r tests=$(echo $1 | sed 's/all/unit,functional,standard,complex/g' | tr ',' ' ')
-		if [[ $1 == "all" ]]; then
-			complex_cfg=$1
+		if [[ $1 == "all" || $1 == "complex" ]]; then
+			complex_type="all"
 		fi
 	fi
 
-	if [[ -n "$COMPLEX_CFG" ]]; then
-		complex_cfg="$COMPLEX_CFG"
-	fi
-
 	if [ $VERBOSE -eq 0 ] ; then
 		printf "# %-68s%10s\n" "Test" "Result"
 		print_border
@@ -569,10 +673,15 @@ function main {
 		;;
 		complex)
 			for test in "${complex_tests[@]}"; do
-				complex_test $test $complex_cfg
+				complex_test $test $complex_type
 
 			done
 		;;
+		multinode)
+			for test in "${multinode_tests[@]}"; do
+					multinode_test $test 3
+			done
+		;;
 		*)
 			errcho "Unknown test set: ${ts}"
 			exit 1
diff --git a/fabtests/test_configs/efa/efa.exclude b/fabtests/test_configs/efa/efa.exclude
index 861f99a..b5a410a 100644
--- a/fabtests/test_configs/efa/efa.exclude
+++ b/fabtests/test_configs/efa/efa.exclude
@@ -95,3 +95,6 @@ rdm_tagged_peek
 
 # fail on timeout - cannot be supported
 dgram_bw
+
+# Multinode tests failing with an unsupported address format
+multinode
diff --git a/fabtests/test_configs/eq_cq.test b/fabtests/test_configs/eq_cq.test
index 6113eb9..1641eef 100644
--- a/fabtests/test_configs/eq_cq.test
+++ b/fabtests/test_configs/eq_cq.test
@@ -1,6 +1,6 @@
-#: "Tests different wait objects for EQ and CQ across sockets and verbs providers"
+#: "Tests different wait objects for EQ and CQ across tcp and verbs providers"
 {
-	prov_name: sockets,
+	prov_name: tcp,
 	test_type: [
 		FT_TEST_LATENCY,
 	],
@@ -25,16 +25,13 @@
 	cq_wait_obj: [
 		FI_WAIT_NONE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
 	test_flags: FT_FLAG_QUICKTEST
 },
 {
-	prov_name: sockets,
+	prov_name: tcp,
 	test_type: [
 		FT_TEST_LATENCY,
 		FT_TEST_BANDWIDTH,
@@ -61,9 +58,6 @@
 		FI_WAIT_FD,
 		FI_WAIT_MUTEX_COND,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -91,9 +85,6 @@
 	cq_wait_obj: [
 		FI_WAIT_NONE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -122,9 +113,6 @@
 		FI_WAIT_UNSPEC,
 		FI_WAIT_FD,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/lat_bw.test b/fabtests/test_configs/lat_bw.test
index cc184a2..4696d2d 100644
--- a/fabtests/test_configs/lat_bw.test
+++ b/fabtests/test_configs/lat_bw.test
@@ -1,6 +1,6 @@
-#: "Latency and bandwidth tests for all providers"
+#: "Latency and bandwidth tests"
 {
-	prov_name: sockets,
+	prov_name: tcp,
 	test_type: [
 		FT_TEST_LATENCY,
 		FT_TEST_BANDWIDTH,
@@ -19,9 +19,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -43,9 +40,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -69,9 +63,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/ofi_rxd/udp.test b/fabtests/test_configs/ofi_rxd/udp.test
index 51c1112..ee10536 100644
--- a/fabtests/test_configs/ofi_rxd/udp.test
+++ b/fabtests/test_configs/ofi_rxd/udp.test
@@ -16,9 +16,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
diff --git a/fabtests/test_configs/ofi_rxd/verbs.test b/fabtests/test_configs/ofi_rxd/verbs.test
new file mode 100644
index 0000000..e41d086
--- /dev/null
+++ b/fabtests/test_configs/ofi_rxd/verbs.test
@@ -0,0 +1,23 @@
+{
+	prov_name: verbs;ofi_rxd,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_SENDDATA,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+},
diff --git a/fabtests/test_configs/ofi_rxm/ofi_rxm.exclude b/fabtests/test_configs/ofi_rxm/ofi_rxm.exclude
index c65fed9..648ca00 100644
--- a/fabtests/test_configs/ofi_rxm/ofi_rxm.exclude
+++ b/fabtests/test_configs/ofi_rxm/ofi_rxm.exclude
@@ -16,6 +16,3 @@ scalable_ep
 shared_av
 multi_mr
 atomic
-
-# Remove this once ubertest supports setting MR modes
-ubertest
diff --git a/fabtests/test_configs/ofi_rxm/tcp.test b/fabtests/test_configs/ofi_rxm/tcp.test
new file mode 100644
index 0000000..baec15f
--- /dev/null
+++ b/fabtests/test_configs/ofi_rxm/tcp.test
@@ -0,0 +1,26 @@
+{
+	prov_name: tcp;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+},
diff --git a/fabtests/test_configs/ofi_rxm/verbs.test b/fabtests/test_configs/ofi_rxm/verbs.test
new file mode 100644
index 0000000..24a06be
--- /dev/null
+++ b/fabtests/test_configs/ofi_rxm/verbs.test
@@ -0,0 +1,110 @@
+#: "Suite of tests for the verbs provider"
+#: "
+# TODO
+#  - Debug WRITEDATA, WRITEMSG, READMSG for RxM before enabling
+#  - Test without FI_MR_LOCAL for RxM
+#  - disable quick test for some configs (takes long time on some fabric)
+#  - Adding more tests results in timeout in runfabtests.sh - fix the script"
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	eq_wait_obj: [
+		FI_WAIT_NONE,
+	],
+	cq_wait_obj: [
+		FI_WAIT_NONE,
+		FI_WAIT_UNSPEC,
+		FI_WAIT_FD,
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+},
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDDATA,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+},
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SENDMSG,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+	msg_flags: FI_REMOTE_CQ_DATA,
+},
+{
+	prov_name: verbs;ofi_rxm,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+	],
+	ep_type: [
+		FI_EP_RDM,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
+	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
+	test_flags: FT_FLAG_QUICKTEST,
+},
diff --git a/fabtests/test_configs/ofi_rxm/verbs/all.test b/fabtests/test_configs/ofi_rxm/verbs/all.test
deleted file mode 100644
index 24a06be..0000000
--- a/fabtests/test_configs/ofi_rxm/verbs/all.test
+++ /dev/null
@@ -1,110 +0,0 @@
-#: "Suite of tests for the verbs provider"
-#: "
-# TODO
-#  - Debug WRITEDATA, WRITEMSG, READMSG for RxM before enabling
-#  - Test without FI_MR_LOCAL for RxM
-#  - disable quick test for some configs (takes long time on some fabric)
-#  - Adding more tests results in timeout in runfabtests.sh - fix the script"
-{
-	prov_name: verbs;ofi_rxm,
-	test_type: [
-		FT_TEST_LATENCY,
-		FT_TEST_BANDWIDTH,
-	],
-	class_function: [
-		FT_FUNC_SEND,
-	],
-	ep_type: [
-		FI_EP_RDM,
-	],
-	comp_type: [
-		FT_COMP_QUEUE,
-	],
-	eq_wait_obj: [
-		FI_WAIT_NONE,
-	],
-	cq_wait_obj: [
-		FI_WAIT_NONE,
-		FI_WAIT_UNSPEC,
-		FI_WAIT_FD,
-	],
-	test_class: [
-		FT_CAP_MSG,
-	],
-	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
-	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
-},
-{
-	prov_name: verbs;ofi_rxm,
-	test_type: [
-		FT_TEST_LATENCY,
-		FT_TEST_BANDWIDTH,
-	],
-	class_function: [
-		FT_FUNC_SEND,
-		FT_FUNC_SENDV,
-		FT_FUNC_SENDDATA,
-		FT_FUNC_INJECT,
-		FT_FUNC_INJECTDATA,
-	],
-	ep_type: [
-		FI_EP_RDM,
-	],
-	comp_type: [
-		FT_COMP_QUEUE,
-	],
-	test_class: [
-		FT_CAP_MSG,
-		FT_CAP_TAGGED,
-	],
-	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
-	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
-},
-{
-	prov_name: verbs;ofi_rxm,
-	test_type: [
-		FT_TEST_LATENCY,
-		FT_TEST_BANDWIDTH,
-	],
-	class_function: [
-		FT_FUNC_SENDMSG,
-	],
-	ep_type: [
-		FI_EP_RDM,
-	],
-	comp_type: [
-		FT_COMP_QUEUE,
-	],
-	test_class: [
-		FT_CAP_MSG,
-		FT_CAP_TAGGED,
-	],
-	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
-	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
-	msg_flags: FI_REMOTE_CQ_DATA,
-},
-{
-	prov_name: verbs;ofi_rxm,
-	test_type: [
-		FT_TEST_LATENCY,
-		FT_TEST_BANDWIDTH,
-	],
-	class_function: [
-		FT_FUNC_WRITE,
-		FT_FUNC_WRITEV,
-		FT_FUNC_READ,
-		FT_FUNC_READV,
-	],
-	ep_type: [
-		FI_EP_RDM,
-	],
-	comp_type: [
-		FT_COMP_QUEUE,
-	],
-	test_class: [
-		FT_CAP_RMA,
-	],
-	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
-	progress: [FI_PROGRESS_MANUAL, FI_PROGRESS_AUTO],
-	test_flags: FT_FLAG_QUICKTEST,
-},
diff --git a/fabtests/test_configs/ofi_rxm/verbs/exclude b/fabtests/test_configs/ofi_rxm/verbs/exclude
deleted file mode 100644
index 648ca00..0000000
--- a/fabtests/test_configs/ofi_rxm/verbs/exclude
+++ /dev/null
@@ -1,18 +0,0 @@
-# Regex patterns of tests to exclude in runfabtests.sh
-
-# Exclude all prefix tests
--k
-
-^fi_msg
--e msg
-^fi_dgram
--e dgram
-
-cm_data
-rdm_rma_simple
-trigger
-shared_ctx
-scalable_ep
-shared_av
-multi_mr
-atomic
diff --git a/fabtests/test_configs/psm/all.test b/fabtests/test_configs/psm/all.test
index a65a160..c864bc2 100644
--- a/fabtests/test_configs/psm/all.test
+++ b/fabtests/test_configs/psm/all.test
@@ -20,7 +20,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_MSG,
@@ -53,7 +53,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_RMA,
diff --git a/fabtests/test_configs/psm2/all.test b/fabtests/test_configs/psm2/all.test
index e573e60..e482d90 100644
--- a/fabtests/test_configs/psm2/all.test
+++ b/fabtests/test_configs/psm2/all.test
@@ -2,7 +2,6 @@
 	prov_name: psm2,
 	test_type: [
 		FT_TEST_LATENCY,
-		FT_TEST_BANDWIDTH,
 	],
 	class_function: [
 		FT_FUNC_SEND,
@@ -21,7 +20,35 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
+	],
+	test_class: [
+		FT_CAP_MSG,
+		FT_CAP_TAGGED,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: psm2,
+	test_type: [
+		FT_TEST_BANDWIDTH,
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_INJECT,
+	],
+	ep_type: [
+		FI_EP_RDM
+	],
+	av_type: [
+		FI_AV_TABLE
+		FI_AV_MAP,
+	],
+	comp_type: [
+		FT_COMP_QUEUE,
+	],
+	mode: [
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_MSG,
@@ -50,7 +77,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_MSG,
@@ -84,7 +111,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_RMA,
diff --git a/fabtests/test_configs/psm2/verify.test b/fabtests/test_configs/psm2/verify.test
index 0e2328c..2b685f4 100644
--- a/fabtests/test_configs/psm2/verify.test
+++ b/fabtests/test_configs/psm2/verify.test
@@ -19,7 +19,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_MSG,
@@ -46,7 +46,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_MSG,
@@ -78,7 +78,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_RMA,
@@ -138,7 +138,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_ATOMIC,
@@ -185,7 +185,7 @@
 		FT_COMP_CNTR,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_ATOMIC,
@@ -237,7 +237,7 @@
 		FT_COMP_QUEUE,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT,
 	],
 	test_class: [
 		FT_CAP_ATOMIC,
diff --git a/fabtests/test_configs/shm/all.test b/fabtests/test_configs/shm/all.test
index 33522c2..a975a7a 100644
--- a/fabtests/test_configs/shm/all.test
+++ b/fabtests/test_configs/shm/all.test
@@ -15,9 +15,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -41,9 +38,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -74,9 +68,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -104,9 +95,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -142,9 +130,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -176,9 +161,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -219,9 +201,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -259,9 +238,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -303,9 +279,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -347,9 +320,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -382,9 +352,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -423,9 +390,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
diff --git a/fabtests/test_configs/shm/quick.test b/fabtests/test_configs/shm/quick.test
index b95011a..94c98b6 100644
--- a/fabtests/test_configs/shm/quick.test
+++ b/fabtests/test_configs/shm/quick.test
@@ -15,9 +15,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -43,9 +40,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -77,9 +71,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -108,9 +99,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -147,9 +135,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -182,9 +167,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -228,9 +210,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -269,9 +248,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -314,9 +290,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -359,9 +332,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -395,9 +365,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -437,9 +404,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
diff --git a/fabtests/test_configs/shm/verify.test b/fabtests/test_configs/shm/verify.test
index 156c441..d94394b 100644
--- a/fabtests/test_configs/shm/verify.test
+++ b/fabtests/test_configs/shm/verify.test
@@ -14,9 +14,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -48,9 +45,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -81,9 +75,6 @@
 	ep_type: [
 		FI_EP_RDM,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -141,9 +132,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -187,9 +175,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -239,9 +224,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -299,9 +281,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -342,9 +321,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -391,9 +367,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
diff --git a/fabtests/test_configs/sockets/all.test b/fabtests/test_configs/sockets/all.test
index 31080aa..f7c27f7 100644
--- a/fabtests/test_configs/sockets/all.test
+++ b/fabtests/test_configs/sockets/all.test
@@ -14,7 +14,6 @@
 	],
 	ep_type: [
 		FI_EP_MSG,
-		FI_EP_DGRAM,
 		FI_EP_RDM,
 	],
 	av_type: [
@@ -24,9 +23,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -58,9 +54,6 @@
 	cq_wait_obj: [
 		FI_WAIT_NONE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -76,7 +69,6 @@
 	],
 	ep_type: [
 		FI_EP_MSG,
-		FI_EP_DGRAM,
 	],
 	av_type: [
 		FI_AV_TABLE,
@@ -93,9 +85,6 @@
 		FI_WAIT_FD,
 		FI_WAIT_MUTEX_COND,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/sockets/complete.test b/fabtests/test_configs/sockets/complete.test
index 8483413..b6c932d 100644
--- a/fabtests/test_configs/sockets/complete.test
+++ b/fabtests/test_configs/sockets/complete.test
@@ -15,7 +15,6 @@
 	],
 	ep_type: [
 		FI_EP_MSG,
-		FI_EP_DGRAM,
 		FI_EP_RDM,
 	],
 	av_type: [
@@ -26,10 +25,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -60,10 +55,6 @@
 		FI_WAIT_FD,
 		FI_WAIT_MUTEX_COND,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -80,7 +71,6 @@
 	],
 	ep_type: [
 		FI_EP_MSG,
-		FI_EP_DGRAM,
 	],
 	av_type: [
 		FI_AV_TABLE,
@@ -97,10 +87,6 @@
 		FI_WAIT_FD,
 		FI_WAIT_MUTEX_COND,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -117,7 +103,6 @@
 	],
 	ep_type: [
 		FI_EP_MSG,
-		FI_EP_DGRAM,
 	],
 	av_type: [
 		FI_AV_TABLE,
@@ -134,10 +119,6 @@
 		FI_WAIT_FD,
 		FI_WAIT_MUTEX_COND,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -171,10 +152,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -235,10 +212,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -285,10 +258,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -341,10 +310,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-		FT_MODE_NONE,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -368,9 +333,6 @@
 	comp_type: [
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -404,9 +366,6 @@
 	comp_type: [
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -441,9 +400,6 @@
 	comp_type: [
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -475,9 +431,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -509,9 +462,6 @@
 		FT_COMP_QUEUE,
 		FT_COMP_CNTR,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
diff --git a/fabtests/test_configs/sockets/quick.test b/fabtests/test_configs/sockets/quick.test
index b913732..b929c5d 100644
--- a/fabtests/test_configs/sockets/quick.test
+++ b/fabtests/test_configs/sockets/quick.test
@@ -15,7 +15,6 @@
 	],
 	ep_type: [
 		FI_EP_MSG,
-		FI_EP_DGRAM,
 		FI_EP_RDM,
 	],
 	av_type: [
@@ -25,9 +24,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -60,9 +56,6 @@
 	cq_wait_obj: [
 		FI_WAIT_NONE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -79,7 +72,6 @@
 	],
 	ep_type: [
 		FI_EP_MSG,
-		FI_EP_DGRAM,
 	],
 	av_type: [
 		FI_AV_TABLE,
@@ -96,9 +88,6 @@
 		FI_WAIT_FD,
 		FI_WAIT_MUTEX_COND,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -131,9 +120,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -171,9 +157,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -206,9 +189,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -241,9 +221,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
diff --git a/fabtests/test_configs/sockets/sockets.exclude b/fabtests/test_configs/sockets/sockets.exclude
index b25e942..ea80e22 100644
--- a/fabtests/test_configs/sockets/sockets.exclude
+++ b/fabtests/test_configs/sockets/sockets.exclude
@@ -2,3 +2,4 @@
 
 -e dgram
 dgram
+multinode
diff --git a/fabtests/test_configs/sockets/verify.test b/fabtests/test_configs/sockets/verify.test
index 79ad508..a284a8c 100644
--- a/fabtests/test_configs/sockets/verify.test
+++ b/fabtests/test_configs/sockets/verify.test
@@ -20,9 +20,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -54,9 +51,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
@@ -114,9 +108,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -160,9 +151,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -212,9 +200,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_ATOMIC,
 	],
@@ -239,9 +224,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 		FT_CAP_TAGGED,
@@ -268,9 +250,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_RMA,
 	],
diff --git a/fabtests/test_configs/tcp/quick.test b/fabtests/test_configs/tcp/quick.test
new file mode 100644
index 0000000..34b323e
--- /dev/null
+++ b/fabtests/test_configs/tcp/quick.test
@@ -0,0 +1,54 @@
+#: "Suite of tests for the tcp provider"
+{
+	prov_name: tcp,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+		FT_TEST_UNIT
+	],
+	class_function: [
+		FT_FUNC_SEND,
+		FT_FUNC_SENDV,
+		FT_FUNC_SENDMSG,
+		FT_FUNC_INJECT,
+		FT_FUNC_INJECTDATA,
+		FT_FUNC_SENDDATA,
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE
+	],
+	test_class: [
+		FT_CAP_MSG,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+},
+{
+	prov_name: tcp,
+	test_type: [
+		FT_TEST_LATENCY,
+		FT_TEST_BANDWIDTH,
+		FT_TEST_UNIT
+	],
+	class_function: [
+		FT_FUNC_READ,
+		FT_FUNC_READV,
+		FT_FUNC_READMSG,
+		FT_FUNC_WRITE,
+		FT_FUNC_WRITEV,
+		FT_FUNC_WRITEMSG,
+		FT_FUNC_WRITEDATA
+	],
+	ep_type: [
+		FI_EP_MSG,
+	],
+	comp_type: [
+		FT_COMP_QUEUE
+	],
+	test_class: [
+		FT_CAP_RMA,
+	],
+	test_flags: FT_FLAG_QUICKTEST
+}
diff --git a/fabtests/test_configs/udp/all.test b/fabtests/test_configs/udp/all.test
index bb1c20b..a5c0582 100644
--- a/fabtests/test_configs/udp/all.test
+++ b/fabtests/test_configs/udp/all.test
@@ -31,9 +31,6 @@
 		FI_WAIT_UNSPEC,
 		FI_WAIT_FD,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/udp/functional.test b/fabtests/test_configs/udp/functional.test
index 37d7af1..6adc2df 100644
--- a/fabtests/test_configs/udp/functional.test
+++ b/fabtests/test_configs/udp/functional.test
@@ -22,9 +22,6 @@
 	cq_wait_obj: [
 		FI_WAIT_NONE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/udp/lat_bw.test b/fabtests/test_configs/udp/lat_bw.test
index fca389d..7d0420f 100644
--- a/fabtests/test_configs/udp/lat_bw.test
+++ b/fabtests/test_configs/udp/lat_bw.test
@@ -17,9 +17,6 @@
 	comp_type: [
 		FT_COMP_QUEUE,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/udp/quick.test b/fabtests/test_configs/udp/quick.test
index 3a6ae21..1ac216b 100644
--- a/fabtests/test_configs/udp/quick.test
+++ b/fabtests/test_configs/udp/quick.test
@@ -31,9 +31,6 @@
 		FI_WAIT_UNSPEC,
 		FI_WAIT_FD,
 	],
-	mode: [
-		FT_MODE_ALL,
-	],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/usnic/all.test b/fabtests/test_configs/usnic/all.test
index 958cc7e..7c93a0c 100644
--- a/fabtests/test_configs/usnic/all.test
+++ b/fabtests/test_configs/usnic/all.test
@@ -32,7 +32,7 @@
 		FI_WAIT_UNSPEC,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT, FI_RX_CQ_DATA,
 	],
 	test_class: [
 		FT_CAP_MSG,
diff --git a/fabtests/test_configs/usnic/quick.test b/fabtests/test_configs/usnic/quick.test
index 9ca00af..225d4cd 100644
--- a/fabtests/test_configs/usnic/quick.test
+++ b/fabtests/test_configs/usnic/quick.test
@@ -32,7 +32,7 @@
 		FI_WAIT_UNSPEC,
 	],
 	mode: [
-		FT_MODE_ALL,
+		FI_CONTEXT, FI_RX_CQ_DATA,
 	],
 	test_class: [
 		FT_CAP_MSG,
diff --git a/fabtests/test_configs/verbs/all.test b/fabtests/test_configs/verbs/all.test
index d5ec27b..2ad282a 100644
--- a/fabtests/test_configs/verbs/all.test
+++ b/fabtests/test_configs/verbs/all.test
@@ -25,6 +25,7 @@
 	test_class: [
 		FT_CAP_MSG,
 	],
+	mode: [FI_CONTEXT, FI_RX_CQ_DATA],
 	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
 },
 {
@@ -45,6 +46,7 @@
 	test_class: [
 		FT_CAP_MSG,
 	],
+	mode: [FI_CONTEXT, FI_RX_CQ_DATA],
 	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
 	msg_flags: FI_REMOTE_CQ_DATA,
 },
@@ -71,6 +73,7 @@
 	test_class: [
 		FT_CAP_RMA,
 	],
+	mode: [FI_CONTEXT, FI_RX_CQ_DATA],
 	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
 },
 {
@@ -91,6 +94,7 @@
 	test_class: [
 		FT_CAP_RMA,
 	],
+	mode: [FI_CONTEXT, FI_RX_CQ_DATA],
 	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
 	msg_flags: FI_REMOTE_CQ_DATA,
 },
@@ -119,6 +123,7 @@
 	test_class: [
 		FT_CAP_MSG,
 	],
+	mode: [FI_CONTEXT, FI_RX_CQ_DATA],
 	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
 },
 {
@@ -147,5 +152,6 @@
 	test_class: [
 		FT_CAP_MSG,
 	],
+	mode: [FI_CONTEXT, FI_RX_CQ_DATA],
 	mr_mode: [FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY],
 },
diff --git a/fabtests/test_configs/verbs/exclude b/fabtests/test_configs/verbs/exclude
deleted file mode 100644
index 1f5b61f..0000000
--- a/fabtests/test_configs/verbs/exclude
+++ /dev/null
@@ -1,19 +0,0 @@
-# Regex patterns of tests to exclude in runfabtests.sh
-
-# Exclude all prefix tests
--k
-
-rdm
-dgram
-
-trigger
-
-# Verbs supports only shared receive context
-shared_ctx$|shared_ctx --no|shared_ctx -e msg$|shared_ctx -e msg --no-rx
-
-scalable_ep
-multi_mr
-multi_recv
-recv_cancel
-unexpected_msg
-inj_complete
diff --git a/fabtests/test_configs/verbs/quick.test b/fabtests/test_configs/verbs/quick.test
index a8f0a23..2797f8b 100644
--- a/fabtests/test_configs/verbs/quick.test
+++ b/fabtests/test_configs/verbs/quick.test
@@ -18,9 +18,8 @@
 	comp_type: [
 		FT_COMP_QUEUE
 	],
-	mode: [
-		FT_MODE_ALL
-	],
+	mr_mode: [ FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY ],
+	mode: [ FI_CONTEXT, FI_RX_CQ_DATA ],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -48,9 +47,8 @@
 	cq_wait_obj: [
 		FI_WAIT_NONE
 	],
-	mode: [
-		FT_MODE_ALL
-	],
+	mr_mode: [ FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY ],
+	mode: [ FI_CONTEXT, FI_RX_CQ_DATA ],
 	test_class: [
 		FT_CAP_MSG,
 	],
@@ -79,9 +77,8 @@
 		FI_WAIT_UNSPEC,
 		FI_WAIT_FD,
 	],
-	mode: [
-		FT_MODE_ALL
-	],
+	mr_mode: [ FI_MR_LOCAL, FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, FI_MR_PROV_KEY ],
+	mode: [ FI_CONTEXT, FI_RX_CQ_DATA ],
 	test_class: [
 		FT_CAP_MSG,
 	],
diff --git a/fabtests/test_configs/verbs/verbs.exclude b/fabtests/test_configs/verbs/verbs.exclude
new file mode 100644
index 0000000..1f5b61f
--- /dev/null
+++ b/fabtests/test_configs/verbs/verbs.exclude
@@ -0,0 +1,19 @@
+# Regex patterns of tests to exclude in runfabtests.sh
+
+# Exclude all prefix tests
+-k
+
+rdm
+dgram
+
+trigger
+
+# Verbs supports only shared receive context
+shared_ctx$|shared_ctx --no|shared_ctx -e msg$|shared_ctx -e msg --no-rx
+
+scalable_ep
+multi_mr
+multi_recv
+recv_cancel
+unexpected_msg
+inj_complete
diff --git a/fabtests/ubertest/config.c b/fabtests/ubertest/config.c
index 16eec1c..d274b65 100644
--- a/fabtests/ubertest/config.c
+++ b/fabtests/ubertest/config.c
@@ -38,8 +38,6 @@
 #define FT_CAP_RMA	FI_RMA | FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE
 #define FT_CAP_ATOMIC	FI_ATOMICS | FI_READ | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE
 
-#define FT_MODE_ALL	FI_CONTEXT | FI_LOCAL_MR | FI_RX_CQ_DATA /*| FI_MSG_PREFIX*/
-#define FT_MODE_NONE	~0ULL
 
 struct key_t {
 	char *str;
@@ -48,68 +46,6 @@ struct key_t {
 	int val_size;
 };
 
-static struct ft_set test_sets_default[] = {
-	{
-		.prov_name = "sockets",
-		.test_type = {
-			FT_TEST_LATENCY,
-			FT_TEST_BANDWIDTH
-		},
-		.class_function = {
-			FT_FUNC_SEND,
-			FT_FUNC_SENDV,
-			FT_FUNC_SENDMSG
-		},
-		.ep_type = {
-			FI_EP_MSG,
-			FI_EP_DGRAM,
-			FI_EP_RDM
-		},
-		.av_type = {
-			FI_AV_TABLE,
-			FI_AV_MAP
-		},
-		.comp_type = {
-			FT_COMP_QUEUE
-		},
-		.mode = {
-			FT_MODE_ALL
-		},
-		.test_class = {
-			FT_CAP_MSG,
-			FT_CAP_TAGGED,
-//			FT_CAP_RMA,
-//			FT_CAP_ATOMIC
-		},
-		.test_flags = FT_FLAG_QUICKTEST
-	},
-	{
-		.prov_name = "verbs",
-		.test_type = {
-			FT_TEST_LATENCY,
-			FT_TEST_BANDWIDTH
-		},
-		.class_function = {
-			FT_FUNC_SEND,
-			FT_FUNC_SENDV,
-			FT_FUNC_SENDMSG
-		},
-		.ep_type = {
-			FI_EP_MSG,
-		},
-		.comp_type = {
-			FT_COMP_QUEUE
-		},
-		.mode = {
-			FT_MODE_ALL
-		},
-		.test_class = {
-			FT_CAP_MSG,
-		},
-		.test_flags = FT_FLAG_QUICKTEST
-	},
-};
-
 static struct ft_series test_series;
 
 size_t sm_size_array[] = {
@@ -458,14 +394,19 @@ static int ft_parse_num(char *str, int len, struct key_t *key, void *buf)
 	} else if (!strncmp(key->str, "tx_op_flags", strlen("tx_op_flags"))) {
 		TEST_ENUM_SET_N_RETURN(str, len, FI_COMPLETION, uint64_t, buf);
 		FT_ERR("Unknown tx_op_flags");
-	} else {
+	} else if (!strncmp(key->str, "comp_type", strlen("comp_type"))) {
 		TEST_ENUM_SET_N_RETURN(str, len, FT_COMP_QUEUE, enum ft_comp_type, buf);
 		TEST_ENUM_SET_N_RETURN(str, len, FT_COMP_CNTR, enum ft_comp_type, buf);
 		TEST_ENUM_SET_N_RETURN(str, len, FT_COMP_ALL, enum ft_comp_type, buf);
-		TEST_SET_N_RETURN(str, len, "FT_MODE_ALL", FT_MODE_ALL, uint64_t, buf);
-		TEST_SET_N_RETURN(str, len, "FT_MODE_NONE", FT_MODE_NONE, uint64_t, buf);
+		FT_ERR("Unknown comp_type");
+	} else if (!strncmp(key->str, "mode", strlen("mode"))) {
+		TEST_ENUM_SET_N_RETURN(str, len, FI_CONTEXT, uint64_t, buf);
+		TEST_ENUM_SET_N_RETURN(str, len, FI_RX_CQ_DATA, uint64_t, buf);
+		FT_ERR("Unsupported mode bit");
+	} else if (!strncmp(key->str, "test_flags", strlen("test_flags"))) {
 		TEST_SET_N_RETURN(str, len, "FT_FLAG_QUICKTEST", FT_FLAG_QUICKTEST, uint64_t, buf);
-		FT_ERR("Unknown comp_type/mode/test_flags");
+	} else {
+		FT_ERR("Unknown test configuration key");
 	}
 
 	return -1;
@@ -682,9 +623,8 @@ struct ft_series *fts_load(char *filename)
 		free(config);
 		fclose(fp);
 	} else {
-		printf("No config file given. Using default tests.\n");
-		test_series.sets = test_sets_default;
-		test_series.nsets = sizeof(test_sets_default) / sizeof(test_sets_default[0]);
+		printf("Test config file required.\n");
+		exit(1);
 	}
 
 	for (fts_start(&test_series, 0); !fts_end(&test_series, 0);
@@ -704,8 +644,7 @@ err1:
 
 void fts_close(struct ft_series *series)
 {
-	if (series->sets != test_sets_default)
-		free(series->sets);
+	free(series->sets);
 }
 
 void fts_start(struct ft_series *series, int index)
@@ -894,8 +833,11 @@ void fts_cur_info(struct ft_series *series, struct ft_info *info)
 		while (set->tx_op_flags[i])
 			info->tx_op_flags |= set->tx_op_flags[i++];
 	}
-	info->mode = !set->mode[series->cur_mode] ?
-			FT_MODE_ALL : set->mode[series->cur_mode];
+	if (set->mode[0]) {
+		i = 0;
+		while (set->mode[i])
+			info->mode |= set->mode[i++];
+	}
 
 	info->ep_type = set->ep_type[series->cur_ep];
 	info->av_type = set->av_type[series->cur_av];
diff --git a/fabtests/ubertest/ofi_atomic.c b/fabtests/ubertest/ofi_atomic.c
index 075d722..76a6c79 100644
--- a/fabtests/ubertest/ofi_atomic.c
+++ b/fabtests/ubertest/ofi_atomic.c
@@ -55,12 +55,12 @@
 #define OFI_OP_READ(type,dst,src)  /* src unused, dst is written to result */
 #define OFI_OP_WRITE(type,dst,src) (dst) = (src)
 
-#define OFI_OP_CSWAP_EQ(type,dst,src,cmp) if ((dst) == (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_NE(type,dst,src,cmp) if ((dst) != (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_LE(type,dst,src,cmp) if ((dst) <= (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_LT(type,dst,src,cmp) if ((dst) <  (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_GE(type,dst,src,cmp) if ((dst) >= (cmp)) (dst) = (src)
-#define OFI_OP_CSWAP_GT(type,dst,src,cmp) if ((dst) >  (cmp)) (dst) = (src)
+#define OFI_OP_CSWAP_EQ(type,dst,src,cmp) if ((cmp) == (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_NE(type,dst,src,cmp) if ((cmp) != (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_LE(type,dst,src,cmp) if ((cmp) <= (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_LT(type,dst,src,cmp) if ((cmp) <  (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_GE(type,dst,src,cmp) if ((cmp) >= (dst)) (dst) = (src)
+#define OFI_OP_CSWAP_GT(type,dst,src,cmp) if ((cmp) >  (dst)) (dst) = (src)
 #define OFI_OP_MSWAP(type,dst,src,cmp)    (dst) = (((src) & (cmp)) | \
 						   ((dst) & ~(cmp)))
 
diff --git a/fabtests/ubertest/test_ctrl.c b/fabtests/ubertest/test_ctrl.c
index cf3757f..dac2a7e 100644
--- a/fabtests/ubertest/test_ctrl.c
+++ b/fabtests/ubertest/test_ctrl.c
@@ -70,7 +70,7 @@ static int ft_init_rx_control(void)
 	ft_rx_ctrl.cq_format = FI_CQ_FORMAT_DATA;
 	ft_rx_ctrl.addr = FI_ADDR_UNSPEC;
 
-	ft_rx_ctrl.msg_size = med_size_array[med_size_cnt - 1];
+	ft_rx_ctrl.msg_size = ft_ctrl.size_array[ft_ctrl.size_cnt - 1];
 	if (fabric_info && fabric_info->ep_attr &&
 	    fabric_info->ep_attr->max_msg_size &&
 	    fabric_info->ep_attr->max_msg_size < ft_rx_ctrl.msg_size)
@@ -120,13 +120,8 @@ static int ft_init_control(void)
 	ft_ctrl.iov_array = sm_size_array;
 	ft_ctrl.iov_cnt = sm_size_cnt;
 
-	if (test_info.test_class & FI_RMA) {
-		ft_ctrl.size_array = lg_size_array;
-		ft_ctrl.size_cnt = lg_size_cnt;
-	} else {
-		ft_ctrl.size_array = med_size_array;
-		ft_ctrl.size_cnt = med_size_cnt;
-	}
+	ft_ctrl.size_array = lg_size_array;
+	ft_ctrl.size_cnt = lg_size_cnt;
 
 	ret = ft_init_rx_control();
 	if (ret)
diff --git a/fabtests/ubertest/uber.c b/fabtests/ubertest/uber.c
index 52ed2f6..a98885b 100644
--- a/fabtests/ubertest/uber.c
+++ b/fabtests/ubertest/uber.c
@@ -68,8 +68,6 @@ enum {
 
 static int results[FT_MAX_RESULT];
 static char *filename = NULL;
-static char *provname = NULL;
-static char *testname = NULL;
 
 
 static int ft_nullstr(char *str)
@@ -370,7 +368,7 @@ static int ft_skip_info(struct fi_info *hints, struct fi_info *info)
 
 	//check needed to skip utility providers, unless requested
 	skip = (!ft_util_name(hints->fabric_attr->prov_name, &len) &&
-		strcmp(hints->fabric_attr->prov_name,
+		strcasecmp(hints->fabric_attr->prov_name,
 		info->fabric_attr->prov_name));
 
 	ret = ft_exchange_uint32(skip, &remote_skip);
@@ -598,6 +596,15 @@ static int ft_server_child()
 	if (ret && ret != -FI_ENODATA) {
 		FT_PRINTERR("fi_getinfo", ret);
 	} else {
+		/* Temporary fix to run one set of tests, rather than
+		 * iterating over all interfaces / addresses.
+		 * TODO: Remove iteration from ft_fw_process_list_server.
+		 */
+		if (info && info->next) {
+			fi_freeinfo(info->next);
+			info->next = NULL;
+		}
+
 		ret = ft_fw_process_list_server(hints, info);
 		if (ret != -FI_ENODATA)
 			fi_freeinfo(info);
@@ -682,8 +689,16 @@ static int ft_client_child(void)
 
 		result = fi_getinfo(FT_FIVERSION, ft_strptr(test_info.node),
 				 ft_strptr(test_info.service), 0, hints, &info);
-		if (result) {
+		if (result)
 			FT_PRINTERR("fi_getinfo", result);
+
+		/* Temporary fix to run one set of tests, rather than
+		 * iterating over all interfaces / addresses.
+		 * TODO: Remove iteration from ft_fw_process_list_client.
+		 */
+		if (info && info->next) {
+			fi_freeinfo(info->next);
+			info->next = NULL;
 		}
 
 		ret = ft_fw_process_list_client(hints, info);
@@ -769,17 +784,14 @@ static void ft_fw_usage(char *program)
 {
 	fprintf(stderr, "Usage:\n");
 	fprintf(stderr, "  %s [OPTIONS] \t\t\tstart server\n", program);
-	fprintf(stderr, "  %s [OPTIONS] <server_node> \tconnect to server\n", program);
+	fprintf(stderr, "  %s [OPTIONS] -u config_file <server_node> \tconnect to server\n", program);
 	fprintf(stderr, "\nOptions:\n");
 	FT_PRINT_OPTS_USAGE("-q <service_port>", "Management port for test");
 	FT_PRINT_OPTS_USAGE("-h", "display this help output");
 	fprintf(stderr, "\nServer only options:\n");
 	FT_PRINT_OPTS_USAGE("-x", "exit after test run");
 	fprintf(stderr, "\nClient only options:\n");
-	FT_PRINT_OPTS_USAGE("-u <test_config_file>", "test configuration file "
-		"(Either config file or both provider and test name are required)");
-	FT_PRINT_OPTS_USAGE("-p <provider_name>", " provider name");
-	FT_PRINT_OPTS_USAGE("-t <test_name>", "test name");
+	FT_PRINT_OPTS_USAGE("-u <test_config_file>", "test configuration file ");
 	FT_PRINT_OPTS_USAGE("-y <start_test_index>", "");
 	FT_PRINT_OPTS_USAGE("-z <end_test_index>", "");
 	FT_PRINT_OPTS_USAGE("-s <address>", "source address");
@@ -792,77 +804,6 @@ void ft_free()
 {
 	if (filename)
 		free(filename);
-	if (testname)
-		free(testname);
-	if (provname)
-		free(provname);
-}
-
-static int ft_get_config_file(char *provname, char *testname, char **filename)
-{
-	char **prov_vec, **path_vec, *str;
-	size_t i, prov_count, path_count, len;
-	int ret = -FI_ENOMEM;
-
-	// TODO use macro for ";"
-	prov_vec = ft_split_and_alloc(provname, ";", &prov_count);
-	if (!prov_vec) {
-		FT_ERR("Unable to split provname\n");
-		return -FI_EINVAL;
-	}
-
-	/* prov_count + count_of(CONFIG_PATH, "test_configs", "testname", ".test") */
-	path_count = prov_count + 4;
-	path_vec = calloc(path_count, sizeof(*path_vec));
-	if (!path_vec)
-		goto err1;
-
-	path_vec[0] = CONFIG_PATH;
-	path_vec[1] = "test_configs";
-
-	/* Path for "prov1;prov2;prov3;..." is ".../prov3/prov2/prov1" */
-	for (i = 0; i < prov_count; i++)
-		path_vec[i + 2] = prov_vec[prov_count - i - 1];
-
-	path_vec[prov_count + 2] = testname;
-	path_vec[prov_count + 3] = "test";
-
-	for (i = 0, len = 0; i < path_count; i++)
-		len += strlen(path_vec[i]) + 1;
-
-	// NULL char at the end
-	len++;
-
-	*filename = calloc(1, len);
-	if (!*filename)
-		goto err2;
-
-	for (i = 0, str = *filename; i < path_count; i++) {
-		if (i < path_count - 1)
-			ret = snprintf(str, len, "/%s", path_vec[i]);
-		else
-			ret = snprintf(str, len, ".%s", path_vec[i]);
-		if (ret < 0)
-			goto err3;
-
-		if (ret >= (int)len) {
-			ret = -FI_ETRUNC;
-			goto err3;
-		}
-		str += ret;
-		len -= ret;
-	}
-	free(path_vec);
-	ft_free_string_array(prov_vec);
-	return 0;
-err3:
-	free(*filename);
-	*filename = NULL;
-err2:
-	free(path_vec);
-err1:
-	ft_free_string_array(prov_vec);
-	return ret;
 }
 
 int main(int argc, char **argv)
@@ -871,17 +812,11 @@ int main(int argc, char **argv)
 	opts = INIT_OPTS;
 	int ret, op;
 
-	while ((op = getopt(argc, argv, "p:u:t:q:xy:z:hf" ADDR_OPTS)) != -1) {
+	while ((op = getopt(argc, argv, "u:q:xy:z:hf" ADDR_OPTS)) != -1) {
 		switch (op) {
 		case 'u':
 			filename = strdup(optarg);
 			break;
-		case 'p':
-			provname = strdup(optarg);
-			break;
-		case 't':
-			testname = strdup(optarg);
-			break;
 		case 'q':
 			service = optarg;
 			break;
@@ -919,21 +854,9 @@ int main(int argc, char **argv)
 		if (!opts.dst_port)
 			opts.dst_port = default_port;
 		if (!filename) {
-			if (!testname || !provname) {
-				ft_fw_usage(argv[0]);
-				ft_free();
-				exit(1);
-			} else {
-				ret = ft_get_config_file(provname, testname,
-							 &filename);
-				if (ret < 0) {
-					ft_free();
-					exit(1);
-				}
-			}
-		} else {
-			testname = NULL;
-			provname = NULL;
+			ft_fw_usage(argv[0]);
+			ft_free();
+			exit(1);
 		}
 		series = fts_load(filename);
 		if (!series) {
diff --git a/fabtests/unit/getinfo_test.c b/fabtests/unit/getinfo_test.c
index 63b2cd8..d69ee2d 100644
--- a/fabtests/unit/getinfo_test.c
+++ b/fabtests/unit/getinfo_test.c
@@ -491,6 +491,58 @@ out:
 
 
 /*
+ * Progress checks
+ */
+static int init_data_manual(struct fi_info *hints)
+{
+	hints->domain_attr->data_progress = FI_PROGRESS_MANUAL;
+	return 0;
+}
+
+static int init_data_auto(struct fi_info *hints)
+{
+	hints->domain_attr->data_progress = FI_PROGRESS_AUTO;
+	return 0;
+}
+
+static int init_ctrl_manual(struct fi_info *hints)
+{
+	hints->domain_attr->control_progress = FI_PROGRESS_MANUAL;
+	return 0;
+}
+
+static int init_ctrl_auto(struct fi_info *hints)
+{
+	hints->domain_attr->control_progress = FI_PROGRESS_AUTO;
+	return 0;
+}
+
+static int check_data_manual(struct fi_info *info)
+{
+	return (info->domain_attr->data_progress != FI_PROGRESS_MANUAL) ?
+		EXIT_FAILURE : 0;
+}
+
+static int check_data_auto(struct fi_info *info)
+{
+	return (info->domain_attr->data_progress != FI_PROGRESS_AUTO) ?
+		EXIT_FAILURE : 0;
+}
+
+static int check_ctrl_manual(struct fi_info *info)
+{
+	return (info->domain_attr->control_progress != FI_PROGRESS_MANUAL) ?
+		EXIT_FAILURE : 0;
+}
+
+static int check_ctrl_auto(struct fi_info *info)
+{
+	return (info->domain_attr->control_progress != FI_PROGRESS_AUTO) ?
+		EXIT_FAILURE : 0;
+}
+
+
+/*
  * getinfo test
  */
 static int getinfo_unit_test(char *node, char *service, uint64_t flags,
@@ -661,6 +713,16 @@ getinfo_test(mr_mode, 5, "Test FI_MR_SCALABLE (v1.0)", NULL, NULL, 0,
 getinfo_test(mr_mode, 6, "Test mr_mode bits", NULL, NULL, 0,
 	     hints, NULL, test_mr_modes, NULL, 0)
 
+/* Progress tests */
+getinfo_test(progress, 1, "Test data manual progress", NULL, NULL, 0,
+	     hints, init_data_manual, NULL, check_data_manual, 0)
+getinfo_test(progress, 2, "Test data auto progress", NULL, NULL, 0,
+	     hints, init_data_auto, NULL, check_data_auto, 0)
+getinfo_test(progress, 3, "Test ctrl manual progress", NULL, NULL, 0,
+	     hints, init_ctrl_manual, NULL, check_ctrl_manual, 0)
+getinfo_test(progress, 4, "Test ctrl auto progress", NULL, NULL, 0,
+	     hints, init_ctrl_auto, NULL, check_ctrl_auto, 0)
+
 
 static void usage(void)
 {
@@ -734,6 +796,10 @@ int main(int argc, char **argv)
 		TEST_ENTRY_GETINFO(mr_mode4),
 		TEST_ENTRY_GETINFO(mr_mode5),
 		TEST_ENTRY_GETINFO(mr_mode6),
+		TEST_ENTRY_GETINFO(progress1),
+		TEST_ENTRY_GETINFO(progress2),
+		TEST_ENTRY_GETINFO(progress3),
+		TEST_ENTRY_GETINFO(progress4),
 		{ NULL, "" }
 	};
 
diff --git a/include/ofi.h b/include/ofi.h
index 3b93cfd..50f5dc5 100644
--- a/include/ofi.h
+++ b/include/ofi.h
@@ -65,6 +65,9 @@
 extern "C" {
 #endif
 
+/* For in-tree providers */
+#define OFI_VERSION_LATEST	FI_VERSION(FI_MAJOR_VERSION, FI_MINOR_VERSION)
+
 #define OFI_GETINFO_INTERNAL	(1ULL << 58)
 #define OFI_CORE_PROV_ONLY	(1ULL << 59)
 
@@ -205,6 +208,12 @@ static inline uint64_t roundup_power_of_two(uint64_t n)
 	return n;
 }
 
+static inline uint64_t rounddown_power_of_two(uint64_t n)
+{
+	uint64_t pof2 = roundup_power_of_two(n);
+	return (pof2 > n) ? (pof2 >> 1) : pof2;
+}
+
 static inline size_t ofi_get_aligned_size(size_t size, size_t alignment)
 {
 	return ((size % alignment) == 0) ?
diff --git a/include/ofi_abi.h b/include/ofi_abi.h
index 8ba35a4..368109a 100644
--- a/include/ofi_abi.h
+++ b/include/ofi_abi.h
@@ -111,7 +111,7 @@ extern "C" {
  * name appended with the ABI version that it is compatible with.
  */
 
-#define CURRENT_ABI "FABRIC_1.2"
+#define CURRENT_ABI "FABRIC_1.3"
 
 #if  HAVE_ALIAS_ATTRIBUTE == 1
 #define DEFAULT_SYMVER_PRE(a) a##_
diff --git a/include/ofi_bitmask.h b/include/ofi_bitmask.h
new file mode 100644
index 0000000..2591b22
--- /dev/null
+++ b/include/ofi_bitmask.h
@@ -0,0 +1,114 @@
+/*
+ * Copyright (c) 2019-2019 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _OFI_BITMASK_H_
+#define _OFI_BITMASK_H_
+
+#include <rdma/fi_errno.h>
+
+#include <stdint.h>
+#include <stdlib.h>
+#include <assert.h>
+#include <string.h>
+
+struct bitmask {
+	size_t size;
+	uint8_t *bytes;
+};
+
+static inline int ofi_bitmask_create(struct bitmask *mask, size_t size)
+{
+	size_t byte_size = size / 8;
+	if (byte_size % 8)
+		byte_size++;
+
+	mask->bytes = calloc(byte_size, 1);
+	if (!mask->bytes)
+		return -FI_ENOMEM;
+
+	mask->size = size;
+
+	return FI_SUCCESS;
+};
+
+static inline void ofi_bitmask_free(struct bitmask *mask)
+{
+	free(mask->bytes);
+	mask->bytes = NULL;
+};
+
+static inline size_t ofi_bitmask_bytesize(struct bitmask *mask)
+{
+	return (mask->size % 8) ? (mask->size / 8 + 1) : (mask->size / 8);
+};
+
+static inline void ofi_bitmask_unset(struct bitmask *mask, size_t idx)
+{
+	assert(idx <= mask->size);
+	mask->bytes[idx / 8] &= ~(0x01 << (idx % 8));
+};
+
+static inline void ofi_bitmask_set(struct bitmask *mask, size_t idx)
+{
+	assert(idx <= mask->size);
+	mask->bytes[idx / 8] |= (0x01 << (idx % 8));
+};
+
+static inline void ofi_bitmask_set_all(struct bitmask *mask)
+{
+	memset(mask->bytes, 0xff, ofi_bitmask_bytesize(mask));
+};
+
+static inline size_t ofi_bitmask_get_lsbset(struct bitmask mask)
+{
+	int cur;
+	uint8_t tmp;
+	size_t ret = 0;
+
+	for (cur = 0; cur < (mask.size/8); cur++) {
+		if (mask.bytes[cur]) {
+			tmp = mask.bytes[cur];
+			while (!(tmp & 0x1)) {
+				tmp >>= 1;
+				ret++;
+			}
+			break;
+		} else {
+			ret += 8;
+		}
+	}
+
+	assert(ret <= (mask.size));
+	return ret;
+};
+
+#endif
diff --git a/include/ofi_coll.h b/include/ofi_coll.h
new file mode 100644
index 0000000..82e5ce6
--- /dev/null
+++ b/include/ofi_coll.h
@@ -0,0 +1,175 @@
+/*
+ * Copyright (c) 2019 Intel Corporation, Inc.  All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _OFI_COLL_H_
+#define _OFI_COLL_H_
+
+#include <rdma/fi_collective.h>
+
+#include <ofi_list.h>
+#include <ofi_atom.h>
+#include <ofi_bitmask.h>
+
+#define OFI_WORLD_GROUP_ID 0
+#define OFI_MAX_GROUP_ID 256
+#define OFI_COLL_TAG_FLAG (1ULL << 63)
+
+enum util_coll_op_type {
+	UTIL_COLL_JOIN_OP,
+	UTIL_COLL_BARRIER_OP,
+	UTIL_COLL_ALLREDUCE_OP,
+	UTIL_COLL_BROADCAST_OP,
+};
+
+struct util_av_set {
+	struct fid_av_set	av_set_fid;
+	struct util_av		*av;
+	fi_addr_t		*fi_addr_array;
+	size_t			fi_addr_count;
+	uint64_t		flags;
+	ofi_atomic32_t		ref;
+	fastlock_t		lock;
+};
+
+enum coll_work_type {
+	UTIL_COLL_SEND,
+	UTIL_COLL_RECV,
+	UTIL_COLL_REDUCE,
+	UTIL_COLL_COPY,
+	UTIL_COLL_COMP,
+};
+
+enum coll_state {
+	UTIL_COLL_WAITING,
+	UTIL_COLL_PROCESSING,
+	UTIL_COLL_COMPLETE
+};
+
+struct util_coll_operation;
+
+struct util_coll_work_item {
+	struct slist_entry		ready_entry;
+	struct dlist_entry		waiting_entry;
+	struct util_coll_operation 	*coll_op;
+	enum coll_work_type		type;
+	enum coll_state			state;
+	int				fence;
+};
+
+struct util_coll_xfer_item {
+	struct util_coll_work_item	hdr;
+	void 				*buf;
+	int				count;
+	enum fi_datatype		datatype;
+	uint64_t			tag;
+	int				remote_rank;
+};
+
+struct util_coll_copy_item {
+	struct util_coll_work_item	hdr;
+	void 				*in_buf;
+	void				*out_buf;
+	int				count;
+	enum fi_datatype		datatype;
+};
+
+struct util_coll_reduce_item {
+	struct util_coll_work_item	hdr;
+	void 				*in_buf;
+	void 				*inout_buf;
+	int				count;
+	enum fi_datatype		datatype;
+	enum fi_op			op;
+};
+
+struct util_coll_mc {
+	struct fid_mc		mc_fid;
+	struct fid_ep		*ep;
+	struct util_av_set	*av_set;
+	uint64_t		local_rank;
+	uint16_t		group_id;
+	uint16_t		seq;
+	ofi_atomic32_t		ref;
+};
+
+struct join_data {
+	struct bitmask data;
+	struct bitmask tmp;
+};
+
+struct barrier_data {
+	uint64_t data;
+	uint64_t tmp;
+};
+
+struct allreduce_data {
+	void	*data;
+	size_t	size;
+};
+
+struct util_coll_operation;
+
+typedef void (*util_coll_comp_fn_t)(struct util_coll_operation *coll_op);
+struct util_coll_operation {
+	enum util_coll_op_type		type;
+	uint32_t			cid;
+	void				*context;
+	struct util_coll_mc		*mc;
+	struct dlist_entry		work_queue;
+	union {
+		struct join_data	join;
+		struct barrier_data	barrier;
+		struct allreduce_data	allreduce;
+	} data;
+	util_coll_comp_fn_t		comp_fn;
+};
+
+int ofi_join_collective(struct fid_ep *ep, fi_addr_t coll_addr,
+			const struct fid_av_set *set, uint64_t flags,
+			struct fid_mc **mc, void *context);
+
+int ofi_av_set(struct fid_av *av, struct fi_av_set_attr *attr,
+	       struct fid_av_set **av_set_fid, void *context);
+
+ssize_t ofi_ep_barrier(struct fid_ep *ep, fi_addr_t coll_addr, void *context);
+
+ssize_t ofi_ep_allreduce(struct fid_ep *ep, const void *buf, size_t count,
+	void *desc, void *result, void *result_desc,
+	fi_addr_t coll_addr, enum fi_datatype datatype, enum fi_op op,
+	uint64_t flags, void *context);
+
+int ofi_coll_ep_progress(struct fid_ep *ep);
+
+void ofi_coll_handle_xfer_comp(uint64_t tag, void *ctx);
+
+
+#endif // _OFI_COLL_H_
diff --git a/include/ofi_enosys.h b/include/ofi_enosys.h
index 5802935..c25b358 100644
--- a/include/ofi_enosys.h
+++ b/include/ofi_enosys.h
@@ -43,6 +43,7 @@
 #include <rdma/fi_eq.h>
 #include <rdma/fi_rma.h>
 #include <rdma/fi_tagged.h>
+#include <rdma/fi_collective.h>
 
 #ifdef __cplusplus
 extern "C" {
@@ -454,6 +455,55 @@ int fi_no_av_insertsym(struct fid_av *av, const char *node, size_t nodecnt,
 int fi_no_av_remove(struct fid_av *av, fi_addr_t *fi_addr, size_t count,
 			uint64_t flags);
 
+/*
+static struct fi_ops_collective X = {
+	.size = sizeof(struct fi_ops_collective),
+	.barrier = fi_coll_no_barrier,
+	.broadcast = fi_coll_no_broadcast,
+	.alltoall = fi_coll_no_alltoall,
+	.allreduce = fi_coll_no_allreduce,
+	.allgather = fi_coll_no_allgather,
+	.reduce_scatter = fi_coll_no_reduce_scatter,
+	.reduce = fi_coll_no_reduce,
+	.scatter = fi_coll_no_scatter,
+	.gather = fi_coll_no_gather,
+	.msg = fi_coll_no_msg,
+};
+*/
+ssize_t fi_coll_no_barrier(struct fid_ep *ep, fi_addr_t coll_addr, void *context);
+ssize_t fi_coll_no_broadcast(struct fid_ep *ep, void *buf, size_t count, void *desc,
+			     fi_addr_t coll_addr, fi_addr_t root_addr,
+			     enum fi_datatype datatype, uint64_t flags, void *context);
+ssize_t fi_coll_no_alltoall(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			    void *result, void *result_desc, fi_addr_t coll_addr,
+			    enum fi_datatype datatype, uint64_t flags, void *context);
+ssize_t fi_coll_no_allreduce(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			     void *result, void *result_desc, fi_addr_t coll_addr,
+			     enum fi_datatype datatype, enum fi_op op, uint64_t flags,
+			     void *context);
+ssize_t fi_coll_no_allgather(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			     void *result, void *result_desc, fi_addr_t coll_addr,
+			     enum fi_datatype datatype, uint64_t flags, void *context);
+ssize_t fi_coll_no_reduce_scatter(struct fid_ep *ep, const void *buf, size_t count,
+				  void *desc, void *result, void *result_desc,
+				  fi_addr_t coll_addr, enum fi_datatype datatype,
+				  enum fi_op op, uint64_t flags, void *context);
+ssize_t fi_coll_no_reduce(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			  void *result, void *result_desc, fi_addr_t coll_addr,
+			  fi_addr_t root_addr, enum fi_datatype datatype, enum fi_op op,
+			  uint64_t flags, void *context);
+ssize_t fi_coll_no_scatter(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			   void *result, void *result_desc, fi_addr_t coll_addr,
+			   fi_addr_t root_addr, enum fi_datatype datatype, uint64_t flags,
+			   void *context);
+ssize_t fi_coll_no_gather(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			  void *result, void *result_desc, fi_addr_t coll_addr,
+			  fi_addr_t root_addr, enum fi_datatype datatype, uint64_t flags,
+			  void *context);
+ssize_t fi_coll_no_msg(struct fid_ep *ep, const struct fi_msg_collective *msg,
+		       struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		       uint64_t flags);
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/include/ofi_list.h b/include/ofi_list.h
index 0cbe06b..1b79d0a 100644
--- a/include/ofi_list.h
+++ b/include/ofi_list.h
@@ -712,4 +712,15 @@ static inline int dlistfd_wait_avail(struct dlistfd_head *head, int timeout)
 	return ret ? ret : !dlistfd_empty(head);
 }
 
+static inline struct dlist_entry *
+dlistfd_remove_first_match(struct dlistfd_head *head, dlist_func_t *match,
+			   const void *arg)
+{
+	struct dlist_entry *entry =
+		dlist_remove_first_match(&head->list, match, arg);
+	if (entry)
+		dlistfd_reset(head);
+	return entry;
+}
+
 #endif /* _OFI_LIST_H_ */
diff --git a/include/ofi_mem.h b/include/ofi_mem.h
index 9ffc4ac..92f3123 100644
--- a/include/ofi_mem.h
+++ b/include/ofi_mem.h
@@ -72,6 +72,8 @@ static inline long ofi_get_page_size()
 }
 ssize_t ofi_get_hugepage_size(void);
 
+size_t ofi_get_mem_size(void);
+
 
 /* We implement memdup to avoid external library dependency */
 static inline void *mem_dup(const void *src, size_t size)
diff --git a/include/ofi_mr.h b/include/ofi_mr.h
index e4edca1..e7ff1af 100644
--- a/include/ofi_mr.h
+++ b/include/ofi_mr.h
@@ -1,5 +1,6 @@
 /*
  * Copyright (c) 2017-2019 Intel Corporation, Inc. All rights reserved.
+ * Copyright (c) 2019 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -102,7 +103,7 @@ static inline uint64_t ofi_mr_get_prov_mode(uint32_t version,
 struct ofi_mr_cache;
 
 struct ofi_mem_monitor {
-	fastlock_t			lock;
+	pthread_mutex_t 		lock;
 	struct dlist_entry		list;
 
 	int (*subscribe)(struct ofi_mem_monitor *notifier,
@@ -165,7 +166,7 @@ struct ofi_mr_map {
 	const struct fi_provider *prov;
 	struct ofi_rbmap	*rbtree;
 	uint64_t		key;
-	enum fi_mr_mode		mode;
+	int			mode;
 };
 
 int ofi_mr_map_init(const struct fi_provider *in_prov, int mode,
@@ -222,7 +223,7 @@ extern struct ofi_mr_cache_params	cache_params;
 
 struct ofi_mr_entry {
 	struct ofi_mr_info		info;
-	unsigned int			cached:1;
+	void				*storage_context;
 	unsigned int			subscribed:1;
 	int				use_cnt;
 	struct dlist_entry		lru_entry;
@@ -285,6 +286,24 @@ void ofi_mr_cache_notify(struct ofi_mr_cache *cache, const void *addr, size_t le
 bool ofi_mr_cache_flush(struct ofi_mr_cache *cache);
 int ofi_mr_cache_search(struct ofi_mr_cache *cache, const struct fi_mr_attr *attr,
 			struct ofi_mr_entry **entry);
+/**
+ * Given an attr (with an iov range), if the iov range is already registered,
+ * return the corresponding ofi_mr_entry. Otherwise, return NULL.
+ * The caller must call ofi_mr_cache_delete on the entry before cleanup if
+ * the returned entry is not NULL.
+ *
+ * @param[in]	cache		The cache the entry belongs to
+ * @param[in]	attr		Information about the region to search
+ *
+ * @returns	entry		The registered entry corresponding to the
+ *				region described in attr
+ * @returns	NULL		The region described in attr is not registered
+ *				with the cache.
+ */
+struct ofi_mr_entry *ofi_mr_cache_find(struct ofi_mr_cache *cache,
+				       const struct fi_mr_attr *attr);
+int ofi_mr_cache_reg(struct ofi_mr_cache *cache, const struct fi_mr_attr *attr,
+		     struct ofi_mr_entry **entry);
 void ofi_mr_cache_delete(struct ofi_mr_cache *cache, struct ofi_mr_entry *entry);
 
 
diff --git a/include/ofi_prov.h b/include/ofi_prov.h
index 2fa887b..c4a63cb 100644
--- a/include/ofi_prov.h
+++ b/include/ofi_prov.h
@@ -125,17 +125,6 @@ USNIC_INI ;
 #  define USNIC_INIT NULL
 #endif
 
-#if (HAVE_MLX) && (HAVE_MLX_DL)
-#  define MLX_INI FI_EXT_INI
-#  define MLX_INIT NULL
-#elif (HAVE_MLX)
-#  define MLX_INI INI_SIG(fi_mlx_ini)
-#  define MLX_INIT fi_mlx_ini()
-MLX_INI ;
-#else
-#  define MLX_INIT NULL
-#endif
-
 #if (HAVE_UDP) && (HAVE_UDP_DL)
 #  define UDP_INI FI_EXT_INI
 #  define UDP_INIT NULL
diff --git a/include/ofi_recvwin.h b/include/ofi_recvwin.h
index 917a0c3..39e9fe1 100644
--- a/include/ofi_recvwin.h
+++ b/include/ofi_recvwin.h
@@ -86,6 +86,18 @@ ofi_recvwin_queue_msg(struct name *recvq, entrytype * msg, uint64_t id)	\
 	ofi_cirque_commit(recvq->pending);				\
 	return 0;							\
 }									\
+				                                        \
+static inline entrytype *						\
+ofi_recvwin_get_msg(struct name *recvq, uint64_t id)	   		\
+{		                                           		\
+	int read_idx;							\
+									\
+	assert(ofi_recvwin_is_allowed(recvq, id));			\
+	read_idx = (ofi_cirque_rindex(recvq->pending)			\
+		    + (id - recvq->exp_msg_id))				\
+		    & recvq->pending->size_mask;			\
+	return &recvq->pending->buf[read_idx];				\
+}									\
 									\
 static inline entrytype *						\
 ofi_recvwin_get_next_msg(struct name *recvq)				\
diff --git a/include/ofi_shm.h b/include/ofi_shm.h
index 0f5351c..0b626ba 100644
--- a/include/ofi_shm.h
+++ b/include/ofi_shm.h
@@ -149,12 +149,19 @@ struct smr_cmd {
 #define SMR_INJECT_SIZE		4096
 #define SMR_COMP_INJECT_SIZE	(SMR_INJECT_SIZE / 2)
 
-#define SMR_NAME_SIZE	32
 struct smr_addr {
-	char		name[SMR_NAME_SIZE];
+	char		name[NAME_MAX];
 	fi_addr_t	addr;
 };
 
+
+struct smr_ep_name {
+	char name[NAME_MAX];
+	struct dlist_entry entry;
+};
+
+struct dlist_entry ep_name_list;
+
 struct smr_region;
 
 struct smr_peer {
diff --git a/include/ofi_tree.h b/include/ofi_tree.h
index 5415c66..0470a91 100644
--- a/include/ofi_tree.h
+++ b/include/ofi_tree.h
@@ -87,6 +87,7 @@ struct ofi_rbnode *ofi_rbmap_search(struct ofi_rbmap *map, void *key,
 int ofi_rbmap_insert(struct ofi_rbmap *map, void *key, void *data,
 		struct ofi_rbnode **node);
 void ofi_rbmap_delete(struct ofi_rbmap *map, struct ofi_rbnode *node);
+int ofi_rbmap_find_delete(struct ofi_rbmap *map, void *key);
 int ofi_rbmap_empty(struct ofi_rbmap *map);
 
 
diff --git a/include/ofi_util.h b/include/ofi_util.h
index 9fb544d..de1cdac 100644
--- a/include/ofi_util.h
+++ b/include/ofi_util.h
@@ -64,6 +64,7 @@
 #include <ofi_indexer.h>
 #include <ofi_epoll.h>
 #include <ofi_proto.h>
+#include <ofi_bitmask.h>
 
 #include "rbtree.h"
 #include "uthash.h"
@@ -82,6 +83,9 @@ extern "C" {
 /* Indicates that an EP has been bound to a counter */
 #define OFI_CNTR_ENABLED	(1ULL << 61)
 
+/* Memory registration should not be cached */
+#define OFI_MR_NOCACHE		BIT_ULL(60)
+
 #define OFI_Q_STRERROR(prov, level, subsys, q, q_str, entry, q_strerror)	\
 	FI_LOG(prov, level, subsys, "fi_" q_str "_readerr: err: %s (%d), "	\
 	       "prov_err: %s (%d)\n", strerror((entry)->err), (entry)->err,	\
@@ -291,6 +295,9 @@ struct util_ep {
 	fastlock_t		lock;
 	ofi_fastlock_acquire_t	lock_acquire;
 	ofi_fastlock_release_t	lock_release;
+
+	struct bitmask		*coll_cid_mask;
+	struct slist		coll_ready_queue;
 };
 
 int ofi_ep_bind_av(struct util_ep *util_ep, struct util_av *av);
@@ -660,6 +667,7 @@ struct util_av {
 	struct util_av_entry	*hash;
 	struct ofi_bufpool	*av_entry_pool;
 
+	struct util_coll_mc	*coll_mc;
 	void			*context;
 	uint64_t		flags;
 	size_t			count;
@@ -800,7 +808,7 @@ const char *ofi_eq_strerror(struct fid_eq *eq_fid, int prov_errno,
 #define FI_PRIMARY_CAPS	(FI_MSG | FI_RMA | FI_TAGGED | FI_ATOMICS | FI_MULTICAST | \
 			 FI_NAMED_RX_CTX | FI_DIRECTED_RECV | \
 			 FI_READ | FI_WRITE | FI_RECV | FI_SEND | \
-			 FI_REMOTE_READ | FI_REMOTE_WRITE)
+			 FI_REMOTE_READ | FI_REMOTE_WRITE | FI_COLLECTIVE)
 
 #define FI_SECONDARY_CAPS (FI_MULTI_RECV | FI_SOURCE | FI_RMA_EVENT | \
 			   FI_SHARED_AV | FI_TRIGGER | FI_FENCE | \
@@ -811,6 +819,9 @@ const char *ofi_eq_strerror(struct fid_eq *eq_fid, int prov_errno,
 #define OFI_TX_RMA_CAPS (FI_RMA | FI_READ | FI_WRITE)
 #define OFI_RX_RMA_CAPS (FI_RMA | FI_REMOTE_READ | FI_REMOTE_WRITE)
 
+int ofi_check_ep_type(const struct fi_provider *prov,
+		      const struct fi_ep_attr *prov_attr,
+		      const struct fi_ep_attr *user_attr);
 int ofi_check_mr_mode(const struct fi_provider *prov, uint32_t api_version,
 		      int prov_mode, const struct fi_info *user_info);
 int ofi_check_fabric_attr(const struct fi_provider *prov,
diff --git a/include/rdma/fabric.h b/include/rdma/fabric.h
index d905ef5..7a4fdbd 100644
--- a/include/rdma/fabric.h
+++ b/include/rdma/fabric.h
@@ -77,7 +77,7 @@ extern "C" {
 #endif
 
 #define FI_MAJOR_VERSION 1
-#define FI_MINOR_VERSION 8
+#define FI_MINOR_VERSION 9
 
 enum {
 	FI_PATH_MAX		= 256,
@@ -162,6 +162,7 @@ typedef struct fid *fid_t;
 #define FI_COMMIT_COMPLETE	(1ULL << 30)
 #define FI_MATCH_COMPLETE	(1ULL << 31)
 
+#define FI_HMEM			(1ULL << 47)
 #define FI_VARIABLE_MSG		(1ULL << 48)
 #define FI_RMA_PMEM		(1ULL << 49)
 #define FI_SOURCE_ERR		(1ULL << 50)
@@ -231,6 +232,7 @@ enum fi_mr_mode {
 #define FI_MR_MMU_NOTIFY	(1 << 7)
 #define FI_MR_RMA_EVENT		(1 << 8)
 #define FI_MR_ENDPOINT		(1 << 9)
+#define FI_MR_HMEM		(1 << 10)
 
 enum fi_progress {
 	FI_PROGRESS_UNSPEC,
@@ -316,6 +318,28 @@ enum {
 	FI_PROTO_EFA
 };
 
+enum {
+	FI_TC_UNSPEC = 0,
+	FI_TC_DSCP = 0x100,
+	FI_TC_LABEL = 0x200,
+	FI_TC_BEST_EFFORT = FI_TC_LABEL,
+	FI_TC_LOW_LATENCY,
+	FI_TC_DEDICATED_ACCESS,
+	FI_TC_BULK_DATA,
+	FI_TC_SCAVENGER,
+	FI_TC_NETWORK_CTRL,
+};
+
+static inline uint32_t fi_tc_dscp_set(uint8_t dscp)
+{
+	return ((uint32_t) dscp) | FI_TC_DSCP;
+}
+
+static inline uint8_t fi_tc_dscp_get(uint32_t tclass)
+{
+	return tclass & FI_TC_DSCP ? (uint8_t) tclass : 0;
+}
+
 /* Mode bits */
 #define FI_CONTEXT		(1ULL << 59)
 #define FI_MSG_PREFIX		(1ULL << 58)
@@ -337,6 +361,7 @@ struct fi_tx_attr {
 	size_t			size;
 	size_t			iov_limit;
 	size_t			rma_iov_limit;
+	uint32_t		tclass;
 };
 
 struct fi_rx_attr {
@@ -393,6 +418,7 @@ struct fi_domain_attr {
 	size_t 			auth_key_size;
 	size_t			max_err_data;
 	size_t			mr_cnt;
+	uint32_t		tclass;
 };
 
 struct fi_fabric_attr {
@@ -486,6 +512,7 @@ enum {
 	FI_CLASS_CONNREQ,
 	FI_CLASS_MC,
 	FI_CLASS_NIC,
+	FI_CLASS_AV_SET,
 };
 
 struct fi_eq_attr;
@@ -645,6 +672,7 @@ enum fi_type {
 	FI_TYPE_MR_MODE,
 	FI_TYPE_OP_TYPE,
 	FI_TYPE_FID,
+	FI_TYPE_COLLECTIVE_OP,
 };
 
 char *fi_tostr(const void *data, enum fi_type datatype);
@@ -666,7 +694,6 @@ struct fi_param {
 int fi_getparams(struct fi_param **params, int *count);
 void fi_freeparams(struct fi_param *params);
 
-
 #ifdef FABRIC_DIRECT
 #include <rdma/fi_direct.h>
 #endif	/* FABRIC_DIRECT */
diff --git a/include/rdma/fi_atomic.h b/include/rdma/fi_atomic.h
index a7dc068..cc8b1e5 100644
--- a/include/rdma/fi_atomic.h
+++ b/include/rdma/fi_atomic.h
@@ -44,7 +44,6 @@ extern "C" {
 
 
 /* Atomic flags */
-#define FI_SCATTER		(1ULL << 57)
 #define FI_FETCH_ATOMIC		(1ULL << 58)
 #define FI_COMPARE_ATOMIC	(1ULL << 59)
 
diff --git a/include/rdma/fi_collective.h b/include/rdma/fi_collective.h
index 67eff6a..2594613 100644
--- a/include/rdma/fi_collective.h
+++ b/include/rdma/fi_collective.h
@@ -42,6 +42,26 @@
 extern "C" {
 #endif
 
+#ifdef FABRIC_DIRECT
+#include <rdma/fi_direct_collective_def.h>
+#endif /* FABRIC_DIRECT */
+
+#ifndef FABRIC_DIRECT_COLLECTIVE_DEF
+
+enum fi_collective_op {
+	FI_BARRIER,
+	FI_BROADCAST,
+	FI_ALLTOALL,
+	FI_ALLREDUCE,
+	FI_ALLGATHER,
+	FI_REDUCE_SCATTER,
+	FI_REDUCE,
+	FI_SCATTER,
+	FI_GATHER,
+};
+
+#endif
+
 
 struct fi_ops_av_set {
 	size_t	size;
@@ -52,6 +72,7 @@ struct fi_ops_av_set {
 	int	(*diff)(struct fid_av_set *dst, const struct fid_av_set *src);
 	int	(*insert)(struct fid_av_set *set, fi_addr_t addr);
 	int	(*remove)(struct fid_av_set *set, fi_addr_t addr);
+	int	(*addr)(struct fid_av_set *set, fi_addr_t *coll_addr);
 };
 
 struct fid_av_set {
@@ -64,6 +85,7 @@ struct fi_collective_attr {
 	struct fi_atomic_attr	datatype_attr;
 	size_t			max_members;
 	uint64_t		mode;
+	enum fi_collective_op	coll;
 };
 
 struct fi_collective_addr {
@@ -76,6 +98,8 @@ struct fi_msg_collective {
 	void			**desc;
 	size_t			iov_count;
 	fi_addr_t		coll_addr;
+	fi_addr_t		root_addr;
+	enum fi_collective_op	coll;
 	enum fi_datatype	datatype;
 	enum fi_op		op;
 	void			*context;
@@ -83,14 +107,47 @@ struct fi_msg_collective {
 
 struct fi_ops_collective {
 	size_t	size;
+
 	ssize_t	(*barrier)(struct fid_ep *ep, fi_addr_t coll_addr,
 			void *context);
-	ssize_t	(*writeread)(struct fid_ep *ep,
+	ssize_t	(*broadcast)(struct fid_ep *ep,
+			void *buf, size_t count, void *desc,
+			fi_addr_t coll_addr, fi_addr_t root_addr,
+			enum fi_datatype datatype, uint64_t flags, void *context);
+	ssize_t	(*alltoall)(struct fid_ep *ep,
+			const void *buf, size_t count, void *desc,
+			void *result, void *result_desc, fi_addr_t coll_addr,
+			enum fi_datatype datatype, uint64_t flags, void *context);
+	ssize_t	(*allreduce)(struct fid_ep *ep,
+			const void *buf, size_t count, void *desc,
+			void *result, void *result_desc, fi_addr_t coll_addr,
+			enum fi_datatype datatype, enum fi_op op,
+			uint64_t flags, void *context);
+	ssize_t	(*allgather)(struct fid_ep *ep,
+			const void *buf, size_t count, void *desc,
+			void *result, void *result_desc, fi_addr_t coll_addr,
+			enum fi_datatype datatype, uint64_t flags, void *context);
+	ssize_t	(*reduce_scatter)(struct fid_ep *ep,
 			const void *buf, size_t count, void *desc,
 			void *result, void *result_desc, fi_addr_t coll_addr,
 			enum fi_datatype datatype, enum fi_op op,
 			uint64_t flags, void *context);
-	ssize_t	(*writereadmsg)(struct fid_ep *ep,
+	ssize_t	(*reduce)(struct fid_ep *ep,
+			const void *buf, size_t count, void *desc,
+			void *result, void *result_desc, fi_addr_t coll_addr,
+			fi_addr_t root_addr, enum fi_datatype datatype, enum fi_op op,
+			uint64_t flags, void *context);
+	ssize_t	(*scatter)(struct fid_ep *ep,
+			const void *buf, size_t count, void *desc,
+			void *result, void *result_desc,
+			fi_addr_t coll_addr, fi_addr_t root_addr,
+			enum fi_datatype datatype, uint64_t flags, void *context);
+	ssize_t	(*gather)(struct fid_ep *ep,
+			const void *buf, size_t count, void *desc,
+			void *result, void *result_desc,
+			fi_addr_t coll_addr, fi_addr_t root_addr,
+			enum fi_datatype datatype, uint64_t flags, void *context);
+	ssize_t	(*msg)(struct fid_ep *ep,
 			const struct fi_msg_collective *msg,
 			struct fi_ioc *resultv, void **result_desc,
 			size_t result_count, uint64_t flags);
@@ -105,10 +162,10 @@ struct fi_ops_collective {
 
 static inline int
 fi_av_set(struct fid_av *av, struct fi_av_set_attr *attr,
-	  struct fid_av_set **av_set, void * context)
+	  struct fid_av_set **set, void * context)
 {
 	return FI_CHECK_OP(av->ops, struct fi_ops_av, av_set) ?
-		av->ops->av_set(av, attr, av_set, context) : -FI_ENOSYS;
+		av->ops->av_set(av, attr, set, context) : -FI_ENOSYS;
 }
 
 static inline int
@@ -142,6 +199,12 @@ fi_av_set_remove(struct fid_av_set *set, fi_addr_t addr)
 }
 
 static inline int
+fi_av_set_addr(struct fid_av_set *set, fi_addr_t *coll_addr)
+{
+	return set->ops->addr(set, coll_addr);
+}
+
+static inline int
 fi_join_collective(struct fid_ep *ep, fi_addr_t coll_addr,
 		   const struct fid_av_set *set,
 		   uint64_t flags, struct fid_mc **mc, void *context)
@@ -149,7 +212,7 @@ fi_join_collective(struct fid_ep *ep, fi_addr_t coll_addr,
 	struct fi_collective_addr addr;
 
 	addr.set = set;
-	addr.join_addr = coll_addr;
+	addr.coll_addr = coll_addr;
 	return fi_join(ep, &addr, flags | FI_COLLECTIVE, mc, context);
 }
 
@@ -161,16 +224,21 @@ fi_barrier(struct fid_ep *ep, fi_addr_t coll_addr, void *context)
 
 static inline ssize_t
 fi_broadcast(struct fid_ep *ep, void *buf, size_t count, void *desc,
-	     fi_addr_t coll_addr, enum fi_datatype datatype,
-	     enum fi_op op, uint64_t flags, void *context)
+	     fi_addr_t coll_addr, fi_addr_t root_addr,
+	     enum fi_datatype datatype, uint64_t flags, void *context)
+{
+	return ep->collective->broadcast(ep, buf, count, desc,
+		coll_addr, root_addr, datatype, flags, context);
+}
+
+static inline ssize_t
+fi_alltoall(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+	    void *result, void *result_desc,
+	    fi_addr_t coll_addr, enum fi_datatype datatype,
+	    uint64_t flags, void *context)
 {
-	if (flags & FI_SEND) {
-		return ep->collective->writeread(ep, buf, count, desc,
-			NULL, NULL, coll_addr, datatype, op, flags, context);
-	} else {
-		return ep->collective->writeread(ep, NULL, count, NULL,
-			buf, desc, coll_addr, datatype, op, flags, context);
-	}
+	return ep->collective->alltoall(ep, buf, count, desc,
+		result, result_desc, coll_addr, datatype, flags, context);
 }
 
 static inline ssize_t
@@ -179,47 +247,64 @@ fi_allreduce(struct fid_ep *ep, const void *buf, size_t count, void *desc,
 	     enum fi_datatype datatype, enum fi_op op,
 	     uint64_t flags, void *context)
 {
-	return ep->collective->writeread(ep, buf, count, desc,
+	return ep->collective->allreduce(ep, buf, count, desc,
 		result, result_desc, coll_addr, datatype, op, flags, context);
 }
 
 static inline ssize_t
+fi_allgather(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+	     void *result, void *result_desc, fi_addr_t coll_addr,
+	     enum fi_datatype datatype, uint64_t flags, void *context)
+{
+	return ep->collective->allgather(ep, buf, count, desc,
+		result, result_desc, coll_addr, datatype, flags, context);
+}
+
+static inline ssize_t
 fi_reduce_scatter(struct fid_ep *ep, const void *buf, size_t count, void *desc,
-		  void *result, void *result_desc,
-		  fi_addr_t coll_addr, enum fi_datatype datatype, enum fi_op op,
+		  void *result, void *result_desc, fi_addr_t coll_addr,
+		  enum fi_datatype datatype, enum fi_op op,
 		  uint64_t flags, void *context)
 {
-	return ep->collective->writeread(ep, buf, count, desc,
-		result, result_desc, coll_addr, datatype, op,
-		flags | FI_SCATTER, context);
+	return ep->collective->reduce_scatter(ep, buf, count, desc,
+		result, result_desc, coll_addr, datatype, op, flags, context);
 }
 
 static inline ssize_t
-fi_alltoall(struct fid_ep *ep, const void *buf, size_t count, void *desc,
-	    void *result, void *result_desc,
-	    fi_addr_t coll_addr, enum fi_datatype datatype,
-	    uint64_t flags, void *context)
+fi_reduce(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+	  void *result, void *result_desc, fi_addr_t coll_addr,
+	  fi_addr_t root_addr, enum fi_datatype datatype, enum fi_op op,
+	  uint64_t flags, void *context)
 {
-	return ep->collective->writeread(ep, buf, count, desc,
-		result, result_desc, coll_addr, datatype, FI_ALLTOALL,
-		flags, context);
+	return ep->collective->reduce(ep, buf, count, desc, result, result_desc,
+		coll_addr, root_addr, datatype, op, flags, context);
 }
 
+
 static inline ssize_t
-fi_allgather(struct fid_ep *ep, const void *buf, size_t count, void *desc,
-	     void *result, void *result_desc,
-	     fi_addr_t coll_addr, enum fi_datatype datatype,
-	     uint64_t flags, void *context)
+fi_scatter(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+	   void *result, void *result_desc, fi_addr_t coll_addr,
+	   fi_addr_t root_addr, enum fi_datatype datatype,
+	   uint64_t flags, void *context)
+{
+	return ep->collective->scatter(ep, buf, count, desc, result, result_desc,
+		coll_addr, root_addr, datatype, flags, context);
+}
+
+
+static inline ssize_t
+fi_gather(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+	  void *result, void *result_desc, fi_addr_t coll_addr,
+	  fi_addr_t root_addr, enum fi_datatype datatype,
+	  uint64_t flags, void *context)
 {
-	return ep->collective->writeread(ep, buf, count, desc,
-		result, result_desc, coll_addr, datatype, FI_ALLGATHER,
-		flags, context);
+	return ep->collective->gather(ep, buf, count, desc, result, result_desc,
+		coll_addr, root_addr, datatype, flags, context);
 }
 
 static inline int
-fi_query_collective(struct fid_domain *domain,
-		    enum fi_datatype datatype, enum fi_op op,
-		    struct fi_collective_attr *attr, uint64_t flags)
+fi_query_collective(struct fid_domain *domain, struct fi_collective_attr *attr,
+		    enum fi_datatype datatype, enum fi_op op, uint64_t flags)
 {
 	return fi_query_atomic(domain, datatype, op, &attr->datatype_attr,
 			       flags | FI_COLLECTIVE);
diff --git a/include/rdma/fi_domain.h b/include/rdma/fi_domain.h
index 44638f9..b23c18c 100644
--- a/include/rdma/fi_domain.h
+++ b/include/rdma/fi_domain.h
@@ -112,6 +112,11 @@ struct fid_mr {
 	uint64_t		key;
 };
 
+enum fi_hmem_iface {
+	FI_HMEM_SYSTEM	= 0,
+	FI_HMEM_CUDA,
+};
+
 struct fi_mr_attr {
 	const struct iovec	*mr_iov;
 	size_t			iov_count;
@@ -121,6 +126,11 @@ struct fi_mr_attr {
 	void			*context;
 	size_t			auth_key_size;
 	uint8_t			*auth_key;
+	enum fi_hmem_iface	iface;
+	union {
+		uint64_t	reserved;
+		int		cuda;
+	} device;
 };
 
 struct fi_mr_modify {
@@ -135,7 +145,7 @@ struct fi_mr_modify {
 
 #ifndef FABRIC_DIRECT_ATOMIC_DEF
 
-#define FI_COLLECTIVE_OFFSET 256
+//#define FI_COLLECTIVE_OFFSET 256
 
 enum fi_datatype {
 	FI_INT8,
@@ -156,7 +166,7 @@ enum fi_datatype {
 	FI_DATATYPE_LAST,
 
 	/* Collective datatypes */
-	FI_VOID = FI_COLLECTIVE_OFFSET,
+//	FI_VOID = FI_COLLECTIVE_OFFSET,
 };
 
 enum fi_op {
@@ -181,12 +191,6 @@ enum fi_op {
 	FI_MSWAP,
 	/* End of point to point atomic ops */
 	FI_ATOMIC_OP_LAST,
-
-	/* Collective only ops */
-	FI_BARRIER = FI_COLLECTIVE_OFFSET,
-	FI_BROADCAST,
-	FI_ALLTOALL,
-	FI_ALLGATHER,
 };
 
 #endif
diff --git a/include/unix/osd.h b/include/unix/osd.h
index 5f6a4d2..bf6fc6e 100644
--- a/include/unix/osd.h
+++ b/include/unix/osd.h
@@ -229,12 +229,12 @@ static inline long ofi_sysconf(int name)
 
 static inline int ofi_is_loopback_addr(struct sockaddr *addr) {
 	return (addr->sa_family == AF_INET &&
-		((struct sockaddr_in *)addr)->sin_addr.s_addr == ntohl(INADDR_LOOPBACK)) ||
+		((struct sockaddr_in *)addr)->sin_addr.s_addr == htonl(INADDR_LOOPBACK)) ||
 		(addr->sa_family == AF_INET6 &&
 		((struct sockaddr_in6 *)addr)->sin6_addr.s6_addr32[0] == 0 &&
 		((struct sockaddr_in6 *)addr)->sin6_addr.s6_addr32[1] == 0 &&
 		((struct sockaddr_in6 *)addr)->sin6_addr.s6_addr32[2] == 0 &&
-		((struct sockaddr_in6 *)addr)->sin6_addr.s6_addr32[3] == ntohl(1));
+		((struct sockaddr_in6 *)addr)->sin6_addr.s6_addr32[3] == htonl(1));
 }
 
 
diff --git a/include/windows/config.h b/include/windows/config.h
index 0e30319..2dafb17 100644
--- a/include/windows/config.h
+++ b/include/windows/config.h
@@ -162,7 +162,7 @@
 #define PACKAGE_NAME "libfabric"
 
 /* Define to the full name and version of this package. */
-#define PACKAGE_STRING "libfabric 1.9.0a1"
+#define PACKAGE_STRING "libfabric 1.9.0rc1"
 
 /* Define to the one symbol short name of this package. */
 #define PACKAGE_TARNAME "libfabric"
@@ -171,7 +171,7 @@
 #define PACKAGE_URL ""
 
 /* Define to the version of this package. */
-#define PACKAGE_VERSION "1.9.0a1"
+#define PACKAGE_VERSION "1.9.0rc1"
 
 /* Define to 1 if pthread_spin_init is available. */
 /* #undef PT_LOCK_SPIN */
diff --git a/include/windows/osd.h b/include/windows/osd.h
index 5c2ea78..91a49cf 100644
--- a/include/windows/osd.h
+++ b/include/windows/osd.h
@@ -213,9 +213,6 @@ extern "C" {
 #define SHUT_RDWR	SD_BOTH
 #endif
 
-#ifndef _SC_PAGESIZE
-#define _SC_PAGESIZE	0
-#endif
 
 #define FI_DESTRUCTOR(func) void func
 
@@ -831,15 +828,33 @@ static inline char * strndup(char const *src, size_t n)
 	return dst;
 }
 
+#ifndef _SC_PAGESIZE
+#define _SC_PAGESIZE	0
+#endif
+
+#ifndef _SC_NPROCESSORS_ONLN
+#define _SC_NPROCESSORS_ONLN 1
+#endif
+
+#ifndef _SC_PHYS_PAGES
+#define _SC_PHYS_PAGES 2
+#endif
+
 static inline long ofi_sysconf(int name)
 {
 	SYSTEM_INFO si;
+	ULONGLONG mem_size = 0;
 
 	GetSystemInfo(&si);
 
 	switch (name) {
 	case _SC_PAGESIZE:
 		return si.dwPageSize;
+	case _SC_NPROCESSORS_ONLN:
+		return si.dwNumberOfProcessors;
+	case _SC_PHYS_PAGES:
+		GetPhysicallyInstalledSystemMemory(&mem_size);
+		return mem_size / si.dwPageSize;
 	default:
 		errno = EINVAL;
 		return -1;
@@ -870,7 +885,7 @@ static inline int ofi_hugepage_enabled(void)
 
 static inline int ofi_is_loopback_addr(struct sockaddr *addr) {
 	return (addr->sa_family == AF_INET &&
-		((struct sockaddr_in *)addr)->sin_addr.s_addr == ntohl(INADDR_LOOPBACK)) ||
+		((struct sockaddr_in *)addr)->sin_addr.s_addr == htonl(INADDR_LOOPBACK)) ||
 		(addr->sa_family == AF_INET6 &&
 		((struct sockaddr_in6 *)addr)->sin6_addr.u.Word[0] == 0 &&
 		((struct sockaddr_in6 *)addr)->sin6_addr.u.Word[1] == 0 &&
@@ -879,7 +894,7 @@ static inline int ofi_is_loopback_addr(struct sockaddr *addr) {
 		((struct sockaddr_in6 *)addr)->sin6_addr.u.Word[4] == 0 &&
 		((struct sockaddr_in6 *)addr)->sin6_addr.u.Word[5] == 0 &&
 		((struct sockaddr_in6 *)addr)->sin6_addr.u.Word[6] == 0 &&
-		((struct sockaddr_in6 *)addr)->sin6_addr.u.Word[7] == ntohs(1));
+		((struct sockaddr_in6 *)addr)->sin6_addr.u.Word[7] == htons(1));
 }
 
 size_t ofi_ifaddr_get_speed(struct ifaddrs *ifa);
diff --git a/libfabric.map.in b/libfabric.map.in
index 53a3ed3..d3815c8 100644
--- a/libfabric.map.in
+++ b/libfabric.map.in
@@ -31,3 +31,10 @@ FABRIC_1.2 {
 		fi_freeinfo;
 		fi_dupinfo;
 } FABRIC_1.1;
+
+FABRIC_1.3 {
+	global:
+		fi_getinfo;
+		fi_freeinfo;
+		fi_dupinfo;
+} FABRIC_1.2;
diff --git a/libfabric.vcxproj b/libfabric.vcxproj
index 7336144..c0380af 100644
--- a/libfabric.vcxproj
+++ b/libfabric.vcxproj
@@ -545,6 +545,7 @@
     <ClCompile Include="prov\util\src\util_av.c" />
     <ClCompile Include="prov\util\src\util_buf.c" />
     <ClCompile Include="prov\util\src\util_cntr.c" />
+    <ClCompile Include="prov\util\src\util_coll.c" />
     <ClCompile Include="prov\util\src\util_cq.c" />
     <ClCompile Include="prov\util\src\util_domain.c" />
     <ClCompile Include="prov\util\src\util_ep.c" />
@@ -587,6 +588,7 @@
     <ClInclude Include="include\ofi_hook.h" />
     <ClInclude Include="include\ofi_mr.h" />
     <ClInclude Include="include\ofi_net.h" />
+    <ClInclude Include="include\ofi_coll.h" />
     <ClInclude Include="include\ofi_enosys.h" />
     <ClInclude Include="include\ofi_file.h" />
     <ClInclude Include="include\ofi_iov.h" />
@@ -614,6 +616,7 @@
     <ClInclude Include="include\rdma\fi_rma.h" />
     <ClInclude Include="include\rdma\fi_tagged.h" />
     <ClInclude Include="include\rdma\fi_trigger.h" />
+    <ClInclude Include="include\rdma\fi_collective.h" />
     <ClInclude Include="include\rdma\providers\fi_log.h" />
     <ClInclude Include="include\rdma\providers\fi_prov.h" />
     <ClInclude Include="include\uthash.h" />
diff --git a/libfabric.vcxproj.filters b/libfabric.vcxproj.filters
index e89b39a..b47b33f 100644
--- a/libfabric.vcxproj.filters
+++ b/libfabric.vcxproj.filters
@@ -402,6 +402,9 @@
     <ClCompile Include="prov\util\src\util_cntr.c">
       <Filter>Source Files\prov\util</Filter>
     </ClCompile>
+    <ClCompile Include="prov\util\src\util_coll.c">
+      <Filter>Source Files\prov\util</Filter>
+    </ClCompile>
     <ClCompile Include="prov\util\src\util_atomic.c">
       <Filter>Source Files\prov\util</Filter>
     </ClCompile>
@@ -494,6 +497,9 @@
     <ClInclude Include="include\ofi.h">
       <Filter>Header Files</Filter>
     </ClInclude>
+    <ClInclude Include="include\ofi_coll.h">
+      <Filter>Header Files</Filter>
+    </ClInclude>
     <ClInclude Include="include\ofi_enosys.h">
       <Filter>Header Files</Filter>
     </ClInclude>
@@ -551,6 +557,9 @@
     <ClInclude Include="include\rdma\fi_trigger.h">
       <Filter>Header Files\rdma</Filter>
     </ClInclude>
+    <ClInclude Include="include\rdma\fi_collective.h">
+      <Filter>Header Files\rdma</Filter>
+    </ClInclude>
     <ClInclude Include="include\windows\osd.h">
       <Filter>Header Files\windows</Filter>
     </ClInclude>
diff --git a/man/fi_atomic.3.md b/man/fi_atomic.3.md
index 37f9daa..455dbd1 100644
--- a/man/fi_atomic.3.md
+++ b/man/fi_atomic.3.md
@@ -130,7 +130,7 @@ int fi_query_atomic(struct fid_domain *domain,
 
 *desc / compare_desc / result_desc*
 : Data descriptor associated with the local data buffer, local compare
-  buffer, and local result buffer, respectively.
+  buffer, and local result buffer, respectively.  See [`fi_mr`(3)](fi_mr.3.html).
 
 *dest_addr*
 : Destination address for connectionless atomic operations.  Ignored for
diff --git a/man/fi_av_set.3.md b/man/fi_av_set.3.md
index f8004b4..f1734f4 100644
--- a/man/fi_av_set.3.md
+++ b/man/fi_av_set.3.md
@@ -9,17 +9,47 @@ tagline: Libfabric Programmer's Manual
 
 fi_av_set \- Address vector set operations
 
-fi_av_open / fi_close
-: Open or close an address vector
+fi_av_set / fi_close
+: Open or close an address vector set
+
+fi_av_set_union
+: Perform a set union operation on two AV sets
+
+fi_av_set_intersect
+: Perform a set intersect operation on two AV sets
+
+fi_av_set_diff
+: Perform a set difference operation on two AV sets
+
+fi_av_set_insert
+: Add an address to an AV set
+
+fi_av_set_remove
+: Remove an address from an AV set
+
+fi_av_set_addr
+: Obtain a collective address for current addresses in an AV set
 
 
 # SYNOPSIS
 
 ```c
-#include <rdma/fi_av_set.h>
+#include <rdma/fi_collective.h>
+
+int fi_av_set(struct fid_av *av, struct fi_av_set_attr *attr,
+	  struct fid_av_set **set, void * context);
+
+int fi_av_set_union(struct fid_av_set *dst,	const struct fid_av_set *src);
+
+int fi_av_set_intersect(struct fid_av_set *dst, const struct fid_av_set *src);
+
+int fi_av_set_diff(struct fid_av_set *dst, const struct fid_av_set *src);
 
-int fi_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
-    struct fid_av **av, void *context);
+int fi_av_set_insert(struct fid_av_set *set, fi_addr_t addr);
+
+int fi_av_set_remove(struct fid_av_set *set, fi_addr_t addr);
+
+int fi_av_set_addr(struct fid_av_set *set, fi_addr_t *coll_addr);
 
 int fi_close(struct fid *av_set);
 ```
@@ -29,6 +59,15 @@ int fi_close(struct fid *av_set);
 *av*
 : Address vector
 
+*set*
+: Address vector set
+
+*dst*
+: Address vector set updated by set operation
+
+*src*
+: Address vector set providing input to a set operation
+
 *attr*
 : Address vector set attributes
 
@@ -38,6 +77,12 @@ int fi_close(struct fid *av_set);
 *flags*
 : Additional flags to apply to the operation.
 
+*addr*
+: Destination address to insert to remove from AV set.
+
+*coll_addr*
+: Address identifying collective group.
+
 # DESCRIPTION
 
 An address vector set (AV set) represents an ordered subset of addresses of an
@@ -139,6 +184,15 @@ The AV set insert call appends the specified address to the end of the AV set.
 The AV set remove call removes the specified address from the given AV set.
 The order of the remaining addresses in the AV set is unchanged.
 
+## fi_av_set_addr
+
+Returns an address that may be used to communicate with all current members
+of an AV set.  This is a local operation only that does not involve network
+communication.  The returned address may be used as input into
+fi_join_collective.  Note that attempting to use the address returned from
+fi_av_set_addr (e.g. passing it to fi_join_collective) while simultaneously
+modifying the addresses stored in an AV set results in undefined behavior.
+
 # NOTES
 
 Developers who are familiar with MPI will find that AV sets are similar to
diff --git a/man/fi_collective.3.md b/man/fi_collective.3.md
index e0a0246..6df674a 100644
--- a/man/fi_collective.3.md
+++ b/man/fi_collective.3.md
@@ -15,22 +15,33 @@ fi_barrier
   the barrier call.
 
 fi_broadcast
-: A single sender transmits data to all receiver peers.
+: A single sender transmits data to all peers, including itself.
+
+fi_alltoall
+: Each peer distributes a slice of its local data to all peers.
 
 fi_allreduce
 : Collective operation where all peers broadcast an atomic operation to all
   other peers.
 
+fi_allgather
+: Each peer sends a complete copy of its local data to all peers.
+
 fi_reduce_scatter
 : Collective call where data is collected from all peers and merged (reduced).
   The results of the reduction is distributed back to the peers, with each
   peer receiving a slice of the results.
 
-fi_alltoall
-: Each peer distributes a slice of its local data to all peers.
+fi_reduce
+: Collective call where data is collected from all peers to a root peer
+   and merged (reduced).
 
-fi_allgather
-: Each peer sends a complete copy of its local data to all peers.
+fi_scatter
+: A single sender distributes (scatters) a slice of its local data to
+  all peers.
+
+fi_gather
+: All peers send their data to a root peer.
 
 fi_query_collective
 : Returns information about which collective operations are supported by a
@@ -49,27 +60,42 @@ ssize_t fi_barrier(struct fid_ep *ep, fi_addr_t coll_addr,
 	void *context);
 
 ssize_t fi_broadcast(struct fid_ep *ep, void *buf, size_t count, void *desc,
-	fi_addr_t coll_addr, enum fi_datatype datatype, enum fi_op op,
+	fi_addr_t coll_addr, fi_addr_t root_addr, enum fi_datatype datatype,
 	uint64_t flags, void *context);
 
-ssize_t fi_allreduce(struct fid_ep *ep, const void *buf, size_t count,
+ssize_t fi_alltoall(struct fid_ep *ep, const void *buf, size_t count,
 	void *desc, void *result, void *result_desc,
-	fi_addr_t coll_addr, enum fi_datatype datatype, enum fi_op op,
+	fi_addr_t coll_addr, enum fi_datatype datatype,
 	uint64_t flags, void *context);
 
-ssize_t fi_reduce_scatter(struct fid_ep *ep, const void *buf, size_t count,
+ssize_t fi_allreduce(struct fid_ep *ep, const void *buf, size_t count,
 	void *desc, void *result, void *result_desc,
 	fi_addr_t coll_addr, enum fi_datatype datatype, enum fi_op op,
 	uint64_t flags, void *context);
 
-ssize_t fi_alltoall(struct fid_ep *ep, const void *buf, size_t count,
+ssize_t fi_allgather(struct fid_ep *ep, const void *buf, size_t count,
 	void *desc, void *result, void *result_desc,
 	fi_addr_t coll_addr, enum fi_datatype datatype,
 	uint64_t flags, void *context);
 
-ssize_t fi_allgather(struct fid_ep *ep, const void *buf, size_t count,
+ssize_t fi_reduce_scatter(struct fid_ep *ep, const void *buf, size_t count,
 	void *desc, void *result, void *result_desc,
-	fi_addr_t coll_addr, enum fi_datatype datatype,
+	fi_addr_t coll_addr, enum fi_datatype datatype, enum fi_op op,
+	uint64_t flags, void *context);
+
+ssize_t fi_reduce(struct fid_ep *ep, const void *buf, size_t count,
+	void *desc, void *result, void *result_desc, fi_addr_t coll_addr,
+	fi_addr_t root_addr, enum fi_datatype datatype, enum fi_op op,
+	uint64_t flags, void *context);
+
+ssize_t fi_scatter(struct fid_ep *ep, const void *buf, size_t count,
+	void *desc, void *result, void *result_desc, fi_addr_t coll_addr,
+	fi_addr_t root_addr, enum fi_datatype datatype,
+	uint64_t flags, void *context);
+
+ssize_t fi_gather(struct fid_ep *ep, const void *buf, size_t count,
+	void *desc, void *result, void *result_desc, fi_addr_t coll_addr,
+	fi_addr_t root_addr, enum fi_datatype datatype,
 	uint64_t flags, void *context);
 
 int fi_query_collective(struct fid_domain *domain,
@@ -107,6 +133,9 @@ int fi_query_collective(struct fid_domain *domain,
 *coll_addr*
 : Address referring to the collective group of endpoints.
 
+*root_addr*
+: Single endpoint that is the source or destination of collective data.
+
 *flags*
 : Additional flags to apply for the atomic operation
 
@@ -166,9 +195,8 @@ associated synchronously with an AV using the fi_ep_bind() call.  Upon
 completion of the fi_join_collective operation, an fi_addr is provided that
 is used as the target address when invoking a collective operation.
 
-For developer convenience, a set of collective APIs are defined.  However,
-these are inline wrappers around the atomic interfaces.  Collective APIs
-differ from message and RMA interfaces in that the format of the data is
+For developer convenience, a set of collective APIs are defined.  Collective
+APIs differ from message and RMA interfaces in that the format of the data is
 known to the provider, and the collective may perform an operation on that
 data.  This aligns collective operations closely with the atomic interfaces.
 
@@ -198,12 +226,12 @@ will report that the join has completed.  Application managed collective
 memberships are an exception.  With application managed memberships, the
 fi_join_collective call may be completed locally without fabric communication.
 For provider managed memberships, the join collective call requires as
-input a coll_addr that refers to an existing collective group.  The
-fi_join_collective call will create a new collective subgroup.  If there is
-no existing collective group (e.g. this is the first group being created),
-or if application managed memberships are used, coll_addr should be set to
-FI_ADDR_UNAVAIL.  For provider managed memberships, this will result in
-using all entries in the associated AV as the base.
+input a coll_addr that refers to either an address associated with an
+AV set (see fi_av_set_addr) or an existing collective group (obtained through
+a previous call to fi_join_collective).  The
+fi_join_collective call will create a new collective subgroup.
+If application managed memberships are used, coll_addr should be set to
+FI_ADDR_UNAVAIL.
 
 Applications must call fi_close on the collective group to disconnect the
 endpoint from the group.  After a join operation has completed, the
@@ -242,6 +270,31 @@ array of integers to a group of peers.
  broadcast
 ```
 
+## All to All (fi_alltoall)
+
+The fi_alltoall collective involves distributing (or scattering) different
+portions of an array of data to peers.  It is best explained using an
+example.  Here three peers perform an all to all collective to exchange
+different entries in an integer array.
+
+```
+[1]   [2]   [3]
+[5]   [6]   [7]
+[9]  [10]  [11]
+   \   |   /
+   All to all
+   /   |   \
+[1]   [5]   [9]
+[2]   [6]  [10]
+[3]   [7]  [11]
+```
+
+Each peer sends a piece of its data to the other peers.
+
+All to all operations may be performed on any non-void datatype.  However,
+all to all does not perform an operation on the data itself, so no operation
+is specified.
+
 ## All Reduce (fi_allreduce)
 
 fi_allreduce can be described as all peers providing input into an atomic
@@ -270,28 +323,25 @@ between three peers.
   All Reduce
 ```
 
-## All to All (fi_alltoall)
+## All Gather (fi_allgather)
 
-The fi_alltoall collective involves distributing (or scattering) different
-portions of an array of data to peers.  It is best explained using an
-example.  Here three peers perform an all to all collective to exchange
-different entries in an integer array.
+Conceptually, all gather can be viewed as the opposite of the scatter
+component from reduce-scatter.  All gather collects data from all peers into
+a single array, then copies that array back to each peer.
 
 ```
-[1]   [2]   [3]
-[5]   [6]   [7]
-[9]  [10]  [11]
-   \   |   /
-   All to all
-   /   |   \
-[1]   [5]   [9]
-[5]   [6]   [7]
-[9]  [10]  [11]
+[1]  [5]  [9]
+  \   |   /
+ All gather
+  /   |   \
+[1]  [1]  [1]
+[5]  [5]  [5]
+[9]  [9]  [9]
 ```
 
-All to all operations may be performed on any non-void datatype.  However,
-all to all does not perform an operation on the data itself, so no operation
-is specified.
+All gather may be performed on any non-void datatype.  However, all gather
+does not perform an operation on the data itself, so no operation is
+specified.
 
 ## Reduce-Scatter (fi_reduce_scatter)
 
@@ -321,25 +371,69 @@ This is shown by the following example:
 The reduce scatter call supports the same datatype and atomic operation as
 fi_allreduce.
 
-## All Gather (fi_allgather)
+## Reduce (fi_reduce)
 
-Conceptually, all gather can be viewed as the opposite of the scatter
-component from reduce-scatter.  All gather collects data from all peers into
-a single array, then copies that array back to each peer.
+The fi_reduce collective is the first half of an fi_allreduce operation.
+With reduce, all peers provide input into an atomic operation, with the
+the results collected by a single 'root' endpoint.
+
+This is shown by the following example, with the leftmost peer identified
+as the root:
 
 ```
-[1]  [5]  [9]
-  \   |   /
- All gather
-  /   |   \
 [1]  [1]  [1]
 [5]  [5]  [5]
 [9]  [9]  [9]
+  \   |   /
+     sum (reduce)
+    /
+ [3]
+[15]
+[27]
 ```
 
-All gather may be performed on any non-void datatype.  However, all gather
-does not perform an operation on the data itself, so no operation is
-specified.
+The reduce call supports the same datatype and atomic operation as
+fi_allreduce.
+
+## Scatter (fi_scatter)
+
+The fi_scatter collective is the second half of an fi_reduce_scatter operation.
+The data from a single 'root' endpoint is split and distributed to all peers.
+
+This is shown by the following example:
+
+```
+ [3]
+[15]
+[27]
+    \
+   scatter
+  /   |   \
+[3] [15] [27]
+```
+
+The scatter operation is used to distribute results to the peers.  No atomic
+operation is performed on the data.
+
+## Gather (fi_gather)
+
+The fi_gather operation is used to collect (gather) the results from all peers
+and store them at a 'root' peer.
+
+This is shown by the following example, with the leftmost peer identified
+as the root.
+
+```
+[1]  [5]  [9]
+  \   |   /
+    gather
+   /
+[1]
+[5]
+[9]
+```
+
+The gather operation does not perform any operation on the data itself.
 
 ## Query Collective Attributes (fi_query_collective)
 
@@ -372,6 +466,7 @@ struct fi_collective_attr {
 	struct fi_atomic_attr datatype_attr;
 	size_t max_members;
 	uint64_t mode;
+	enum fi_collective_op coll;
 };
 {% endhighlight %}
 
@@ -393,6 +488,12 @@ For a description of struct fi_atomic_attr, see
 *mode*
 : This field is reserved and should be 0.
 
+*coll*
+: Specifies the collective operation for which information is being
+  requested. Valid values are FI_BARRIER, FI_BROADCAST, FI_ALLTOALL,
+  FI_ALLREDUCE, FI_ALLGATHER, FI_REDUCE_SCATTER, FI_REDUCE, FI_SCATTER,
+  and FI_GATHER.
+
 If a collective operation is supported, the query call will return 0,
 along with attributes on the limits for using that collective operation
 through the provider.
diff --git a/man/fi_cq.3.md b/man/fi_cq.3.md
index c7d0cff..38e6f35 100644
--- a/man/fi_cq.3.md
+++ b/man/fi_cq.3.md
@@ -723,6 +723,7 @@ The operational flags for the described completion levels are defined below.
   claiming the message or results.  As a result, match complete may involve
   additional provider level acknowledgements or lengthy delays.  However, this
   completion model enables peer applications to synchronize their execution.
+  Many providers may not support this semantic.
 
 *FI_COMMIT_COMPLETE*
 : Indicates that a completion should not be generated (locally or at the
@@ -734,6 +735,26 @@ The operational flags for the described completion levels are defined below.
   memory regions over reliable endpoints.  This completion mode is
   experimental.
 
+*FI_FENCE*
+: This is not a completion level, but plays a role in the completion
+  ordering between operations that would not normally be ordered.  An
+  operation that is marked with the FI_FENCE flag and all
+  operations posted after the fenced operation are deferred until all
+  previous operations targeting the same peer endpoint have completed.
+  Additionally, the completion of the fenced operation indicates that
+  prior operations have met the same completion level as the fenced
+  operation.  For example, if an operation is posted as
+  FI_DELIVERY_COMPLETE | FI_FENCE, then its completion indicates prior
+  operations have met the semantic required for FI_DELIVERY_COMPLETE.
+  This is true even if the prior operation was posted with a lower
+  completion level, such as FI_TRANSMIT_COMPLETE or FI_INJECT_COMPLETE.
+
+  Note that a completion generated for an operation posted prior to
+  the fenced operation only guarantees that the completion level
+  that was originally requested has been met.  It is the completion
+  of the fenced operation that guarantees that the additional
+  semantics have been met.
+ 
 # NOTES
 
 A completion queue must be bound to at least one enabled endpoint before any
diff --git a/man/fi_domain.3.md b/man/fi_domain.3.md
index 28d52da..6746f54 100644
--- a/man/fi_domain.3.md
+++ b/man/fi_domain.3.md
@@ -134,6 +134,7 @@ struct fi_domain_attr {
 	size_t                auth_key_size;
 	size_t                max_err_data;
 	size_t                mr_cnt;
+	uint32_t              tclass;
 };
 ```
 
@@ -666,6 +667,12 @@ Applications can set the mr_cnt on input to fi_getinfo, in order to
 indicate their memory registration requirements.  Doing so may allow the
 provider to optimize any memory registration cache or lookup tables.
 
+## Traffic Class (tclass)
+
+This specifies the default traffic class that will be associated any endpoints
+created within the domain.  See [`fi_endpoint`(3)](fi_endpoint.3.html
+for additional information.
+
 # RETURN VALUE
 
 Returns 0 on success. On error, a negative value corresponding to fabric
diff --git a/man/fi_efa.7.md b/man/fi_efa.7.md
index c71eebf..ef871df 100644
--- a/man/fi_efa.7.md
+++ b/man/fi_efa.7.md
@@ -155,6 +155,19 @@ These OFI runtime parameters apply only to the RDM endpoint.
 : Time interval (us) for the base timeout to use for exponential backoff
   to a peer after a receiver not ready error.
 
+*FI_EFA_ENABLE_SHM_TRANSFER*
+: Enable SHM provider to provide the communication across all intra-node processes.
+  SHM transfer will be disabled in the case where
+  [`ptrace protection`](https://wiki.ubuntu.com/SecurityTeam/Roadmap/KernelHardening#ptrace_Protection)
+  is turned on. You can turn it off to enable shm transfer.
+
+*FI_EFA_SHM_AV_SIZE*
+: Defines the maximum number of entries in SHM provider's address vector.
+
+*FI_EFA_SHM_MAX_MEDIUM_SIZE*
+: Defines the switch point between small/medium message and large message. The message
+  larger than this switch point will be transferred with large message protocol.
+
 # SEE ALSO
 
 [`fabric`(7)](fabric.7.html),
diff --git a/man/fi_endpoint.3.md b/man/fi_endpoint.3.md
index 433762c..a3f7827 100644
--- a/man/fi_endpoint.3.md
+++ b/man/fi_endpoint.3.md
@@ -41,6 +41,9 @@ fi_getopt / fi_setopt
 fi_rx_context / fi_tx_context / fi_srx_context  / fi_stx_context
 :   Open a transmit or receive context.
 
+fi_tc_dscp_set / fi_tc_dscp_get
+:   Convert between a DSCP value and a network traffic class
+
 fi_rx_size_left / fi_tx_size_left (DEPRECATED)
 :   Query the lower bound on how many RX/TX operations may be posted without
     an operation returning -FI_EAGAIN.  This functions have been deprecated
@@ -100,6 +103,10 @@ int fi_getopt(struct fid *ep, int level, int optname,
 int fi_setopt(struct fid *ep, int level, int optname,
     const void *optval, size_t optlen);
 
+uint32_t fi_tc_dscp_set(uint8_t dscp);
+
+uint8_t fi_tc_dscp_get(uint32_t tclass);
+
 DEPRECATED ssize_t fi_rx_size_left(struct fid_ep *ep);
 
 DEPRECATED ssize_t fi_tx_size_left(struct fid_ep *ep);
@@ -513,6 +520,16 @@ The following option levels and option names and parameters are defined.
   sized renedezvous protocol message usually results in better latency for the
   overall transfer of a large message.
 
+## fi_tc_dscp_set
+
+This call converts a DSCP defined value into a libfabric traffic class value.
+It should be used when assigning a DSCP value when setting the tclass field
+in either domain or endpoint attributes
+
+## fi_tc_dscp_get
+
+This call returns the DSCP value associated with the tclass field for the
+domain or endpoint attributes.
 
 ## fi_rx_size_left (DEPRECATED)
 
@@ -844,6 +861,7 @@ struct fi_tx_attr {
 	size_t    size;
 	size_t    iov_limit;
 	size_t    rma_iov_limit;
+	uint32_t  tclass;
 };
 {% endhighlight %}
 
@@ -1061,6 +1079,57 @@ number of RMA IO vectors that may be specified when initiating an
 operation from the local endpoint, as well as the maximum number of
 IO vectors that may be carried in a single request from a remote endpoint.
 
+## Traffic Class (tclass)
+
+Traffic classes can be a differentiated services
+code point (DSCP) value, one of the following defined labels, or a
+provider-specific definition.  If tclass is unset or set to FI_TC_UNSPEC,
+the endpoint will use the default traffic class associated with the
+domain.
+
+*FI_TC_BEST_EFFORT*
+: This is the default in the absence of any other local or fabric configuration.
+  This class carries the traffic for a number of applications executing
+  concurrently over the same network infrastructure. Even though it is shared,
+  network capacity and resource allocation are distributed fairly across the
+  applications.
+
+*FI_TC_LOW_LATENCY*
+: This class supports low latency, low jitter data patterns typically caused by
+  transactional data exchanges, barrier synchronizations, and collective
+  operations that are typical of HPC applications. This class often requires
+  maximum tolerable latencies that data transfers must achieve for correct or
+  performance operations.  Fulfillment of such requests in this class will
+  typically require accompanying bandwidth and message size limitations so
+  as not to consume excessive bandwidth at high priority.
+
+*FI_TC_DEDICATED_ACCESS*
+: This class operates at the highest priority, except the management class.
+  It carries a high bandwidth allocation, minimum latency targets, and the
+  highest scheduling and arbitration priority.
+
+*FI_TC_BULK_DATA*
+: This class is intended for large data transfers associated with I/O and
+  is present to separate sustained I/O transfers from other application
+  inter-process communications.
+
+*FI_TC_SCAVENGER*
+: This class is used for data that is desired but does not have strict delivery
+  requirements, such as in-band network or application level monitoring data.
+  Use of this class indicates that the traffic is considered lower priority
+  and should not interfere with higher priority workflows.
+
+*FI_TC_NETWORK_CTRL*
+: This class is intended for traffic directly related to fabric (network)
+  management, which is critical to the correct operation of the network.
+  Its use is typically restricted to privileged network management applications.
+
+*fi_tc_dscp_set / fi_tc_dscp_get*
+: DSCP values are supported via the DSCP get and set functions.  The
+  definitions for DSCP values are outside the scope of libfabric.  See
+  the fi_tc_dscp_set and fi_tc_dscp_get function definitions for details
+  on their use.
+
 # RECEIVE CONTEXT ATTRIBUTES
 
 Attributes specific to the receive capabilities of an endpoint are
diff --git a/man/fi_getinfo.3.md b/man/fi_getinfo.3.md
index 8fab0f3..e6dd173 100644
--- a/man/fi_getinfo.3.md
+++ b/man/fi_getinfo.3.md
@@ -420,6 +420,10 @@ additional optimizations.
   are any messages larger than an endpoint configurable size.  This
   flag requires that FI_MSG and/or FI_TAGGED be set.
 
+*FI_HMEM*
+: Specifies that the endpoint should support transfers to and from
+  device memory. 
+
 Capabilities may be grouped into two general categories: primary and
 secondary.  Primary capabilities must explicitly be requested by an
 application, and a provider must enable support for only those primary
@@ -431,7 +435,7 @@ would not compromise performance or security.
 
 Primary capabilities: FI_MSG, FI_RMA, FI_TAGGED, FI_ATOMIC, FI_MULTICAST,
 FI_NAMED_RX_CTX, FI_DIRECTED_RECV, FI_READ, FI_WRITE, FI_RECV, FI_SEND,
-FI_REMOTE_READ, FI_REMOTE_WRITE, and FI_VARIABLE_MSG.
+FI_REMOTE_READ, FI_REMOTE_WRITE, FI_VARIABLE_MSG, FI_HMEM.
 
 Secondary capabilities: FI_MULTI_RECV, FI_SOURCE, FI_RMA_EVENT, FI_SHARED_AV,
 FI_TRIGGER, FI_FENCE, FI_LOCAL_COMM, FI_REMOTE_COMM, FI_SOURCE_ERR, FI_RMA_PMEM.
diff --git a/man/fi_mlx.7.md b/man/fi_mlx.7.md
index c6688eb..0c38235 100644
--- a/man/fi_mlx.7.md
+++ b/man/fi_mlx.7.md
@@ -11,60 +11,8 @@ fi_mlx \- The MLX Fabric Provider
 
 # OVERVIEW
 
-The *mlx* provider runs over the UCX library
-that is currently supported by the Mellanox infiniband fabrics.
-The *mlx* provider makes use of UCX tag matching API in order to
-implement a limited set of the libfabric data transfer APIs, namely,
-tagged message queue.
-
-Supported UCP API version: 1.0
-
-# LIMITATIONS
-
-The *mlx* provider doesn't support all the features defined in the
-libfabric API. Here are some of the limitations:
-
-Endpoint types
-: Only supported type:  *FI_RDM*
-
-Endpoint capabilities
-: Endpoints can support the only data transfer capability
-  *FI_TAGGED*.
-
-
-Modes
-: *FI_CONTEXT* is required. That means, all the requests that generate
-  completions must have a valid pointer to type *struct fi_context*
-  passed as the operation context.
-
-Threading
-: The supported mode is FI_THREAD_DOMAIN, i.e. the *mlx* provider is not thread safe.
-
-
-Unsupported features
-: These features are unsupported: connection management, event queue, 
-  scalable endpoint, passive endpoint, shared receive context,
-  rma, atomics.
-
-
-# RUNTIME PARAMETERS
-
-*FI_MLX_CONFIG*
-: The path to the MLX configuration file (default: none).
-
-*FI_MLX_TINJECT_LIMIT*
-: Maximal tinject message size (default: 1024).
-
-*FI_MLX_NS_ENABLE*
-: Enforce usage of name server functionality for MLX provider
-  (default: disabled).
-
-*FI_MLX_NS_PORT*
-: MLX provider's name server port (default: 12345).
-
-*FI_MLX_NS_IFACE*
-: IPv4 network interface for MLX provider's name server
-  (default: any).
+The mlx provider was deprecated and removed in libfabric 1.9
+due to a lack of a maintainer.
 
 # SEE ALSO
 
diff --git a/man/fi_mr.3.md b/man/fi_mr.3.md
index 1ac392a..54ebc72 100644
--- a/man/fi_mr.3.md
+++ b/man/fi_mr.3.md
@@ -32,7 +32,7 @@ fi_mr_unmap_key
 : Releases a previously mapped raw memory region key.
 
 fi_mr_bind
-: Associate a registered memory region with a completion counter.
+: Associate a registered memory region with a completion counter or an endpoint.
 
 fi_mr_refresh
 : Updates the memory pages associated with a memory region.
@@ -164,11 +164,13 @@ The following apply to memory registration.
 *FI_MR_LOCAL*
 : When the FI_MR_LOCAL mode bit is set, applications must register all
   data buffers that will be accessed by the local hardware and provide
-  a valid mem_desc parameter into applicable data transfer operations.
+  a valid desc parameter into applicable data transfer operations.
   When FI_MR_LOCAL is zero, applications are not required to register
   data buffers before using them for local operations (e.g. send and
-  receive data buffers), and the mem_desc parameter into data transfer
-  operations is ignored.
+  receive data buffers).  The desc parameter into data transfer
+  operations will be ignored in this case, unless otherwise required
+  (e.g. se  FI_MR_HMEM).  It is recommended that applications pass in
+  NULL for desc when not required.
 
   A provider may hide local registration requirements from applications
   by making use of an internal registration cache or similar mechanisms.
@@ -245,17 +247,34 @@ The following apply to memory registration.
   MR with an endpoint, the application must use fi_mr_bind().  To
   enable the memory region, the application must call fi_mr_enable().
 
+*FI_MR_HMEM*
+: This mode bit is associated with the FI_HMEM capability.
+  If FI_MR_HMEM is set, the application must register buffers that
+  were allocated using a device call and provide a valid desc
+  parameter into applicable data transfer operations even if they are
+  only used for local operations (e.g. send and receive data buffers).
+  Device memory must be registered using the fi_mr_regattr call, with
+  the iface and device fields filled out.
+
+  If FI_MR_HMEM is set, but FI_MR_LOCAL is unset, only device buffers
+  must be registered when used locally.  In this case, the desc parameter
+  passed into data transfer operations must either be valid or NULL.
+  Similarly, if FI_MR_LOCAL is set, but FI_MR_HMEM is not, the desc
+  parameter must either be valid or NULL.
+
 *Basic Memory Registration*
 : Basic memory registration is indicated by the FI_MR_BASIC mr_mode bit.
   FI_MR_BASIC is maintained for backwards compatibility (libfabric version
   1.4 or earlier).  The behavior of basic registration is equivalent
   to setting the following mr_mode bits to one: FI_MR_VIRT_ADDR,
   FI_MR_ALLOCATED, and FI_MR_PROV_KEY.  Additionally, providers that
-  support basic registration usually required FI_MR_LOCAL.  FI_MR_BASIC 
-  must either be set alone, or in conjunction with FI_MR_LOCAL.  Other
-  mr_mode bit pairings are invalid.  Unlike other mr_mode bits, if
-  FI_MR_BASIC is set on input to fi_getinfo(),  it will not be cleared
-  by the provider.  That is, setting FI_MR_BASIC
+  support basic registration usually required the fi_info mode bit FI_LOCAL_MR.
+  As a result, it is recommended that applications migrating from libfabric 1.4
+  or earlier or wanting to support basic memory registration set the mr_mode
+  to FI_MR_VIRT_ADDR | FI_MR_ALLOCATED | FI_MR_PROV_KEY | FI_MR_LOCAL.
+  FI_MR_BASIC must be set alone.  Other mr_mode bit pairings are invalid.
+  Unlike other mr_mode bits, if FI_MR_BASIC is set on input to fi_getinfo(),
+  it will not be cleared by the provider.  That is, setting FI_MR_BASIC
   to one requests basic registration.
 
 The registrations functions -- fi_mr_reg, fi_mr_regv, and
@@ -452,6 +471,11 @@ struct fi_mr_attr {
 	void               *context;
 	size_t             auth_key_size;
 	uint8_t            *auth_key;
+	enum fi_hmem_iface  iface;
+	union {
+		uint64_t	reserved;
+		int		cuda;
+	} device;
 };
 ```
 ## mr_iov
@@ -544,6 +568,26 @@ region.  The domain authorization key will be used if the auth_key_size
 provided is 0.  This field is ignored unless the fabric is opened with API 
 version 1.5 or greater.
 
+## iface
+Indicates the software interfaces used by the application to allocate and
+manage the memory region. This field is ignored unless the application has
+requested the FI_HMEM capability.
+
+*FI_HMEM_SYSTEM*
+: Uses standard operating system calls and libraries, such as malloc,
+  calloc, realloc, mmap, and free.
+
+*FI_HMEM_CUDA*
+: Uses Nvidia CUDA interfaces such as cuMemAlloc, cuMemAllocHost,
+  cuMemAllocManaged, cuMemFree, cudaMalloc, cudaFree.
+
+## device
+Reserved 64 bits for device identifier if using non-standard HMEM interface.
+This field is ignore unless the iface field is valid.
+
+*cuda*
+: For FI_HMEM_CUDA, this is equivalent to CUdevice (int).
+
 # NOTES
 
 Direct access to an application's memory by a remote peer requires that
diff --git a/man/fi_mrail.7.md b/man/fi_mrail.7.md
index 6c12cab..af0be9b 100644
--- a/man/fi_mrail.7.md
+++ b/man/fi_mrail.7.md
@@ -34,7 +34,7 @@ capabilities / modes:
 
 Applications need to:
   * Support FI_MR_RAW MR mode bit to make use of FI_RMA capability.
-  * Set FI_OFI_MRAIL_ADDR_STRC env variable (see RUNTIME PARAMETERS section below).
+  * Set FI_OFI_MRAIL_ADDR env variable (see RUNTIME PARAMETERS section below).
 
 # SUPPORTED FEATURES
 
@@ -69,16 +69,31 @@ feature not listed in "Supported features" can be assumed as unsupported.
 
 # FUNCTIONALITY OVERVIEW
 
-For messages (FI_MSG, FI_TAGGED), the provider sends one message per rail in a
-round-robin manner. Ordering is guaranteed through the use of sequence numbers.
+For messages (FI_MSG, FI_TAGGED), the provider uses different policies to send messages
+over one or more rails based on message size (See *FI_OFI_MRIAL_CONFIG* in the RUNTIME
+PARAMETERS section). Ordering is guaranteed through the use of sequence numbers.
+
 For RMA, the data is striped equally across all rails.
 
 # RUNTIME PARAMETERS
 
 The ofi_mrail provider checks for the following environment variables.
 
+*FI_OFI_MRAIL_ADDR*
+: Comma delimited list of individual rail addresses. Each address can be an address in
+  FI_ADDR_STR format, a host name, an IP address, or a netdev interface name.
+
 *FI_OFI_MRAIL_ADDR_STRC*
-: Comma delimited list of individual rail addresses in FI_ADDR_STR format.
+: Deprecated. Replaced by *FI_OFI_MRAIL_ADDR*.
+
+*FI_OFI_MRAIL_CONFIG*
+: Comma separated list of `<max_size>:<policy>` pairs, sorted in ascending order of
+ `<max_size>`. Each pair indicated the rail sharing policy to be used for messages
+  up to the size `<max_size>` and not covered by all previous pairs. The value of
+  `<policy>` can be *fixed* (a fixed rail is used), *round-robin* (one rail per
+  message, selected in round-robin fashion), or *striping* (striping across all the
+  rails). The default configuration is `16384:fixed,ULONG_MAX:striping`. The value
+  ULONG_MAX can be input as -1.
 
 # SEE ALSO
 
diff --git a/man/fi_msg.3.md b/man/fi_msg.3.md
index 0879a71..0d1f9bd 100644
--- a/man/fi_msg.3.md
+++ b/man/fi_msg.3.md
@@ -68,7 +68,7 @@ ssize_t fi_injectdata(struct fid_ep *ep, const void *buf, size_t len,
 : Count of vectored data entries.
 
 *desc*
-: Descriptor associated with the data buffer
+: Descriptor associated with the data buffer.  See [`fi_mr`(3)](fi_mr.3.html).
 
 *data*
 : Remote CQ data to transfer with the sent message.
diff --git a/man/fi_rma.3.md b/man/fi_rma.3.md
index 38f684f..312d9de 100644
--- a/man/fi_rma.3.md
+++ b/man/fi_rma.3.md
@@ -82,6 +82,7 @@ ssize_t fi_inject_writedata(struct fid_ep *ep, const void *buf, size_t len,
 
 *desc*
 : Descriptor associated with the local data buffer
+  See [`fi_mr`(3)](fi_mr.3.html).
 
 *data*
 : Remote CQ data to transfer with the operation.
diff --git a/man/fi_shm.7.md b/man/fi_shm.7.md
index 242a3eb..4fa4a5a 100644
--- a/man/fi_shm.7.md
+++ b/man/fi_shm.7.md
@@ -74,7 +74,7 @@ of operations.
   provided (and in the case of setting the src address without FI_SOURCE and
   no hints), the process ID will be used as a default address.
   On endpoint creation, if the src_addr has the "fi_shm://" prefix, the provider
-  will append ":[dom_idx]:[ep_idx]" as a unique endpoint name (essentially,
+  will append ":[uid]:[dom_idx]:[ep_idx]" as a unique endpoint name (essentially,
   in place of a service).  In the case of the "fi_ns://" prefix (or any other
   prefix if one was provided by the application), no supplemental information
   is required to make it unique and it will remain with only the
diff --git a/man/fi_tagged.3.md b/man/fi_tagged.3.md
index d1b1371..b3f3bc2 100644
--- a/man/fi_tagged.3.md
+++ b/man/fi_tagged.3.md
@@ -75,7 +75,8 @@ ssize_t fi_tinjectdata(struct fid_ep *ep, const void *buf, size_t len,
 : Mask of bits to ignore applied to the tag for receive operations.
 
 *desc*
-: Memory descriptor associated with the data buffer
+: Memory descriptor associated with the data buffer.
+  See [`fi_mr`(3)](fi_mr.3.html).
 
 *data*
 : Remote CQ data to transfer with the sent data.
diff --git a/man/fi_trigger.3.md b/man/fi_trigger.3.md
index 5623e25..637d0a8 100644
--- a/man/fi_trigger.3.md
+++ b/man/fi_trigger.3.md
@@ -94,12 +94,10 @@ struct fi_trigger_threshold {
   they will be triggered in the order in which they were submitted to
   the endpoint.
 
-# EXPERIMENTAL DEFERRED WORK QUEUES
+# DEFERRED WORK QUEUES
 
 The following feature and description are enhancements to triggered
-operation support, but should be considered experimental.  Until the
-experimental tag is removed, the interfaces, semantics, and data
-structures defined below may change between library versions.
+operation support.
 
 The deferred work queue interface is designed as primitive constructs
 that can be used to implement application-level collective operations.
diff --git a/man/man3/fi_atomic.3 b/man/man3/fi_atomic.3
index 36ed67a..5c38a5c 100644
--- a/man/man3/fi_atomic.3
+++ b/man/man3/fi_atomic.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_atomic" "3" "2019\-07\-17" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_atomic" "3" "2019\-09\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -155,6 +155,7 @@ Local data buffer to store initial value of remote buffer
 .B \f[I]desc / compare_desc / result_desc\f[]
 Data descriptor associated with the local data buffer, local compare
 buffer, and local result buffer, respectively.
+See \f[C]fi_mr\f[](3).
 .RS
 .RE
 .TP
diff --git a/man/man3/fi_av_set.3 b/man/man3/fi_av_set.3
index 8ba0dcb..2725a28 100644
--- a/man/man3/fi_av_set.3
+++ b/man/man3/fi_av_set.3
@@ -1,23 +1,65 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_av_set" "3" "2019\-07\-17" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_av_set" "3" "2019\-10\-02" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
 fi_av_set \- Address vector set operations
 .TP
-.B fi_av_open / fi_close
-Open or close an address vector
+.B fi_av_set / fi_close
+Open or close an address vector set
+.RS
+.RE
+.TP
+.B fi_av_set_union
+Perform a set union operation on two AV sets
+.RS
+.RE
+.TP
+.B fi_av_set_intersect
+Perform a set intersect operation on two AV sets
+.RS
+.RE
+.TP
+.B fi_av_set_diff
+Perform a set difference operation on two AV sets
+.RS
+.RE
+.TP
+.B fi_av_set_insert
+Add an address to an AV set
+.RS
+.RE
+.TP
+.B fi_av_set_remove
+Remove an address from an AV set
+.RS
+.RE
+.TP
+.B fi_av_set_addr
+Obtain a collective address for current addresses in an AV set
 .RS
 .RE
 .SH SYNOPSIS
 .IP
 .nf
 \f[C]
-#include\ <rdma/fi_av_set.h>
+#include\ <rdma/fi_collective.h>
+
+int\ fi_av_set(struct\ fid_av\ *av,\ struct\ fi_av_set_attr\ *attr,
+\ \ \ \ \ \ struct\ fid_av_set\ **set,\ void\ *\ context);
+
+int\ fi_av_set_union(struct\ fid_av_set\ *dst,\ const\ struct\ fid_av_set\ *src);
 
-int\ fi_av_open(struct\ fid_domain\ *domain,\ struct\ fi_av_attr\ *attr,
-\ \ \ \ struct\ fid_av\ **av,\ void\ *context);
+int\ fi_av_set_intersect(struct\ fid_av_set\ *dst,\ const\ struct\ fid_av_set\ *src);
+
+int\ fi_av_set_diff(struct\ fid_av_set\ *dst,\ const\ struct\ fid_av_set\ *src);
+
+int\ fi_av_set_insert(struct\ fid_av_set\ *set,\ fi_addr_t\ addr);
+
+int\ fi_av_set_remove(struct\ fid_av_set\ *set,\ fi_addr_t\ addr);
+
+int\ fi_av_set_addr(struct\ fid_av_set\ *set,\ fi_addr_t\ *coll_addr);
 
 int\ fi_close(struct\ fid\ *av_set);
 \f[]
@@ -29,6 +71,21 @@ Address vector
 .RS
 .RE
 .TP
+.B \f[I]set\f[]
+Address vector set
+.RS
+.RE
+.TP
+.B \f[I]dst\f[]
+Address vector set updated by set operation
+.RS
+.RE
+.TP
+.B \f[I]src\f[]
+Address vector set providing input to a set operation
+.RS
+.RE
+.TP
 .B \f[I]attr\f[]
 Address vector set attributes
 .RS
@@ -43,6 +100,16 @@ User specified context associated with the address vector set
 Additional flags to apply to the operation.
 .RS
 .RE
+.TP
+.B \f[I]addr\f[]
+Destination address to insert to remove from AV set.
+.RS
+.RE
+.TP
+.B \f[I]coll_addr\f[]
+Address identifying collective group.
+.RS
+.RE
 .SH DESCRIPTION
 .PP
 An address vector set (AV set) represents an ordered subset of addresses
@@ -164,6 +231,17 @@ AV set.
 The AV set remove call removes the specified address from the given AV
 set.
 The order of the remaining addresses in the AV set is unchanged.
+.SS fi_av_set_addr
+.PP
+Returns an address that may be used to communicate with all current
+members of an AV set.
+This is a local operation only that does not involve network
+communication.
+The returned address may be used as input into fi_join_collective.
+Note that attempting to use the address returned from fi_av_set_addr
+(e.g.
+passing it to fi_join_collective) while simultaneously modifying the
+addresses stored in an AV set results in undefined behavior.
 .SH NOTES
 .PP
 Developers who are familiar with MPI will find that AV sets are similar
diff --git a/man/man3/fi_collective.3 b/man/man3/fi_collective.3
index ba4bfb1..ad3b3e0 100644
--- a/man/man3/fi_collective.3
+++ b/man/man3/fi_collective.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_collective" "3" "2019\-07\-17" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_collective" "3" "2019\-10\-09" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .TP
@@ -16,7 +16,12 @@ the barrier call.
 .RE
 .TP
 .B fi_broadcast
-A single sender transmits data to all receiver peers.
+A single sender transmits data to all peers, including itself.
+.RS
+.RE
+.TP
+.B fi_alltoall
+Each peer distributes a slice of its local data to all peers.
 .RS
 .RE
 .TP
@@ -26,6 +31,11 @@ all other peers.
 .RS
 .RE
 .TP
+.B fi_allgather
+Each peer sends a complete copy of its local data to all peers.
+.RS
+.RE
+.TP
 .B fi_reduce_scatter
 Collective call where data is collected from all peers and merged
 (reduced).
@@ -34,13 +44,20 @@ peer receiving a slice of the results.
 .RS
 .RE
 .TP
-.B fi_alltoall
-Each peer distributes a slice of its local data to all peers.
+.B fi_reduce
+Collective call where data is collected from all peers to a root peer
+and merged (reduced).
 .RS
 .RE
 .TP
-.B fi_allgather
-Each peer sends a complete copy of its local data to all peers.
+.B fi_scatter
+A single sender distributes (scatters) a slice of its local data to all
+peers.
+.RS
+.RE
+.TP
+.B fi_gather
+All peers send their data to a root peer.
 .RS
 .RE
 .TP
@@ -63,27 +80,42 @@ ssize_t\ fi_barrier(struct\ fid_ep\ *ep,\ fi_addr_t\ coll_addr,
 \ \ \ \ void\ *context);
 
 ssize_t\ fi_broadcast(struct\ fid_ep\ *ep,\ void\ *buf,\ size_t\ count,\ void\ *desc,
-\ \ \ \ fi_addr_t\ coll_addr,\ enum\ fi_datatype\ datatype,\ enum\ fi_op\ op,
+\ \ \ \ fi_addr_t\ coll_addr,\ fi_addr_t\ root_addr,\ enum\ fi_datatype\ datatype,
 \ \ \ \ uint64_t\ flags,\ void\ *context);
 
-ssize_t\ fi_allreduce(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
+ssize_t\ fi_alltoall(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
 \ \ \ \ void\ *desc,\ void\ *result,\ void\ *result_desc,
-\ \ \ \ fi_addr_t\ coll_addr,\ enum\ fi_datatype\ datatype,\ enum\ fi_op\ op,
+\ \ \ \ fi_addr_t\ coll_addr,\ enum\ fi_datatype\ datatype,
 \ \ \ \ uint64_t\ flags,\ void\ *context);
 
-ssize_t\ fi_reduce_scatter(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
+ssize_t\ fi_allreduce(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
 \ \ \ \ void\ *desc,\ void\ *result,\ void\ *result_desc,
 \ \ \ \ fi_addr_t\ coll_addr,\ enum\ fi_datatype\ datatype,\ enum\ fi_op\ op,
 \ \ \ \ uint64_t\ flags,\ void\ *context);
 
-ssize_t\ fi_alltoall(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
+ssize_t\ fi_allgather(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
 \ \ \ \ void\ *desc,\ void\ *result,\ void\ *result_desc,
 \ \ \ \ fi_addr_t\ coll_addr,\ enum\ fi_datatype\ datatype,
 \ \ \ \ uint64_t\ flags,\ void\ *context);
 
-ssize_t\ fi_allgather(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
+ssize_t\ fi_reduce_scatter(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
 \ \ \ \ void\ *desc,\ void\ *result,\ void\ *result_desc,
-\ \ \ \ fi_addr_t\ coll_addr,\ enum\ fi_datatype\ datatype,
+\ \ \ \ fi_addr_t\ coll_addr,\ enum\ fi_datatype\ datatype,\ enum\ fi_op\ op,
+\ \ \ \ uint64_t\ flags,\ void\ *context);
+
+ssize_t\ fi_reduce(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
+\ \ \ \ void\ *desc,\ void\ *result,\ void\ *result_desc,\ fi_addr_t\ coll_addr,
+\ \ \ \ fi_addr_t\ root_addr,\ enum\ fi_datatype\ datatype,\ enum\ fi_op\ op,
+\ \ \ \ uint64_t\ flags,\ void\ *context);
+
+ssize_t\ fi_scatter(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
+\ \ \ \ void\ *desc,\ void\ *result,\ void\ *result_desc,\ fi_addr_t\ coll_addr,
+\ \ \ \ fi_addr_t\ root_addr,\ enum\ fi_datatype\ datatype,
+\ \ \ \ uint64_t\ flags,\ void\ *context);
+
+ssize_t\ fi_gather(struct\ fid_ep\ *ep,\ const\ void\ *buf,\ size_t\ count,
+\ \ \ \ void\ *desc,\ void\ *result,\ void\ *result_desc,\ fi_addr_t\ coll_addr,
+\ \ \ \ fi_addr_t\ root_addr,\ enum\ fi_datatype\ datatype,
 \ \ \ \ uint64_t\ flags,\ void\ *context);
 
 int\ fi_query_collective(struct\ fid_domain\ *domain,
@@ -139,6 +171,11 @@ Address referring to the collective group of endpoints.
 .RS
 .RE
 .TP
+.B \f[I]root_addr\f[]
+Single endpoint that is the source or destination of collective data.
+.RS
+.RE
+.TP
 .B \f[I]flags\f[]
 Additional flags to apply for the atomic operation
 .RS
@@ -214,7 +251,6 @@ provided that is used as the target address when invoking a collective
 operation.
 .PP
 For developer convenience, a set of collective APIs are defined.
-However, these are inline wrappers around the atomic interfaces.
 Collective APIs differ from message and RMA interfaces in that the
 format of the data is known to the provider, and the collective may
 perform an operation on that data.
@@ -251,13 +287,12 @@ Application managed collective memberships are an exception.
 With application managed memberships, the fi_join_collective call may be
 completed locally without fabric communication.
 For provider managed memberships, the join collective call requires as
-input a coll_addr that refers to an existing collective group.
+input a coll_addr that refers to either an address associated with an AV
+set (see fi_av_set_addr) or an existing collective group (obtained
+through a previous call to fi_join_collective).
 The fi_join_collective call will create a new collective subgroup.
-If there is no existing collective group (e.g.
-this is the first group being created), or if application managed
-memberships are used, coll_addr should be set to FI_ADDR_UNAVAIL.
-For provider managed memberships, this will result in using all entries
-in the associated AV as the base.
+If application managed memberships are used, coll_addr should be set to
+FI_ADDR_UNAVAIL.
 .PP
 Applications must call fi_close on the collective group to disconnect
 the endpoint from the group.
@@ -300,6 +335,33 @@ transfer an array of integers to a group of peers.
 \ broadcast
 \f[]
 .fi
+.SS All to All (fi_alltoall)
+.PP
+The fi_alltoall collective involves distributing (or scattering)
+different portions of an array of data to peers.
+It is best explained using an example.
+Here three peers perform an all to all collective to exchange different
+entries in an integer array.
+.IP
+.nf
+\f[C]
+[1]\ \ \ [2]\ \ \ [3]
+[5]\ \ \ [6]\ \ \ [7]
+[9]\ \ [10]\ \ [11]
+\ \ \ \\\ \ \ |\ \ \ /
+\ \ \ All\ to\ all
+\ \ \ /\ \ \ |\ \ \ \\
+[1]\ \ \ [5]\ \ \ [9]
+[2]\ \ \ [6]\ \ [10]
+[3]\ \ \ [7]\ \ [11]
+\f[]
+.fi
+.PP
+Each peer sends a piece of its data to the other peers.
+.PP
+All to all operations may be performed on any non\-void datatype.
+However, all to all does not perform an operation on the data itself, so
+no operation is specified.
 .SS All Reduce (fi_allreduce)
 .PP
 fi_allreduce can be described as all peers providing input into an
@@ -331,30 +393,27 @@ involving summing an array of integers between three peers.
 \ \ All\ Reduce
 \f[]
 .fi
-.SS All to All (fi_alltoall)
+.SS All Gather (fi_allgather)
 .PP
-The fi_alltoall collective involves distributing (or scattering)
-different portions of an array of data to peers.
-It is best explained using an example.
-Here three peers perform an all to all collective to exchange different
-entries in an integer array.
+Conceptually, all gather can be viewed as the opposite of the scatter
+component from reduce\-scatter.
+All gather collects data from all peers into a single array, then copies
+that array back to each peer.
 .IP
 .nf
 \f[C]
-[1]\ \ \ [2]\ \ \ [3]
-[5]\ \ \ [6]\ \ \ [7]
-[9]\ \ [10]\ \ [11]
-\ \ \ \\\ \ \ |\ \ \ /
-\ \ \ All\ to\ all
-\ \ \ /\ \ \ |\ \ \ \\
-[1]\ \ \ [5]\ \ \ [9]
-[5]\ \ \ [6]\ \ \ [7]
-[9]\ \ [10]\ \ [11]
+[1]\ \ [5]\ \ [9]
+\ \ \\\ \ \ |\ \ \ /
+\ All\ gather
+\ \ /\ \ \ |\ \ \ \\
+[1]\ \ [1]\ \ [1]
+[5]\ \ [5]\ \ [5]
+[9]\ \ [9]\ \ [9]
 \f[]
 .fi
 .PP
-All to all operations may be performed on any non\-void datatype.
-However, all to all does not perform an operation on the data itself, so
+All gather may be performed on any non\-void datatype.
+However, all gather does not perform an operation on the data itself, so
 no operation is specified.
 .SS Reduce\-Scatter (fi_reduce_scatter)
 .PP
@@ -387,28 +446,75 @@ This is shown by the following example:
 .PP
 The reduce scatter call supports the same datatype and atomic operation
 as fi_allreduce.
-.SS All Gather (fi_allgather)
+.SS Reduce (fi_reduce)
 .PP
-Conceptually, all gather can be viewed as the opposite of the scatter
-component from reduce\-scatter.
-All gather collects data from all peers into a single array, then copies
-that array back to each peer.
+The fi_reduce collective is the first half of an fi_allreduce operation.
+With reduce, all peers provide input into an atomic operation, with the
+the results collected by a single \[aq]root\[aq] endpoint.
+.PP
+This is shown by the following example, with the leftmost peer
+identified as the root:
 .IP
 .nf
 \f[C]
-[1]\ \ [5]\ \ [9]
-\ \ \\\ \ \ |\ \ \ /
-\ All\ gather
-\ \ /\ \ \ |\ \ \ \\
 [1]\ \ [1]\ \ [1]
 [5]\ \ [5]\ \ [5]
 [9]\ \ [9]\ \ [9]
+\ \ \\\ \ \ |\ \ \ /
+\ \ \ \ \ sum\ (reduce)
+\ \ \ \ /
+\ [3]
+[15]
+[27]
 \f[]
 .fi
 .PP
-All gather may be performed on any non\-void datatype.
-However, all gather does not perform an operation on the data itself, so
-no operation is specified.
+The reduce call supports the same datatype and atomic operation as
+fi_allreduce.
+.SS Scatter (fi_scatter)
+.PP
+The fi_scatter collective is the second half of an fi_reduce_scatter
+operation.
+The data from a single \[aq]root\[aq] endpoint is split and distributed
+to all peers.
+.PP
+This is shown by the following example:
+.IP
+.nf
+\f[C]
+\ [3]
+[15]
+[27]
+\ \ \ \ \\
+\ \ \ scatter
+\ \ /\ \ \ |\ \ \ \\
+[3]\ [15]\ [27]
+\f[]
+.fi
+.PP
+The scatter operation is used to distribute results to the peers.
+No atomic operation is performed on the data.
+.SS Gather (fi_gather)
+.PP
+The fi_gather operation is used to collect (gather) the results from all
+peers and store them at a \[aq]root\[aq] peer.
+.PP
+This is shown by the following example, with the leftmost peer
+identified as the root.
+.IP
+.nf
+\f[C]
+[1]\ \ [5]\ \ [9]
+\ \ \\\ \ \ |\ \ \ /
+\ \ \ \ gather
+\ \ \ /
+[1]
+[5]
+[9]
+\f[]
+.fi
+.PP
+The gather operation does not perform any operation on the data itself.
 .SS Query Collective Attributes (fi_query_collective)
 .PP
 The fi_query_collective call reports which collective operations are
@@ -443,6 +549,7 @@ struct\ fi_collective_attr\ {
 \ \ \ \ struct\ fi_atomic_attr\ datatype_attr;
 \ \ \ \ size_t\ max_members;
 \ \ \ \ uint64_t\ mode;
+\ \ \ \ enum\ fi_collective_op\ coll;
 };
 \f[]
 .fi
@@ -471,6 +578,14 @@ operation.
 This field is reserved and should be 0.
 .RS
 .RE
+.TP
+.B \f[I]coll\f[]
+Specifies the collective operation for which information is being
+requested.
+Valid values are FI_BARRIER, FI_BROADCAST, FI_ALLTOALL, FI_ALLREDUCE,
+FI_ALLGATHER, FI_REDUCE_SCATTER, FI_REDUCE, FI_SCATTER, and FI_GATHER.
+.RS
+.RE
 .PP
 If a collective operation is supported, the query call will return 0,
 along with attributes on the limits for using that collective operation
diff --git a/man/man3/fi_cq.3 b/man/man3/fi_cq.3
index 9ad3243..34eecfb 100644
--- a/man/man3/fi_cq.3
+++ b/man/man3/fi_cq.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_cq" "3" "2019\-02\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_cq" "3" "2019\-09\-26" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -943,6 +943,7 @@ As a result, match complete may involve additional provider level
 acknowledgements or lengthy delays.
 However, this completion model enables peer applications to synchronize
 their execution.
+Many providers may not support this semantic.
 .RS
 .RE
 .TP
@@ -957,6 +958,29 @@ in the case of power failure.
 This completion mode applies only to operations that target persistent
 memory regions over reliable endpoints.
 This completion mode is experimental.
+.TP
+.B \f[I]FI_FENCE\f[]
+This is not a completion level, but plays a role in the completion
+ordering between operations that would not normally be ordered.
+An operation that is marked with the FI_FENCE flag and all operations
+posted after the fenced operation are deferred until all previous
+operations targeting the same peer endpoint have completed.
+Additionally, the completion of the fenced operation indicates that
+prior operations have met the same completion level as the fenced
+operation.
+For example, if an operation is posted as FI_DELIVERY_COMPLETE |
+FI_FENCE, then its completion indicates prior operations have met the
+semantic required for FI_DELIVERY_COMPLETE.
+This is true even if the prior operation was posted with a lower
+completion level, such as FI_TRANSMIT_COMPLETE or FI_INJECT_COMPLETE.
+.RS
+.RE
+.PP
+Note that a completion generated for an operation posted prior to the
+fenced operation only guarantees that the completion level that was
+originally requested has been met.
+It is the completion of the fenced operation that guarantees that the
+additional semantics have been met.
 .SH NOTES
 .PP
 A completion queue must be bound to at least one enabled endpoint before
diff --git a/man/man3/fi_domain.3 b/man/man3/fi_domain.3
index a358698..6e7684f 100644
--- a/man/man3/fi_domain.3
+++ b/man/man3/fi_domain.3
@@ -1,7 +1,7 @@
 .\"t
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_domain" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_domain" "3" "2019\-10\-08" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -144,6 +144,7 @@ struct\ fi_domain_attr\ {
 \ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ auth_key_size;
 \ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ max_err_data;
 \ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ mr_cnt;
+\ \ \ \ uint32_t\ \ \ \ \ \ \ \ \ \ \ \ \ \ tclass;
 };
 \f[]
 .fi
@@ -879,6 +880,12 @@ Applications can set the mr_cnt on input to fi_getinfo, in order to
 indicate their memory registration requirements.
 Doing so may allow the provider to optimize any memory registration
 cache or lookup tables.
+.SS Traffic Class (tclass)
+.PP
+This specifies the default traffic class that will be associated any
+endpoints created within the domain.
+See [\f[C]fi_endpoint\f[](3)](fi_endpoint.3.html for additional
+information.
 .SH RETURN VALUE
 .PP
 Returns 0 on success.
diff --git a/man/man3/fi_endpoint.3 b/man/man3/fi_endpoint.3
index 03d78db..0ea352f 100644
--- a/man/man3/fi_endpoint.3
+++ b/man/man3/fi_endpoint.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_endpoint" "3" "2019\-05\-14" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_endpoint" "3" "2019\-10\-08" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -58,6 +58,11 @@ Open a transmit or receive context.
 .RS
 .RE
 .TP
+.B fi_tc_dscp_set / fi_tc_dscp_get
+Convert between a DSCP value and a network traffic class
+.RS
+.RE
+.TP
 .B fi_rx_size_left / fi_tx_size_left (DEPRECATED)
 Query the lower bound on how many RX/TX operations may be posted without
 an operation returning \-FI_EAGAIN.
@@ -120,6 +125,10 @@ int\ fi_getopt(struct\ fid\ *ep,\ int\ level,\ int\ optname,
 int\ fi_setopt(struct\ fid\ *ep,\ int\ level,\ int\ optname,
 \ \ \ \ const\ void\ *optval,\ size_t\ optlen);
 
+uint32_t\ fi_tc_dscp_set(uint8_t\ dscp);
+
+uint8_t\ fi_tc_dscp_get(uint32_t\ tclass);
+
 DEPRECATED\ ssize_t\ fi_rx_size_left(struct\ fid_ep\ *ep);
 
 DEPRECATED\ ssize_t\ fi_tx_size_left(struct\ fid_ep\ *ep);
@@ -650,6 +659,16 @@ latency for the overall transfer of a large message.
 .RS
 .RE
 .RE
+.SS fi_tc_dscp_set
+.PP
+This call converts a DSCP defined value into a libfabric traffic class
+value.
+It should be used when assigning a DSCP value when setting the tclass
+field in either domain or endpoint attributes
+.SS fi_tc_dscp_get
+.PP
+This call returns the DSCP value associated with the tclass field for
+the domain or endpoint attributes.
 .SS fi_rx_size_left (DEPRECATED)
 .PP
 This function has been deprecated and will be removed in a future
@@ -1054,6 +1073,7 @@ struct\ fi_tx_attr\ {
 \ \ \ \ size_t\ \ \ \ size;
 \ \ \ \ size_t\ \ \ \ iov_limit;
 \ \ \ \ size_t\ \ \ \ rma_iov_limit;
+\ \ \ \ uint32_t\ \ tclass;
 };
 \f[]
 .fi
@@ -1327,6 +1347,75 @@ This limit applies to both the number of RMA IO vectors that may be
 specified when initiating an operation from the local endpoint, as well
 as the maximum number of IO vectors that may be carried in a single
 request from a remote endpoint.
+.SS Traffic Class (tclass)
+.PP
+Traffic classes can be a differentiated services code point (DSCP)
+value, one of the following defined labels, or a provider\-specific
+definition.
+If tclass is unset or set to FI_TC_UNSPEC, the endpoint will use the
+default traffic class associated with the domain.
+.TP
+.B \f[I]FI_TC_BEST_EFFORT\f[]
+This is the default in the absence of any other local or fabric
+configuration.
+This class carries the traffic for a number of applications executing
+concurrently over the same network infrastructure.
+Even though it is shared, network capacity and resource allocation are
+distributed fairly across the applications.
+.RS
+.RE
+.TP
+.B \f[I]FI_TC_LOW_LATENCY\f[]
+This class supports low latency, low jitter data patterns typically
+caused by transactional data exchanges, barrier synchronizations, and
+collective operations that are typical of HPC applications.
+This class often requires maximum tolerable latencies that data
+transfers must achieve for correct or performance operations.
+Fulfillment of such requests in this class will typically require
+accompanying bandwidth and message size limitations so as not to consume
+excessive bandwidth at high priority.
+.RS
+.RE
+.TP
+.B \f[I]FI_TC_DEDICATED_ACCESS\f[]
+This class operates at the highest priority, except the management
+class.
+It carries a high bandwidth allocation, minimum latency targets, and the
+highest scheduling and arbitration priority.
+.RS
+.RE
+.TP
+.B \f[I]FI_TC_BULK_DATA\f[]
+This class is intended for large data transfers associated with I/O and
+is present to separate sustained I/O transfers from other application
+inter\-process communications.
+.RS
+.RE
+.TP
+.B \f[I]FI_TC_SCAVENGER\f[]
+This class is used for data that is desired but does not have strict
+delivery requirements, such as in\-band network or application level
+monitoring data.
+Use of this class indicates that the traffic is considered lower
+priority and should not interfere with higher priority workflows.
+.RS
+.RE
+.TP
+.B \f[I]FI_TC_NETWORK_CTRL\f[]
+This class is intended for traffic directly related to fabric (network)
+management, which is critical to the correct operation of the network.
+Its use is typically restricted to privileged network management
+applications.
+.RS
+.RE
+.TP
+.B \f[I]fi_tc_dscp_set / fi_tc_dscp_get\f[]
+DSCP values are supported via the DSCP get and set functions.
+The definitions for DSCP values are outside the scope of libfabric.
+See the fi_tc_dscp_set and fi_tc_dscp_get function definitions for
+details on their use.
+.RS
+.RE
 .SH RECEIVE CONTEXT ATTRIBUTES
 .PP
 Attributes specific to the receive capabilities of an endpoint are
diff --git a/man/man3/fi_getinfo.3 b/man/man3/fi_getinfo.3
index 5a1e6bd..fafc690 100644
--- a/man/man3/fi_getinfo.3
+++ b/man/man3/fi_getinfo.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_getinfo" "3" "2019\-02\-04" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_getinfo" "3" "2019\-09\-25" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -554,6 +554,12 @@ configurable size.
 This flag requires that FI_MSG and/or FI_TAGGED be set.
 .RS
 .RE
+.TP
+.B \f[I]FI_HMEM\f[]
+Specifies that the endpoint should support transfers to and from device
+memory.
+.RS
+.RE
 .PP
 Capabilities may be grouped into two general categories: primary and
 secondary.
@@ -568,7 +574,8 @@ doing so would not compromise performance or security.
 .PP
 Primary capabilities: FI_MSG, FI_RMA, FI_TAGGED, FI_ATOMIC,
 FI_MULTICAST, FI_NAMED_RX_CTX, FI_DIRECTED_RECV, FI_READ, FI_WRITE,
-FI_RECV, FI_SEND, FI_REMOTE_READ, FI_REMOTE_WRITE, and FI_VARIABLE_MSG.
+FI_RECV, FI_SEND, FI_REMOTE_READ, FI_REMOTE_WRITE, FI_VARIABLE_MSG,
+FI_HMEM.
 .PP
 Secondary capabilities: FI_MULTI_RECV, FI_SOURCE, FI_RMA_EVENT,
 FI_SHARED_AV, FI_TRIGGER, FI_FENCE, FI_LOCAL_COMM, FI_REMOTE_COMM,
diff --git a/man/man3/fi_mr.3 b/man/man3/fi_mr.3
index a228df9..d04f268 100644
--- a/man/man3/fi_mr.3
+++ b/man/man3/fi_mr.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_mr" "3" "2019\-05\-04" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_mr" "3" "2019\-09\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -43,7 +43,8 @@ Releases a previously mapped raw memory region key.
 .RE
 .TP
 .B fi_mr_bind
-Associate a registered memory region with a completion counter.
+Associate a registered memory region with a completion counter or an
+endpoint.
 .RS
 .RE
 .TP
@@ -214,11 +215,15 @@ receive and tagged receive operations.
 .B \f[I]FI_MR_LOCAL\f[]
 When the FI_MR_LOCAL mode bit is set, applications must register all
 data buffers that will be accessed by the local hardware and provide a
-valid mem_desc parameter into applicable data transfer operations.
+valid desc parameter into applicable data transfer operations.
 When FI_MR_LOCAL is zero, applications are not required to register data
 buffers before using them for local operations (e.g.
-send and receive data buffers), and the mem_desc parameter into data
-transfer operations is ignored.
+send and receive data buffers).
+The desc parameter into data transfer operations will be ignored in this
+case, unless otherwise required (e.g.
+se FI_MR_HMEM).
+It is recommended that applications pass in NULL for desc when not
+required.
 .RS
 .RE
 .PP
@@ -316,6 +321,25 @@ To enable the memory region, the application must call fi_mr_enable().
 .RS
 .RE
 .TP
+.B \f[I]FI_MR_HMEM\f[]
+This mode bit is associated with the FI_HMEM capability.
+If FI_MR_HMEM is set, the application must register buffers that were
+allocated using a device call and provide a valid desc parameter into
+applicable data transfer operations even if they are only used for local
+operations (e.g.
+send and receive data buffers).
+Device memory must be registered using the fi_mr_regattr call, with the
+iface and device fields filled out.
+.RS
+.RE
+.PP
+If FI_MR_HMEM is set, but FI_MR_LOCAL is unset, only device buffers must
+be registered when used locally.
+In this case, the desc parameter passed into data transfer operations
+must either be valid or NULL.
+Similarly, if FI_MR_LOCAL is set, but FI_MR_HMEM is not, the desc
+parameter must either be valid or NULL.
+.TP
 .B \f[I]Basic Memory Registration\f[]
 Basic memory registration is indicated by the FI_MR_BASIC mr_mode bit.
 FI_MR_BASIC is maintained for backwards compatibility (libfabric version
@@ -324,9 +348,12 @@ The behavior of basic registration is equivalent to setting the
 following mr_mode bits to one: FI_MR_VIRT_ADDR, FI_MR_ALLOCATED, and
 FI_MR_PROV_KEY.
 Additionally, providers that support basic registration usually required
+the fi_info mode bit FI_LOCAL_MR.
+As a result, it is recommended that applications migrating from
+libfabric 1.4 or earlier or wanting to support basic memory registration
+set the mr_mode to FI_MR_VIRT_ADDR | FI_MR_ALLOCATED | FI_MR_PROV_KEY |
 FI_MR_LOCAL.
-FI_MR_BASIC must either be set alone, or in conjunction with
-FI_MR_LOCAL.
+FI_MR_BASIC must be set alone.
 Other mr_mode bit pairings are invalid.
 Unlike other mr_mode bits, if FI_MR_BASIC is set on input to
 fi_getinfo(), it will not be cleared by the provider.
@@ -546,6 +573,11 @@ struct\ fi_mr_attr\ {
 \ \ \ \ void\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ *context;
 \ \ \ \ size_t\ \ \ \ \ \ \ \ \ \ \ \ \ auth_key_size;
 \ \ \ \ uint8_t\ \ \ \ \ \ \ \ \ \ \ \ *auth_key;
+\ \ \ \ enum\ fi_hmem_iface\ \ iface;
+\ \ \ \ union\ {
+\ \ \ \ \ \ \ \ uint64_t\ \ \ \ reserved;
+\ \ \ \ \ \ \ \ int\ \ \ \ \ cuda;
+\ \ \ \ }\ device;
 };
 \f[]
 .fi
@@ -652,6 +684,34 @@ The domain authorization key will be used if the auth_key_size provided
 is 0.
 This field is ignored unless the fabric is opened with API version 1.5
 or greater.
+.SS iface
+.PP
+Indicates the software interfaces used by the application to allocate
+and manage the memory region.
+This field is ignored unless the application has requested the FI_HMEM
+capability.
+.TP
+.B \f[I]FI_HMEM_SYSTEM\f[]
+Uses standard operating system calls and libraries, such as malloc,
+calloc, realloc, mmap, and free.
+.RS
+.RE
+.TP
+.B \f[I]FI_HMEM_CUDA\f[]
+Uses Nvidia CUDA interfaces such as cuMemAlloc, cuMemAllocHost,
+cuMemAllocManaged, cuMemFree, cudaMalloc, cudaFree.
+.RS
+.RE
+.SS device
+.PP
+Reserved 64 bits for device identifier if using non\-standard HMEM
+interface.
+This field is ignore unless the iface field is valid.
+.TP
+.B \f[I]cuda\f[]
+For FI_HMEM_CUDA, this is equivalent to CUdevice (int).
+.RS
+.RE
 .SH NOTES
 .PP
 Direct access to an application\[aq]s memory by a remote peer requires
diff --git a/man/man3/fi_msg.3 b/man/man3/fi_msg.3
index c4fa5fe..4f93946 100644
--- a/man/man3/fi_msg.3
+++ b/man/man3/fi_msg.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_msg" "3" "2019\-02\-04" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_msg" "3" "2019\-09\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -79,7 +79,8 @@ Count of vectored data entries.
 .RE
 .TP
 .B \f[I]desc\f[]
-Descriptor associated with the data buffer
+Descriptor associated with the data buffer.
+See \f[C]fi_mr\f[](3).
 .RS
 .RE
 .TP
diff --git a/man/man3/fi_rma.3 b/man/man3/fi_rma.3
index 8904963..9b16a50 100644
--- a/man/man3/fi_rma.3
+++ b/man/man3/fi_rma.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_rma" "3" "2019\-02\-04" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_rma" "3" "2019\-09\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -97,7 +97,7 @@ Protection key associated with the remote memory.
 .RE
 .TP
 .B \f[I]desc\f[]
-Descriptor associated with the local data buffer
+Descriptor associated with the local data buffer See \f[C]fi_mr\f[](3).
 .RS
 .RE
 .TP
diff --git a/man/man3/fi_tagged.3 b/man/man3/fi_tagged.3
index a150b7e..e470060 100644
--- a/man/man3/fi_tagged.3
+++ b/man/man3/fi_tagged.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_tagged" "3" "2019\-02\-04" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_tagged" "3" "2019\-09\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -90,7 +90,8 @@ Mask of bits to ignore applied to the tag for receive operations.
 .RE
 .TP
 .B \f[I]desc\f[]
-Memory descriptor associated with the data buffer
+Memory descriptor associated with the data buffer.
+See \f[C]fi_mr\f[](3).
 .RS
 .RE
 .TP
diff --git a/man/man3/fi_trigger.3 b/man/man3/fi_trigger.3
index 7015699..590b077 100644
--- a/man/man3/fi_trigger.3
+++ b/man/man3/fi_trigger.3
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_trigger" "3" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_trigger" "3" "2019\-09\-17" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -95,12 +95,10 @@ Threshold operations are triggered in the order of the threshold values.
 This is true even if the counter increments by a value greater than 1.
 If two triggered operations have the same threshold, they will be
 triggered in the order in which they were submitted to the endpoint.
-.SH EXPERIMENTAL DEFERRED WORK QUEUES
+.SH DEFERRED WORK QUEUES
 .PP
 The following feature and description are enhancements to triggered
-operation support, but should be considered experimental.
-Until the experimental tag is removed, the interfaces, semantics, and
-data structures defined below may change between library versions.
+operation support.
 .PP
 The deferred work queue interface is designed as primitive constructs
 that can be used to implement application\-level collective operations.
diff --git a/man/man7/fi_efa.7 b/man/man7/fi_efa.7
index dc6b13b..3fb7ae7 100644
--- a/man/man7/fi_efa.7
+++ b/man/man7/fi_efa.7
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_efa" "7" "2019\-06\-15" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_efa" "7" "2019\-11\-04" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -217,6 +217,28 @@ Time interval (us) for the base timeout to use for exponential backoff
 to a peer after a receiver not ready error.
 .RS
 .RE
+.TP
+.B \f[I]FI_EFA_ENABLE_SHM_TRANSFER\f[]
+Enable SHM provider to provide the communication across all intra\-node
+processes.
+SHM transfer will be disabled in the case where
+\f[C]ptrace\ protection\f[] is turned on.
+You can turn it off to enable shm transfer.
+.RS
+.RE
+.TP
+.B \f[I]FI_EFA_SHM_AV_SIZE\f[]
+Defines the maximum number of entries in SHM provider\[aq]s address
+vector.
+.RS
+.RE
+.TP
+.B \f[I]FI_EFA_SHM_MAX_MEDIUM_SIZE\f[]
+Defines the switch point between small/medium message and large message.
+The message larger than this switch point will be transferred with large
+message protocol.
+.RS
+.RE
 .SH SEE ALSO
 .PP
 \f[C]fabric\f[](7), \f[C]fi_provider\f[](7), \f[C]fi_getinfo\f[](3)
diff --git a/man/man7/fi_mlx.7 b/man/man7/fi_mlx.7
index d38ee44..1a3df04 100644
--- a/man/man7/fi_mlx.7
+++ b/man/man7/fi_mlx.7
@@ -1,84 +1,14 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_mlx" "7" "2018\-10\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_mlx" "7" "2019\-09\-17" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
 fi_mlx \- The MLX Fabric Provider
 .SH OVERVIEW
 .PP
-The \f[I]mlx\f[] provider runs over the UCX library that is currently
-supported by the Mellanox infiniband fabrics.
-The \f[I]mlx\f[] provider makes use of UCX tag matching API in order to
-implement a limited set of the libfabric data transfer APIs, namely,
-tagged message queue.
-.PP
-Supported UCP API version: 1.0
-.SH LIMITATIONS
-.PP
-The \f[I]mlx\f[] provider doesn\[aq]t support all the features defined
-in the libfabric API.
-Here are some of the limitations:
-.TP
-.B Endpoint types
-Only supported type: \f[I]FI_RDM\f[]
-.RS
-.RE
-.TP
-.B Endpoint capabilities
-Endpoints can support the only data transfer capability
-\f[I]FI_TAGGED\f[].
-.RS
-.RE
-.TP
-.B Modes
-\f[I]FI_CONTEXT\f[] is required.
-That means, all the requests that generate completions must have a valid
-pointer to type \f[I]struct fi_context\f[] passed as the operation
-context.
-.RS
-.RE
-.TP
-.B Threading
-The supported mode is FI_THREAD_DOMAIN, i.e.
-the \f[I]mlx\f[] provider is not thread safe.
-.RS
-.RE
-.TP
-.B Unsupported features
-These features are unsupported: connection management, event queue,
-scalable endpoint, passive endpoint, shared receive context, rma,
-atomics.
-.RS
-.RE
-.SH RUNTIME PARAMETERS
-.TP
-.B \f[I]FI_MLX_CONFIG\f[]
-The path to the MLX configuration file (default: none).
-.RS
-.RE
-.TP
-.B \f[I]FI_MLX_TINJECT_LIMIT\f[]
-Maximal tinject message size (default: 1024).
-.RS
-.RE
-.TP
-.B \f[I]FI_MLX_NS_ENABLE\f[]
-Enforce usage of name server functionality for MLX provider (default:
-disabled).
-.RS
-.RE
-.TP
-.B \f[I]FI_MLX_NS_PORT\f[]
-MLX provider\[aq]s name server port (default: 12345).
-.RS
-.RE
-.TP
-.B \f[I]FI_MLX_NS_IFACE\f[]
-IPv4 network interface for MLX provider\[aq]s name server (default:
-any).
-.RS
-.RE
+The mlx provider was deprecated and removed in libfabric 1.9 due to a
+lack of a maintainer.
 .SH SEE ALSO
 .PP
 \f[C]fabric\f[](7), \f[C]fi_provider\f[](7),
diff --git a/man/man7/fi_mrail.7 b/man/man7/fi_mrail.7
index 1b6e239..36b92f2 100644
--- a/man/man7/fi_mrail.7
+++ b/man/man7/fi_mrail.7
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_mrail" "7" "2018\-12\-27" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_mrail" "7" "2019\-09\-17" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -28,8 +28,8 @@ FI_AV_TABLE
 .PP
 Applications need to: * Support FI_MR_RAW MR mode bit to make use of
 FI_RMA capability.
-* Set FI_OFI_MRAIL_ADDR_STRC env variable (see RUNTIME PARAMETERS
-section below).
+* Set FI_OFI_MRAIL_ADDR env variable (see RUNTIME PARAMETERS section
+below).
 .SH SUPPORTED FEATURES
 .TP
 .B \f[I]Endpoint types\f[]
@@ -71,16 +71,40 @@ Multicast
 Triggered operations
 .SH FUNCTIONALITY OVERVIEW
 .PP
-For messages (FI_MSG, FI_TAGGED), the provider sends one message per
-rail in a round\-robin manner.
+For messages (FI_MSG, FI_TAGGED), the provider uses different policies
+to send messages over one or more rails based on message size (See
+\f[I]FI_OFI_MRIAL_CONFIG\f[] in the RUNTIME PARAMETERS section).
 Ordering is guaranteed through the use of sequence numbers.
+.PP
 For RMA, the data is striped equally across all rails.
 .SH RUNTIME PARAMETERS
 .PP
 The ofi_mrail provider checks for the following environment variables.
 .TP
+.B \f[I]FI_OFI_MRAIL_ADDR\f[]
+Comma delimited list of individual rail addresses.
+Each address can be an address in FI_ADDR_STR format, a host name, an IP
+address, or a netdev interface name.
+.RS
+.RE
+.TP
 .B \f[I]FI_OFI_MRAIL_ADDR_STRC\f[]
-Comma delimited list of individual rail addresses in FI_ADDR_STR format.
+Deprecated.
+Replaced by \f[I]FI_OFI_MRAIL_ADDR\f[].
+.RS
+.RE
+.TP
+.B \f[I]FI_OFI_MRAIL_CONFIG\f[]
+Comma separated list of \f[C]<max_size>:<policy>\f[] pairs, sorted in
+ascending order of \f[C]<max_size>\f[].
+Each pair indicated the rail sharing policy to be used for messages up
+to the size \f[C]<max_size>\f[] and not covered by all previous pairs.
+The value of \f[C]<policy>\f[] can be \f[I]fixed\f[] (a fixed rail is
+used), \f[I]round\-robin\f[] (one rail per message, selected in
+round\-robin fashion), or \f[I]striping\f[] (striping across all the
+rails).
+The default configuration is \f[C]16384:fixed,ULONG_MAX:striping\f[].
+The value ULONG_MAX can be input as \-1.
 .RS
 .RE
 .SH SEE ALSO
diff --git a/man/man7/fi_shm.7 b/man/man7/fi_shm.7
index 910387e..944c615 100644
--- a/man/man7/fi_shm.7
+++ b/man/man7/fi_shm.7
@@ -1,6 +1,6 @@
 .\" Automatically generated by Pandoc 1.19.2.4
 .\"
-.TH "fi_shm" "7" "2019\-02\-05" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
+.TH "fi_shm" "7" "2019\-10\-23" "Libfabric Programmer\[aq]s Manual" "\@VERSION\@"
 .hy
 .SH NAME
 .PP
@@ -89,8 +89,8 @@ If no node or service are provided (and in the case of setting the src
 address without FI_SOURCE and no hints), the process ID will be used as
 a default address.
 On endpoint creation, if the src_addr has the "fi_shm://" prefix, the
-provider will append ":[dom_idx]:[ep_idx]" as a unique endpoint name
-(essentially, in place of a service).
+provider will append ":[uid]:[dom_idx]:[ep_idx]" as a unique endpoint
+name (essentially, in place of a service).
 In the case of the "fi_ns://" prefix (or any other prefix if one was
 provided by the application), no supplemental information is required to
 make it unique and it will remain with only the application\-defined
diff --git a/prov/bgq/src/fi_bgq_init.c b/prov/bgq/src/fi_bgq_init.c
index b734bcf..9680d2f 100644
--- a/prov/bgq/src/fi_bgq_init.c
+++ b/prov/bgq/src/fi_bgq_init.c
@@ -330,7 +330,7 @@ static void fi_bgq_fini()
 static struct fi_provider fi_bgq_provider = {
 	.name 		= FI_BGQ_PROVIDER_NAME,
 	.version 	= FI_VERSION(0, 1),
-	.fi_version 	= FI_VERSION(1, 6),
+	.fi_version 	= OFI_VERSION_LATEST,
 	.getinfo	= fi_bgq_getinfo,
 	.fabric		= fi_bgq_fabric,
 	.cleanup	= fi_bgq_fini
diff --git a/prov/efa/src/efa.h b/prov/efa/src/efa.h
index 914fdf4..ce455d8 100644
--- a/prov/efa/src/efa.h
+++ b/prov/efa/src/efa.h
@@ -106,6 +106,7 @@ struct efa_fabric {
 struct efa_ep_addr {
 	uint8_t			raw[16];
 	uint16_t		qpn;
+	struct efa_ep_addr	*next;
 };
 
 #define EFA_EP_ADDR_LEN sizeof(struct efa_ep_addr)
diff --git a/prov/efa/src/efa_fabric.c b/prov/efa/src/efa_fabric.c
index ed4cc44..26cf0ea 100644
--- a/prov/efa/src/efa_fabric.c
+++ b/prov/efa/src/efa_fabric.c
@@ -72,7 +72,7 @@
 
 #define EFA_NO_DEFAULT -1
 
-#define EFA_DEF_MR_CACHE_ENABLE 0
+#define EFA_DEF_MR_CACHE_ENABLE 1
 #define EFA_DEF_MR_CACHE_MERGE_REGIONS 1
 
 int efa_mr_cache_enable		= EFA_DEF_MR_CACHE_ENABLE;
@@ -889,7 +889,7 @@ static void fi_efa_fini(void)
 struct fi_provider efa_prov = {
 	.name = EFA_PROV_NAME,
 	.version = EFA_PROV_VERS,
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = efa_getinfo,
 	.fabric = efa_fabric,
 	.cleanup = fi_efa_fini
diff --git a/prov/efa/src/efa_mr.c b/prov/efa/src/efa_mr.c
index b9f72fd..a4bd69c 100644
--- a/prov/efa/src/efa_mr.c
+++ b/prov/efa/src/efa_mr.c
@@ -35,6 +35,10 @@
 #include "efa.h"
 #include "efa_verbs.h"
 
+static int efa_mr_reg(struct fid *fid, const void *buf, size_t len,
+		      uint64_t access, uint64_t offset, uint64_t requested_key,
+		      uint64_t flags, struct fid_mr **mr_fid, void *context);
+
 static int efa_mr_cache_close(fid_t fid)
 {
 	struct efa_mem_desc *mr = container_of(fid, struct efa_mem_desc,
@@ -113,6 +117,12 @@ static int efa_mr_cache_reg(struct fid *fid, const void *buf, size_t len,
 		.context	= context,
 	};
 
+	if (flags & OFI_MR_NOCACHE) {
+		ret = efa_mr_reg(fid, buf, len, access, offset, requested_key,
+				flags, mr_fid, context);
+		return ret;
+	}
+
 	if (access & ~EFA_MR_SUPPORTED_PERMISSIONS) {
 		EFA_WARN(FI_LOG_MR,
 			 "Unsupported access permissions. requested[0x%" PRIx64 "] supported[0x%" PRIx64 "]\n",
@@ -189,27 +199,41 @@ static int efa_mr_reg(struct fid *fid, const void *buf, size_t len,
 		      uint64_t flags, struct fid_mr **mr_fid, void *context)
 {
 	struct fid_domain *domain_fid;
-	struct efa_mem_desc *md;
+	struct efa_mem_desc *md = NULL;
 	int fi_ibv_access = 0;
+	int ret;
 
-	if (flags)
-		return -FI_EBADFLAGS;
+	if (flags && flags != OFI_MR_NOCACHE) {
+		EFA_WARN(FI_LOG_MR, "Unsupported flag type. requested[0x%" PRIx64 "] supported[0x%" PRIx64 "]\n",
+				flags, (uint64_t) OFI_MR_NOCACHE);
+		ret = -FI_EBADFLAGS;
+		goto err;
+	}
 
-	if (fid->fclass != FI_CLASS_DOMAIN)
-		return -FI_EINVAL;
+	if (fid->fclass != FI_CLASS_DOMAIN) {
+		EFA_WARN(FI_LOG_MR,
+			 "Unsupported domain. requested[0x%" PRIx64 "] supported[0x%" PRIx64 "]\n",
+			 fid->fclass, (uint64_t) FI_CLASS_DOMAIN);
+                ret = -FI_EINVAL;
+                goto err;
+        }
 
 	if (access & ~EFA_MR_SUPPORTED_PERMISSIONS) {
 		EFA_WARN(FI_LOG_MR,
 			 "Unsupported access permissions. requested[0x%" PRIx64 "] supported[0x%" PRIx64 "]\n",
 			 access, (uint64_t)EFA_MR_SUPPORTED_PERMISSIONS);
-		return -FI_EINVAL;
+		ret = -FI_EINVAL;
+		goto err;
 	}
 
 	domain_fid = container_of(fid, struct fid_domain, fid);
 
 	md = calloc(1, sizeof(*md));
-	if (!md)
-		return -FI_ENOMEM;
+	if (!md) {
+		EFA_WARN(FI_LOG_MR, "Unable to initialize md");
+		ret = -FI_ENOMEM;
+		goto err;
+	}
 
 	md->domain = container_of(domain_fid, struct efa_domain,
 				  util_domain.domain_fid);
@@ -224,6 +248,7 @@ static int efa_mr_reg(struct fid *fid, const void *buf, size_t len,
 	md->mr = efa_cmd_reg_mr(md->domain->pd, (void *)buf, len, fi_ibv_access);
 	if (!md->mr) {
 		EFA_WARN_ERRNO(FI_LOG_MR, "efa_cmd_reg_mr", errno);
+		ret = -errno;
 		goto err;
 	}
 
@@ -234,8 +259,11 @@ static int efa_mr_reg(struct fid *fid, const void *buf, size_t len,
 	return 0;
 
 err:
-	free(md);
-	return -errno;
+	EFA_WARN(FI_LOG_MR, "Unable to register MR: %s\n",
+			fi_strerror(-ret));
+	if (md)
+		free(md);
+	return ret;
 }
 
 static int efa_mr_regv(struct fid *fid, const struct iovec *iov,
diff --git a/prov/efa/src/rxr/rxr.h b/prov/efa/src/rxr/rxr.h
index 8201b12..23ba414 100644
--- a/prov/efa/src/rxr/rxr.h
+++ b/prov/efa/src/rxr/rxr.h
@@ -64,8 +64,8 @@
 
 #define RXR_MAJOR_VERSION	(2)
 #define RXR_MINOR_VERSION	(0)
-#define RXR_PROTOCOL_VERSION	(2)
-#define RXR_FI_VERSION		FI_VERSION(1, 8)
+#define RXR_PROTOCOL_VERSION	(3)
+#define RXR_FI_VERSION		OFI_VERSION_LATEST
 
 #define RXR_IOV_LIMIT		(4)
 
@@ -84,7 +84,7 @@ extern const uint32_t rxr_poison_value;
 #define RXR_RECVWIN_SIZE		(16384)
 #define RXR_DEF_CQ_SIZE			(8192)
 #define RXR_REMOTE_CQ_DATA_LEN		(8)
-#define RXR_MIN_AV_SIZE			(8192)
+#define RXR_MIN_AV_SIZE			(16384)
 /* maximum timeout for RNR backoff (microseconds) */
 #define RXR_DEF_RNR_MAX_TIMEOUT		(1000000)
 /* bounds for random RNR backoff timeout */
@@ -169,12 +169,23 @@ extern const uint32_t rxr_poison_value;
 
 #define RXR_MTU_MAX_LIMIT	BIT_ULL(15)
 
+
+/*
+ * Specific flags and attributes for shm provider
+ */
+#define RXR_SHM_HDR		BIT_ULL(10)
+#define RXR_SHM_HDR_DATA	BIT_ULL(11)
+#define RXR_SHM_MAX_AV_COUNT       (256)
+
+extern struct fi_info *shm_info;
+
 extern struct fi_provider *lower_efa_prov;
 extern struct fi_provider rxr_prov;
 extern struct fi_info rxr_info;
 extern struct rxr_env rxr_env;
 extern struct fi_fabric_attr rxr_fabric_attr;
 extern struct util_prov rxr_util_prov;
+extern struct efa_ep_addr *local_efa_addr;
 
 struct rxr_env {
 	int rx_window_size;
@@ -182,6 +193,9 @@ struct rxr_env {
 	int tx_max_credits;
 	int tx_queue_size;
 	int enable_sas_ordering;
+	int enable_shm_transfer;
+	int shm_av_size;
+	int shm_max_medium_size;
 	int recvwin_size;
 	int cq_size;
 	size_t max_memcpy_size;
@@ -194,15 +208,30 @@ struct rxr_env {
 	int rx_copy_ooo;
 	int max_timeout;
 	int timeout_interval;
+	size_t efa_cq_read_size;
+	size_t shm_cq_read_size;
+};
+
+enum rxr_lower_ep_type {
+	EFA_EP = 1,
+	SHM_EP,
 };
 
 enum rxr_pkt_type {
 	RXR_RTS_PKT = 1,
 	RXR_CONNACK_PKT,
-	/* Large message types */
 	RXR_CTS_PKT,
 	RXR_DATA_PKT,
 	RXR_READRSP_PKT,
+	RXR_RMA_CONTEXT_PKT,
+	RXR_EOR_PKT,
+};
+
+/* RMA context packet types which are used only on local EP */
+enum rxr_rma_context_pkt_type {
+	RXR_SHM_RMA_READ = 1,
+	RXR_SHM_RMA_WRITE,
+	RXR_SHM_LARGE_READ,
 };
 
 /* pkt_entry types for rx pkts */
@@ -226,9 +255,11 @@ enum rxr_x_entry_type {
 
 enum rxr_tx_comm_type {
 	RXR_TX_FREE = 0,	/* tx_entry free state */
+	RXR_TX_SHM_RMA,		/* tx_entry issuing read operation over shm provider */
 	RXR_TX_RTS,		/* tx_entry sending RTS message */
 	RXR_TX_SEND,		/* tx_entry sending data in progress */
-	RXR_TX_QUEUED_RTS,	/* tx_entry was unable to send RTS */
+	RXR_TX_QUEUED_SHM_RMA,	/* tx_entry was unable to send RMA operations over shm provider */
+	RXR_TX_QUEUED_CTRL,	/* tx_entry was unable to send ctrl packet */
 	RXR_TX_QUEUED_RTS_RNR,  /* tx_entry RNR sending RTS packet */
 	RXR_TX_QUEUED_DATA_RNR,	/* tx_entry RNR sending data packets */
 	RXR_TX_SENT_READRSP,	/* tx_entry (on remote EP) sent
@@ -250,7 +281,9 @@ enum rxr_rx_comm_type {
 	RXR_RX_UNEXP,		/* rx_entry unexp msg waiting for post recv */
 	RXR_RX_MATCHED,		/* rx_entry matched with RTS msg */
 	RXR_RX_RECV,		/* rx_entry large msg recv data pkts */
-	RXR_RX_QUEUED_CTS,	/* rx_entry was unable to send CTS */
+	RXR_RX_QUEUED_CTRL,	/* rx_entry was unable to send ctrl packet */
+	RXR_RX_QUEUED_SHM_LARGE_READ,	/* rx_entry was unable to issue RMA Read for large message over shm */
+	RXR_RX_QUEUED_EOR,	/* rx_entry was unable to send EOR over shm */
 	RXR_RX_QUEUED_CTS_RNR,	/* rx_entry RNR sending CTS */
 	RXR_RX_WAIT_READ_FINISH, /* rx_entry wait for send to finish, FI_READ */
 };
@@ -269,6 +302,7 @@ enum rxr_peer_state {
 struct rxr_fabric {
 	struct util_fabric util_fabric;
 	struct fid_fabric *lower_fabric;
+	struct fid_fabric *shm_fabric;
 #ifdef RXR_PERF_ENABLED
 	struct ofi_perfset perf_set;
 #endif
@@ -277,18 +311,22 @@ struct rxr_fabric {
 struct rxr_mr {
 	struct fid_mr mr_fid;
 	struct fid_mr *msg_mr;
+	struct fid_mr *shm_msg_mr;
 	struct rxr_domain *domain;
 };
 
 struct rxr_av_entry {
 	uint8_t addr[RXR_MAX_NAME_LENGTH];
 	fi_addr_t rdm_addr;
+	fi_addr_t shm_rdm_addr;
+	bool local_mapping;
 	UT_hash_handle hh;
 };
 
 struct rxr_av {
 	struct util_av util_av;
 	struct fid_av *rdm_av;
+	struct fid_av *shm_rdm_av;
 	struct rxr_av_entry *av_map;
 
 	int rdm_av_used;
@@ -298,6 +336,8 @@ struct rxr_av {
 struct rxr_peer {
 	bool tx_init;			/* tracks initialization of tx state */
 	bool rx_init;			/* tracks initialization of rx state */
+	bool is_local;			/* local/remote peer flag */
+	fi_addr_t shm_fiaddr;		/* fi_addr_t addr from shm provider */
 	struct rxr_robuf *robuf;	/* tracks expected msg_id on rx */
 	uint32_t next_msg_id;		/* sender's view of msg_id */
 	enum rxr_peer_state state;	/* state of CM protocol with peer */
@@ -313,6 +353,11 @@ struct rxr_peer {
 	struct dlist_entry entry;	/* linked to rxr_ep peer_list */
 };
 
+struct rxr_queued_ctrl_info {
+	int type;
+	int inject;
+};
+
 struct rxr_rx_entry {
 	/* Must remain at the top */
 	enum rxr_x_entry_type type;
@@ -339,10 +384,12 @@ struct rxr_rx_entry {
 	uint64_t bytes_done;
 	int64_t window;
 	uint16_t credit_request;
+	int credit_cts;
 
 	uint64_t total_len;
 
 	enum rxr_rx_comm_type state;
+	struct rxr_queued_ctrl_info queued_ctrl;
 
 	uint64_t fi_flags;
 	uint16_t rxr_flags;
@@ -350,6 +397,10 @@ struct rxr_rx_entry {
 	size_t iov_count;
 	struct iovec iov[RXR_IOV_LIMIT];
 
+	/* iov_count on sender side, used for large message READ over shm */
+	size_t rma_iov_count;
+	struct fi_rma_iov rma_iov[RXR_IOV_LIMIT];
+
 	struct fi_cq_tagged_entry cq_entry;
 
 	/* entry is linked with rx entry lists in rxr_ep */
@@ -386,6 +437,7 @@ struct rxr_tx_entry {
 	/* Must remain at the top */
 	enum rxr_x_entry_type type;
 
+	uint32_t op;
 	fi_addr_t addr;
 
 	/*
@@ -407,6 +459,7 @@ struct rxr_tx_entry {
 	uint64_t total_len;
 
 	enum rxr_tx_comm_type state;
+	struct rxr_queued_ctrl_info queued_ctrl;
 
 	uint64_t fi_flags;
 	uint64_t send_flags;
@@ -420,6 +473,9 @@ struct rxr_tx_entry {
 	size_t rma_iov_count;
 	struct fi_rma_iov rma_iov[RXR_IOV_LIMIT];
 
+	/* App-provided reg descriptor */
+	void *desc[RXR_IOV_LIMIT];
+
 	/* Only used with mr threshold switch from memcpy */
 	size_t iov_mr_start;
 	struct fid_mr *mr[RXR_IOV_LIMIT];
@@ -448,6 +504,7 @@ struct rxr_tx_entry {
 struct rxr_domain {
 	struct util_domain util_domain;
 	struct fid_domain *rdm_domain;
+	struct fid_domain *shm_domain;
 
 	size_t addrlen;
 	uint8_t mr_local;
@@ -473,6 +530,10 @@ struct rxr_ep {
 	struct fid_ep *rdm_ep;
 	struct fid_cq *rdm_cq;
 
+	/* shm provider fid */
+	struct fid_ep *shm_ep;
+	struct fid_cq *shm_cq;
+
 	/*
 	 * RxR rx/tx queue sizes. These may be different from the core
 	 * provider's rx/tx size and will either limit the number of possible
@@ -508,8 +569,15 @@ struct rxr_ep {
 	size_t min_multi_recv_size;
 
 	/* buffer pool for send & recv */
-	struct ofi_bufpool *tx_pkt_pool;
-	struct ofi_bufpool *rx_pkt_pool;
+	struct ofi_bufpool *tx_pkt_efa_pool;
+	struct ofi_bufpool *rx_pkt_efa_pool;
+
+	/*
+	 * buffer pool for send & recv for shm as mtu size is different from
+	 * the one of efa, and do not require local memory registration
+	 */
+	struct ofi_bufpool *tx_pkt_shm_pool;
+	struct ofi_bufpool *rx_pkt_shm_pool;
 
 	/* staging area for unexpected and out-of-order packets */
 	struct ofi_bufpool *rx_unexp_pkt_pool;
@@ -536,6 +604,8 @@ struct rxr_ep {
 	struct dlist_entry rx_unexp_tagged_list;
 	/* list of pre-posted recv buffers */
 	struct dlist_entry rx_posted_buf_list;
+	/* list of pre-posted recv buffers for shm */
+	struct dlist_entry rx_posted_buf_shm_list;
 	/* tx entries with queued messages */
 	struct dlist_entry tx_entry_queued_list;
 	/* rx entries with queued messages */
@@ -568,10 +638,13 @@ struct rxr_ep {
 	size_t failed_send_comps;
 	size_t recv_comps;
 #endif
+	/* number of posted buffer for shm */
+	size_t posted_bufs_shm;
+	size_t rx_bufs_shm_to_post;
 
 	/* number of posted buffers */
-	size_t posted_bufs;
-	size_t rx_bufs_to_post;
+	size_t posted_bufs_efa;
+	size_t rx_bufs_efa_to_post;
 	/* number of buffers available for large messages */
 	size_t available_data_bufs;
 	/* Timestamp of when available_data_bufs was exhausted. */
@@ -620,6 +693,24 @@ struct rxr_rts_hdr {
 static_assert(sizeof(struct rxr_rts_hdr) == 32, "rxr_rts_hdr check");
 #endif
 
+/*
+ * EOR packet, used to acknowledge the sender that large message
+ * copy has been finished.
+ */
+struct rxr_eor_hdr {
+	uint8_t type;
+	uint8_t version;
+	uint16_t flags;
+	/* end of rxr_base_hdr */
+	uint32_t tx_id;
+	uint32_t rx_id;
+};
+
+#if defined(static_assert) && defined(__x86_64__)
+static_assert(sizeof(struct rxr_eor_hdr) == 12, "rxr_eor_hdr check");
+#endif
+
+
 struct rxr_connack_hdr {
 	uint8_t type;
 	uint8_t version;
@@ -662,21 +753,6 @@ struct rxr_data_hdr {
 static_assert(sizeof(struct rxr_data_hdr) == 24, "rxr_data_hdr check");
 #endif
 
-struct rxr_readrsp_hdr {
-	uint8_t type;
-	uint8_t version;
-	uint16_t flags;
-	/* end of rxr_base_hdr */
-	uint8_t pad[4];
-	uint32_t rx_id;
-	uint32_t tx_id;
-	uint64_t seg_size;
-};
-
-#if defined(static_assert) && defined(__x86_64__)
-static_assert(sizeof(struct rxr_readrsp_hdr) == sizeof(struct rxr_data_hdr), "rxr_readrsp_hdr check");
-#endif
-
 /*
  * Control header without completion data. We will send more data with the RTS
  * packet if RXR_REMOTE_CQ_DATA is not set.
@@ -728,9 +804,17 @@ struct rxr_data_pkt {
 	char data[];
 };
 
-struct rxr_readrsp_pkt {
-	struct rxr_readrsp_hdr hdr;
-	char data[];
+/*
+ * RMA context packet, used to differentiate the normal RMA read, normal RMA
+ * write, and the RMA read in two-sided large message transfer
+ */
+struct rxr_rma_context_pkt {
+	uint8_t type;
+	uint8_t version;
+	uint16_t flags;
+	/* end of rxr_base_hdr */
+	uint32_t tx_id;
+	uint8_t rma_context_type;
 };
 
 struct rxr_pkt_entry {
@@ -774,8 +858,17 @@ DECLARE_FREESTACK(struct rxr_robuf, rxr_robuf_fs);
 
 #define RXR_DATA_HDR_SIZE		(sizeof(struct rxr_data_hdr))
 
-#define RXR_READRSP_HDR_SIZE	(sizeof(struct rxr_readrsp_hdr))
+static inline void rxr_copy_shm_cq_entry(struct fi_cq_tagged_entry *cq_tagged_entry,
+					 struct fi_cq_data_entry *shm_cq_entry)
+{
+	cq_tagged_entry->op_context = shm_cq_entry->op_context;
+	cq_tagged_entry->flags = shm_cq_entry->flags;
+	cq_tagged_entry->len = shm_cq_entry->len;
+	cq_tagged_entry->buf = shm_cq_entry->buf;
+	cq_tagged_entry->data = shm_cq_entry->data;
+	cq_tagged_entry->tag = 0; // No tag for RMA;
 
+}
 static inline struct rxr_peer *rxr_ep_get_peer(struct rxr_ep *ep,
 					       fi_addr_t addr)
 {
@@ -818,29 +911,8 @@ struct rxr_rx_entry *rxr_ep_rx_entry_init(struct rxr_ep *ep,
 					  fi_addr_t addr, uint32_t op,
 					  uint64_t flags);
 
-void rxr_generic_tx_entry_init(struct rxr_ep *ep,
-			       struct rxr_tx_entry *tx_entry,
-			       const struct iovec *iov,
-			       size_t iov_count,
-			       const struct fi_rma_iov *rma_iov,
-			       size_t rma_iov_count,
-			       fi_addr_t addr, uint64_t tag,
-			       uint64_t data, void *context,
-			       uint32_t op, uint64_t flags);
-
-struct rxr_tx_entry *rxr_ep_tx_entry_init(struct rxr_ep *rxr_ep,
-					  const struct iovec *iov,
-					  size_t iov_count,
-					  const struct fi_rma_iov *rma_iov,
-					  size_t rma_iov_count,
-					  fi_addr_t addr, uint64_t tag,
-					  uint64_t data, void *context,
-					  uint32_t op, uint64_t flags);
-
-ssize_t rxr_tx(struct fid_ep *ep, const struct iovec *iov, size_t iov_count,
-	       const struct fi_rma_iov *rma_iov, size_t rma_iov_count,
-	       fi_addr_t addr, uint64_t tag, uint64_t data, void *context,
-	       uint32_t op, uint64_t flags);
+void rxr_tx_entry_init(struct rxr_ep *rxr_ep, struct rxr_tx_entry *tx_entry,
+		       const struct fi_msg *msg, uint32_t op, uint64_t flags);
 
 static inline void
 rxr_copy_pkt_entry(struct rxr_ep *ep,
@@ -930,20 +1002,6 @@ static inline void rxr_release_tx_pkt_entry(struct rxr_ep *ep,
 	ofi_buf_free(pkt);
 }
 
-static inline void rxr_release_rx_pkt_entry(struct rxr_ep *ep,
-					    struct rxr_pkt_entry *pkt)
-{
-#if ENABLE_DEBUG
-	dlist_remove(&pkt->dbg_entry);
-#endif
-#ifdef ENABLE_EFA_POISONING
-	/* the same pool size is used for all types of rx pkt_entries */
-	rxr_poison_mem_region((uint32_t *)pkt, ep->rx_pkt_pool_entry_sz);
-#endif
-	pkt->state = RXR_PKT_ENTRY_FREE;
-	ofi_buf_free(pkt);
-}
-
 static inline void rxr_release_tx_entry(struct rxr_ep *ep,
 					struct rxr_tx_entry *tx_entry)
 {
@@ -1001,11 +1059,6 @@ static inline struct rxr_cts_hdr *rxr_get_cts_hdr(void *pkt)
 	return (struct rxr_cts_hdr *)pkt;
 }
 
-static inline struct rxr_readrsp_hdr *rxr_get_readrsp_hdr(void *pkt)
-{
-	return (struct rxr_readrsp_hdr *)pkt;
-}
-
 static inline struct rxr_ctrl_cq_pkt *rxr_get_ctrl_cq_pkt(void *pkt)
 {
 	return (struct rxr_ctrl_cq_pkt *)pkt;
@@ -1063,12 +1116,14 @@ static inline uint64_t rxr_get_rts_data_size(struct rxr_ep *ep,
 					     struct rxr_rts_hdr *rts_hdr)
 {
 	/*
-	 * for read request, rts packet contain no data
-	 * because data is on remote host
+	 * read RTS contain no data, because data is on remote EP.
 	 */
 	if (rts_hdr->flags & RXR_READ_REQ)
 		return 0;
 
+	if (rts_hdr->flags & RXR_SHM_HDR)
+		return (rts_hdr->flags & RXR_SHM_HDR_DATA) ? rts_hdr->data_len : 0;
+
 	size_t max_payload_size;
 
 	if (rts_hdr->flags & RXR_REMOTE_CQ_DATA)
@@ -1109,6 +1164,30 @@ static inline int rxr_need_sas_ordering(struct rxr_ep *ep)
 		rxr_env.enable_sas_ordering);
 }
 
+static inline void rxr_release_rx_pkt_entry(struct rxr_ep *ep,
+					    struct rxr_pkt_entry *pkt_entry)
+{
+	if (pkt_entry->type == RXR_PKT_ENTRY_POSTED) {
+		struct rxr_peer *peer;
+
+		peer = rxr_ep_get_peer(ep, pkt_entry->addr);
+		assert(peer);
+		if (peer->is_local)
+			ep->rx_bufs_shm_to_post++;
+		else
+			ep->rx_bufs_efa_to_post++;
+	}
+#if ENABLE_DEBUG
+	dlist_remove(&pkt_entry->dbg_entry);
+#endif
+#ifdef ENABLE_EFA_POISONING
+	/* the same pool size is used for all types of rx pkt_entries */
+	rxr_poison_mem_region((uint32_t *)pkt, ep->rx_pkt_pool_entry_sz);
+#endif
+	pkt_entry->state = RXR_PKT_ENTRY_FREE;
+	ofi_buf_free(pkt_entry);
+}
+
 /* Initialization functions */
 void rxr_reset_rx_tx_to_core(const struct fi_info *user_info,
 			     struct fi_info *core_info);
@@ -1134,32 +1213,46 @@ int rxr_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 
 /* EP sub-functions */
 void rxr_ep_progress(struct util_ep *util_ep);
+void rxr_ep_progress_internal(struct rxr_ep *rxr_ep);
 struct rxr_pkt_entry *rxr_ep_get_pkt_entry(struct rxr_ep *rxr_ep,
 					   struct ofi_bufpool *pkt_pool);
-int rxr_ep_post_buf(struct rxr_ep *ep, uint64_t flags);
+int rxr_ep_post_buf(struct rxr_ep *ep, uint64_t flags, enum rxr_lower_ep_type lower_ep);
 ssize_t rxr_ep_send_msg(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry,
 			const struct fi_msg *msg, uint64_t flags);
 ssize_t rxr_ep_post_data(struct rxr_ep *rxr_ep, struct rxr_tx_entry *tx_entry);
-ssize_t rxr_ep_post_readrsp(struct rxr_ep *rxr_ep, struct rxr_tx_entry *tx_entry);
 void rxr_ep_init_connack_pkt_entry(struct rxr_ep *ep,
 				   struct rxr_pkt_entry *pkt_entry,
 				   fi_addr_t addr);
 void rxr_ep_calc_cts_window_credits(struct rxr_ep *ep, struct rxr_peer *peer,
 				    uint64_t size, int request,
 				    int *window, int *credits);
+
+int rxr_ep_set_tx_credit_request(struct rxr_ep *rxr_ep,
+				 struct rxr_tx_entry *tx_entry);
+
+void rxr_inline_mr_reg(struct rxr_domain *rxr_domain,
+		       struct rxr_tx_entry *tx_entry);
+
+char *rxr_ep_init_rts_hdr(struct rxr_ep *ep,
+			  struct rxr_tx_entry *tx_entry,
+			  struct rxr_pkt_entry *pkt_entry);
+
 void rxr_ep_init_cts_pkt_entry(struct rxr_ep *ep,
 			       struct rxr_rx_entry *rx_entry,
 			       struct rxr_pkt_entry *pkt_entry,
 			       uint64_t size,
 			       int *credits);
-void rxr_ep_init_readrsp_pkt_entry(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
-				   struct rxr_pkt_entry *pkt_entry);
 struct rxr_rx_entry *rxr_ep_get_new_unexp_rx_entry(struct rxr_ep *ep,
 						   struct rxr_pkt_entry *unexp_entry);
 struct rxr_rx_entry *rxr_ep_split_rx_entry(struct rxr_ep *ep,
 					   struct rxr_rx_entry *posted_entry,
 					   struct rxr_rx_entry *consumer_entry,
 					   struct rxr_pkt_entry *pkt_entry);
+int rxr_ep_efa_addr_to_str(const void *addr, char *temp_name);
+
+int rxr_ep_post_ctrl_or_queue(struct rxr_ep *ep, int entry_type, void *x_entry,
+			      int ctrl_type, bool inject);
+
 #if ENABLE_DEBUG
 void rxr_ep_print_pkt(char *prefix,
 		      struct rxr_ep *ep,
@@ -1176,25 +1269,48 @@ ssize_t rxr_cq_post_cts(struct rxr_ep *ep,
 			struct rxr_rx_entry *rx_entry,
 			uint64_t size);
 
-int rxr_cq_handle_rx_completion(struct rxr_ep *ep,
-				struct fi_cq_msg_entry *comp,
-				struct rxr_pkt_entry *pkt_entry,
+void rxr_cq_write_rx_completion(struct rxr_ep *ep,
 				struct rxr_rx_entry *rx_entry);
 
+void rxr_cq_handle_rx_completion(struct rxr_ep *ep,
+				 struct rxr_pkt_entry *pkt_entry,
+				 struct rxr_rx_entry *rx_entry);
+
 void rxr_cq_write_tx_completion(struct rxr_ep *ep,
-				struct fi_cq_msg_entry *comp,
 				struct rxr_tx_entry *tx_entry);
 
-void rxr_cq_recv_rts_data(struct rxr_ep *ep,
+ssize_t rxr_cq_recv_shm_large_message(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry);
+void rxr_cq_process_shm_large_message(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry,
+				      struct rxr_rts_hdr *rts_hdr, char *data);
+
+void rxr_cq_process_shm_large_message(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry,
+				      struct rxr_rts_hdr *rts_hdr, char *data);
+
+char *rxr_cq_read_rts_hdr(struct rxr_ep *ep,
 			  struct rxr_rx_entry *rx_entry,
-			  struct rxr_rts_hdr *rts_hdr);
+			  struct rxr_pkt_entry *pkt_entry);
+
+int rxr_cq_handle_rts_with_data(struct rxr_ep *ep,
+				struct rxr_rx_entry *rx_entry,
+				struct rxr_pkt_entry *pkt_entry,
+				char *data, size_t data_size);
+
+int rxr_cq_handle_pkt_with_data(struct rxr_ep *ep,
+				struct rxr_rx_entry *rx_entry,
+				struct rxr_pkt_entry *pkt_entry,
+				char *data, size_t seg_offset,
+				size_t seg_size);
 
 void rxr_cq_handle_pkt_recv_completion(struct rxr_ep *ep,
-				       struct fi_cq_msg_entry *comp,
+				       struct fi_cq_data_entry *comp,
 				       fi_addr_t src_addr);
 
 void rxr_cq_handle_pkt_send_completion(struct rxr_ep *rxr_ep,
-				       struct fi_cq_msg_entry *comp);
+				       struct fi_cq_data_entry *comp);
+
+void rxr_cq_handle_shm_rma_write_data(struct rxr_ep *ep,
+				      struct fi_cq_data_entry *shm_comp,
+				      fi_addr_t src_addr);
 
 /* Aborts if unable to write to the eq */
 static inline void rxr_eq_write_error(struct rxr_ep *ep, ssize_t err,
@@ -1287,11 +1403,13 @@ static inline ssize_t rxr_ep_sendv_pkt(struct rxr_ep *ep,
 				       uint64_t flags)
 {
 	struct fi_msg msg;
+	struct rxr_peer *peer;
 
 	msg.msg_iov = iov;
 	msg.desc = desc;
 	msg.iov_count = count;
-	msg.addr = addr;
+	peer = rxr_ep_get_peer(ep, addr);
+	msg.addr = peer->is_local ? peer->shm_fiaddr : addr;
 	msg.context = pkt_entry;
 	msg.data = 0;
 
@@ -1309,11 +1427,28 @@ static inline ssize_t rxr_ep_send_pkt_flags(struct rxr_ep *ep,
 	iov.iov_base = rxr_pkt_start(pkt_entry);
 	iov.iov_len = pkt_entry->pkt_size;
 
-	desc = rxr_ep_mr_local(ep) ? fi_mr_desc(pkt_entry->mr) : NULL;
+	if (rxr_ep_get_peer(ep, addr)->is_local)
+		desc = NULL;
+	else
+		desc = rxr_ep_mr_local(ep) ? fi_mr_desc(pkt_entry->mr) : NULL;
 
 	return rxr_ep_sendv_pkt(ep, pkt_entry, addr, &iov, &desc, 1, flags);
 }
 
+static inline ssize_t rxr_ep_inject_pkt(struct rxr_ep *ep,
+					struct rxr_pkt_entry *pkt_entry,
+					fi_addr_t addr)
+{
+	struct rxr_peer *peer;
+
+	/* currently only EOR packet is injected using shm ep */
+	peer = rxr_ep_get_peer(ep, addr);
+	assert(peer);
+	assert(rxr_env.enable_shm_transfer && peer->is_local);
+	return fi_inject(ep->shm_ep, rxr_pkt_start(pkt_entry), pkt_entry->pkt_size,
+			 peer->shm_fiaddr);
+}
+
 static inline ssize_t rxr_ep_send_pkt(struct rxr_ep *ep,
 				      struct rxr_pkt_entry *pkt_entry,
 				      fi_addr_t addr)
@@ -1321,30 +1456,6 @@ static inline ssize_t rxr_ep_send_pkt(struct rxr_ep *ep,
 	return rxr_ep_send_pkt_flags(ep, pkt_entry, addr, 0);
 }
 
-static inline int rxr_ep_post_cts_or_queue(struct rxr_ep *ep,
-					   struct rxr_rx_entry *rx_entry,
-					   uint64_t bytes_left)
-{
-	int ret;
-
-	if (rx_entry->state == RXR_RX_QUEUED_CTS)
-		return 0;
-
-	ret = rxr_cq_post_cts(ep, rx_entry, bytes_left);
-	if (OFI_UNLIKELY(ret)) {
-		if (ret == -FI_EAGAIN) {
-			rx_entry->state = RXR_RX_QUEUED_CTS;
-			dlist_insert_tail(&rx_entry->queued_entry,
-					  &ep->rx_entry_queued_list);
-			ret = 0;
-		} else {
-			if (rxr_cq_handle_rx_error(ep, rx_entry, ret))
-				assert(0 && "failed to write err cq entry");
-		}
-	}
-	return ret;
-}
-
 static inline bool rxr_peer_timeout_expired(struct rxr_ep *ep,
 					    struct rxr_peer *peer,
 					    uint64_t ts)
diff --git a/prov/efa/src/rxr/rxr_av.c b/prov/efa/src/rxr/rxr_av.c
index 6e1cb5a..7984af9 100644
--- a/prov/efa/src/rxr/rxr_av.c
+++ b/prov/efa/src/rxr/rxr_av.c
@@ -32,48 +32,117 @@
  */
 
 #include "rxr.h"
+#include "efa.h"
 #include <inttypes.h>
 
 /*
+ * Local/remote peer detection by comparing peer GID with stored local GIDs
+ */
+static bool rxr_is_local_peer(struct rxr_av *av, const void *addr)
+{
+	struct efa_ep_addr *cur_efa_addr = local_efa_addr;
+
+#if ENABLE_DEBUG
+	char peer_gid[INET6_ADDRSTRLEN] = { 0 };
+
+	if (!inet_ntop(AF_INET6, ((struct efa_ep_addr *)addr)->raw, peer_gid, INET6_ADDRSTRLEN)) {
+		FI_WARN(&rxr_prov, FI_LOG_AV, "Failed to get current EFA's GID, errno: %d\n", errno);
+		return 0;
+	}
+	FI_DBG(&rxr_prov, FI_LOG_AV, "The peer's GID is %s.\n", peer_gid);
+#endif
+	while (cur_efa_addr) {
+		if (!memcmp(((struct efa_ep_addr *)addr)->raw, cur_efa_addr->raw, 16)) {
+			FI_DBG(&rxr_prov, FI_LOG_AV, "The peer is local.\n");
+			return 1;
+		}
+		cur_efa_addr = cur_efa_addr->next;
+	}
+
+	return 0;
+}
+
+/*
  * Insert address translation in core av & in hash. Return 1 on successful
  * insertion regardless of whether it is in the hash table or not, 0 if the
  * lower layer av insert fails.
+ *
+ * If shm transfer is enabled and the addr comes from local peer,
+ * 1. convert addr to format 'gid_qpn', which will be set as shm's ep name later.
+ * 2. insert gid_qpn into shm's av
+ * 3. store returned fi_addr from shm into the hash table
  */
 int rxr_av_insert_rdm_addr(struct rxr_av *av, const void *addr,
 			   fi_addr_t *rdm_fiaddr, uint64_t flags,
 			   void *context)
 {
 	struct rxr_av_entry *av_entry;
+	fi_addr_t shm_fiaddr;
+	struct rxr_peer *peer;
+	struct rxr_ep *rxr_ep;
+	struct util_ep *util_ep;
+	struct dlist_entry *ep_list_entry;
+	char smr_name[NAME_MAX];
 	int ret = 1;
 
 	fastlock_acquire(&av->util_av.lock);
 
 	HASH_FIND(hh, av->av_map, addr, av->rdm_addrlen, av_entry);
 
-	if (!av_entry) {
-		ret = fi_av_insert(av->rdm_av, addr, 1,
-				   rdm_fiaddr, flags, context);
+	if (av_entry) {
+		*rdm_fiaddr = (fi_addr_t)av_entry->rdm_addr;
+		goto find_out;
+	}
+	ret = fi_av_insert(av->rdm_av, addr, 1, rdm_fiaddr, flags, context);
+	if (OFI_UNLIKELY(ret != 1)) {
+		FI_DBG(&rxr_prov, FI_LOG_AV,
+		       "Error in inserting address: %s\n", fi_strerror(-ret));
+		goto out;
+	}
+	av_entry = calloc(1, sizeof(*av_entry));
+	if (OFI_UNLIKELY(!av_entry)) {
+		ret = -FI_ENOMEM;
+		FI_WARN(&rxr_prov, FI_LOG_AV,
+			"Failed to allocate memory for av_entry\n");
+		goto out;
+	}
+	memcpy(av_entry->addr, addr, av->rdm_addrlen);
+	av_entry->rdm_addr = *(uint64_t *)rdm_fiaddr;
+
+	/* If peer is local, insert the address into shm provider's av */
+	if (rxr_env.enable_shm_transfer && rxr_is_local_peer(av, addr)) {
+		ret = rxr_ep_efa_addr_to_str(addr, smr_name);
+		if (ret != FI_SUCCESS)
+			goto out;
+
+		ret = fi_av_insert(av->shm_rdm_av, smr_name, 1, &shm_fiaddr, flags, context);
 		if (OFI_UNLIKELY(ret != 1)) {
-			FI_DBG(&rxr_prov, FI_LOG_AV,
-			       "Error in inserting address: %s\n", fi_strerror(-ret));
+			FI_DBG(&rxr_prov, FI_LOG_AV, "Failed to insert address to shm provider's av: %s\n",
+			       fi_strerror(-ret));
 			goto out;
-		} else {
-			av_entry = calloc(1, sizeof(*av_entry));
-			if (OFI_UNLIKELY(!av_entry)) {
-				ret = -FI_ENOMEM;
-				FI_WARN(&rxr_prov, FI_LOG_AV,
-					"Failed to allocate memory for av_entry\n");
-				goto out;
-			}
-			memcpy(av_entry->addr, addr, av->rdm_addrlen);
-			av_entry->rdm_addr = *(uint64_t *)rdm_fiaddr;
-			HASH_ADD(hh, av->av_map, addr,
-				 av->rdm_addrlen, av_entry);
 		}
-	} else {
-		*rdm_fiaddr = (fi_addr_t)av_entry->rdm_addr;
+		FI_DBG(&rxr_prov, FI_LOG_AV,
+			"Insert %s to shm provider's av. addr = %" PRIu64 " rdm_fiaddr = %" PRIu64
+			" shm_rdm_fiaddr = %" PRIu64 "\n", smr_name, *(uint64_t *)addr, *rdm_fiaddr, shm_fiaddr);
+		av_entry->local_mapping = 1;
+		av_entry->shm_rdm_addr = shm_fiaddr;
+
+		/*
+		 * Walk through all the EPs that bound to the AV,
+		 * update is_local flag and shm fi_addr_t in corresponding peer structure
+		 */
+		dlist_foreach(&av->util_av.ep_list, ep_list_entry) {
+			util_ep = container_of(ep_list_entry, struct util_ep, av_entry);
+			rxr_ep = container_of(util_ep, struct rxr_ep, util_ep);
+			peer = rxr_ep_get_peer(rxr_ep, *rdm_fiaddr);
+			peer->shm_fiaddr = shm_fiaddr;
+			peer->is_local = 1;
+		}
 	}
 
+	HASH_ADD(hh, av->av_map, addr, av->rdm_addrlen, av_entry);
+
+find_out:
 	FI_DBG(&rxr_prov, FI_LOG_AV,
 	       "addr = %" PRIu64 " rdm_fiaddr =  %" PRIu64 "\n",
 	       *(uint64_t *)addr, *rdm_fiaddr);
@@ -185,6 +254,13 @@ static int rxr_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
 
 		HASH_FIND(hh, av->av_map, addr, av->rdm_addrlen, av_entry);
 
+		/* remove an address from shm provider's av */
+		if (rxr_env.enable_shm_transfer && av_entry->local_mapping) {
+			ret = fi_av_remove(av->shm_rdm_av, &av_entry->shm_rdm_addr, 1, flags);
+			if (ret)
+				break;
+		}
+
 		if (av_entry) {
 			HASH_DEL(av->av_map, av_entry);
 			free(av_entry);
@@ -235,6 +311,13 @@ static int rxr_av_close(struct fid *fid)
 	ret = fi_close(&av->rdm_av->fid);
 	if (ret)
 		goto err;
+	if (rxr_env.enable_shm_transfer) {
+		ret = fi_close(&av->shm_rdm_av->fid);
+		if (ret) {
+			FI_WARN(&rxr_prov, FI_LOG_AV, "Failed to close shm av\n");
+			goto err;
+		}
+	}
 
 	ret = ofi_av_close(&av->util_av);
 	if (ret)
@@ -269,7 +352,8 @@ int rxr_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	struct rxr_domain *domain;
 	struct fi_av_attr av_attr;
 	struct util_av_attr util_attr;
-	int ret;
+	size_t universe_size;
+	int ret, retv;
 
 	if (!attr)
 		return -FI_EINVAL;
@@ -296,8 +380,18 @@ int rxr_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	else
 		attr->count = MAX(attr->count, RXR_MIN_AV_SIZE);
 
+	if (fi_param_get_size_t(NULL, "universe_size",
+				&universe_size) == FI_SUCCESS)
+		attr->count = MAX(attr->count, universe_size);
+
 	util_attr.addrlen = sizeof(fi_addr_t);
 	util_attr.flags = 0;
+	if (attr->type == FI_AV_UNSPEC){
+		if (domain->util_domain.av_type != FI_AV_UNSPEC)
+			attr->type = domain->util_domain.av_type;
+		else
+			attr->type = FI_AV_TABLE;
+	}
 	ret = ofi_av_init(&domain->util_domain, attr, &util_attr,
 			  &av->util_av, context);
 	if (ret)
@@ -314,6 +408,19 @@ int rxr_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	if (ret)
 		goto err;
 
+	if (rxr_env.enable_shm_transfer) {
+		/*
+		 * shm av supports maximum 256 entries
+		 * Reset the count to 128 to reduce memory footprint and satisfy
+		 * the need of the instances with more CPUs.
+		 */
+		assert(rxr_env.shm_av_size <= RXR_SHM_MAX_AV_COUNT);
+		av_attr.count = rxr_env.shm_av_size;
+		ret = fi_av_open(domain->shm_domain, &av_attr, &av->shm_rdm_av, context);
+		if (ret)
+			goto err_close_rdm_av;
+	}
+
 	av->rdm_addrlen = domain->addrlen;
 
 	*av_fid = &av->util_av.av_fid;
@@ -322,6 +429,11 @@ int rxr_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	(*av_fid)->ops = &rxr_av_ops;
 	return 0;
 
+err_close_rdm_av:
+	retv = fi_close(&av->rdm_av->fid);
+	if (retv)
+		FI_WARN(&rxr_prov, FI_LOG_AV,
+				"Unable to close rdm av: %s\n", fi_strerror(-retv));
 err:
 	free(av);
 	return ret;
diff --git a/prov/efa/src/rxr/rxr_cq.c b/prov/efa/src/rxr/rxr_cq.c
index eb27587..e581dba 100644
--- a/prov/efa/src/rxr/rxr_cq.c
+++ b/prov/efa/src/rxr/rxr_cq.c
@@ -103,8 +103,10 @@ int rxr_cq_handle_rx_error(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry,
 		dlist_remove(&rx_entry->rx_pending_entry);
 #endif
 		break;
-	case RXR_RX_QUEUED_CTS:
+	case RXR_RX_QUEUED_CTRL:
 	case RXR_RX_QUEUED_CTS_RNR:
+	case RXR_RX_QUEUED_SHM_LARGE_READ:
+	case RXR_RX_QUEUED_EOR:
 		dlist_remove(&rx_entry->queued_entry);
 		break;
 	default:
@@ -119,8 +121,6 @@ int rxr_cq_handle_rx_error(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry,
 		rxr_release_tx_pkt_entry(ep, pkt_entry);
 
 	if (rx_entry->unexp_rts_pkt) {
-		if (rx_entry->unexp_rts_pkt->type == RXR_PKT_ENTRY_POSTED)
-			ep->rx_bufs_to_post++;
 		rxr_release_rx_pkt_entry(ep, rx_entry->unexp_rts_pkt);
 		rx_entry->unexp_rts_pkt = NULL;
 	}
@@ -182,11 +182,13 @@ int rxr_cq_handle_tx_error(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
 
 	switch (tx_entry->state) {
 	case RXR_TX_RTS:
+	case RXR_TX_SHM_RMA:
 		break;
 	case RXR_TX_SEND:
 		dlist_remove(&tx_entry->entry);
 		break;
-	case RXR_TX_QUEUED_RTS:
+	case RXR_TX_QUEUED_CTRL:
+	case RXR_TX_QUEUED_SHM_RMA:
 	case RXR_TX_QUEUED_RTS_RNR:
 	case RXR_TX_QUEUED_DATA_RNR:
 		dlist_remove(&tx_entry->queued_entry);
@@ -361,7 +363,6 @@ int rxr_cq_handle_cq_error(struct rxr_ep *ep, ssize_t err)
 			rxr_release_tx_pkt_entry(ep, pkt_entry);
 		} else if (err_entry.flags & FI_RECV) {
 			rxr_release_rx_pkt_entry(ep, pkt_entry);
-			ep->rx_bufs_to_post++;
 		} else {
 			assert(0 && "unknown err_entry flags in CONNACK packet");
 		}
@@ -375,7 +376,6 @@ int rxr_cq_handle_cq_error(struct rxr_ep *ep, ssize_t err)
 		 * we will write to the eq instead.
 		 */
 		rxr_release_rx_pkt_entry(ep, pkt_entry);
-		ep->rx_bufs_to_post++;
 		goto write_err;
 	}
 
@@ -384,7 +384,8 @@ int rxr_cq_handle_cq_error(struct rxr_ep *ep, ssize_t err)
 	 * packet. Decrement the tx_pending counter and fall through to
 	 * the rx or tx entry handlers.
 	 */
-	rxr_ep_dec_tx_pending(ep, peer, 1);
+	if (!peer->is_local)
+		rxr_ep_dec_tx_pending(ep, peer, 1);
 	if (RXR_GET_X_ENTRY_TYPE(pkt_entry) == RXR_TX_ENTRY) {
 		tx_entry = (struct rxr_tx_entry *)pkt_entry->x_entry;
 		if (err_entry.err != -FI_EAGAIN ||
@@ -448,12 +449,15 @@ static int rxr_cq_match_trecv(struct dlist_entry *item, const void *arg)
 {
 	struct rxr_pkt_entry *pkt_entry = (struct rxr_pkt_entry *)arg;
 	struct rxr_rx_entry *rx_entry;
+	uint64_t match_tag;
 
 	rx_entry = container_of(item, struct rxr_rx_entry, entry);
 
+	match_tag = rxr_get_rts_hdr(pkt_entry->pkt)->tag;
+
 	return rxr_match_addr(rx_entry->addr, pkt_entry->addr) &&
 	       rxr_match_tag(rx_entry->cq_entry.tag, rx_entry->ignore,
-			     rxr_get_rts_hdr(pkt_entry->pkt)->tag);
+			     match_tag);
 }
 
 static void rxr_cq_post_connack(struct rxr_ep *ep,
@@ -466,7 +470,7 @@ static void rxr_cq_post_connack(struct rxr_ep *ep,
 	if (peer->state == RXR_PEER_ACKED)
 		return;
 
-	pkt_entry = rxr_get_pkt_entry(ep, ep->tx_pkt_pool);
+	pkt_entry = rxr_get_pkt_entry(ep, ep->tx_pkt_efa_pool);
 	if (OFI_UNLIKELY(!pkt_entry))
 		return;
 
@@ -495,50 +499,8 @@ static void rxr_cq_post_connack(struct rxr_ep *ep,
 	return;
 }
 
-ssize_t rxr_cq_post_cts(struct rxr_ep *ep,
-			struct rxr_rx_entry *rx_entry,
-			uint64_t size)
-{
-	ssize_t ret;
-	struct rxr_pkt_entry *pkt_entry;
-	int credits;
-
-	if (OFI_UNLIKELY(ep->posted_bufs == 0 || ep->available_data_bufs == 0))
-		return -FI_EAGAIN;
-
-	pkt_entry = rxr_get_pkt_entry(ep, ep->tx_pkt_pool);
-
-	if (OFI_UNLIKELY(!pkt_entry))
-		return -FI_EAGAIN;
-
-	rxr_ep_init_cts_pkt_entry(ep, rx_entry, pkt_entry, size, &credits);
-
-	ret = rxr_ep_send_pkt(ep, pkt_entry, rx_entry->addr);
-	if (OFI_UNLIKELY(ret))
-		goto release_pkt;
-
-	rx_entry->window = rxr_get_cts_hdr(pkt_entry->pkt)->window;
-	ep->available_data_bufs -= credits;
-
-	/*
-	 * Set a timer if available_bufs is exhausted. We may encounter a
-	 * scenario where a peer has stopped responding so we need a fallback
-	 * to replenish the credits.
-	 */
-	if (OFI_UNLIKELY(ep->available_data_bufs == 0))
-		ep->available_data_bufs_ts = fi_gettime_us();
-
-	return ret;
-
-release_pkt:
-	rxr_release_tx_pkt_entry(ep, pkt_entry);
-	return ret;
-}
-
-int rxr_cq_write_rx_completion(struct rxr_ep *ep,
-			       struct fi_cq_msg_entry *comp,
-			       struct rxr_pkt_entry *pkt_entry,
-			       struct rxr_rx_entry *rx_entry)
+void rxr_cq_write_rx_completion(struct rxr_ep *ep,
+				struct rxr_rx_entry *rx_entry)
 {
 	struct util_cq *rx_cq = ep->util_ep.rx_cq;
 	int ret = 0;
@@ -566,7 +528,7 @@ int rxr_cq_write_rx_completion(struct rxr_ep *ep,
 				fi_strerror(-ret));
 
 		rxr_cntr_report_error(ep, rx_entry->cq_entry.flags);
-		goto out;
+		return;
 	}
 
 	if (!(rx_entry->rxr_flags & RXR_RECV_CANCEL) &&
@@ -576,7 +538,7 @@ int rxr_cq_write_rx_completion(struct rxr_ep *ep,
 		       "Writing recv completion for rx_entry from peer: %"
 		       PRIu64 " rx_id: %" PRIu32 " msg_id: %" PRIu32
 		       " tag: %lx total_len: %" PRIu64 "\n",
-		       pkt_entry->addr, rx_entry->rx_id, rx_entry->msg_id,
+		       rx_entry->addr, rx_entry->rx_id, rx_entry->msg_id,
 		       rx_entry->cq_entry.tag, rx_entry->total_len);
 
 		if (ep->util_ep.caps & FI_SOURCE)
@@ -605,44 +567,31 @@ int rxr_cq_write_rx_completion(struct rxr_ep *ep,
 				fi_strerror(-ret));
 			if (rxr_cq_handle_rx_error(ep, rx_entry, ret))
 				assert(0 && "failed to write err cq entry");
-			if (pkt_entry->type == RXR_PKT_ENTRY_POSTED)
-				ep->rx_bufs_to_post++;
-			rxr_release_rx_pkt_entry(ep, pkt_entry);
-			return ret;
+			return;
 		}
 	}
 
 	rxr_cntr_report_rx_completion(ep, rx_entry);
-
-out:
-	return 0;
 }
 
-int rxr_cq_handle_rx_completion(struct rxr_ep *ep,
-				struct fi_cq_msg_entry *comp,
-				struct rxr_pkt_entry *pkt_entry,
-				struct rxr_rx_entry *rx_entry)
+void rxr_cq_handle_rx_completion(struct rxr_ep *ep,
+				 struct rxr_pkt_entry *pkt_entry,
+				 struct rxr_rx_entry *rx_entry)
 {
-	int ret = 0;
 	struct rxr_tx_entry *tx_entry = NULL;
 
-	if (rx_entry->fi_flags & FI_MULTI_RECV)
-		rxr_cq_handle_multi_recv_completion(ep, rx_entry);
-
 	if (rx_entry->cq_entry.flags & FI_WRITE) {
 		/*
 		 * must be on the remote side, notify cq/counter
 		 * if FI_RMA_EVENT is requested or REMOTE_CQ_DATA is on
 		 */
 		if (rx_entry->cq_entry.flags & FI_REMOTE_CQ_DATA)
-			ret = rxr_cq_write_rx_completion(ep, comp, pkt_entry, rx_entry);
+			rxr_cq_write_rx_completion(ep, rx_entry);
 		else if (ep->util_ep.caps & FI_RMA_EVENT)
 			rxr_cntr_report_rx_completion(ep, rx_entry);
 
-		if (pkt_entry->type == RXR_PKT_ENTRY_POSTED)
-			ep->rx_bufs_to_post++;
 		rxr_release_rx_pkt_entry(ep, pkt_entry);
-		return ret;
+		return;
 	}
 
 	if (rx_entry->cq_entry.flags & FI_READ) {
@@ -677,7 +626,7 @@ int rxr_cq_handle_rx_completion(struct rxr_ep *ep,
 		assert(tx_entry->state == RXR_TX_WAIT_READ_FINISH);
 		if (tx_entry->fi_flags & FI_COMPLETION) {
 			/* Note write_tx_completion() will release tx_entry */
-			rxr_cq_write_tx_completion(ep, comp, tx_entry);
+			rxr_cq_write_tx_completion(ep, tx_entry);
 		} else {
 			rxr_cntr_report_tx_completion(ep, tx_entry);
 			rxr_release_tx_entry(ep, tx_entry);
@@ -687,32 +636,136 @@ int rxr_cq_handle_rx_completion(struct rxr_ep *ep,
 		 * do not call rxr_release_rx_entry here because
 		 * caller will release
 		 */
-		if (pkt_entry->type == RXR_PKT_ENTRY_POSTED)
-			ep->rx_bufs_to_post++;
 		rxr_release_rx_pkt_entry(ep, pkt_entry);
-		return 0;
+		return;
 	}
 
-	ret = rxr_cq_write_rx_completion(ep, comp, pkt_entry, rx_entry);
-	if (pkt_entry->type == RXR_PKT_ENTRY_POSTED)
-		ep->rx_bufs_to_post++;
+	if (rx_entry->fi_flags & FI_MULTI_RECV)
+		rxr_cq_handle_multi_recv_completion(ep, rx_entry);
+
+	rxr_cq_write_rx_completion(ep, rx_entry);
 	rxr_release_rx_pkt_entry(ep, pkt_entry);
+	return;
+}
+
+ssize_t rxr_cq_recv_shm_large_message(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry)
+{
+	struct rxr_pkt_entry *pkt_entry;
+	struct rxr_rma_context_pkt *rma_context_pkt;
+	struct fi_msg_rma msg;
+	struct iovec msg_iov[RXR_IOV_LIMIT];
+	struct fi_rma_iov rma_iov[RXR_IOV_LIMIT];
+	fi_addr_t src_shm_fiaddr;
+	uint64_t remain_len;
+	struct rxr_peer *peer;
+	int ret, i;
+
+	if (rx_entry->state == RXR_RX_QUEUED_SHM_LARGE_READ)
+		return 0;
+
+	pkt_entry = rxr_get_pkt_entry(ep, ep->tx_pkt_shm_pool);
+	assert(pkt_entry);
+
+	pkt_entry->x_entry = (void *)rx_entry;
+	pkt_entry->addr = rx_entry->addr;
+	rma_context_pkt = (struct rxr_rma_context_pkt *)pkt_entry->pkt;
+	rma_context_pkt->type = RXR_RMA_CONTEXT_PKT;
+	rma_context_pkt->version = RXR_PROTOCOL_VERSION;
+	rma_context_pkt->rma_context_type = RXR_SHM_LARGE_READ;
+	rma_context_pkt->tx_id = rx_entry->tx_id;
+
+	peer = rxr_ep_get_peer(ep, rx_entry->addr);
+	src_shm_fiaddr = peer->shm_fiaddr;
+
+	memset(&msg, 0, sizeof(msg));
+
+	remain_len = rx_entry->total_len;
+
+	for (i = 0; i < rx_entry->rma_iov_count; i++) {
+		rma_iov[i].addr = rx_entry->rma_iov[i].addr;
+		rma_iov[i].len = rx_entry->rma_iov[i].len;
+		rma_iov[i].key = 0;
+	}
+
+	/*
+	 * shm provider will compare #bytes CMA copied with total length of recv buffer
+	 * (msg_iov here). If they are not equal, an error is returned when reading shm
+	 * provider's cq. So shrink the total length of recv buffer if applicable
+	 */
+	for (i = 0; i < rx_entry->iov_count; i++) {
+		msg_iov[i].iov_base = (void *)rx_entry->iov[i].iov_base;
+		msg_iov[i].iov_len = (remain_len < rx_entry->iov[i].iov_len) ?
+					remain_len : rx_entry->iov[i].iov_len;
+		remain_len -= msg_iov[i].iov_len;
+		if (remain_len == 0)
+			break;
+	}
+
+	msg.msg_iov = msg_iov;
+	msg.iov_count = rx_entry->iov_count;
+	msg.desc = NULL;
+	msg.addr = src_shm_fiaddr;
+	msg.context = pkt_entry;
+	msg.rma_iov = rma_iov;
+	msg.rma_iov_count = rx_entry->rma_iov_count;
+
+	ret = fi_readmsg(ep->shm_ep, &msg, 0);
+
 	return ret;
 }
 
-void rxr_cq_recv_rts_data(struct rxr_ep *ep,
+void rxr_cq_process_shm_large_message(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry,
+				      struct rxr_rts_hdr *rts_hdr, char *data)
+{
+	struct iovec *iovec_ptr;
+	int ret, i;
+
+	/* get iov_count of sender first */
+	memcpy(&rx_entry->rma_iov_count, data, sizeof(size_t));
+	data += sizeof(size_t);
+
+	iovec_ptr = (struct iovec *)data;
+	for (i = 0; i < rx_entry->rma_iov_count; i++) {
+		iovec_ptr = iovec_ptr + i;
+		rx_entry->rma_iov[i].addr = (intptr_t) iovec_ptr->iov_base;
+		rx_entry->rma_iov[i].len = iovec_ptr->iov_len;
+		rx_entry->rma_iov[i].key = 0;
+	}
+
+	ret = rxr_cq_recv_shm_large_message(ep, rx_entry);
+
+	if (OFI_UNLIKELY(ret)) {
+		if (ret == -FI_EAGAIN) {
+			rx_entry->state = RXR_RX_QUEUED_SHM_LARGE_READ;
+			dlist_insert_tail(&rx_entry->queued_entry,  &ep->rx_entry_queued_list);
+			return;
+		}
+		FI_WARN(&rxr_prov, FI_LOG_CQ,
+			"A large message RMA READ failed over shm provider.\n");
+		if (rxr_cq_handle_rx_error(ep, rx_entry, ret))
+			assert(0 && "failed to write err cq entry");
+	}
+}
+
+char *rxr_cq_read_rts_hdr(struct rxr_ep *ep,
 			  struct rxr_rx_entry *rx_entry,
-			  struct rxr_rts_hdr *rts_hdr)
+			  struct rxr_pkt_entry *pkt_entry)
 {
 	char *data;
-	uint32_t emulated_rma_flags = 0;
-	int ret = 0;
-	struct fi_rma_iov *rma_iov = NULL;
-
+	struct rxr_rts_hdr *rts_hdr = NULL;
 	/*
 	 * Use the correct header and grab CQ data and data, but ignore the
 	 * source_address since that has been fetched and processed already
 	 */
+
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+
+	rx_entry->addr = pkt_entry->addr;
+	rx_entry->tx_id = rts_hdr->tx_id;
+	rx_entry->msg_id = rts_hdr->msg_id;
+	rx_entry->total_len = rts_hdr->data_len;
+	rx_entry->cq_entry.tag = rts_hdr->tag;
+
 	if (rts_hdr->flags & RXR_REMOTE_CQ_DATA) {
 		rx_entry->cq_entry.flags |= FI_REMOTE_CQ_DATA;
 		data = rxr_get_ctrl_cq_pkt(rts_hdr)->data + rts_hdr->addrlen;
@@ -723,67 +776,18 @@ void rxr_cq_recv_rts_data(struct rxr_ep *ep,
 		data = rxr_get_ctrl_pkt(rts_hdr)->data + rts_hdr->addrlen;
 	}
 
-	if (rts_hdr->flags & (RXR_READ_REQ | RXR_WRITE)) {
-		rma_iov = (struct fi_rma_iov *)data;
-
-		if (rts_hdr->flags & RXR_READ_REQ) {
-			emulated_rma_flags = FI_SEND;
-			rx_entry->cq_entry.flags |= (FI_RMA | FI_READ);
-		} else {
-			assert(rts_hdr->flags | RXR_WRITE);
-			emulated_rma_flags = FI_RECV;
-			rx_entry->cq_entry.flags |= (FI_RMA | FI_WRITE);
-		}
-
-		assert(rx_entry->iov_count == 0);
-
-		rx_entry->iov_count = rts_hdr->rma_iov_count;
-		ret = rxr_rma_verified_copy_iov(ep, rma_iov, rts_hdr->rma_iov_count, emulated_rma_flags,
-						rx_entry->iov);
-		if (ret) {
-			FI_WARN(&rxr_prov, FI_LOG_CQ, "RMA address verify failed!\n");
-			rxr_cq_handle_cq_error(ep, -FI_EIO);
-		}
-
-		rx_entry->cq_entry.len = ofi_total_iov_len(&rx_entry->iov[0],
-							   rx_entry->iov_count);
-		rx_entry->cq_entry.buf = rx_entry->iov[0].iov_base;
-		data += rts_hdr->rma_iov_count * sizeof(struct fi_rma_iov);
-	}
-
-	/* we are sinking message for CANCEL/DISCARD entry */
-	if (OFI_UNLIKELY(rx_entry->rxr_flags & RXR_RECV_CANCEL)) {
-		rx_entry->bytes_done += rxr_get_rts_data_size(ep, rts_hdr);
-		return;
-	}
-
-	if (rx_entry->cq_entry.flags & FI_READ)  {
-		uint64_t *ptr = (uint64_t *)data;
-
-		rx_entry->bytes_done = 0;
-		rx_entry->rma_initiator_rx_id = *ptr;
-		ptr += 1;
-		rx_entry->window = *ptr;
-		assert(rx_entry->window > 0);
-	} else {
-		rx_entry->bytes_done += ofi_copy_to_iov(rx_entry->iov, rx_entry->iov_count,
-							0, data, rxr_get_rts_data_size(ep, rts_hdr));
-
-		assert(rx_entry->bytes_done == MIN(rx_entry->cq_entry.len, rxr_get_rts_data_size(ep, rts_hdr)));
-	}
+	return data;
 }
 
-static int rxr_cq_process_rts(struct rxr_ep *ep,
-			      struct rxr_pkt_entry *pkt_entry)
+int rxr_cq_process_msg_rts(struct rxr_ep *ep,
+			   struct rxr_pkt_entry *pkt_entry)
 {
+	struct rxr_peer *peer;
 	struct rxr_rts_hdr *rts_hdr;
 	struct dlist_entry *match;
 	struct rxr_rx_entry *rx_entry;
-	struct rxr_tx_entry *tx_entry;
-	uint64_t bytes_left;
-	uint64_t tag = 0;
-	uint32_t op;
-	int ret = 0;
+	char *data;
+	size_t data_size;
 
 	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
 
@@ -791,22 +795,6 @@ static int rxr_cq_process_rts(struct rxr_ep *ep,
 		match = dlist_find_first_match(&ep->rx_tagged_list,
 					       &rxr_cq_match_trecv,
 					       (void *)pkt_entry);
-	} else if (rts_hdr->flags & (RXR_READ_REQ | RXR_WRITE)) {
-		/*
-		 * rma is one sided operation, match is not expected
-		 * we need to create a rx entry upon receiving a rts
-		 */
-		tag = ~0; // RMA is not tagged
-		op = (rts_hdr->flags & RXR_READ_REQ) ? ofi_op_read_rsp : ofi_op_write_async;
-		rx_entry = rxr_ep_get_rx_entry(ep, NULL, 0, tag, 0, NULL, pkt_entry->addr, op, 0);
-		if (OFI_UNLIKELY(!rx_entry)) {
-			FI_WARN(&rxr_prov, FI_LOG_CQ,
-				"RX entries exhausted.\n");
-			rxr_eq_write_error(ep, FI_ENOBUFS, -FI_ENOBUFS);
-			return -FI_ENOBUFS;
-		}
-		dlist_insert_tail(&rx_entry->entry, &ep->rx_list);
-		match = &rx_entry->entry;
 	} else {
 		match = dlist_find_first_match(&ep->rx_list,
 					       &rxr_cq_match_recv,
@@ -821,116 +809,64 @@ static int rxr_cq_process_rts(struct rxr_ep *ep,
 			rxr_eq_write_error(ep, FI_ENOBUFS, -FI_ENOBUFS);
 			return -FI_ENOBUFS;
 		}
+
+		/* we are not releasing pkt_entry here because it will be
+		 * processed later
+		 */
 		pkt_entry = rx_entry->unexp_rts_pkt;
 		rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
-	} else {
-		rx_entry = container_of(match, struct rxr_rx_entry, entry);
-		if (rx_entry->rxr_flags & RXR_MULTI_RECV_POSTED) {
-			rx_entry = rxr_ep_split_rx_entry(ep, rx_entry,
-							 NULL, pkt_entry);
-			if (OFI_UNLIKELY(!rx_entry)) {
-				FI_WARN(&rxr_prov, FI_LOG_CQ,
-					"RX entries exhausted.\n");
-				rxr_eq_write_error(ep, FI_ENOBUFS, -FI_ENOBUFS);
-				return -FI_ENOBUFS;
-			}
-		}
-
-		rx_entry->state = RXR_RX_MATCHED;
-
-		if (!(rx_entry->fi_flags & FI_MULTI_RECV) ||
-		    !rxr_multi_recv_buffer_available(ep,
-						     rx_entry->master_entry))
-			dlist_remove(match);
-	}
-
-	rx_entry->addr = pkt_entry->addr;
-	rx_entry->tx_id = rts_hdr->tx_id;
-	rx_entry->msg_id = rts_hdr->msg_id;
-	rx_entry->total_len = rts_hdr->data_len;
-	rx_entry->cq_entry.tag = rts_hdr->tag;
-
-	if (OFI_UNLIKELY(!match))
+		rxr_cq_read_rts_hdr(ep, rx_entry, pkt_entry);
 		return 0;
+	}
 
-	/*
-	 * TODO: Change protocol to contact sender to stop sending when the
-	 * message is truncated instead of sinking the additional data.
-	 */
-
-	rxr_cq_recv_rts_data(ep, rx_entry, rts_hdr);
+	rx_entry = container_of(match, struct rxr_rx_entry, entry);
+	if (rx_entry->rxr_flags & RXR_MULTI_RECV_POSTED) {
+		rx_entry = rxr_ep_split_rx_entry(ep, rx_entry,
+						 NULL, pkt_entry);
+		if (OFI_UNLIKELY(!rx_entry)) {
+			FI_WARN(&rxr_prov, FI_LOG_CQ,
+				"RX entries exhausted.\n");
+			rxr_eq_write_error(ep, FI_ENOBUFS, -FI_ENOBUFS);
+			return -FI_ENOBUFS;
+		}
+	}
 
-	if (rx_entry->cq_entry.flags & FI_READ) {
-		/*
-		 * create a tx_entry for sending data back to initiator
-		 */
-		tx_entry = rxr_readrsp_tx_entry_init(ep, rx_entry);
+	rx_entry->state = RXR_RX_MATCHED;
 
-		/* the only difference between a read response packet and
-		 * a data packet is that read response packet has remote EP tx_id
-		 * which initiator EP rx_entry need to send CTS back
-		 */
+	if (!(rx_entry->fi_flags & FI_MULTI_RECV) ||
+	    !rxr_multi_recv_buffer_available(ep, rx_entry->master_entry))
+		dlist_remove(match);
 
-		ret = rxr_ep_post_readrsp(ep, tx_entry);
-		if (!ret) {
-			tx_entry->state = RXR_TX_SENT_READRSP;
-			if (tx_entry->bytes_sent < tx_entry->total_len) {
-				/* as long as read response packet has been sent,
-				 * data packets are ready to be sent. it is OK that
-				 * data packets arrive before read response packet,
-				 * because tx_id is needed by the initator EP in order
-				 * to send a CTS, which will not occur until
-				 * all data packets in current window are received, which
-				 * include the data in the read response packet.
-				 */
-				dlist_insert_tail(&tx_entry->entry, &ep->tx_pending_list);
-				tx_entry->state = RXR_TX_SEND;
-			}
-		} else if (ret == -FI_EAGAIN) {
-			dlist_insert_tail(&tx_entry->queued_entry, &ep->tx_entry_queued_list);
-			tx_entry->state = RXR_TX_QUEUED_READRSP;
-			ret = 0;
-		} else {
-			if (rxr_cq_handle_tx_error(ep, tx_entry, ret))
-				assert(0 && "failed to write err cq entry");
-		}
+	peer = rxr_ep_get_peer(ep, pkt_entry->addr);
+	assert(peer);
 
-		rx_entry->state = RXR_RX_WAIT_READ_FINISH;
-		if (pkt_entry->type == RXR_PKT_ENTRY_POSTED)
-			ep->rx_bufs_to_post++;
+	data = rxr_cq_read_rts_hdr(ep, rx_entry, pkt_entry);
+	if (peer->is_local && !(rts_hdr->flags & RXR_SHM_HDR_DATA)) {
+		rxr_cq_process_shm_large_message(ep, rx_entry, rts_hdr, data);
 		rxr_release_rx_pkt_entry(ep, pkt_entry);
-		return ret;
+		return 0;
 	}
 
-	bytes_left = rx_entry->total_len - rxr_get_rts_data_size(ep, rts_hdr);
-	rx_entry->cq_entry.len = MIN(rx_entry->total_len,
-				     rx_entry->cq_entry.len);
+	data_size = rxr_get_rts_data_size(ep, rts_hdr);
+	return rxr_cq_handle_rts_with_data(ep, rx_entry,
+					   pkt_entry, data,
+					   data_size);
+}
 
-	if (!bytes_left) {
-		ret = rxr_cq_handle_rx_completion(ep, NULL,
-						  pkt_entry, rx_entry);
-		rxr_multi_recv_free_posted_entry(ep, rx_entry);
-		if (!ret)
-			rxr_release_rx_entry(ep, rx_entry);
-		return ret;
-	}
+static int rxr_cq_process_rts(struct rxr_ep *ep,
+			      struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_rts_hdr *rts_hdr;
 
-#if ENABLE_DEBUG
-	dlist_insert_tail(&rx_entry->rx_pending_entry, &ep->rx_pending_list);
-	ep->rx_pending++;
-#endif
-	rx_entry->state = RXR_RX_RECV;
-	if (rts_hdr->flags & RXR_CREDIT_REQUEST)
-		rx_entry->credit_request = rts_hdr->credit_request;
-	else
-		rx_entry->credit_request = rxr_env.tx_min_credits;
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
 
-	ret = rxr_ep_post_cts_or_queue(ep, rx_entry, bytes_left);
-	if (pkt_entry->type == RXR_PKT_ENTRY_POSTED)
-		ep->rx_bufs_to_post++;
-	rxr_release_rx_pkt_entry(ep, pkt_entry);
+	if (rts_hdr->flags & RXR_READ_REQ)
+		return rxr_rma_proc_read_rts(ep, pkt_entry);
 
-	return ret;
+	if (rts_hdr->flags & RXR_WRITE)
+		return rxr_rma_proc_write_rts(ep, pkt_entry);
+
+	return rxr_cq_process_msg_rts(ep, pkt_entry);
 }
 
 static int rxr_cq_reorder_msg(struct rxr_ep *ep,
@@ -972,7 +908,6 @@ static int rxr_cq_reorder_msg(struct rxr_ep *ep,
 		rxr_copy_pkt_entry(ep, ooo_entry, pkt_entry, RXR_PKT_ENTRY_OOO);
 		rts_hdr = rxr_get_rts_hdr(ooo_entry->pkt);
 		rxr_release_rx_pkt_entry(ep, pkt_entry);
-		ep->rx_bufs_to_post++;
 	} else {
 		ooo_entry = pkt_entry;
 	}
@@ -1011,63 +946,87 @@ static void rxr_cq_proc_pending_items_in_recvwin(struct rxr_ep *ep,
 	return;
 }
 
-static void rxr_cq_handle_rts(struct rxr_ep *ep,
-			      struct fi_cq_msg_entry *comp,
-			      struct rxr_pkt_entry *pkt_entry,
-			      fi_addr_t src_addr)
+/* Handle RMA writes with immediate data at remote endpoint, write a completion */
+void rxr_cq_handle_shm_rma_write_data(struct rxr_ep *ep, struct fi_cq_data_entry *shm_comp, fi_addr_t src_addr)
 {
-	fi_addr_t rdm_addr;
-	struct rxr_rts_hdr *rts_hdr;
-	struct rxr_av *av;
-	struct rxr_peer *peer;
-	void *raw_address;
-	int i, ret;
+	struct rxr_rx_entry *rx_entry;
+	int ret;
 
-	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
-	av = rxr_ep_av(ep);
+	struct util_cq *rx_cq = ep->util_ep.rx_cq;
+	rx_entry = rxr_ep_get_rx_entry(ep, NULL, 0, 0, 0, NULL, src_addr, 0, 0);
+	rxr_copy_shm_cq_entry(&rx_entry->cq_entry, shm_comp);
+
+	if (ep->util_ep.caps & FI_SOURCE)
+		ret = ofi_cq_write_src(rx_cq,
+				       rx_entry->cq_entry.op_context,
+				       rx_entry->cq_entry.flags,
+				       rx_entry->cq_entry.len,
+				       rx_entry->cq_entry.buf,
+				       rx_entry->cq_entry.data,
+				       rx_entry->cq_entry.tag,
+				       src_addr);
+	else
+		ret = ofi_cq_write(rx_cq,
+				       rx_entry->cq_entry.op_context,
+				       rx_entry->cq_entry.flags,
+				       rx_entry->cq_entry.len,
+				       rx_entry->cq_entry.buf,
+				       rx_entry->cq_entry.data,
+				       rx_entry->cq_entry.tag);
 
-	if (OFI_UNLIKELY(src_addr == FI_ADDR_NOTAVAIL)) {
-		assert(rts_hdr->flags & RXR_REMOTE_SRC_ADDR);
-		assert(rts_hdr->addrlen > 0);
-		if (rxr_get_base_hdr(pkt_entry->pkt)->version !=
-		    RXR_PROTOCOL_VERSION) {
-			char buffer[ep->core_addrlen * 3];
-			int length = 0;
-
-			for (i = 0; i < ep->core_addrlen; i++)
-				length += sprintf(&buffer[length], "%02x ",
-						  ep->core_addr[i]);
-			FI_WARN(&rxr_prov, FI_LOG_CQ,
-				"Host %s:Invalid protocol version %d. Expected protocol version %d.\n",
-				buffer,
-				rxr_get_base_hdr(pkt_entry->pkt)->version,
-				RXR_PROTOCOL_VERSION);
-			rxr_eq_write_error(ep, FI_EIO, -FI_EINVAL);
-			fprintf(stderr, "Invalid protocol version %d. Expected protocol version %d. %s:%d\n",
-				rxr_get_base_hdr(pkt_entry->pkt)->version,
-				RXR_PROTOCOL_VERSION, __FILE__, __LINE__);
-			abort();
-		}
-		raw_address = (rts_hdr->flags & RXR_REMOTE_CQ_DATA) ?
-			      rxr_get_ctrl_cq_pkt(rts_hdr)->data
-			      : rxr_get_ctrl_pkt(rts_hdr)->data;
-
-		ret = rxr_av_insert_rdm_addr(av,
-					     (void *)raw_address,
-					     &rdm_addr, 0, NULL);
-		if (OFI_UNLIKELY(ret != 1)) {
-			rxr_eq_write_error(ep, FI_EINVAL, ret);
-			return;
-		}
+	rxr_rm_rx_cq_check(ep, rx_cq);
 
-		pkt_entry->addr = rdm_addr;
-	} else {
-		pkt_entry->addr = src_addr;
+	if (OFI_UNLIKELY(ret)) {
+		FI_WARN(&rxr_prov, FI_LOG_CQ,
+			"Unable to deliver immediate data of shm provider's RMA write operation: %s\n",
+			fi_strerror(-ret));
+		if (rxr_cq_handle_rx_error(ep, rx_entry, ret))
+			assert(0 && "failed to write err cq entry");
 	}
+	rxr_cntr_report_rx_completion(ep, rx_entry);
+	rxr_release_rx_entry(ep, rx_entry);
+}
+
+/*
+ * Sender handles the acknowledgment (RXR_EOR_PKT) from receiver on the completion
+ * of the large message copy via fi_readmsg operation
+ */
+static void rxr_cq_handle_eor(struct rxr_ep *ep,
+				  struct fi_cq_data_entry *comp,
+				  struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_eor_hdr *shm_eor;
+	struct rxr_tx_entry *tx_entry;
+
+	shm_eor = (struct rxr_eor_hdr *)pkt_entry->pkt;
+
+	/* pre-post buf used here, so can NOT track back to tx_entry with x_entry */
+	tx_entry = ofi_bufpool_get_ibuf(ep->tx_entry_pool, shm_eor->tx_id);
+	rxr_cq_write_tx_completion(ep, tx_entry);
+	rxr_release_rx_pkt_entry(ep, pkt_entry);
+}
+
+static void rxr_cq_handle_rts(struct rxr_ep *ep,
+			      struct fi_cq_data_entry *comp,
+			      struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_rts_hdr *rts_hdr;
+	struct rxr_peer *peer;
+	int ret;
 
 	peer = rxr_ep_get_peer(ep, pkt_entry->addr);
 	assert(peer);
 
+	if (rxr_env.enable_shm_transfer && peer->is_local) {
+		/* no need to reorder msg for shm_ep
+		 * rxr_cq_process_rts will write error cq entry if needed
+		 */
+		rxr_cq_process_rts(ep, pkt_entry);
+		return;
+	}
+
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+
 	if (ep->core_caps & FI_SOURCE)
 		rxr_cq_post_connack(ep, peer, pkt_entry->addr);
 
@@ -1084,7 +1043,6 @@ static void rxr_cq_handle_rts(struct rxr_ep *ep,
 			if (!rts_hdr->addrlen)
 				rxr_eq_write_error(ep, FI_EIO, ret);
 			rxr_release_rx_pkt_entry(ep, pkt_entry);
-			ep->rx_bufs_to_post++;
 			return;
 		} else if (OFI_UNLIKELY(ret == -FI_ENOMEM)) {
 			rxr_eq_write_error(ep, FI_ENOBUFS, -FI_ENOBUFS);
@@ -1109,12 +1067,10 @@ static void rxr_cq_handle_rts(struct rxr_ep *ep,
 	/* process pending items in reorder buff */
 	if (rxr_need_sas_ordering(ep))
 		rxr_cq_proc_pending_items_in_recvwin(ep, peer);
-
-	return;
 }
 
 static void rxr_cq_handle_connack(struct rxr_ep *ep,
-				  struct fi_cq_msg_entry *comp,
+				  struct fi_cq_data_entry *comp,
 				  struct rxr_pkt_entry *pkt_entry,
 				  fi_addr_t src_addr)
 {
@@ -1130,60 +1086,134 @@ static void rxr_cq_handle_connack(struct rxr_ep *ep,
 	FI_DBG(&rxr_prov, FI_LOG_CQ,
 	       "CONNACK received from %" PRIu64 "\n", src_addr);
 	rxr_release_rx_pkt_entry(ep, pkt_entry);
-	ep->rx_bufs_to_post++;
 }
 
-void rxr_cq_handle_pkt_with_data(struct rxr_ep *ep,
-				 struct rxr_rx_entry *rx_entry,
-				 struct fi_cq_msg_entry *comp,
-				 struct rxr_pkt_entry *pkt_entry,
-				 char *data, size_t seg_offset,
-				 size_t seg_size)
+int rxr_cq_handle_rts_with_data(struct rxr_ep *ep,
+				struct rxr_rx_entry *rx_entry,
+				struct rxr_pkt_entry *pkt_entry,
+				char *data, size_t data_size)
 {
-	struct rxr_peer *peer;
-	uint64_t bytes;
+	struct rxr_rts_hdr *rts_hdr;
+	int64_t bytes_left, bytes_copied;
 	ssize_t ret;
 
-	peer = rxr_ep_get_peer(ep, rx_entry->addr);
-	peer->rx_credits += ofi_div_ceil(seg_size, ep->max_data_payload_size);
-	rx_entry->window -= seg_size;
 
-	if (ep->available_data_bufs < rxr_get_rx_pool_chunk_cnt(ep))
-		ep->available_data_bufs++;
+	/* rx_entry->cq_entry.len is total recv buffer size.
+	 * rx_entry->total_len is from rts_hdr and is total send buffer size.
+	 * if send buffer size < recv buffer size, we adjust value of rx_entry->cq_entry.len.
+	 * if send buffer size > recv buffer size, we have a truncated message.
+	 */
+	if (rx_entry->cq_entry.len > rx_entry->total_len)
+		rx_entry->cq_entry.len = rx_entry->total_len;
+
+	bytes_copied = ofi_copy_to_iov(rx_entry->iov, rx_entry->iov_count,
+				       0, data, data_size);
+
+	if (OFI_UNLIKELY(bytes_copied < data_size)) {
+		/* recv buffer is not big enough to hold rts, this must be a truncated message */
+		assert(bytes_copied == rx_entry->cq_entry.len &&
+		       rx_entry->cq_entry.len < rx_entry->total_len);
+		rx_entry->bytes_done = bytes_copied;
+		bytes_left = 0;
+	} else {
+		assert(bytes_copied == data_size);
+		rx_entry->bytes_done = data_size;
+		bytes_left = rx_entry->total_len - data_size;
+	}
 
-	bytes = rx_entry->total_len - rx_entry->bytes_done -
-		seg_size;
+	assert(bytes_left >= 0);
+	if (!bytes_left) {
+		/* rxr_cq_handle_rx_completion() releases pkt_entry, thus
+		 * we do not release it here.
+		 */
+		rxr_cq_handle_rx_completion(ep, pkt_entry, rx_entry);
+		rxr_multi_recv_free_posted_entry(ep, rx_entry);
+		rxr_release_rx_entry(ep, rx_entry);
+		return 0;
+	}
 
-	if (!rx_entry->window && bytes > 0)
-		rxr_ep_post_cts_or_queue(ep, rx_entry, bytes);
+#if ENABLE_DEBUG
+	dlist_insert_tail(&rx_entry->rx_pending_entry, &ep->rx_pending_list);
+	ep->rx_pending++;
+#endif
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+	rx_entry->state = RXR_RX_RECV;
+	if (rts_hdr->flags & RXR_CREDIT_REQUEST)
+		rx_entry->credit_request = rts_hdr->credit_request;
+	else
+		rx_entry->credit_request = rxr_env.tx_min_credits;
+	ret = rxr_ep_post_ctrl_or_queue(ep, RXR_RX_ENTRY, rx_entry, RXR_CTS_PKT, 0);
+	rxr_release_rx_pkt_entry(ep, pkt_entry);
+	return ret;
+}
 
+int rxr_cq_handle_pkt_with_data(struct rxr_ep *ep,
+				struct rxr_rx_entry *rx_entry,
+				struct rxr_pkt_entry *pkt_entry,
+				char *data, size_t seg_offset,
+				size_t seg_size)
+{
+	struct rxr_peer *peer;
+	int64_t bytes_left, bytes_copied;
+	ssize_t ret = 0;
+
+#if ENABLE_DEBUG
+	int pkt_type = rxr_get_base_hdr(pkt_entry->pkt)->type;
+	assert(pkt_type == RXR_DATA_PKT || pkt_type == RXR_READRSP_PKT);
+#endif
 	/* we are sinking message for CANCEL/DISCARD entry */
-	if (OFI_LIKELY(!(rx_entry->rxr_flags & RXR_RECV_CANCEL))) {
-		ofi_copy_to_iov(rx_entry->iov, rx_entry->iov_count,
-				seg_offset, data, seg_size);
+	if (OFI_LIKELY(!(rx_entry->rxr_flags & RXR_RECV_CANCEL)) &&
+	    rx_entry->cq_entry.len > seg_offset) {
+		bytes_copied = ofi_copy_to_iov(rx_entry->iov, rx_entry->iov_count,
+					       seg_offset, data, seg_size);
+		if (bytes_copied != MIN(seg_size, rx_entry->cq_entry.len - seg_offset)) {
+			FI_WARN(&rxr_prov, FI_LOG_CQ, "wrong size! bytes_copied: %ld\n",
+				bytes_copied);
+			if (rxr_cq_handle_rx_error(ep, rx_entry, -FI_EINVAL))
+				assert(0 && "error writing error cq entry for EOR\n");
+		}
 	}
 
 	rx_entry->bytes_done += seg_size;
-	if (rx_entry->total_len == rx_entry->bytes_done) {
+
+	peer = rxr_ep_get_peer(ep, rx_entry->addr);
+	peer->rx_credits += ofi_div_ceil(seg_size, ep->max_data_payload_size);
+
+	rx_entry->window -= seg_size;
+	if (ep->available_data_bufs < rxr_get_rx_pool_chunk_cnt(ep))
+		ep->available_data_bufs++;
+
+	/* bytes_done is total bytes sent/received, which could be larger than
+	 * to bytes copied to recv buffer (for truncated messages).
+	 * rx_entry->total_len is from rts_hdr and is the size of send buffer,
+	 * thus we always have:
+	 *             rx_entry->total >= rx_entry->bytes_done
+	 */
+	bytes_left = rx_entry->total_len - rx_entry->bytes_done;
+	assert(bytes_left >= 0);
+	if (!bytes_left) {
 #if ENABLE_DEBUG
 		dlist_remove(&rx_entry->rx_pending_entry);
 		ep->rx_pending--;
 #endif
-		ret = rxr_cq_handle_rx_completion(ep, comp,
-						  pkt_entry, rx_entry);
+		rxr_cq_handle_rx_completion(ep, pkt_entry, rx_entry);
 
 		rxr_multi_recv_free_posted_entry(ep, rx_entry);
-		if (OFI_LIKELY(!ret))
-			rxr_release_rx_entry(ep, rx_entry);
-		return;
+		rxr_release_rx_entry(ep, rx_entry);
+		return 0;
+	}
+
+	if (!rx_entry->window) {
+		assert(rx_entry->state == RXR_RX_RECV);
+		ret = rxr_ep_post_ctrl_or_queue(ep, RXR_RX_ENTRY, rx_entry, RXR_CTS_PKT, 0);
 	}
 
 	rxr_release_rx_pkt_entry(ep, pkt_entry);
-	ep->rx_bufs_to_post++;
+	return ret;
 }
 
 static void rxr_cq_handle_readrsp(struct rxr_ep *ep,
-				  struct fi_cq_msg_entry *comp,
+				  struct fi_cq_data_entry *comp,
 				  struct rxr_pkt_entry *pkt_entry)
 {
 	struct rxr_readrsp_pkt *readrsp_pkt = NULL;
@@ -1195,12 +1225,13 @@ static void rxr_cq_handle_readrsp(struct rxr_ep *ep,
 	rx_entry = ofi_bufpool_get_ibuf(ep->rx_entry_pool, readrsp_hdr->rx_id);
 	assert(rx_entry->cq_entry.flags & FI_READ);
 	rx_entry->tx_id = readrsp_hdr->tx_id;
-	rxr_cq_handle_pkt_with_data(ep, rx_entry, comp, pkt_entry,
-				    readrsp_pkt->data, 0, readrsp_hdr->seg_size);
+	rxr_cq_handle_pkt_with_data(ep, rx_entry, pkt_entry,
+				    readrsp_pkt->data,
+				    0, readrsp_hdr->seg_size);
 }
 
 static void rxr_cq_handle_cts(struct rxr_ep *ep,
-			      struct fi_cq_msg_entry *comp,
+			      struct fi_cq_data_entry *comp,
 			      struct rxr_pkt_entry *pkt_entry)
 {
 	struct rxr_peer *peer;
@@ -1223,7 +1254,6 @@ static void rxr_cq_handle_cts(struct rxr_ep *ep,
 		peer->tx_credits += tx_entry->credit_request - tx_entry->credit_allocated;
 
 	rxr_release_rx_pkt_entry(ep, pkt_entry);
-	ep->rx_bufs_to_post++;
 
 	if (tx_entry->state != RXR_TX_SEND) {
 		tx_entry->state = RXR_TX_SEND;
@@ -1233,7 +1263,7 @@ static void rxr_cq_handle_cts(struct rxr_ep *ep,
 }
 
 static void rxr_cq_handle_data(struct rxr_ep *ep,
-			       struct fi_cq_msg_entry *comp,
+			       struct fi_cq_data_entry *comp,
 			       struct rxr_pkt_entry *pkt_entry)
 {
 	struct rxr_data_pkt *data_pkt;
@@ -1244,14 +1274,13 @@ static void rxr_cq_handle_data(struct rxr_ep *ep,
 					 data_pkt->hdr.rx_id);
 
 	rxr_cq_handle_pkt_with_data(ep, rx_entry,
-				    comp, pkt_entry,
+				    pkt_entry,
 				    data_pkt->data,
 				    data_pkt->hdr.seg_offset,
 				    data_pkt->hdr.seg_size);
 }
 
 void rxr_cq_write_tx_completion(struct rxr_ep *ep,
-				struct fi_cq_msg_entry *comp,
 				struct rxr_tx_entry *tx_entry)
 {
 	struct util_cq *tx_cq = ep->util_ep.tx_cq;
@@ -1302,17 +1331,61 @@ void rxr_cq_write_tx_completion(struct rxr_ep *ep,
 	return;
 }
 
+fi_addr_t rxr_cq_insert_addr_from_rts(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry)
+{
+	int i, ret;
+	void *raw_address;
+	fi_addr_t rdm_addr;
+	struct rxr_av *av;
+	struct rxr_rts_hdr *rts_hdr;
+
+	assert(rxr_get_base_hdr(pkt_entry->pkt)->type == RXR_RTS_PKT);
+
+	av = rxr_ep_av(ep);
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+	assert(rts_hdr->flags & RXR_REMOTE_SRC_ADDR);
+	assert(rts_hdr->addrlen > 0);
+	if (rxr_get_base_hdr(pkt_entry->pkt)->version !=
+	    RXR_PROTOCOL_VERSION) {
+		char buffer[ep->core_addrlen * 3];
+		int length = 0;
+
+		for (i = 0; i < ep->core_addrlen; i++)
+			length += sprintf(&buffer[length], "%02x ",
+					  ep->core_addr[i]);
+		FI_WARN(&rxr_prov, FI_LOG_CQ,
+			"Host %s:Invalid protocol version %d. Expected protocol version %d.\n",
+			buffer,
+			rxr_get_base_hdr(pkt_entry->pkt)->version,
+			RXR_PROTOCOL_VERSION);
+		rxr_eq_write_error(ep, FI_EIO, -FI_EINVAL);
+		fprintf(stderr, "Invalid protocol version %d. Expected protocol version %d. %s:%d\n",
+			rxr_get_base_hdr(pkt_entry->pkt)->version,
+			RXR_PROTOCOL_VERSION, __FILE__, __LINE__);
+		abort();
+	}
+
+	raw_address = (rts_hdr->flags & RXR_REMOTE_CQ_DATA) ?
+		      rxr_get_ctrl_cq_pkt(rts_hdr)->data
+		      : rxr_get_ctrl_pkt(rts_hdr)->data;
+
+	ret = rxr_av_insert_rdm_addr(av, (void *)raw_address, &rdm_addr, 0, NULL);
+	if (OFI_UNLIKELY(ret != 1)) {
+		rxr_eq_write_error(ep, FI_EINVAL, ret);
+		return -1;
+	}
+
+	return rdm_addr;
+}
+
 void rxr_cq_handle_pkt_recv_completion(struct rxr_ep *ep,
-				       struct fi_cq_msg_entry *cq_entry,
+				       struct fi_cq_data_entry *cq_entry,
 				       fi_addr_t src_addr)
 {
+	struct rxr_peer *peer;
 	struct rxr_pkt_entry *pkt_entry;
 
 	pkt_entry = (struct rxr_pkt_entry *)cq_entry->op_context;
-	ep->posted_bufs--;
-
-	assert(rxr_get_base_hdr(pkt_entry->pkt)->version ==
-	       RXR_PROTOCOL_VERSION);
 
 #if ENABLE_DEBUG
 	dlist_remove(&pkt_entry->dbg_entry);
@@ -1321,10 +1394,27 @@ void rxr_cq_handle_pkt_recv_completion(struct rxr_ep *ep,
 	rxr_ep_print_pkt("Received", ep, (struct rxr_base_hdr *)pkt_entry->pkt);
 #endif
 #endif
+	if (OFI_UNLIKELY(src_addr == FI_ADDR_NOTAVAIL))
+		pkt_entry->addr = rxr_cq_insert_addr_from_rts(ep, pkt_entry);
+	else
+		pkt_entry->addr = src_addr;
+
+	assert(rxr_get_base_hdr(pkt_entry->pkt)->version ==
+	       RXR_PROTOCOL_VERSION);
+
+	peer = rxr_ep_get_peer(ep, pkt_entry->addr);
+
+	if (rxr_env.enable_shm_transfer && peer->is_local)
+		ep->posted_bufs_shm--;
+	else
+		ep->posted_bufs_efa--;
 
 	switch (rxr_get_base_hdr(pkt_entry->pkt)->type) {
 	case RXR_RTS_PKT:
-		rxr_cq_handle_rts(ep, cq_entry, pkt_entry, src_addr);
+		rxr_cq_handle_rts(ep, cq_entry, pkt_entry);
+		return;
+	case RXR_EOR_PKT:
+		rxr_cq_handle_eor(ep, cq_entry, pkt_entry);
 		return;
 	case RXR_CONNACK_PKT:
 		rxr_cq_handle_connack(ep, cq_entry, pkt_entry, src_addr);
@@ -1363,7 +1453,65 @@ static int rxr_send_completion_mr_dereg(struct rxr_tx_entry *tx_entry)
 	return ret;
 }
 
-void rxr_cq_handle_pkt_send_completion(struct rxr_ep *ep, struct fi_cq_msg_entry *comp)
+void rxr_cq_handle_rma_context_pkt(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_tx_entry *tx_entry = NULL;
+	struct rxr_rx_entry *rx_entry = NULL;
+	struct rxr_rma_context_pkt *rma_context_pkt;
+	int ret;
+
+	assert(rxr_get_base_hdr(pkt_entry->pkt)->version == RXR_PROTOCOL_VERSION);
+
+	rma_context_pkt = (struct rxr_rma_context_pkt *)pkt_entry->pkt;
+
+	switch (rma_context_pkt->rma_context_type) {
+	case RXR_SHM_RMA_READ:
+	case RXR_SHM_RMA_WRITE:
+		/* Completion of RMA READ/WRTITE operations that apps call */
+		tx_entry = pkt_entry->x_entry;
+
+		if (tx_entry->fi_flags & FI_COMPLETION) {
+			rxr_cq_write_tx_completion(ep, tx_entry);
+		} else {
+			rxr_cntr_report_tx_completion(ep, tx_entry);
+			rxr_release_tx_entry(ep, tx_entry);
+		}
+		rxr_release_tx_pkt_entry(ep, pkt_entry);
+		break;
+	case RXR_SHM_LARGE_READ:
+		/*
+		 * This must be on the receiver (remote) side of two-sided message
+		 * transfer, which is also the initiator of RMA READ.
+		 * We get RMA READ completion for previously issued
+		 * fi_read operation over shm provider, which means
+		 * receiver side has received all data from sender
+		 */
+		rx_entry = pkt_entry->x_entry;
+		rx_entry->cq_entry.len = rx_entry->total_len;
+		rx_entry->bytes_done = rx_entry->total_len;
+
+		ret = rxr_ep_post_ctrl_or_queue(ep, RXR_TX_ENTRY, rx_entry, RXR_EOR_PKT, 1);
+		if (ret) {
+			if (rxr_cq_handle_rx_error(ep, rx_entry, ret))
+				assert(0 && "error writing error cq entry for EOR\n");
+		}
+
+		if (rx_entry->fi_flags & FI_MULTI_RECV)
+			rxr_cq_handle_multi_recv_completion(ep, rx_entry);
+		rxr_cq_write_rx_completion(ep, rx_entry);
+		rxr_multi_recv_free_posted_entry(ep, rx_entry);
+		if (OFI_LIKELY(!ret))
+			rxr_release_rx_entry(ep, rx_entry);
+		rxr_release_rx_pkt_entry(ep, pkt_entry);
+		break;
+	default:
+		FI_WARN(&rxr_prov, FI_LOG_CQ, "invalid rma_context_type in RXR_RMA_CONTEXT_PKT %d\n",
+			rma_context_pkt->rma_context_type);
+		assert(0 && "invalid RXR_RMA_CONTEXT_PKT rma_context_type\n");
+	}
+}
+
+void rxr_cq_handle_pkt_send_completion(struct rxr_ep *ep, struct fi_cq_data_entry *comp)
 {
 	struct rxr_pkt_entry *pkt_entry;
 	struct rxr_tx_entry *tx_entry = NULL;
@@ -1390,6 +1538,9 @@ void rxr_cq_handle_pkt_send_completion(struct rxr_ep *ep, struct fi_cq_msg_entry
 		 * completion notice, we will have a released tx_entry at this point.
 		 * Nonetheless, because for FI_READ tx_entry will be release in rxr_handle_rx_completion,
 		 * we will ignore it here.
+		 *
+		 * For shm provider, we will write completion for small & medium  message, as data has
+		 * been sent in the RTS packet; for large message, will wait for the EOR packet
 		 */
 		rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
 		if (!(rts_hdr->flags & RXR_READ_REQ)) {
@@ -1414,6 +1565,9 @@ void rxr_cq_handle_pkt_send_completion(struct rxr_ep *ep, struct fi_cq_msg_entry
 		assert(tx_entry->cq_entry.flags & FI_READ);
 		tx_entry->bytes_acked += readrsp_hdr->seg_size;
 		break;
+	case RXR_RMA_CONTEXT_PKT:
+		rxr_cq_handle_rma_context_pkt(ep, pkt_entry);
+		return;
 	default:
 		FI_WARN(&rxr_prov, FI_LOG_CQ,
 			"invalid control pkt type %d\n",
@@ -1460,19 +1614,20 @@ void rxr_cq_handle_pkt_send_completion(struct rxr_ep *ep, struct fi_cq_msg_entry
 			rxr_release_tx_entry(ep, tx_entry);
 		} else if (tx_entry->cq_entry.flags & FI_WRITE) {
 			if (tx_entry->fi_flags & FI_COMPLETION) {
-				rxr_cq_write_tx_completion(ep, comp, tx_entry);
+				rxr_cq_write_tx_completion(ep, tx_entry);
 			} else {
 				rxr_cntr_report_tx_completion(ep, tx_entry);
 				rxr_release_tx_entry(ep, tx_entry);
 			}
 		} else {
 			assert(tx_entry->cq_entry.flags & FI_SEND);
-			rxr_cq_write_tx_completion(ep, comp, tx_entry);
+			rxr_cq_write_tx_completion(ep, tx_entry);
 		}
 	}
 
 	rxr_release_tx_pkt_entry(ep, pkt_entry);
-	rxr_ep_dec_tx_pending(ep, peer, 0);
+	if (!peer->is_local)
+		rxr_ep_dec_tx_pending(ep, peer, 0);
 	return;
 }
 
diff --git a/prov/efa/src/rxr/rxr_domain.c b/prov/efa/src/rxr/rxr_domain.c
index ce91c91..061b2b0 100644
--- a/prov/efa/src/rxr/rxr_domain.c
+++ b/prov/efa/src/rxr/rxr_domain.c
@@ -38,6 +38,7 @@
 #include <ofi_util.h>
 #include <ofi_recvwin.h>
 
+#include "efa.h"
 #include "rxr.h"
 #include "rxr_cntr.h"
 
@@ -70,6 +71,12 @@ static int rxr_domain_close(fid_t fid)
 	if (ret)
 		return ret;
 
+	if (rxr_env.enable_shm_transfer) {
+		ret = fi_close(&rxr_domain->shm_domain->fid);
+		if (ret)
+			return ret;
+	}
+
 	free(rxr_domain);
 	return 0;
 }
@@ -93,7 +100,7 @@ static int rxr_mr_close(fid_t fid)
 
 	ret = ofi_mr_map_remove(&rxr_domain->util_domain.mr_map,
 				rxr_mr->mr_fid.key);
-	if (ret)
+	if (ret && ret != -FI_ENOKEY)
 		FI_WARN(&rxr_prov, FI_LOG_MR,
 			"Unable to remove MR entry from util map (%s)\n",
 			fi_strerror(-ret));
@@ -102,6 +109,13 @@ static int rxr_mr_close(fid_t fid)
 	if (ret)
 		FI_WARN(&rxr_prov, FI_LOG_MR,
 			"Unable to close MR\n");
+
+	if (rxr_env.enable_shm_transfer && rxr_mr->shm_msg_mr) {
+		ret = fi_close(&rxr_mr->shm_msg_mr->fid);
+		if (ret)
+			FI_WARN(&rxr_prov, FI_LOG_MR,
+				"Unable to close shm MR\n");
+	}
 	free(rxr_mr);
 	return ret;
 }
@@ -114,13 +128,20 @@ static struct fi_ops rxr_mr_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
+/*
+ * The mr key generated in lower EFA registration will be used in SHM
+ * registration and mr_map in an unified way
+ */
 int rxr_mr_regattr(struct fid *domain_fid, const struct fi_mr_attr *attr,
 		   uint64_t flags, struct fid_mr **mr)
 {
 	struct rxr_domain *rxr_domain;
 	struct fi_mr_attr *core_attr;
+	struct fi_mr_attr *shm_attr;
 	struct rxr_mr *rxr_mr;
+	uint64_t user_attr_access, core_attr_access;
 	int ret;
+	bool key_exists;
 
 	rxr_domain = container_of(domain_fid, struct rxr_domain,
 				  util_domain.domain_fid.fid);
@@ -129,9 +150,14 @@ int rxr_mr_regattr(struct fid *domain_fid, const struct fi_mr_attr *attr,
 	if (!rxr_mr)
 		return -FI_ENOMEM;
 
+	/* recorde the memory access permission requested by user */
+	user_attr_access = attr->access;
+	shm_attr = (struct fi_mr_attr *)attr;
+
 	/* discard const qualifier to override access registered with EFA */
 	core_attr = (struct fi_mr_attr *)attr;
-	core_attr->access = FI_SEND | FI_RECV;
+	core_attr_access = FI_SEND | FI_RECV;
+	core_attr->access = core_attr_access;
 
 	ret = fi_mr_regattr(rxr_domain->rdm_domain, core_attr, flags,
 			    &rxr_mr->msg_mr);
@@ -152,14 +178,39 @@ int rxr_mr_regattr(struct fid *domain_fid, const struct fi_mr_attr *attr,
 	*mr = &rxr_mr->mr_fid;
 
 	assert(rxr_mr->mr_fid.key != FI_KEY_NOTAVAIL);
-	ret = ofi_mr_map_insert(&rxr_domain->util_domain.mr_map, attr,
+	key_exists = false;
+	core_attr->requested_key = rxr_mr->mr_fid.key;
+	core_attr->access = core_attr_access;
+	ret = ofi_mr_map_insert(&rxr_domain->util_domain.mr_map, core_attr,
 				&rxr_mr->mr_fid.key, mr);
 	if (ret) {
-		FI_WARN(&rxr_prov, FI_LOG_MR,
-			"Unable to add MR to map buf (%s): %p len: %zu\n",
-			fi_strerror(-ret), attr->mr_iov->iov_base,
-			attr->mr_iov->iov_len);
-		goto err;
+		if (efa_mr_cache_enable && ret == -FI_ENOKEY) {
+			key_exists = true;
+		} else {
+			FI_WARN(&rxr_prov, FI_LOG_MR,
+				"Unable to add MR to map buf (%s): %p len: %zu\n",
+				fi_strerror(-ret), attr->mr_iov->iov_base,
+				attr->mr_iov->iov_len);
+			goto err;
+		}
+	}
+
+	/* Call shm provider to register memory */
+	if (rxr_env.enable_shm_transfer && !key_exists) {
+		shm_attr->access = user_attr_access;
+		shm_attr->requested_key = rxr_mr->mr_fid.key;
+		ret = fi_mr_regattr(rxr_domain->shm_domain, shm_attr, flags,
+				    &rxr_mr->shm_msg_mr);
+		if (ret) {
+			FI_WARN(&rxr_prov, FI_LOG_MR,
+				"Unable to register shm MR buf (%s): %p len: %zu\n",
+				fi_strerror(-ret), attr->mr_iov->iov_base,
+				attr->mr_iov->iov_len);
+			fi_close(&rxr_mr->msg_mr->fid);
+			ofi_mr_map_remove(&rxr_domain->util_domain.mr_map,
+					  rxr_mr->mr_fid.key);
+			goto err;
+		}
 	}
 
 	return 0;
@@ -247,6 +298,15 @@ int rxr_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 	if (ret)
 		goto err_free_core_info;
 
+	/* Open shm provider's access domain */
+	if (rxr_env.enable_shm_transfer) {
+		assert(!strcmp(shm_info->fabric_attr->name, "shm"));
+		ret = fi_domain(rxr_fabric->shm_fabric, shm_info,
+				&rxr_domain->shm_domain, context);
+		if (ret)
+			goto err_close_core_domain;
+	}
+
 	rxr_domain->rdm_mode = rdm_info->mode;
 	rxr_domain->addrlen = (info->src_addr) ?
 				info->src_addrlen : info->dest_addrlen;
@@ -257,19 +317,16 @@ int rxr_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 
 	ret = ofi_domain_init(fabric, info, &rxr_domain->util_domain, context);
 	if (ret)
-		goto err_close_core_domain;
+		goto err_close_shm_domain;
 
 	rxr_domain->do_progress = 0;
 
 	/*
-	 * ofi_domain_init() would have stored the RxR mr_modes in the map, but
-	 * we need the rbtree insertions and lookups to use the lower-provider
-	 * specific key, since the latter can not support application keys
-	 * (FI_MR_PROV_KEY only). Storing the lower provider's mode in the map
-	 * instead.
+	 * ofi_domain_init() would have stored the RxR mr_modes in the mr_map, but
+	 * we need the rbtree insertions and lookups to use EFA provider's
+	 * specific key, so unset the FI_MR_PROV_KEY bit for mr_map.
 	 */
-	rxr_domain->util_domain.mr_map.mode |=
-				OFI_MR_BASIC_MAP | FI_MR_LOCAL | FI_MR_BASIC;
+	rxr_domain->util_domain.mr_map.mode &= ~FI_MR_PROV_KEY;
 
 	*domain = &rxr_domain->util_domain.domain_fid;
 	(*domain)->fid.ops = &rxr_domain_fi_ops;
@@ -278,6 +335,13 @@ int rxr_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 	fi_freeinfo(rdm_info);
 	return 0;
 
+err_close_shm_domain:
+	if (rxr_env.enable_shm_transfer) {
+		retv = fi_close(&rxr_domain->shm_domain->fid);
+		if (retv)
+			FI_WARN(&rxr_prov, FI_LOG_DOMAIN,
+				"Unable to close shm domain: %s\n", fi_strerror(-retv));
+	}
 err_close_core_domain:
 	retv = fi_close(&rxr_domain->rdm_domain->fid);
 	if (retv)
diff --git a/prov/efa/src/rxr/rxr_ep.c b/prov/efa/src/rxr/rxr_ep.c
index d898d7f..ecb3573 100644
--- a/prov/efa/src/rxr/rxr_ep.c
+++ b/prov/efa/src/rxr/rxr_ep.c
@@ -50,8 +50,6 @@ struct rxr_match_info {
 	uint64_t ignore;
 };
 
-static void rxr_ep_progress_internal(struct rxr_ep *ep);
-
 #if ENABLE_DEBUG
 static void rxr_ep_print_rts_pkt(struct rxr_ep *ep,
 				 char *prefix, struct rxr_rts_hdr *rts_hdr)
@@ -195,6 +193,7 @@ struct rxr_rx_entry *rxr_ep_rx_entry_init(struct rxr_ep *ep,
 	rx_entry->tag = tag;
 	rx_entry->ignore = ignore;
 	rx_entry->unexp_rts_pkt = NULL;
+	rx_entry->rma_iov_count = 0;
 	dlist_init(&rx_entry->queued_pkts);
 
 	memset(&rx_entry->cq_entry, 0, sizeof(rx_entry->cq_entry));
@@ -220,10 +219,10 @@ struct rxr_rx_entry *rxr_ep_rx_entry_init(struct rxr_ep *ep,
 		rx_entry->cq_entry.flags = (FI_RECV | FI_MSG);
 		break;
 	case ofi_op_read_rsp:
-		rx_entry->cq_entry.flags = (FI_REMOTE_READ | FI_MSG);
+		rx_entry->cq_entry.flags = (FI_REMOTE_READ | FI_RMA);
 		break;
-	case ofi_op_write_async:
-		rx_entry->cq_entry.flags = (FI_REMOTE_WRITE | FI_MSG);
+	case ofi_op_write:
+		rx_entry->cq_entry.flags = (FI_REMOTE_WRITE | FI_RMA);
 		break;
 	default:
 		FI_WARN(&rxr_prov, FI_LOG_EP_CTRL,
@@ -280,7 +279,6 @@ struct rxr_rx_entry *rxr_ep_get_new_unexp_rx_entry(struct rxr_ep *ep,
 		rxr_copy_pkt_entry(ep, unexp_entry, pkt_entry,
 				   RXR_PKT_ENTRY_UNEXP);
 		rxr_release_rx_pkt_entry(ep, pkt_entry);
-		ep->rx_bufs_to_post++;
 	} else {
 		unexp_entry = pkt_entry;
 	}
@@ -316,15 +314,14 @@ struct rxr_rx_entry *rxr_ep_split_rx_entry(struct rxr_ep *ep,
 					   struct rxr_pkt_entry *pkt_entry)
 {
 	struct rxr_rx_entry *rx_entry;
-	struct rxr_rts_hdr *rts_pkt;
+	struct rxr_rts_hdr *rts_pkt = NULL;
 	size_t buf_len, consumed_len;
 
 	rts_pkt = rxr_get_rts_hdr(pkt_entry->pkt);
 	if (!consumer_entry) {
 		rx_entry = rxr_ep_get_rx_entry(ep, posted_entry->iov,
-					       posted_entry->iov_count,
-					       rts_pkt->tag, 0, NULL,
-					       pkt_entry->addr, ofi_op_msg,
+					       posted_entry->iov_count, rts_pkt->tag,
+					       0, NULL, pkt_entry->addr, ofi_op_msg,
 					       posted_entry->fi_flags);
 		if (OFI_UNLIKELY(!rx_entry))
 			return NULL;
@@ -362,25 +359,32 @@ struct rxr_rx_entry *rxr_ep_split_rx_entry(struct rxr_ep *ep,
 }
 
 /* Post buf as undirected recv (FI_ADDR_UNSPEC) */
-int rxr_ep_post_buf(struct rxr_ep *ep, uint64_t flags)
+int rxr_ep_post_buf(struct rxr_ep *ep, uint64_t flags, enum rxr_lower_ep_type lower_ep_type)
 {
 	struct fi_msg msg;
 	struct iovec msg_iov;
 	void *desc;
-	struct rxr_pkt_entry *rx_pkt_entry;
+	struct rxr_pkt_entry *rx_pkt_entry = NULL;
 	int ret = 0;
 
-	rx_pkt_entry = rxr_get_pkt_entry(ep, ep->rx_pkt_pool);
+	switch (lower_ep_type) {
+	case SHM_EP:
+		rx_pkt_entry = rxr_get_pkt_entry(ep, ep->rx_pkt_shm_pool);
+		break;
+	case EFA_EP:
+		rx_pkt_entry = rxr_get_pkt_entry(ep, ep->rx_pkt_efa_pool);
+		break;
+	default:
+		FI_WARN(&rxr_prov, FI_LOG_EP_CTRL,
+			"invalid lower EP type %d\n", lower_ep_type);
+		assert(0 && "invalid lower EP type\n");
+	}
 	if (OFI_UNLIKELY(!rx_pkt_entry)) {
 		FI_WARN(&rxr_prov, FI_LOG_EP_CTRL,
 			"Unable to allocate rx_pkt_entry\n");
 		return -FI_ENOMEM;
 	}
 
-#if ENABLE_DEBUG
-	dlist_insert_tail(&rx_pkt_entry->dbg_entry,
-			  &ep->rx_posted_buf_list);
-#endif
 	rx_pkt_entry->x_entry = NULL;
 	rx_pkt_entry->type = RXR_PKT_ENTRY_POSTED;
 
@@ -388,24 +392,54 @@ int rxr_ep_post_buf(struct rxr_ep *ep, uint64_t flags)
 	msg_iov.iov_len = ep->mtu_size;
 
 	msg.msg_iov = &msg_iov;
-	desc = rxr_ep_mr_local(ep) ? fi_mr_desc(rx_pkt_entry->mr) : NULL;
-	msg.desc = &desc;
 	msg.iov_count = 1;
 	msg.addr = FI_ADDR_UNSPEC;
 	msg.context = rx_pkt_entry;
 	msg.data = 0;
 
-	ret = fi_recvmsg(ep->rdm_ep, &msg, flags);
-
-	if (OFI_UNLIKELY(ret)) {
-		rxr_release_rx_pkt_entry(ep, rx_pkt_entry);
+	switch (lower_ep_type) {
+	case SHM_EP:
+		/* pre-post buffer with shm */
+#if ENABLE_DEBUG
+		dlist_insert_tail(&rx_pkt_entry->dbg_entry,
+				  &ep->rx_posted_buf_shm_list);
+#endif
+		desc = NULL;
+		msg.desc = &desc;
+		ret = fi_recvmsg(ep->shm_ep, &msg, flags);
+		if (OFI_UNLIKELY(ret)) {
+			rxr_release_rx_pkt_entry(ep, rx_pkt_entry);
+			FI_WARN(&rxr_prov, FI_LOG_EP_CTRL,
+				"failed to post buf for shm  %d (%s)\n", -ret,
+				fi_strerror(-ret));
+			return ret;
+		}
+		ep->posted_bufs_shm++;
+		break;
+	case EFA_EP:
+		/* pre-post buffer with efa */
+#if ENABLE_DEBUG
+		dlist_insert_tail(&rx_pkt_entry->dbg_entry,
+				  &ep->rx_posted_buf_list);
+#endif
+		desc = rxr_ep_mr_local(ep) ? fi_mr_desc(rx_pkt_entry->mr) : NULL;
+		msg.desc = &desc;
+		ret = fi_recvmsg(ep->rdm_ep, &msg, flags);
+		if (OFI_UNLIKELY(ret)) {
+			rxr_release_rx_pkt_entry(ep, rx_pkt_entry);
+			FI_WARN(&rxr_prov, FI_LOG_EP_CTRL,
+				"failed to post buf %d (%s)\n", -ret,
+				fi_strerror(-ret));
+			return ret;
+		}
+		ep->posted_bufs_efa++;
+		break;
+	default:
 		FI_WARN(&rxr_prov, FI_LOG_EP_CTRL,
-			"failed to post buf %d (%s)\n", -ret,
-			fi_strerror(-ret));
-		return ret;
+			"invalid lower EP type %d\n", lower_ep_type);
+		assert(0 && "invalid lower EP type\n");
 	}
 
-	ep->posted_bufs++;
 	return 0;
 }
 
@@ -437,10 +471,12 @@ static int rxr_ep_handle_unexp_match(struct rxr_ep *ep,
 				     void *context, fi_addr_t addr,
 				     uint32_t op, uint64_t flags)
 {
+	struct rxr_peer *peer;
 	struct rxr_pkt_entry *pkt_entry;
 	struct rxr_rts_hdr *rts_hdr;
-	uint64_t bytes_left, len;
-	int ret = 0;
+	uint64_t len;
+	char *data;
+	size_t data_size;
 
 	rx_entry->fi_flags = flags;
 	rx_entry->ignore = ignore;
@@ -476,36 +512,18 @@ static int rxr_ep_handle_unexp_match(struct rxr_ep *ep,
 		rx_entry->ignore = ~0;
 	}
 
-	rxr_cq_recv_rts_data(ep, rx_entry, rts_hdr);
-
-	/*
-	 * TODO: Unsure how to handle fi_cq_msg_entry when writing completion
-	 * events in the unexpected path. Right now this field is unused. If
-	 * that changes we'll need to parse the flags as we get completion
-	 * events from the provider in the recv path and save the flags in the
-	 * rx_entry for the unexp message path to use when the app calls recv.
-	 */
-	if (rx_entry->total_len - rx_entry->bytes_done == 0) {
-		ret = rxr_cq_handle_rx_completion(ep, NULL,
-						  pkt_entry, rx_entry);
-		if (!ret)
-			rxr_release_rx_entry(ep, rx_entry);
+	peer = rxr_ep_get_peer(ep, pkt_entry->addr);
+	data = rxr_cq_read_rts_hdr(ep, rx_entry, pkt_entry);
+	if (peer->is_local && !(rts_hdr->flags & RXR_SHM_HDR_DATA)) {
+		rxr_cq_process_shm_large_message(ep, rx_entry, rts_hdr, data);
+		rxr_release_rx_pkt_entry(ep, pkt_entry);
 		return 0;
 	}
 
-	rx_entry->state = RXR_RX_RECV;
-#if ENABLE_DEBUG
-	dlist_insert_tail(&rx_entry->rx_pending_entry, &ep->rx_pending_list);
-	ep->rx_pending++;
-#endif
-	bytes_left = rx_entry->total_len - rx_entry->bytes_done;
-	if (!rx_entry->window && bytes_left > 0)
-		ret = rxr_ep_post_cts_or_queue(ep, rx_entry, bytes_left);
-
-	if (pkt_entry->type == RXR_PKT_ENTRY_POSTED)
-		ep->rx_bufs_to_post++;
-	rxr_release_rx_pkt_entry(ep, pkt_entry);
-	return ret;
+	data_size = rxr_get_rts_data_size(ep, rts_hdr);
+	return rxr_cq_handle_rts_with_data(ep, rx_entry,
+					   pkt_entry, data,
+					   data_size);
 }
 
 /*
@@ -920,48 +938,55 @@ static ssize_t rxr_ep_recvv(struct fid_ep *ep, const struct iovec *iov,
 	return rxr_ep_recvmsg(ep, &msg, 0);
 }
 
-
-void rxr_generic_tx_entry_init(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
-			       const struct iovec *iov, size_t iov_count,
-			       const struct fi_rma_iov *rma_iov,
-			       size_t rma_iov_count, fi_addr_t addr,
-			       uint64_t tag, uint64_t data, void *context,
-			       uint32_t op, uint64_t flags)
+void rxr_tx_entry_init(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
+		       const struct fi_msg *msg, uint32_t op, uint64_t flags)
 {
+	uint64_t tx_op_flags;
+
 	tx_entry->type = RXR_TX_ENTRY;
+	tx_entry->op = op;
 	tx_entry->tx_id = ofi_buf_index(tx_entry);
 	tx_entry->state = RXR_TX_RTS;
-	tx_entry->addr = addr;
-	tx_entry->tag = tag;
+	tx_entry->addr = msg->addr;
 
 	tx_entry->send_flags = 0;
 	tx_entry->bytes_acked = 0;
 	tx_entry->bytes_sent = 0;
 	tx_entry->window = 0;
-	tx_entry->total_len = ofi_total_iov_len(iov, iov_count);
-	tx_entry->iov_count = iov_count;
+	tx_entry->total_len = ofi_total_iov_len(msg->msg_iov, msg->iov_count);
+	tx_entry->iov_count = msg->iov_count;
 	tx_entry->iov_index = 0;
 	tx_entry->iov_mr_start = 0;
 	tx_entry->iov_offset = 0;
 	tx_entry->msg_id = ~0;
 	dlist_init(&tx_entry->queued_pkts);
 
-	memcpy(&tx_entry->iov[0], iov, sizeof(*iov) * iov_count);
+	memcpy(&tx_entry->iov[0], msg->msg_iov, sizeof(struct iovec) * msg->iov_count);
+	if (msg->desc)
+		memcpy(&tx_entry->desc[0], msg->desc, sizeof(*msg->desc) * msg->iov_count);
+	else
+		memset(&tx_entry->desc[0], 0, sizeof(*msg->desc) * msg->iov_count);
+
+	/* set flags */
+	assert(ep->util_ep.tx_msg_flags == 0 ||
+	       ep->util_ep.tx_msg_flags == FI_COMPLETION);
+	tx_op_flags = ep->util_ep.tx_op_flags;
+	if (ep->util_ep.tx_msg_flags == 0)
+		tx_op_flags &= ~FI_COMPLETION;
+	tx_entry->fi_flags = flags | tx_op_flags;
 
 	/* cq_entry on completion */
-	tx_entry->cq_entry.op_context = context;
-	tx_entry->cq_entry.len = ofi_total_iov_len(iov, iov_count);
+	tx_entry->cq_entry.op_context = msg->context;
+	tx_entry->cq_entry.len = ofi_total_iov_len(msg->msg_iov, msg->iov_count);
 	if (OFI_LIKELY(tx_entry->cq_entry.len > 0))
-		tx_entry->cq_entry.buf = iov[0].iov_base;
+		tx_entry->cq_entry.buf = msg->msg_iov[0].iov_base;
 	else
 		tx_entry->cq_entry.buf = NULL;
 
-	tx_entry->cq_entry.data = data;
-	tx_entry->cq_entry.tag = 0;
+	tx_entry->cq_entry.data = msg->data;
 	switch (op) {
 	case ofi_op_tagged:
 		tx_entry->cq_entry.flags = FI_TRANSMIT | FI_MSG | FI_TAGGED;
-		tx_entry->cq_entry.tag = tag;
 		break;
 	case ofi_op_write:
 		tx_entry->cq_entry.flags = FI_RMA | FI_WRITE;
@@ -973,27 +998,19 @@ void rxr_generic_tx_entry_init(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
 		tx_entry->cq_entry.flags = FI_TRANSMIT | FI_MSG;
 		break;
 	default:
-		FI_WARN(&rxr_prov, FI_LOG_CQ, "invalid operation type in %s\n",
-			__func__);
+		FI_WARN(&rxr_prov, FI_LOG_CQ, "invalid operation type\n");
 		assert(0);
 	}
-
-	if (tx_entry->cq_entry.flags & FI_RMA) {
-		assert(rma_iov_count>0);
-		assert(rma_iov);
-		tx_entry->rma_iov_count = rma_iov_count;
-		memcpy(tx_entry->rma_iov, rma_iov, sizeof(struct fi_rma_iov) * rma_iov_count);
-	}
 }
 
 /* create a new tx entry */
-struct rxr_tx_entry *rxr_ep_tx_entry_init(struct rxr_ep *rxr_ep, const struct iovec *iov, size_t iov_count,
-					  const struct fi_rma_iov *rma_iov, size_t rma_iov_count,
-					  fi_addr_t addr, uint64_t tag, uint64_t data, void *context,
-					  uint32_t op, uint64_t flags)
+struct rxr_tx_entry *rxr_ep_alloc_tx_entry(struct rxr_ep *rxr_ep,
+					   const struct fi_msg *msg,
+					   uint32_t op,
+					   uint64_t tag,
+					   uint64_t flags)
 {
 	struct rxr_tx_entry *tx_entry;
-	uint64_t tx_op_flags;
 
 	tx_entry = ofi_buf_alloc(rxr_ep->tx_entry_pool);
 	if (OFI_UNLIKELY(!tx_entry)) {
@@ -1001,20 +1018,16 @@ struct rxr_tx_entry *rxr_ep_tx_entry_init(struct rxr_ep *rxr_ep, const struct io
 		return NULL;
 	}
 
+	rxr_tx_entry_init(rxr_ep, tx_entry, msg, op, flags);
+
+	if (op == ofi_op_tagged) {
+		tx_entry->cq_entry.tag = tag;
+		tx_entry->tag = tag;
+	}
+
 #if ENABLE_DEBUG
 	dlist_insert_tail(&tx_entry->tx_entry_entry, &rxr_ep->tx_entry_list);
 #endif
-
-	rxr_generic_tx_entry_init(rxr_ep, tx_entry, iov, iov_count, rma_iov,
-				  rma_iov_count, addr, tag, data, context,
-				  op, flags);
-
-	assert(rxr_ep->util_ep.tx_msg_flags == 0 || rxr_ep->util_ep.tx_msg_flags == FI_COMPLETION);
-	tx_op_flags = rxr_ep->util_ep.tx_op_flags;
-	if (rxr_ep->util_ep.tx_msg_flags == 0)
-		tx_op_flags &= ~FI_COMPLETION;
-	tx_entry->fi_flags = flags | tx_op_flags;
-
 	return tx_entry;
 }
 
@@ -1067,12 +1080,12 @@ ssize_t rxr_ep_send_msg(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry,
 	struct rxr_peer *peer;
 	size_t ret;
 
+	peer = rxr_ep_get_peer(ep, pkt_entry->addr);
 	assert(ep->tx_pending <= ep->max_outstanding_tx);
 
 	if (ep->tx_pending == ep->max_outstanding_tx)
 		return -FI_EAGAIN;
 
-	peer = rxr_ep_get_peer(ep, pkt_entry->addr);
 	if (peer->rnr_state & RXR_PEER_IN_BACKOFF)
 		return -FI_EAGAIN;
 
@@ -1082,10 +1095,13 @@ ssize_t rxr_ep_send_msg(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry,
 	rxr_ep_print_pkt("Sent", ep, (struct rxr_base_hdr *)pkt_entry->pkt);
 #endif
 #endif
-	ret = fi_sendmsg(ep->rdm_ep, msg, flags);
-
-	if (OFI_LIKELY(!ret))
-		rxr_ep_inc_tx_pending(ep, peer);
+	if (rxr_env.enable_shm_transfer && peer->is_local) {
+		ret = fi_sendmsg(ep->shm_ep, msg, flags);
+	} else {
+		ret = fi_sendmsg(ep->rdm_ep, msg, flags);
+		if (OFI_LIKELY(!ret))
+			rxr_ep_inc_tx_pending(ep, peer);
+	}
 
 	return ret;
 }
@@ -1128,7 +1144,7 @@ static ssize_t rxr_ep_mr_send_data_pkt_entry(struct rxr_ep *ep,
 	 * and corresponding fid_mrs
 	 */
 	struct iovec iov[ep->core_iov_limit];
-	struct fid_mr *mr[ep->core_iov_limit];
+	void *desc[ep->core_iov_limit];
 	/* Constructed iov's total size */
 	uint64_t payload_size = 0;
 	/* pkt_entry offset to write data into */
@@ -1145,7 +1161,7 @@ static ssize_t rxr_ep_mr_send_data_pkt_entry(struct rxr_ep *ep,
 	/* Assign packet header in constructed iov */
 	iov[i].iov_base = rxr_pkt_start(pkt_entry);
 	iov[i].iov_len = RXR_DATA_HDR_SIZE;
-	mr[i] = rxr_ep_mr_local(ep) ? fi_mr_desc(pkt_entry->mr) : NULL;
+	desc[i] = rxr_ep_mr_local(ep) ? fi_mr_desc(pkt_entry->mr) : NULL;
 	i++;
 
 	/*
@@ -1156,15 +1172,18 @@ static ssize_t rxr_ep_mr_send_data_pkt_entry(struct rxr_ep *ep,
 	 */
 	while (tx_entry->iov_index < tx_entry->iov_count &&
 	       remaining_len > 0 && i < ep->core_iov_limit) {
-		/* If the iov was pre registered after the RTS */
 		if (!rxr_ep_mr_local(ep) ||
-		    tx_entry->mr[tx_entry->iov_index]) {
+		    /* from the inline registration post-RTS */
+		    tx_entry->mr[tx_entry->iov_index] ||
+		    /* from application-provided descriptor */
+		    tx_entry->desc[tx_entry->iov_index]) {
 			iov[i].iov_base =
 				(char *)tx_iov[tx_entry->iov_index].iov_base +
 				tx_entry->iov_offset;
-			mr[i] = rxr_ep_mr_local(ep) ?
-				fi_mr_desc(tx_entry->mr[tx_entry->iov_index]) :
-				NULL;
+			if (rxr_ep_mr_local(ep))
+				desc[i] = tx_entry->desc[tx_entry->iov_index] ?
+					  tx_entry->desc[tx_entry->iov_index] :
+					  fi_mr_desc(tx_entry->mr[tx_entry->iov_index]);
 
 			len = tx_iov[tx_entry->iov_index].iov_len
 			      - tx_entry->iov_offset;
@@ -1188,7 +1207,7 @@ static ssize_t rxr_ep_mr_send_data_pkt_entry(struct rxr_ep *ep,
 
 			iov[i].iov_base = (char *)data_pkt->data + pkt_used;
 			iov[i].iov_len = len;
-			mr[i] = fi_mr_desc(pkt_entry->mr);
+			desc[i] = fi_mr_desc(pkt_entry->mr);
 			pkt_used += len;
 		}
 		payload_size += len;
@@ -1204,7 +1223,7 @@ static ssize_t rxr_ep_mr_send_data_pkt_entry(struct rxr_ep *ep,
 	       i, payload_size);
 	ret = rxr_ep_sendv_pkt(ep, pkt_entry, tx_entry->addr,
 			       (const struct iovec *)iov,
-			       (void **)mr, i, tx_entry->send_flags);
+			       desc, i, tx_entry->send_flags);
 	return ret;
 }
 
@@ -1215,7 +1234,7 @@ ssize_t rxr_ep_post_data(struct rxr_ep *rxr_ep,
 	struct rxr_data_pkt *data_pkt;
 	ssize_t ret;
 
-	pkt_entry = rxr_get_pkt_entry(rxr_ep, rxr_ep->tx_pkt_pool);
+	pkt_entry = rxr_get_pkt_entry(rxr_ep, rxr_ep->tx_pkt_efa_pool);
 
 	if (OFI_UNLIKELY(!pkt_entry))
 		return -FI_ENOMEM;
@@ -1255,32 +1274,40 @@ ssize_t rxr_ep_post_data(struct rxr_ep *rxr_ep,
 	return ret;
 }
 
-ssize_t rxr_ep_post_readrsp(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry)
+void rxr_inline_mr_reg(struct rxr_domain *rxr_domain,
+		       struct rxr_tx_entry *tx_entry)
 {
-	struct rxr_pkt_entry *pkt_entry;
 	ssize_t ret;
-	size_t data_len;
+	size_t offset;
+	int index;
 
-	pkt_entry = rxr_get_pkt_entry(ep, ep->tx_pkt_pool);
-	if (OFI_UNLIKELY(!pkt_entry))
-		return -FI_EAGAIN;
+	/* Set the iov index and iov offset from bytes sent */
+	offset = tx_entry->bytes_sent;
+	for (index = 0; index < tx_entry->iov_count; ++index) {
+		if (offset >= tx_entry->iov[index].iov_len) {
+			offset -= tx_entry->iov[index].iov_len;
+		} else {
+			tx_entry->iov_index = index;
+			tx_entry->iov_offset = offset;
+			break;
+		}
+	}
 
-	rxr_ep_init_readrsp_pkt_entry(ep, tx_entry, pkt_entry);
-	ret = rxr_ep_send_pkt(ep, pkt_entry, tx_entry->addr);
-	if (OFI_UNLIKELY(ret)) {
-		rxr_release_tx_pkt_entry(ep, pkt_entry);
-		FI_WARN(&rxr_prov, FI_LOG_CQ,
-			"Failed to send a read response packet: ret %zd\n", ret);
-		return ret;
+	tx_entry->iov_mr_start = index;
+	while (index < tx_entry->iov_count) {
+		if (tx_entry->iov[index].iov_len > rxr_env.max_memcpy_size) {
+			ret = fi_mr_reg(rxr_domain->rdm_domain,
+					tx_entry->iov[index].iov_base,
+					tx_entry->iov[index].iov_len,
+					FI_SEND, 0, 0, 0,
+					&tx_entry->mr[index], NULL);
+			if (ret)
+				tx_entry->mr[index] = NULL;
+		}
+		index++;
 	}
 
-	data_len = rxr_get_readrsp_hdr(pkt_entry->pkt)->seg_size;
-	tx_entry->bytes_sent += data_len;
-	tx_entry->window -= data_len;
-	assert(tx_entry->window >= 0);
-	assert(tx_entry->bytes_sent <= tx_entry->total_len);
-	assert(tx_entry->bytes_acked == 0);
-	return 0;
+	return;
 }
 
 void rxr_ep_calc_cts_window_credits(struct rxr_ep *ep, struct rxr_peer *peer,
@@ -1306,7 +1333,7 @@ void rxr_ep_calc_cts_window_credits(struct rxr_ep *ep, struct rxr_peer *peer,
 	 * number of credits are allocated to the transfer so the sender can
 	 * make progress.
 	 */
-	*credits = MIN(MIN(ep->available_data_bufs, ep->posted_bufs),
+	*credits = MIN(MIN(ep->available_data_bufs, ep->posted_bufs_efa),
 		       peer->rx_credits);
 	*credits = MIN(request, *credits);
 	*credits = MAX(*credits, rxr_env.tx_min_credits);
@@ -1315,18 +1342,16 @@ void rxr_ep_calc_cts_window_credits(struct rxr_ep *ep, struct rxr_peer *peer,
 		peer->rx_credits -= ofi_div_ceil(*window, ep->max_data_payload_size);
 }
 
-void rxr_ep_init_cts_pkt_entry(struct rxr_ep *ep,
-			       struct rxr_rx_entry *rx_entry,
-			       struct rxr_pkt_entry *pkt_entry,
-			       uint64_t size,
-			       int *credits)
+int rxr_ep_init_cts_pkt(struct rxr_ep *ep,
+			struct rxr_rx_entry *rx_entry,
+			struct rxr_pkt_entry *pkt_entry)
 {
 	int window = 0;
 	struct rxr_cts_hdr *cts_hdr;
 	struct rxr_peer *peer;
+	size_t bytes_left;
 
 	cts_hdr = (struct rxr_cts_hdr *)pkt_entry->pkt;
-
 	cts_hdr->type = RXR_CTS_PKT;
 	cts_hdr->version = RXR_PROTOCOL_VERSION;
 	cts_hdr->flags = 0;
@@ -1337,14 +1362,34 @@ void rxr_ep_init_cts_pkt_entry(struct rxr_ep *ep,
 	cts_hdr->tx_id = rx_entry->tx_id;
 	cts_hdr->rx_id = rx_entry->rx_id;
 
+	bytes_left = rx_entry->total_len - rx_entry->bytes_done;
 	peer = rxr_ep_get_peer(ep, rx_entry->addr);
-	rxr_ep_calc_cts_window_credits(ep, peer, size, rx_entry->credit_request,
-				       &window, credits);
+	rxr_ep_calc_cts_window_credits(ep, peer, bytes_left,
+				       rx_entry->credit_request,
+				       &window, &rx_entry->credit_cts);
 	cts_hdr->window = window;
-
 	pkt_entry->pkt_size = RXR_CTS_HDR_SIZE;
 	pkt_entry->addr = rx_entry->addr;
 	pkt_entry->x_entry = (void *)rx_entry;
+	return 0;
+}
+
+void rxr_ep_handle_cts_sent(struct rxr_ep *ep,
+			    struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_rx_entry *rx_entry;
+
+	rx_entry = (struct rxr_rx_entry *)pkt_entry->x_entry;
+	rx_entry->window = rxr_get_cts_hdr(pkt_entry->pkt)->window;
+	ep->available_data_bufs -= rx_entry->credit_cts;
+
+	/*
+	 * Set a timer if available_bufs is exhausted. We may encounter a
+	 * scenario where a peer has stopped responding so we need a fallback
+	 * to replenish the credits.
+	 */
+	if (OFI_UNLIKELY(ep->available_data_bufs == 0))
+		ep->available_data_bufs_ts = fi_gettime_us();
 }
 
 void rxr_ep_init_connack_pkt_entry(struct rxr_ep *ep,
@@ -1363,39 +1408,14 @@ void rxr_ep_init_connack_pkt_entry(struct rxr_ep *ep,
 	pkt_entry->addr = addr;
 }
 
-void rxr_ep_init_readrsp_pkt_entry(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
-				   struct rxr_pkt_entry *pkt_entry)
-{
-	struct rxr_readrsp_pkt *readrsp_pkt;
-	struct rxr_readrsp_hdr *readrsp_hdr;
-	size_t mtu = ep->mtu_size;
-
-	readrsp_pkt = (struct rxr_readrsp_pkt *)pkt_entry->pkt;
-	readrsp_hdr = &readrsp_pkt->hdr;
-	readrsp_hdr->type = RXR_READRSP_PKT;
-	readrsp_hdr->version = RXR_PROTOCOL_VERSION;
-	readrsp_hdr->flags = 0;
-	readrsp_hdr->tx_id = tx_entry->tx_id;
-	readrsp_hdr->rx_id = tx_entry->rx_id;
-	readrsp_hdr->seg_size = ofi_copy_from_iov(readrsp_pkt->data,
-						  mtu - RXR_READRSP_HDR_SIZE,
-						  tx_entry->iov,
-						  tx_entry->iov_count, 0);
-	pkt_entry->pkt_size = RXR_READRSP_HDR_SIZE + readrsp_hdr->seg_size;
-	pkt_entry->addr = tx_entry->addr;
-}
-
-/* Initialize RTS packet */
-void rxr_init_rts_pkt_entry(struct rxr_ep *ep,
-			    struct rxr_tx_entry *tx_entry,
-			    struct rxr_pkt_entry *pkt_entry)
+/* RTS related functions */
+char *rxr_ep_init_rts_hdr(struct rxr_ep *ep,
+			  struct rxr_tx_entry *tx_entry,
+			  struct rxr_pkt_entry *pkt_entry)
 {
 	struct rxr_rts_hdr *rts_hdr;
 	struct rxr_peer *peer;
-	char *data, *src;
-	uint64_t data_len;
-	size_t mtu = ep->mtu_size;
-	int rmalen = 0;
+	char *src;
 
 	rts_hdr = (struct rxr_rts_hdr *)pkt_entry->pkt;
 	peer = rxr_ep_get_peer(ep, tx_entry->addr);
@@ -1407,7 +1427,6 @@ void rxr_init_rts_pkt_entry(struct rxr_ep *ep,
 	rts_hdr->data_len = tx_entry->total_len;
 	rts_hdr->tx_id = tx_entry->tx_id;
 	rts_hdr->msg_id = tx_entry->msg_id;
-
 	/*
 	 * Even with protocol versions prior to v3 that did not include a
 	 * request in the RTS, the receiver can test for this flag and decide if
@@ -1430,6 +1449,9 @@ void rxr_init_rts_pkt_entry(struct rxr_ep *ep,
 		src = rxr_get_ctrl_pkt(rts_hdr)->data;
 	}
 
+	if (tx_entry->cq_entry.flags & FI_TAGGED)
+		rts_hdr->flags |= RXR_TAGGED;
+
 	rts_hdr->addrlen = 0;
 	if (OFI_UNLIKELY(peer->state != RXR_PEER_ACKED)) {
 		/*
@@ -1444,95 +1466,243 @@ void rxr_init_rts_pkt_entry(struct rxr_ep *ep,
 		pkt_entry->pkt_size += rts_hdr->addrlen;
 	}
 
-	rts_hdr->rma_iov_count = 0;
-	if (tx_entry->cq_entry.flags & FI_RMA) {
-		if (tx_entry->cq_entry.flags & FI_WRITE) {
-			rts_hdr->flags |= RXR_WRITE;
-		} else {
-			assert(tx_entry->cq_entry.flags & FI_READ);
-			rts_hdr->flags |= RXR_READ_REQ;
-		}
+	return src;
+}
 
-		rmalen = tx_entry->rma_iov_count * sizeof(struct fi_rma_iov);
-		rts_hdr->rma_iov_count = tx_entry->rma_iov_count;
-		memcpy(src, tx_entry->rma_iov, rmalen);
-		src += rmalen;
-		pkt_entry->pkt_size += rmalen;
-	}
+static size_t rxr_ep_init_rts_pkt(struct rxr_ep *ep,
+				  struct rxr_tx_entry *tx_entry,
+				  struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_peer *peer;
+	struct rxr_rts_hdr *rts_hdr;
+	char *data, *src;
+	uint64_t data_len;
+	size_t mtu = ep->mtu_size;
 
-	/*
-	 * currently copying for both INJECT and SEND,
-	 * need to optimize for SEND (small & large) messages
-	 */
-	if (rts_hdr->flags & RXR_READ_REQ) {
-		/* no data to send, but need to send rx_id and window */
-		memcpy(src, &tx_entry->rma_loc_rx_id, sizeof(uint64_t));
-		src += sizeof(uint64_t);
-		pkt_entry->pkt_size += sizeof(uint64_t);
-		memcpy(src, &tx_entry->rma_window, sizeof(uint64_t));
-		src += sizeof(uint64_t);
-		pkt_entry->pkt_size += sizeof(uint64_t);
+	if (tx_entry->op == ofi_op_read_req)
+		return rxr_rma_init_read_rts(ep, tx_entry, pkt_entry);
+
+	src = rxr_ep_init_rts_hdr(ep, tx_entry, pkt_entry);
+	if (tx_entry->op == ofi_op_write)
+		src = rxr_rma_init_rts_hdr(ep, tx_entry, pkt_entry, src);
+
+	peer = rxr_ep_get_peer(ep, tx_entry->addr);
+	assert(peer);
+	data = src;
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+	if (rxr_env.enable_shm_transfer && peer->is_local) {
+		rts_hdr->flags |= RXR_SHM_HDR;
+		/* will be sent over shm provider */
+		if (tx_entry->total_len <= rxr_env.shm_max_medium_size) {
+			data_len = ofi_copy_from_iov(data, rxr_env.shm_max_medium_size,
+						     tx_entry->iov, tx_entry->iov_count, 0);
+			assert(data_len == tx_entry->total_len);
+			rts_hdr->flags |= RXR_SHM_HDR_DATA;
+			pkt_entry->pkt_size += data_len;
+		} else {
+			/* rendezvous protocol
+			 * place iov_count first, then local iov
+			 */
+			memcpy(data, &tx_entry->iov_count, sizeof(size_t));
+			data += sizeof(size_t);
+			pkt_entry->pkt_size += sizeof(size_t);
+			memcpy(data, tx_entry->iov, sizeof(struct iovec) * tx_entry->iov_count);
+			pkt_entry->pkt_size += sizeof(struct iovec) * tx_entry->iov_count;
+		}
 	} else {
-		data = src;
+		/* will be sent over efa provider */
 		data_len = ofi_copy_from_iov(data, mtu - pkt_entry->pkt_size,
 					     tx_entry->iov, tx_entry->iov_count, 0);
 		assert(data_len == rxr_get_rts_data_size(ep, rts_hdr));
-
 		pkt_entry->pkt_size += data_len;
 	}
 
 	assert(pkt_entry->pkt_size <= mtu);
 	pkt_entry->addr = tx_entry->addr;
 	pkt_entry->x_entry = (void *)tx_entry;
-
-	if (tx_entry->cq_entry.flags & FI_TAGGED)
-		rts_hdr->flags |= RXR_TAGGED;
+	return 0;
 }
 
-static void rxr_inline_mr_reg(struct rxr_domain *rxr_domain,
-			      struct rxr_tx_entry *tx_entry,
-			      size_t index)
+void rxr_ep_handle_rts_sent(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry)
 {
-	ssize_t ret;
+	struct rxr_peer *peer;
+	struct rxr_tx_entry *tx_entry;
+	size_t data_sent;
 
-	tx_entry->iov_mr_start = index;
-	while (index < tx_entry->iov_count) {
-		if (tx_entry->iov[index].iov_len > rxr_env.max_memcpy_size) {
-			ret = fi_mr_reg(rxr_domain->rdm_domain,
-					tx_entry->iov[index].iov_base,
-					tx_entry->iov[index].iov_len,
-					FI_SEND, 0, 0, 0,
-					&tx_entry->mr[index], NULL);
-			if (ret)
-				tx_entry->mr[index] = NULL;
-		}
-		index++;
+	tx_entry = (struct rxr_tx_entry *)pkt_entry->x_entry;
+
+	peer = rxr_ep_get_peer(ep, pkt_entry->addr);
+	assert(peer);
+	if (tx_entry->op == ofi_op_read_req) {
+		tx_entry->bytes_sent = 0;
+		tx_entry->state = RXR_TX_WAIT_READ_FINISH;
+		return;
 	}
 
+	data_sent = rxr_get_rts_data_size(ep, rxr_get_rts_hdr(pkt_entry->pkt));
+
+	tx_entry->bytes_sent += data_sent;
+
+	if ((rxr_env.enable_shm_transfer && peer->is_local) ||
+	    !(efa_mr_cache_enable && tx_entry->total_len > data_sent))
+		return;
+
+	/*
+	 * Register the data buffers inline only if the application did not
+	 * provide a descriptor with the tx op
+	 */
+	if (rxr_ep_mr_local(ep) && !tx_entry->desc[0])
+		rxr_inline_mr_reg(rxr_ep_domain(ep), tx_entry);
+
 	return;
 }
 
-/* Post request to send */
-static size_t rxr_ep_post_rts(struct rxr_ep *rxr_ep, struct rxr_tx_entry *tx_entry)
+int rxr_ep_init_ctrl_pkt(struct rxr_ep *rxr_ep, int entry_type, void *x_entry,
+			 int ctrl_type, struct rxr_pkt_entry *pkt_entry)
+{
+	int ret = 0;
+
+	switch (ctrl_type) {
+	case RXR_RTS_PKT:
+		ret = rxr_ep_init_rts_pkt(rxr_ep, (struct rxr_tx_entry *)x_entry, pkt_entry);
+		break;
+	case RXR_READRSP_PKT:
+		ret = rxr_rma_init_readrsp_pkt(rxr_ep, (struct rxr_tx_entry *)x_entry, pkt_entry);
+		break;
+	case RXR_CTS_PKT:
+		ret = rxr_ep_init_cts_pkt(rxr_ep, (struct rxr_rx_entry *)x_entry, pkt_entry);
+		break;
+	case RXR_EOR_PKT:
+		ret = rxr_rma_init_eor_pkt(rxr_ep, (struct rxr_rx_entry *)x_entry, pkt_entry);
+		break;
+	default:
+		ret = -FI_EINVAL;
+		assert(0 && "unknown pkt type to init");
+		break;
+	}
+
+	return ret;
+}
+
+void rxr_ep_handle_ctrl_sent(struct rxr_ep *rxr_ep, struct rxr_pkt_entry *pkt_entry)
+{
+	int ctrl_type = rxr_get_base_hdr(pkt_entry->pkt)->type;
+
+	switch (ctrl_type) {
+	case RXR_RTS_PKT:
+		rxr_ep_handle_rts_sent(rxr_ep, pkt_entry);
+		break;
+	case RXR_READRSP_PKT:
+		rxr_rma_handle_readrsp_sent(rxr_ep, pkt_entry);
+		break;
+	case RXR_CTS_PKT:
+		rxr_ep_handle_cts_sent(rxr_ep, pkt_entry);
+		break;
+	case RXR_EOR_PKT:
+		rxr_rma_handle_eor_sent(rxr_ep, pkt_entry);
+		break;
+	default:
+		assert(0 && "Unknown packet type to handle sent");
+		break;
+	}
+}
+
+static size_t rxr_ep_post_ctrl(struct rxr_ep *rxr_ep, int entry_type, void *x_entry,
+			       int ctrl_type, bool inject)
 {
 	struct rxr_pkt_entry *pkt_entry;
+	struct rxr_tx_entry *tx_entry;
+	struct rxr_rx_entry *rx_entry;
 	struct rxr_peer *peer;
-	size_t pending = 0;
-	ssize_t ret;
-	uint64_t data_sent, offset;
-	int i;
+	ssize_t err;
+	fi_addr_t addr;
 
-	pkt_entry = rxr_get_pkt_entry(rxr_ep, rxr_ep->tx_pkt_pool);
+	if (entry_type == RXR_TX_ENTRY) {
+		tx_entry = (struct rxr_tx_entry *)x_entry;
+		addr = tx_entry->addr;
+	} else {
+		rx_entry = (struct rxr_rx_entry *)x_entry;
+		addr = rx_entry->addr;
+	}
 
-	if (OFI_UNLIKELY(!pkt_entry))
+	peer = rxr_ep_get_peer(rxr_ep, addr);
+	if (peer->is_local)
+		pkt_entry = rxr_get_pkt_entry(rxr_ep, rxr_ep->tx_pkt_shm_pool);
+	else
+		pkt_entry = rxr_get_pkt_entry(rxr_ep, rxr_ep->tx_pkt_efa_pool);
+
+	if (!pkt_entry)
 		return -FI_EAGAIN;
 
+	err = rxr_ep_init_ctrl_pkt(rxr_ep, entry_type, x_entry, ctrl_type, pkt_entry);
+	if (OFI_UNLIKELY(err)) {
+		rxr_release_tx_pkt_entry(rxr_ep, pkt_entry);
+		return err;
+	}
+
+	/* if send, tx_pkt_entry will be released while handle completion
+	 * if inject, there will not be completion, therefore tx_pkt_entry has to be
+	 * released here
+	 */
+	if (inject) {
+		err = rxr_ep_inject_pkt(rxr_ep, pkt_entry, addr);
+		rxr_release_tx_pkt_entry(rxr_ep, pkt_entry);
+	} else {
+		err = rxr_ep_send_pkt(rxr_ep, pkt_entry, addr);
+		if (OFI_UNLIKELY(err))
+			rxr_release_tx_pkt_entry(rxr_ep, pkt_entry);
+	}
+
+	if (OFI_UNLIKELY(err))
+		return err;
+
+	rxr_ep_handle_ctrl_sent(rxr_ep, pkt_entry);
+	return 0;
+}
+
+int rxr_ep_post_ctrl_or_queue(struct rxr_ep *ep, int entry_type, void *x_entry, int ctrl_type, bool inject)
+{
+	ssize_t err;
+	struct rxr_tx_entry *tx_entry;
+	struct rxr_rx_entry *rx_entry;
+
+	err = rxr_ep_post_ctrl(ep, entry_type, x_entry, ctrl_type, inject);
+	if (err == -FI_EAGAIN) {
+		if (entry_type == RXR_TX_ENTRY) {
+			tx_entry = (struct rxr_tx_entry *)x_entry;
+			tx_entry->state = RXR_TX_QUEUED_CTRL;
+			tx_entry->queued_ctrl.type = ctrl_type;
+			dlist_insert_tail(&tx_entry->queued_entry,
+					  &ep->tx_entry_queued_list);
+		} else {
+			assert(entry_type == RXR_RX_ENTRY);
+			rx_entry = (struct rxr_rx_entry *)x_entry;
+			rx_entry->state = RXR_RX_QUEUED_CTRL;
+			rx_entry->queued_ctrl.type = ctrl_type;
+			rx_entry->queued_ctrl.inject = inject;
+			dlist_insert_tail(&rx_entry->queued_entry,
+					  &ep->rx_entry_queued_list);
+		}
+
+		err = 0;
+	}
+
+	return err;
+}
+
+/* Generic send */
+int rxr_ep_set_tx_credit_request(struct rxr_ep *rxr_ep, struct rxr_tx_entry *tx_entry)
+{
+	struct rxr_peer *peer;
+	int pending;
+
+	peer = rxr_ep_get_peer(rxr_ep, tx_entry->addr);
+	assert(peer);
 	/*
 	 * Init tx state for this peer. The rx state and reorder buffers will be
 	 * initialized on the first recv so as to not allocate resources unless
 	 * necessary.
 	 */
-	peer = rxr_ep_get_peer(rxr_ep, tx_entry->addr);
 	if (!peer->tx_init) {
 		peer->tx_credits = rxr_env.tx_max_credits;
 		peer->tx_init = 1;
@@ -1556,199 +1726,75 @@ static size_t rxr_ep_post_rts(struct rxr_ep *rxr_ep, struct rxr_tx_entry *tx_ent
 	if (!tx_entry->credit_request)
 		return -FI_EAGAIN;
 
-	rxr_init_rts_pkt_entry(rxr_ep, tx_entry, pkt_entry);
-
-	ret = rxr_ep_send_pkt(rxr_ep, pkt_entry, tx_entry->addr);
-	if (OFI_UNLIKELY(ret)) {
-		rxr_release_tx_pkt_entry(rxr_ep, pkt_entry);
-		return ret;
-	}
-
-	if (tx_entry->cq_entry.flags & FI_READ) {
-		tx_entry->bytes_sent = 0;
-		assert(tx_entry->state == RXR_TX_RTS ||
-		       tx_entry->state == RXR_TX_QUEUED_RTS);
-		tx_entry->state = RXR_TX_WAIT_READ_FINISH;
-		return 0;
-	}
-
-	data_sent = rxr_get_rts_data_size(rxr_ep, rxr_get_rts_hdr(pkt_entry->pkt));
-
-	tx_entry->bytes_sent += data_sent;
-
-	if (!(efa_mr_cache_enable && tx_entry->total_len > data_sent))
-		return ret;
-
-	/* Set the iov index and iov offset from bytes sent */
-	offset = data_sent;
-	for (i = 0; i < tx_entry->iov_count; i++) {
-		if (offset >= tx_entry->iov[i].iov_len) {
-			offset -= tx_entry->iov[i].iov_len;
-		} else {
-			tx_entry->iov_index = i;
-			tx_entry->iov_offset = offset;
-			break;
-		}
-	}
-
-	if (rxr_ep_mr_local(rxr_ep))
-		rxr_inline_mr_reg(rxr_ep_domain(rxr_ep), tx_entry, i);
-
 	return 0;
 }
 
-
-
-/* Generic send */
-ssize_t rxr_tx(struct fid_ep *ep, const struct iovec *iov, size_t iov_count,
-	       const struct fi_rma_iov *rma_iov, size_t rma_iov_count,
-	       fi_addr_t addr, uint64_t tag, uint64_t data, void *context,
-	       uint32_t op, uint64_t flags)
+ssize_t rxr_generic_send(struct fid_ep *ep, const struct fi_msg *msg,
+			 uint64_t tag, uint32_t op, uint64_t flags)
 {
 	struct rxr_ep *rxr_ep;
-	ssize_t ret;
+	ssize_t err;
 	struct rxr_tx_entry *tx_entry;
 	struct rxr_peer *peer;
 
 	FI_DBG(&rxr_prov, FI_LOG_EP_DATA,
-	       "%s: iov_len: %lu tag: %lx op: %x flags: %lx\n",
-	       __func__, ofi_total_iov_len(iov, iov_count), tag, op, flags);
+	       "iov_len: %lu tag: %lx op: %x flags: %lx\n",
+	       ofi_total_iov_len(msg->msg_iov, msg->iov_count),
+	       tag, op, flags);
 
 	rxr_ep = container_of(ep, struct rxr_ep, util_ep.ep_fid.fid);
-
-	assert(iov_count <= rxr_ep->tx_iov_limit);
+	assert(msg->iov_count <= rxr_ep->tx_iov_limit);
 
 	rxr_perfset_start(rxr_ep, perf_rxr_tx);
-
 	fastlock_acquire(&rxr_ep->util_ep.lock);
 
 	if (OFI_UNLIKELY(is_tx_res_full(rxr_ep))) {
-		ret = -FI_EAGAIN;
+		err = -FI_EAGAIN;
 		goto out;
 	}
 
-	tx_entry = rxr_ep_tx_entry_init(rxr_ep, iov, iov_count,
-					rma_iov, rma_iov_count,
-					addr, tag, data, context,
-					op, flags);
+	tx_entry = rxr_ep_alloc_tx_entry(rxr_ep, msg, op, tag, flags);
 
 	if (OFI_UNLIKELY(!tx_entry)) {
-		ret = -FI_EAGAIN;
+		err = -FI_EAGAIN;
 		rxr_ep_progress_internal(rxr_ep);
 		goto out;
 	}
 
-	peer = rxr_ep_get_peer(rxr_ep, addr);
-	tx_entry->msg_id = (peer->next_msg_id != ~0) ?
-			    peer->next_msg_id++ : ++peer->next_msg_id;
-
-	if (op == ofi_op_read_req) {
-		int ignore = ~0;
-		struct rxr_rx_entry *rx_entry = NULL;
-		int credits = 0;
-		int window = 0;
-		/* this rx_entry works same as a receiving rx_entry thus
-		 * we use ofi_op_msg for its op.
-		 * it does not write a rx completion.
-		 */
-		rx_entry = rxr_ep_get_rx_entry(rxr_ep, iov, iov_count, tag,
-					       ignore, context,
-					       addr, ofi_op_msg, 0);
-		if (!rx_entry) {
-			rxr_release_tx_entry(rxr_ep, tx_entry);
-			FI_WARN(&rxr_prov, FI_LOG_CQ,
-				"RX entries exhausted.\n");
-			rxr_eq_write_error(rxr_ep, FI_ENOBUFS, -FI_ENOBUFS);
-			ret = -FI_ENOBUFS;
-			goto out;
-		}
+	peer = rxr_ep_get_peer(rxr_ep, msg->addr);
+	assert(tx_entry->op == ofi_op_msg || tx_entry->op == ofi_op_tagged);
 
-		/*
-		 * this rx_entry does not know its tx_id, because remote
-		 * tx_entry has not been created yet.
-		 * set tx_id to -1, and the correct one will be filled in
-		 * rxr_cq_handle_readrsp()
-		 */
-		assert(rx_entry);
-		rx_entry->tx_id = -1;
-		rx_entry->cq_entry.flags |= FI_READ;
-		rx_entry->total_len = rx_entry->cq_entry.len;
-
-		/*
-		 * there will not be a CTS for fi_read, we calculate CTS
-		 * window here, and send it via RTS.
-		 * meanwhile set rx_entry->state to RXR_RX_RECV so that
-		 * this rx_entry is ready to receive
-		 */
-
-		/* If there is no available buffer, we do not proceed.
-		 * It is important to decrease peer->next_msg_id by 1
-		 * in this case because this message was not sent.
-		 */
-		if (rxr_ep->available_data_bufs==0) {
+	if (!(rxr_env.enable_shm_transfer && peer->is_local)) {
+		err = rxr_ep_set_tx_credit_request(rxr_ep, tx_entry);
+		if (OFI_UNLIKELY(err)) {
 			rxr_release_tx_entry(rxr_ep, tx_entry);
-			rxr_release_rx_entry(rxr_ep, rx_entry);
-			peer->next_msg_id--;
-			ret = -FI_EAGAIN;
-			rxr_ep_progress_internal(rxr_ep);
 			goto out;
 		}
-
-		rxr_ep_calc_cts_window_credits(rxr_ep, peer,
-					       tx_entry->total_len,
-					       tx_entry->credit_request,
-					       &window,
-					       &credits);
-
-		rx_entry->window = window;
-		rxr_ep->available_data_bufs -= credits;
-
-		rx_entry->state = RXR_RX_RECV;
-		/* rma_loc_tx_id is used in rxr_cq_handle_rx_completion()
-		 * to locate the tx_entry for tx completion.
-		 */
-		rx_entry->rma_loc_tx_id = tx_entry->tx_id;
-#if ENABLE_DEBUG
-		dlist_insert_tail(&rx_entry->rx_pending_entry,
-				  &rxr_ep->rx_pending_list);
-		rxr_ep->rx_pending++;
-#endif
-		/*
-		 * this tx_entry does not need a rx_id, because it does not
-		 * send any data.
-		 * the rma_loc_rx_id and rma_window will be sent to remote EP
-		 * via RTS
-		 */
-		tx_entry->rma_loc_rx_id = rx_entry->rx_id;
-		tx_entry->rma_window = rx_entry->window;
 	}
 
-	ret = rxr_ep_post_rts(rxr_ep, tx_entry);
+	if (!(rxr_env.enable_shm_transfer && peer->is_local) &&
+	    rxr_need_sas_ordering(rxr_ep))
+		tx_entry->msg_id = (peer->next_msg_id != ~0) ?
+				    peer->next_msg_id++ : ++peer->next_msg_id;
 
-	if (OFI_UNLIKELY(ret)) {
-		if (ret == -FI_EAGAIN) {
-			tx_entry->state = RXR_TX_QUEUED_RTS;
-			dlist_insert_tail(&tx_entry->queued_entry,
-					  &rxr_ep->tx_entry_queued_list);
-			ret = 0;
-		} else {
-			peer = rxr_ep_get_peer(rxr_ep, addr);
+	err = rxr_ep_post_ctrl_or_queue(rxr_ep, RXR_TX_ENTRY, tx_entry, RXR_RTS_PKT, 0);
+	if (OFI_UNLIKELY(err)) {
+		rxr_release_tx_entry(rxr_ep, tx_entry);
+		if (!(rxr_env.enable_shm_transfer && peer->is_local) &&
+		    rxr_need_sas_ordering(rxr_ep))
 			peer->next_msg_id--;
-		}
 	}
 
 out:
 	fastlock_release(&rxr_ep->util_ep.lock);
 	rxr_perfset_end(rxr_ep, perf_rxr_tx);
-	return ret;
+	return err;
 }
 
 static ssize_t rxr_ep_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
 			      uint64_t flags)
 {
-	return rxr_tx(ep, msg->msg_iov, msg->iov_count, NULL, 0,
-		      msg->addr, 0, msg->data, msg->context,
-		      ofi_op_msg, flags);
+	return rxr_generic_send(ep, msg, 0, ofi_op_msg, flags);
 }
 
 static ssize_t rxr_ep_sendv(struct fid_ep *ep, const struct iovec *iov,
@@ -1781,13 +1827,21 @@ static ssize_t rxr_ep_senddata(struct fid_ep *ep, const void *buf, size_t len,
 			       void *desc, uint64_t data, fi_addr_t dest_addr,
 			       void *context)
 {
+	struct fi_msg msg;
 	struct iovec iov;
 
 	iov.iov_base = (void *)buf;
 	iov.iov_len = len;
 
-	return rxr_tx(ep, &iov, 1, NULL, 0, dest_addr, 0, data, context,
-		      ofi_op_msg, FI_REMOTE_CQ_DATA);
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_iov = &iov;
+	msg.desc = desc;
+	msg.iov_count = 1;
+	msg.addr = dest_addr;
+	msg.context = context;
+	msg.data = data;
+
+	return rxr_generic_send(ep, &msg, 0, ofi_op_msg, FI_REMOTE_CQ_DATA);
 }
 
 static ssize_t rxr_ep_inject(struct fid_ep *ep, const void *buf, size_t len,
@@ -1796,18 +1850,24 @@ static ssize_t rxr_ep_inject(struct fid_ep *ep, const void *buf, size_t len,
 #if ENABLE_DEBUG
 	struct rxr_ep *rxr_ep;
 #endif
+	struct fi_msg msg;
 	struct iovec iov;
 
 	iov.iov_base = (void *)buf;
 	iov.iov_len = len;
 
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_iov = &iov;
+	msg.iov_count = 1;
+	msg.addr = dest_addr;
+
 #if ENABLE_DEBUG
 	rxr_ep = container_of(ep, struct rxr_ep, util_ep.ep_fid.fid);
 	assert(len <= rxr_ep->core_inject_size - RXR_CTRL_HDR_SIZE_NO_CQ);
 #endif
 
-	return rxr_tx(ep, &iov, 1, NULL, 0, dest_addr, 0, 0, NULL, ofi_op_msg,
-		      RXR_NO_COMPLETION | FI_INJECT);
+	return rxr_generic_send(ep, &msg, 0, ofi_op_msg,
+				RXR_NO_COMPLETION | FI_INJECT);
 }
 
 static ssize_t rxr_ep_injectdata(struct fid_ep *ep, const void *buf,
@@ -1817,11 +1877,18 @@ static ssize_t rxr_ep_injectdata(struct fid_ep *ep, const void *buf,
 #if ENABLE_DEBUG
 	struct rxr_ep *rxr_ep;
 #endif
+	struct fi_msg msg;
 	struct iovec iov;
 
 	iov.iov_base = (void *)buf;
 	iov.iov_len = len;
 
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_iov = &iov;
+	msg.iov_count = 1;
+	msg.addr = dest_addr;
+	msg.data = data;
+
 #if ENABLE_DEBUG
 	rxr_ep = container_of(ep, struct rxr_ep, util_ep.ep_fid.fid);
 	/*
@@ -1832,8 +1899,8 @@ static ssize_t rxr_ep_injectdata(struct fid_ep *ep, const void *buf,
 	assert(len <= rxr_ep->core_inject_size - RXR_CTRL_HDR_SIZE_NO_CQ);
 #endif
 
-	return rxr_tx(ep, &iov, 1, NULL, 0, dest_addr, 0, data, NULL,
-		      ofi_op_msg, RXR_NO_COMPLETION | FI_REMOTE_CQ_DATA | FI_INJECT);
+	return rxr_generic_send(ep, &msg, 0, ofi_op_msg,
+				RXR_NO_COMPLETION | FI_REMOTE_CQ_DATA | FI_INJECT);
 }
 
 static struct fi_ops_msg rxr_ops_msg = {
@@ -1891,12 +1958,19 @@ out:
 	return ret;
 }
 
-ssize_t rxr_ep_tsendmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *msg,
+ssize_t rxr_ep_tsendmsg(struct fid_ep *ep_fid, const struct fi_msg_tagged *tmsg,
 			uint64_t flags)
 {
-	return rxr_tx(ep_fid, msg->msg_iov, msg->iov_count, NULL, 0,
-		      msg->addr, msg->tag, msg->data, msg->context,
-		      ofi_op_tagged, flags);
+	struct fi_msg msg;
+
+	msg.msg_iov = tmsg->msg_iov;
+	msg.desc = tmsg->desc;
+	msg.iov_count = tmsg->iov_count;
+	msg.addr = tmsg->addr;
+	msg.context = tmsg->context;
+	msg.data = tmsg->data;
+
+	return rxr_generic_send(ep_fid, &msg, tmsg->tag, ofi_op_tagged, flags);
 }
 
 ssize_t rxr_ep_tsendv(struct fid_ep *ep_fid, const struct iovec *iov,
@@ -1924,8 +1998,7 @@ ssize_t rxr_ep_tsend(struct fid_ep *ep_fid, const void *buf, size_t len,
 
 	msg_iov.iov_base = (void *)buf;
 	msg_iov.iov_len = len;
-
-	return rxr_ep_tsendv(ep_fid, &msg_iov, desc, 1, dest_addr, tag,
+	return rxr_ep_tsendv(ep_fid, &msg_iov, &desc, 1, dest_addr, tag,
 			     context);
 }
 
@@ -1935,31 +2008,45 @@ ssize_t rxr_ep_tinject(struct fid_ep *ep_fid, const void *buf, size_t len,
 #if ENABLE_DEBUG
 	struct rxr_ep *rxr_ep;
 #endif
+	struct fi_msg msg;
 	struct iovec iov;
 
 	iov.iov_base = (void *)buf;
 	iov.iov_len = len;
 
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_iov = &iov;
+	msg.iov_count = 1;
+	msg.addr = dest_addr;
+
 #if ENABLE_DEBUG
 	rxr_ep = container_of(ep_fid, struct rxr_ep, util_ep.ep_fid.fid);
 	assert(len <= rxr_ep->core_inject_size - RXR_CTRL_HDR_SIZE_NO_CQ);
 #endif
 
-	return rxr_tx(ep_fid, &iov, 1, NULL, 0, dest_addr, tag, 0, NULL,
-		      ofi_op_tagged, RXR_NO_COMPLETION | FI_INJECT);
+	return rxr_generic_send(ep_fid, &msg, tag, ofi_op_tagged,
+				RXR_NO_COMPLETION | FI_INJECT);
 }
 
 ssize_t rxr_ep_tsenddata(struct fid_ep *ep_fid, const void *buf, size_t len,
 			 void *desc, uint64_t data, fi_addr_t dest_addr,
 			 uint64_t tag, void *context)
 {
+	struct fi_msg msg;
 	struct iovec iov;
 
 	iov.iov_base = (void *)buf;
 	iov.iov_len = len;
 
-	return rxr_tx(ep_fid, &iov, 1, NULL, 0, dest_addr, tag, data, context,
-		      ofi_op_tagged, FI_REMOTE_CQ_DATA);
+	msg.msg_iov = &iov;
+	msg.desc = desc;
+	msg.iov_count = 1;
+	msg.addr = dest_addr;
+	msg.context = context;
+	msg.data = data;
+
+	return rxr_generic_send(ep_fid, &msg, tag, ofi_op_tagged,
+				FI_REMOTE_CQ_DATA);
 }
 
 ssize_t rxr_ep_tinjectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
@@ -1968,11 +2055,18 @@ ssize_t rxr_ep_tinjectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
 #if ENABLE_DEBUG
 	struct rxr_ep *rxr_ep;
 #endif
+	struct fi_msg msg;
 	struct iovec iov;
 
 	iov.iov_base = (void *)buf;
 	iov.iov_len = len;
 
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_iov = &iov;
+	msg.iov_count = 1;
+	msg.addr = dest_addr;
+	msg.data = data;
+
 #if ENABLE_DEBUG
 	rxr_ep = container_of(ep_fid, struct rxr_ep, util_ep.ep_fid.fid);
 	/*
@@ -1983,8 +2077,8 @@ ssize_t rxr_ep_tinjectdata(struct fid_ep *ep_fid, const void *buf, size_t len,
 	assert(len <= rxr_ep->core_inject_size - RXR_CTRL_HDR_SIZE_NO_CQ);
 #endif
 
-	return rxr_tx(ep_fid, &iov, 1, NULL, 0, dest_addr, tag, data, NULL,
-		      ofi_op_tagged, RXR_NO_COMPLETION | FI_REMOTE_CQ_DATA | FI_INJECT);
+	return rxr_generic_send(ep_fid, &msg, tag, ofi_op_tagged,
+				RXR_NO_COMPLETION | FI_REMOTE_CQ_DATA | FI_INJECT);
 }
 
 static struct fi_ops_tagged rxr_ops_tagged = {
@@ -2089,6 +2183,12 @@ static void rxr_ep_free_res(struct rxr_ep *rxr_ep)
 					tx_entry_entry);
 		rxr_release_tx_entry(rxr_ep, tx_entry);
 	}
+	if (rxr_env.enable_shm_transfer) {
+		dlist_foreach_safe(&rxr_ep->rx_posted_buf_shm_list, entry, tmp) {
+			pkt = container_of(entry, struct rxr_pkt_entry, dbg_entry);
+			ofi_buf_free(pkt);
+		}
+	}
 #endif
 
 	if (rxr_ep->rx_entry_pool)
@@ -2106,11 +2206,19 @@ static void rxr_ep_free_res(struct rxr_ep *rxr_ep)
 	if (rxr_ep->rx_unexp_pkt_pool)
 		ofi_bufpool_destroy(rxr_ep->rx_unexp_pkt_pool);
 
-	if (rxr_ep->rx_pkt_pool)
-		ofi_bufpool_destroy(rxr_ep->rx_pkt_pool);
+	if (rxr_ep->rx_pkt_efa_pool)
+		ofi_bufpool_destroy(rxr_ep->rx_pkt_efa_pool);
+
+	if (rxr_ep->tx_pkt_efa_pool)
+		ofi_bufpool_destroy(rxr_ep->tx_pkt_efa_pool);
 
-	if (rxr_ep->tx_pkt_pool)
-		ofi_bufpool_destroy(rxr_ep->tx_pkt_pool);
+	if (rxr_env.enable_shm_transfer) {
+		if (rxr_ep->rx_pkt_shm_pool)
+			ofi_bufpool_destroy(rxr_ep->rx_pkt_shm_pool);
+
+		if (rxr_ep->tx_pkt_shm_pool)
+			ofi_bufpool_destroy(rxr_ep->tx_pkt_shm_pool);
+	}
 }
 
 static int rxr_ep_close(struct fid *fid)
@@ -2132,6 +2240,22 @@ static int rxr_ep_close(struct fid *fid)
 		retv = ret;
 	}
 
+	/* Close shm provider's endpoint and cq */
+	if (rxr_env.enable_shm_transfer) {
+		ret = fi_close(&rxr_ep->shm_ep->fid);
+		if (ret) {
+			FI_WARN(&rxr_prov, FI_LOG_EP_CTRL, "Unable to close shm EP\n");
+			retv = ret;
+		}
+
+		ret = fi_close(&rxr_ep->shm_cq->fid);
+		if (ret) {
+			FI_WARN(&rxr_prov, FI_LOG_EP_CTRL, "Unable to close shm CQ\n");
+			retv = ret;
+		}
+	}
+
+
 	ret = ofi_endpoint_close(&rxr_ep->util_ep);
 	if (ret) {
 		FI_WARN(&rxr_prov, FI_LOG_EP_CTRL, "Unable to close util EP\n");
@@ -2151,7 +2275,12 @@ static int rxr_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 	struct rxr_av *av;
 	struct util_cntr *cntr;
 	struct util_eq *eq;
+	struct dlist_entry *ep_list_first_entry;
+	struct util_ep *util_ep;
+	struct rxr_ep *rxr_first_ep;
+	struct rxr_peer *first_ep_peer, *peer;
 	int ret = 0;
+	size_t i;
 
 	switch (bfid->fclass) {
 	case FI_CLASS_AV:
@@ -2171,11 +2300,41 @@ static int rxr_ep_bind(struct fid *ep_fid, struct fid *bfid, uint64_t flags)
 		if (!rxr_ep->peer)
 			return -FI_ENOMEM;
 
-		rxr_ep->robuf_fs = rxr_robuf_fs_create(rxr_ep->rx_size,
+		rxr_ep->robuf_fs = rxr_robuf_fs_create(av->util_av.count,
 						       NULL, NULL);
 		if (!rxr_ep->robuf_fs)
 			return -FI_ENOMEM;
 
+		/* Bind shm provider endpoint & shm av */
+		if (rxr_env.enable_shm_transfer) {
+			ret = fi_ep_bind(rxr_ep->shm_ep, &av->shm_rdm_av->fid, flags);
+			if (ret)
+				return ret;
+
+			/*
+			 * We always update the new added EP's local information with the first
+			 * bound EP. The if (ep_list_first_entry->next) check here is to skip the
+			 * update for the first bound EP.
+			 */
+			ep_list_first_entry = av->util_av.ep_list.next;
+			if (ep_list_first_entry->next) {
+				util_ep = container_of(ep_list_first_entry, struct util_ep, av_entry);
+				rxr_first_ep = container_of(util_ep, struct rxr_ep, util_ep);
+
+				/*
+				 * Copy the entire peer array, because we may not be able to make the
+				 * assumption that insertions are always indexed in order in the future.
+				 */
+				for (i = 0; i <= av->util_av.count; i++) {
+					first_ep_peer = rxr_ep_get_peer(rxr_first_ep, i);
+					if (first_ep_peer->is_local) {
+						peer = rxr_ep_get_peer(rxr_ep, i);
+						peer->shm_fiaddr = first_ep_peer->shm_fiaddr;
+						peer->is_local = 1;
+					}
+				}
+			}
+		}
 		break;
 	case FI_CLASS_CQ:
 		cq = container_of(bfid, struct util_cq, cq_fid.fid);
@@ -2212,15 +2371,15 @@ static int rxr_ep_ctrl(struct fid *fid, int command, void *arg)
 	size_t i;
 	struct rxr_ep *ep;
 	uint64_t flags = FI_MORE;
-	size_t rx_size;
+	size_t rx_size, shm_rx_size;
+	char shm_ep_name[NAME_MAX];
 
 	switch (command) {
 	case FI_ENABLE:
-		/* Enable core provider endpoint & post recv buff */
+		/* Enable core endpoints & post recv buff */
 		ep = container_of(fid, struct rxr_ep, util_ep.ep_fid.fid);
 
 		rx_size = rxr_get_rx_pool_chunk_cnt(ep);
-
 		ret = fi_enable(ep->rdm_ep);
 		if (ret)
 			return ret;
@@ -2230,7 +2389,7 @@ static int rxr_ep_ctrl(struct fid *fid, int command, void *arg)
 			if (i == rx_size - 1)
 				flags = 0;
 
-			ret = rxr_ep_post_buf(ep, flags);
+			ret = rxr_ep_post_buf(ep, flags, EFA_EP);
 
 			if (ret)
 				goto out;
@@ -2245,6 +2404,36 @@ static int rxr_ep_ctrl(struct fid *fid, int command, void *arg)
 		assert(ret != -FI_ETOOSMALL);
 		FI_DBG(&rxr_prov, FI_LOG_EP_CTRL, "core_addrlen = %ld\n",
 		       ep->core_addrlen);
+
+		/* Enable shm provider endpoint & post recv buff.
+		 * Once core ep enabled, 18 bytes efa_addr (16 bytes raw + 2 bytes qpn) is set.
+		 * We convert the address to 'gid_qpn' format, and set it as shm ep name, so
+		 * that shm ep can create shared memory region with it when enabling.
+		 * In this way, each peer is able to open and map to other local peers'
+		 * shared memory region.
+		 */
+		if (rxr_env.enable_shm_transfer) {
+			ret = rxr_ep_efa_addr_to_str(ep->core_addr, shm_ep_name);
+			if (ret < 0)
+				goto out;
+
+			fi_setname(&ep->shm_ep->fid, shm_ep_name, sizeof(shm_ep_name));
+			shm_rx_size = shm_info->rx_attr->size;
+			ret = fi_enable(ep->shm_ep);
+			if (ret)
+				return ret;
+			/* Pre-post buffer to receive from shm provider */
+			for (i = 0; i < shm_rx_size; i++) {
+				if (i == shm_rx_size - 1)
+					flags = 0;
+
+				ret = rxr_ep_post_buf(ep, flags, SHM_EP);
+
+				if (ret)
+					goto out;
+			}
+		}
+
 out:
 		fastlock_release(&ep->util_ep.lock);
 		break;
@@ -2398,8 +2587,8 @@ static int rxr_buf_region_alloc_hndlr(struct ofi_bufpool_region *region)
 	struct fid_mr *mr;
 	struct rxr_domain *domain = region->pool->attr.context;
 
-	ret = fi_mr_reg(domain->rdm_domain, region->mem_region,
-			region->pool->region_size,
+	ret = fi_mr_reg(domain->rdm_domain, region->alloc_region,
+			region->pool->alloc_size,
 			FI_SEND | FI_RECV, 0, 0, 0, &mr, NULL);
 
 	region->context = mr;
@@ -2450,12 +2639,12 @@ int rxr_ep_init(struct rxr_ep *ep)
 #endif
 
 	ret = rxr_create_pkt_pool(ep, entry_sz, rxr_get_tx_pool_chunk_cnt(ep),
-				  &ep->tx_pkt_pool);
+				  &ep->tx_pkt_efa_pool);
 	if (ret)
 		goto err_out;
 
 	ret = rxr_create_pkt_pool(ep, entry_sz, rxr_get_rx_pool_chunk_cnt(ep),
-				  &ep->rx_pkt_pool);
+				  &ep->rx_pkt_efa_pool);
 	if (ret)
 		goto err_free_tx_pool;
 
@@ -2500,6 +2689,27 @@ int rxr_ep_init(struct rxr_ep *ep)
 	if (ret)
 		goto err_free_readrsp_tx_entry_pool;
 
+	/* create pkt pool for shm */
+	if (rxr_env.enable_shm_transfer) {
+		ret = ofi_bufpool_create(&ep->tx_pkt_shm_pool,
+					 entry_sz,
+					 RXR_BUF_POOL_ALIGNMENT,
+					 shm_info->tx_attr->size,
+					 shm_info->tx_attr->size, 0);
+		if (ret)
+			goto err_free_rx_entry_pool;
+
+		ret = ofi_bufpool_create(&ep->rx_pkt_shm_pool,
+					 entry_sz,
+					 RXR_BUF_POOL_ALIGNMENT,
+					 shm_info->rx_attr->size,
+					 shm_info->rx_attr->size, 0);
+		if (ret)
+			goto err_free_tx_pkt_shm_pool;
+
+		dlist_init(&ep->rx_posted_buf_shm_list);
+	}
+
 	/* Initialize entry list */
 	dlist_init(&ep->rx_list);
 	dlist_init(&ep->rx_unexp_list);
@@ -2520,6 +2730,13 @@ int rxr_ep_init(struct rxr_ep *ep)
 #endif
 
 	return 0;
+
+err_free_tx_pkt_shm_pool:
+	if (ep->tx_pkt_shm_pool)
+		ofi_bufpool_destroy(ep->tx_pkt_shm_pool);
+err_free_rx_entry_pool:
+	if (ep->rx_entry_pool)
+		ofi_bufpool_destroy(ep->rx_entry_pool);
 err_free_readrsp_tx_entry_pool:
 	if (ep->readrsp_tx_entry_pool)
 		ofi_bufpool_destroy(ep->readrsp_tx_entry_pool);
@@ -2533,11 +2750,11 @@ err_free_rx_unexp_pool:
 	if (rxr_env.rx_copy_unexp && ep->rx_unexp_pkt_pool)
 		ofi_bufpool_destroy(ep->rx_unexp_pkt_pool);
 err_free_rx_pool:
-	if (ep->rx_pkt_pool)
-		ofi_bufpool_destroy(ep->rx_pkt_pool);
+	if (ep->rx_pkt_efa_pool)
+		ofi_bufpool_destroy(ep->rx_pkt_efa_pool);
 err_free_tx_pool:
-	if (ep->tx_pkt_pool)
-		ofi_bufpool_destroy(ep->tx_pkt_pool);
+	if (ep->tx_pkt_efa_pool)
+		ofi_bufpool_destroy(ep->tx_pkt_efa_pool);
 err_out:
 	return ret;
 }
@@ -2576,12 +2793,23 @@ static inline int rxr_ep_bulk_post_recv(struct rxr_ep *ep)
 	uint64_t flags = FI_MORE;
 	int ret;
 
-	while (ep->rx_bufs_to_post) {
-		if (ep->rx_bufs_to_post == 1)
+	while (ep->rx_bufs_efa_to_post) {
+		if (ep->rx_bufs_efa_to_post == 1)
 			flags = 0;
-		ret = rxr_ep_post_buf(ep, flags);
+		ret = rxr_ep_post_buf(ep, flags, EFA_EP);
 		if (OFI_LIKELY(!ret))
-			ep->rx_bufs_to_post--;
+			ep->rx_bufs_efa_to_post--;
+		else
+			return ret;
+	}
+	/* bulk post recv buf for shm provider */
+	flags = FI_MORE;
+	while (rxr_env.enable_shm_transfer && ep->rx_bufs_shm_to_post) {
+		if (ep->rx_bufs_shm_to_post == 1)
+			flags = 0;
+		ret = rxr_ep_post_buf(ep, flags, SHM_EP);
+		if (OFI_LIKELY(!ret))
+			ep->rx_bufs_shm_to_post--;
 		else
 			return ret;
 	}
@@ -2598,6 +2826,11 @@ static inline int rxr_ep_send_queued_pkts(struct rxr_ep *ep,
 
 	dlist_foreach_container_safe(pkts, struct rxr_pkt_entry,
 				     pkt_entry, entry, tmp) {
+		if (rxr_env.enable_shm_transfer &&
+				rxr_ep_get_peer(ep, pkt_entry->addr)->is_local) {
+			dlist_remove(&pkt_entry->entry);
+			continue;
+		}
 		ret = rxr_ep_send_pkt(ep, pkt_entry, pkt_entry->addr);
 		if (ret)
 			return ret;
@@ -2638,30 +2871,24 @@ static inline void rxr_ep_check_peer_backoff_timer(struct rxr_ep *ep)
 	}
 }
 
-static void rxr_ep_progress_internal(struct rxr_ep *ep)
+static inline void rxr_ep_poll_cq(struct rxr_ep *ep,
+				  struct fid_cq *cq,
+				  size_t cqe_to_process,
+				  bool is_shm_cq)
 {
-	struct fi_cq_msg_entry cq_entry;
-	struct rxr_rx_entry *rx_entry;
-	struct rxr_tx_entry *tx_entry;
-	struct dlist_entry *tmp;
+	struct fi_cq_data_entry cq_entry;
 	fi_addr_t src_addr;
 	ssize_t ret;
 	int i;
 
-	rxr_ep_check_available_data_bufs_timer(ep);
+	VALGRIND_MAKE_MEM_DEFINED(&cq_entry, sizeof(struct fi_cq_data_entry));
 
-	VALGRIND_MAKE_MEM_DEFINED(&cq_entry, sizeof(struct fi_cq_msg_entry));
-
-	for (ret = 1, i = 0; ret > 0 && i < 100; i++) {
-		if (ep->core_caps & FI_SOURCE) {
-			ret = fi_cq_readfrom(ep->rdm_cq, &cq_entry, 1, &src_addr);
-		} else {
-			ret = fi_cq_read(ep->rdm_cq, &cq_entry, 1);
-			src_addr = FI_ADDR_NOTAVAIL;
-		}
+	for (i = 0; i < cqe_to_process; i++) {
+		ret = fi_cq_readfrom(cq, &cq_entry, 1, &src_addr);
 
 		if (ret == -FI_EAGAIN)
-			break;
+			return;
+
 		if (OFI_UNLIKELY(ret < 0)) {
 			if (rxr_cq_handle_cq_error(ep, ret))
 				assert(0 &&
@@ -2670,15 +2897,22 @@ static void rxr_ep_progress_internal(struct rxr_ep *ep)
 			return;
 		}
 
-		if (cq_entry.flags & FI_SEND) {
+		if (OFI_UNLIKELY(ret == 0))
+			return;
+
+		if (is_shm_cq && (cq_entry.flags & FI_REMOTE_CQ_DATA)) {
+			rxr_cq_handle_shm_rma_write_data(ep, &cq_entry, src_addr);
+		} else if (cq_entry.flags & (FI_SEND | FI_READ | FI_WRITE)) {
 #if ENABLE_DEBUG
-			ep->send_comps++;
+			if (!is_shm_cq)
+				ep->send_comps++;
 #endif
 			rxr_cq_handle_pkt_send_completion(ep, &cq_entry);
-		} else if (cq_entry.flags & FI_RECV) {
+		} else if (cq_entry.flags & (FI_RECV | FI_REMOTE_CQ_DATA)) {
 			rxr_cq_handle_pkt_recv_completion(ep, &cq_entry, src_addr);
 #if ENABLE_DEBUG
-			ep->recv_comps++;
+			if (!is_shm_cq)
+				ep->recv_comps++;
 #endif
 		} else {
 			FI_WARN(&rxr_prov, FI_LOG_EP_CTRL,
@@ -2686,6 +2920,23 @@ static void rxr_ep_progress_internal(struct rxr_ep *ep)
 			assert(0 && "Unhandled cq type");
 		}
 	}
+}
+
+void rxr_ep_progress_internal(struct rxr_ep *ep)
+{
+	struct rxr_rx_entry *rx_entry;
+	struct rxr_tx_entry *tx_entry;
+	struct dlist_entry *tmp;
+	ssize_t ret;
+
+	rxr_ep_check_available_data_bufs_timer(ep);
+
+	// Poll the EFA completion queue
+	rxr_ep_poll_cq(ep, ep->rdm_cq, rxr_env.efa_cq_read_size, 0);
+
+	// Poll the SHM completion queue if enabled
+	if (rxr_env.enable_shm_transfer)
+		rxr_ep_poll_cq(ep, ep->shm_cq, rxr_env.shm_cq_read_size, 1);
 
 	ret = rxr_ep_bulk_post_recv(ep);
 
@@ -2700,14 +2951,17 @@ static void rxr_ep_progress_internal(struct rxr_ep *ep)
 
 	/*
 	 * Send any queued RTS/CTS packets.
+	 * Send any queued large message RMA Read and EOR for shm
 	 */
 	dlist_foreach_container_safe(&ep->rx_entry_queued_list,
 				     struct rxr_rx_entry,
 				     rx_entry, queued_entry, tmp) {
-		if (rx_entry->state == RXR_RX_QUEUED_CTS)
-			ret = rxr_cq_post_cts(ep, rx_entry,
-					      rx_entry->total_len -
-					      rx_entry->bytes_done);
+		if (rx_entry->state == RXR_RX_QUEUED_CTRL)
+			ret = rxr_ep_post_ctrl(ep, RXR_RX_ENTRY, rx_entry,
+					       rx_entry->queued_ctrl.type,
+					       rx_entry->queued_ctrl.inject);
+		else if (rx_entry->state == RXR_RX_QUEUED_SHM_LARGE_READ)
+			ret = rxr_cq_recv_shm_large_message(ep, rx_entry);
 		else
 			ret = rxr_ep_send_queued_pkts(ep,
 						      &rx_entry->queued_pkts);
@@ -2723,10 +2977,12 @@ static void rxr_ep_progress_internal(struct rxr_ep *ep)
 	dlist_foreach_container_safe(&ep->tx_entry_queued_list,
 				     struct rxr_tx_entry,
 				     tx_entry, queued_entry, tmp) {
-		if (tx_entry->state == RXR_TX_QUEUED_RTS)
-			ret = rxr_ep_post_rts(ep, tx_entry);
-		else if (tx_entry->state == RXR_TX_QUEUED_READRSP)
-			ret = rxr_ep_post_readrsp(ep, tx_entry);
+		if (tx_entry->state == RXR_TX_QUEUED_CTRL)
+			ret = rxr_ep_post_ctrl(ep, RXR_TX_ENTRY, tx_entry,
+					       tx_entry->queued_ctrl.type,
+					       tx_entry->queued_ctrl.inject);
+		else if (tx_entry->state == RXR_TX_QUEUED_SHM_RMA)
+			ret = rxr_rma_post_shm_rma(ep, tx_entry);
 		else
 			ret = rxr_ep_send_queued_pkts(ep,
 						      &tx_entry->queued_pkts);
@@ -2738,17 +2994,11 @@ static void rxr_ep_progress_internal(struct rxr_ep *ep)
 
 		dlist_remove(&tx_entry->queued_entry);
 
-		if (tx_entry->state == RXR_TX_QUEUED_RTS ||
-		    tx_entry->state == RXR_TX_QUEUED_RTS_RNR) {
+		if (tx_entry->state == RXR_TX_QUEUED_RTS_RNR)
 			tx_entry->state = RXR_TX_RTS;
-		} else if (tx_entry->state == RXR_TX_QUEUED_READRSP) {
-			tx_entry->state = RXR_TX_SENT_READRSP;
-			if (tx_entry->bytes_sent < tx_entry->total_len) {
-				tx_entry->state = RXR_TX_SEND;
-				dlist_insert_tail(&tx_entry->entry,
-						  &ep->tx_pending_list);
-			}
-		} else if (tx_entry->state == RXR_TX_QUEUED_DATA_RNR) {
+		else if (tx_entry->state == RXR_TX_QUEUED_SHM_RMA)
+			tx_entry->state = RXR_TX_SHM_RMA;
+		else if (tx_entry->state == RXR_TX_QUEUED_DATA_RNR) {
 			tx_entry->state = RXR_TX_SEND;
 			dlist_insert_tail(&tx_entry->entry,
 					  &ep->tx_pending_list);
@@ -2824,7 +3074,7 @@ int rxr_endpoint(struct fid_domain *domain, struct fi_info *info,
 	rxr_domain = container_of(domain, struct rxr_domain,
 				  util_domain.domain_fid);
 	memset(&cq_attr, 0, sizeof(cq_attr));
-	cq_attr.format = FI_CQ_FORMAT_MSG;
+	cq_attr.format = FI_CQ_FORMAT_DATA;
 	cq_attr.wait_obj = FI_WAIT_NONE;
 
 	ret = ofi_endpoint_init(domain, &rxr_util_prov, info, &rxr_ep->util_ep,
@@ -2843,7 +3093,16 @@ int rxr_endpoint(struct fid_domain *domain, struct fi_info *info,
 	ret = fi_endpoint(rxr_domain->rdm_domain, rdm_info,
 			  &rxr_ep->rdm_ep, rxr_ep);
 	if (ret)
-		goto err_close_ofi_ep;
+		goto err_free_rdm_info;
+
+	/* Open shm provider's endpoint */
+	if (rxr_env.enable_shm_transfer) {
+		assert(!strcmp(shm_info->fabric_attr->name, "shm"));
+		ret = fi_endpoint(rxr_domain->shm_domain, shm_info,
+				  &rxr_ep->shm_ep, rxr_ep);
+		if (ret)
+			goto err_close_core_ep;
+	}
 
 	rxr_ep->rx_size = info->rx_attr->size;
 	rxr_ep->tx_size = info->tx_attr->size;
@@ -2890,26 +3149,39 @@ int rxr_endpoint(struct fid_domain *domain, struct fi_info *info,
 	rxr_ep->recv_comps = 0;
 #endif
 
-	rxr_ep->posted_bufs = 0;
-	rxr_ep->rx_bufs_to_post = 0;
+	rxr_ep->posted_bufs_shm = 0;
+	rxr_ep->rx_bufs_shm_to_post = 0;
+	rxr_ep->posted_bufs_efa = 0;
+	rxr_ep->rx_bufs_efa_to_post = 0;
 	rxr_ep->tx_pending = 0;
 	rxr_ep->available_data_bufs_ts = 0;
 
-	fi_freeinfo(rdm_info);
-
 	ret = fi_cq_open(rxr_domain->rdm_domain, &cq_attr,
 			 &rxr_ep->rdm_cq, rxr_ep);
 	if (ret)
-		goto err_close_core_ep;
+		goto err_close_shm_ep;
 
 	ret = fi_ep_bind(rxr_ep->rdm_ep, &rxr_ep->rdm_cq->fid,
 			 FI_TRANSMIT | FI_RECV);
 	if (ret)
 		goto err_close_core_cq;
 
+	/* Bind ep with shm provider's cq */
+	if (rxr_env.enable_shm_transfer) {
+		ret = fi_cq_open(rxr_domain->shm_domain, &cq_attr,
+				 &rxr_ep->shm_cq, rxr_ep);
+		if (ret)
+			goto err_close_core_cq;
+
+		ret = fi_ep_bind(rxr_ep->shm_ep, &rxr_ep->shm_cq->fid,
+				 FI_TRANSMIT | FI_RECV);
+		if (ret)
+			goto err_close_shm_cq;
+	}
+
 	ret = rxr_ep_init(rxr_ep);
 	if (ret)
-		goto err_close_core_cq;
+		goto err_close_shm_cq;
 
 	*ep = &rxr_ep->util_ep.ep_fid;
 	(*ep)->msg = &rxr_ops_msg;
@@ -2920,16 +3192,32 @@ int rxr_endpoint(struct fid_domain *domain, struct fi_info *info,
 	(*ep)->cm = &rxr_ep_cm;
 	return 0;
 
+err_close_shm_cq:
+	if (rxr_env.enable_shm_transfer && rxr_ep->shm_cq) {
+		retv = fi_close(&rxr_ep->shm_cq->fid);
+		if (retv)
+			FI_WARN(&rxr_prov, FI_LOG_CQ, "Unable to close shm cq: %s\n",
+				fi_strerror(-retv));
+	}
 err_close_core_cq:
 	retv = fi_close(&rxr_ep->rdm_cq->fid);
 	if (retv)
 		FI_WARN(&rxr_prov, FI_LOG_CQ, "Unable to close cq: %s\n",
 			fi_strerror(-retv));
+err_close_shm_ep:
+	if (rxr_env.enable_shm_transfer && rxr_ep->shm_ep) {
+		retv = fi_close(&rxr_ep->shm_ep->fid);
+		if (retv)
+			FI_WARN(&rxr_prov, FI_LOG_EP_CTRL, "Unable to close shm EP: %s\n",
+				fi_strerror(-retv));
+	}
 err_close_core_ep:
 	retv = fi_close(&rxr_ep->rdm_ep->fid);
 	if (retv)
 		FI_WARN(&rxr_prov, FI_LOG_EP_CTRL, "Unable to close EP: %s\n",
 			fi_strerror(-retv));
+err_free_rdm_info:
+	fi_freeinfo(rdm_info);
 err_close_ofi_ep:
 	retv = ofi_endpoint_close(&rxr_ep->util_ep);
 	if (retv)
diff --git a/prov/efa/src/rxr/rxr_fabric.c b/prov/efa/src/rxr/rxr_fabric.c
index 0a33227..163c525 100644
--- a/prov/efa/src/rxr/rxr_fabric.c
+++ b/prov/efa/src/rxr/rxr_fabric.c
@@ -64,6 +64,12 @@ static int rxr_fabric_close(fid_t fid)
 	if (ret)
 		return ret;
 
+	if (rxr_env.enable_shm_transfer) {
+		ret = fi_close(&rxr_fabric->shm_fabric->fid);
+		if (ret)
+			return ret;
+	}
+
 	ret = ofi_fabric_close(&rxr_fabric->util_fabric);
 	if (ret)
 		return ret;
@@ -122,7 +128,17 @@ int rxr_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
 	ret = lower_efa_prov->fabric(rdm_info->fabric_attr,
 				     &rxr_fabric->lower_fabric, context);
 	if (ret)
-		goto err_free_info;
+		goto err_free_rdm_info;
+
+	/* Open shm provider's fabric domain */
+	if (rxr_env.enable_shm_transfer) {
+		assert(!strcmp(shm_info->fabric_attr->name, "shm"));
+		ret = fi_fabric(shm_info->fabric_attr,
+				       &rxr_fabric->shm_fabric, context);
+		if (ret)
+			goto err_close_rdm_fabric;
+	}
+
 
 #ifdef RXR_PERF_ENABLED
 	ret = ofi_perfset_create(&rxr_prov, &rxr_fabric->perf_set,
@@ -142,7 +158,14 @@ int rxr_fabric(struct fi_fabric_attr *attr, struct fid_fabric **fabric,
 	free(hints.fabric_attr);
 	fi_freeinfo(rdm_info);
 	return 0;
-err_free_info:
+
+err_close_rdm_fabric:
+	retv = fi_close(&rxr_fabric->lower_fabric->fid);
+	if (retv)
+		FI_WARN(&rxr_prov, FI_LOG_FABRIC,
+			"Unable to close lower rdm fabric: %s\n",
+			fi_strerror(-retv));
+err_free_rdm_info:
 	fi_freeinfo(rdm_info);
 err_free_hints:
 	free(hints.fabric_attr);
diff --git a/prov/efa/src/rxr/rxr_init.c b/prov/efa/src/rxr/rxr_init.c
index c06e952..d0124ad 100644
--- a/prov/efa/src/rxr/rxr_init.c
+++ b/prov/efa/src/rxr/rxr_init.c
@@ -37,7 +37,11 @@
 #include "rxr.h"
 #include "efa.h"
 
+struct fi_info *shm_info;
+
 struct fi_provider *lower_efa_prov;
+struct efa_ep_addr *local_efa_addr;
+
 
 struct rxr_env rxr_env = {
 	.rx_window_size	= RXR_DEF_MAX_RX_WINDOW,
@@ -45,6 +49,9 @@ struct rxr_env rxr_env = {
 	.tx_min_credits = RXR_DEF_MIN_TX_CREDITS,
 	.tx_queue_size = 0,
 	.enable_sas_ordering = 1,
+	.enable_shm_transfer = 1,
+	.shm_av_size = 128,
+	.shm_max_medium_size = 4096,
 	.recvwin_size = RXR_RECVWIN_SIZE,
 	.cq_size = RXR_DEF_CQ_SIZE,
 	.max_memcpy_size = 4096,
@@ -57,6 +64,8 @@ struct rxr_env rxr_env = {
 	.rx_copy_ooo = 1,
 	.max_timeout = RXR_DEF_RNR_MAX_TIMEOUT,
 	.timeout_interval = 0, /* 0 is random timeout */
+	.efa_cq_read_size = 50,
+	.shm_cq_read_size = 50,
 };
 
 static void rxr_init_env(void)
@@ -66,6 +75,9 @@ static void rxr_init_env(void)
 	fi_param_get_int(&rxr_prov, "tx_min_credits", &rxr_env.tx_min_credits);
 	fi_param_get_int(&rxr_prov, "tx_queue_size", &rxr_env.tx_queue_size);
 	fi_param_get_int(&rxr_prov, "enable_sas_ordering", &rxr_env.enable_sas_ordering);
+	fi_param_get_int(&rxr_prov, "enable_shm_transfer", &rxr_env.enable_shm_transfer);
+	fi_param_get_int(&rxr_prov, "shm_av_size", &rxr_env.shm_av_size);
+	fi_param_get_int(&rxr_prov, "shm_max_medium_size", &rxr_env.shm_max_medium_size);
 	fi_param_get_int(&rxr_prov, "recvwin_size", &rxr_env.recvwin_size);
 	fi_param_get_int(&rxr_prov, "cq_size", &rxr_env.cq_size);
 	fi_param_get_size_t(&rxr_prov, "max_memcpy_size",
@@ -91,6 +103,41 @@ static void rxr_init_env(void)
 	fi_param_get_int(&rxr_prov, "max_timeout", &rxr_env.max_timeout);
 	fi_param_get_int(&rxr_prov, "timeout_interval",
 			 &rxr_env.timeout_interval);
+	fi_param_get_size_t(&rxr_prov, "efa_cq_read_size",
+			 &rxr_env.efa_cq_read_size);
+	fi_param_get_size_t(&rxr_prov, "shm_cq_read_size",
+			 &rxr_env.shm_cq_read_size);
+}
+
+/*
+ * Stringify the void *addr to a string smr_name formatted as `gid_qpn`, which
+ * will be used to insert into shm provider's AV. Then shm uses smr_name as
+ * ep_name to create the shared memory region.
+ *
+ * The IPv6 address length is 46, but the max supported name length for shm is 32.
+ * The string `gid_qpn` could be truncated during snprintf.
+ * The current way works because the IPv6 addresses starting with FE in hexadecimals represent
+ * link local IPv6 addresses, which has reserved first 64 bits (FE80::/64).
+ * e.g., fe80:0000:0000:0000:0436:29ff:fe8e:ceaa -> fe80::436:29ff:fe8e:ceaa
+ * And the length of string `gid_qpn` (fe80::436:29ff:fe8e:ceaa_***) will not exceed 32.
+ * If the address is NOT link local, we need to think another reasonable way to
+ * generate the string.
+ */
+int rxr_ep_efa_addr_to_str(const void *addr, char *smr_name)
+{
+	char gid[INET6_ADDRSTRLEN] = { 0 };
+	uint16_t qpn;
+	int ret;
+
+	if (!inet_ntop(AF_INET6, ((struct efa_ep_addr *)addr)->raw, gid, INET6_ADDRSTRLEN)) {
+		printf("Failed to get current EFA's GID, errno: %d\n", errno);
+		return 0;
+	}
+	qpn = ((struct efa_ep_addr *)addr)->qpn;
+
+	ret = snprintf(smr_name, NAME_MAX, "/%ld_%s_%d", (size_t) getuid(), gid, qpn);
+
+	return (ret <= 0) ? ret : FI_SUCCESS;
 }
 
 void rxr_info_to_core_mr_modes(uint32_t version,
@@ -182,6 +229,22 @@ static int rxr_info_to_core(uint32_t version, const struct fi_info *rxr_info,
 	return ret;
 }
 
+/* Explicitly set all necessary bits before calling shm provider's getinfo function */
+void rxr_set_shm_hints(struct fi_info *shm_hints)
+{
+	shm_hints->caps = FI_MSG | FI_TAGGED | FI_RECV | FI_SEND | FI_READ
+			   | FI_WRITE | FI_REMOTE_READ | FI_REMOTE_WRITE
+			   | FI_MULTI_RECV | FI_RMA;
+	shm_hints->domain_attr->av_type = FI_AV_TABLE;
+	shm_hints->domain_attr->mr_mode = FI_MR_VIRT_ADDR;
+	shm_hints->domain_attr->caps |= FI_LOCAL_COMM;
+	shm_hints->tx_attr->msg_order = FI_ORDER_SAS;
+	shm_hints->rx_attr->msg_order = FI_ORDER_SAS;
+	shm_hints->fabric_attr->name = strdup("shm");
+	shm_hints->fabric_attr->prov_name = strdup("shm");
+	shm_hints->ep_attr->type = FI_EP_RDM;
+}
+
 /* Pass tx/rx attr that user specifies down to core provider */
 void rxr_reset_rx_tx_to_core(const struct fi_info *user_info,
 			     struct fi_info *core_info)
@@ -309,6 +372,49 @@ int rxr_get_lower_rdm_info(uint32_t version, const char *node,
 	return ret;
 }
 
+/*
+ * Call getinfo on lower efa provider to get all locally qualified fi_info
+ * structure, then store the corresponding efa nic GIDs
+ */
+int rxr_get_local_gids(struct fi_provider *lower_efa_prov)
+{
+	struct fi_info *core_info, *cur;
+	struct efa_ep_addr *cur_efa_addr;
+	int ret;
+
+	cur_efa_addr = local_efa_addr = NULL;
+	core_info = cur = NULL;
+
+	ret = lower_efa_prov->getinfo(rxr_prov.fi_version, NULL, NULL, 0, NULL, &core_info);
+	if (ret)
+		return ret;
+
+	local_efa_addr = (struct efa_ep_addr *)malloc(sizeof(struct efa_ep_addr));
+	if (!local_efa_addr) {
+		ret = -FI_ENOMEM;
+		goto out;
+	}
+	local_efa_addr->next = NULL;
+
+	cur_efa_addr = local_efa_addr;
+	for (cur = core_info; cur; cur = cur->next) {
+		memcpy(cur_efa_addr->raw, ((struct efa_ep_addr *)cur->src_addr)->raw, 16);
+		if (cur->next) {
+			cur_efa_addr->next = (struct efa_ep_addr *)malloc(sizeof(struct efa_ep_addr));
+			if (!cur_efa_addr->next) {
+				ret = -FI_ENOMEM;
+				goto out;
+			}
+			cur_efa_addr = cur_efa_addr->next;
+			cur_efa_addr->next = NULL;
+		}
+	}
+
+out:
+	fi_freeinfo(core_info);
+	return ret;
+}
+
 static int rxr_dgram_getinfo(uint32_t version, const char *node,
 			     const char *service, uint64_t flags,
 			     const struct fi_info *hints, struct fi_info **info,
@@ -360,6 +466,7 @@ static int rxr_getinfo(uint32_t version, const char *node,
 		       const struct fi_info *hints, struct fi_info **info)
 {
 	struct fi_info *core_info, *util_info, *cur, *tail;
+	struct fi_info *shm_hints;
 	int ret;
 
 	*info = tail = core_info = NULL;
@@ -410,6 +517,26 @@ dgram_info:
 	 */
 	if (ret == -FI_ENODATA && *info)
 		ret = 0;
+
+	if (rxr_env.enable_shm_transfer && !shm_info) {
+		shm_info = fi_allocinfo();
+		shm_hints = fi_allocinfo();
+		rxr_set_shm_hints(shm_hints);
+		ret = fi_getinfo(FI_VERSION(1, 8), NULL, NULL, 0, shm_hints, &shm_info);
+		fi_freeinfo(shm_hints);
+		if (ret) {
+			FI_WARN(&rxr_prov, FI_LOG_CORE, "Failed to get shm provider's info.\n");
+			goto out;
+		}
+		assert(!strcmp(shm_info->fabric_attr->name, "shm"));
+		if (shm_info->ep_attr->max_msg_size != SIZE_MAX) {
+			fprintf(stderr, "SHM transfer will be disabled because of ptrace protection.\n"
+				"To enable SHM transfer, please refer to the man page fi_efa.7 for more information.\n"
+				"Also note that turning off ptrace protection has security implications. If you cannot\n"
+				"turn it off, you can suppress this message by setting FI_EFA_ENABLE_SHM_TRANSFER=0\n");
+			rxr_env.enable_shm_transfer = 0;
+		}
+	}
 out:
 	fi_freeinfo(core_info);
 	return ret;
@@ -417,8 +544,26 @@ out:
 
 static void rxr_fini(void)
 {
+	struct efa_ep_addr *cur;
+
 	if (lower_efa_prov)
 		lower_efa_prov->cleanup();
+
+	if (rxr_env.enable_shm_transfer) {
+		/* Cleanup all local efa nic GIDs */
+		while (local_efa_addr) {
+			cur = local_efa_addr;
+			local_efa_addr = local_efa_addr->next;
+			free(cur);
+		}
+		if (shm_info)
+			fi_freeinfo(shm_info);
+	}
+
+#if HAVE_EFA_DL
+	ofi_monitor_cleanup();
+	ofi_mem_fini();
+#endif
 }
 
 struct fi_provider rxr_prov = {
@@ -442,6 +587,12 @@ EFA_INI
 			"Defines the maximum number of unacknowledged sends with the NIC.");
 	fi_param_define(&rxr_prov, "enable_sas_ordering", FI_PARAM_INT,
 			"Enable packet reordering for the RDM endpoint. This is always enabled when FI_ORDER_SAS is requested by the application. (Default: 1)");
+	fi_param_define(&rxr_prov, "enable_shm_transfer", FI_PARAM_INT,
+			"Enable using SHM provider to provide the communication between processes on the same system. (Default: 1)");
+	fi_param_define(&rxr_prov, "shm_av_size", FI_PARAM_INT,
+			"Defines the maximum number of entries in SHM provider's address vector (Default 128).");
+	fi_param_define(&rxr_prov, "shm_max_medium_size", FI_PARAM_INT,
+			"Defines the switch point between small/medium message and large message. The message larger than this switch point will be transferred with large message protocol (Default 4096).");
 	fi_param_define(&rxr_prov, "recvwin_size", FI_PARAM_INT,
 			"Defines the size of sliding receive window. (Default: 16384)");
 	fi_param_define(&rxr_prov, "cq_size", FI_PARAM_INT,
@@ -450,21 +601,21 @@ EFA_INI
 			"Enables using the mr cache and in-line registration instead of a bounce buffer for iov's larger than max_memcpy_size. Defaults to true. When disabled, only uses a bounce buffer.");
 	fi_param_define(&rxr_prov, "mr_cache_merge_regions", FI_PARAM_BOOL,
 			"Enables merging overlapping and adjacent memory registration regions. Defaults to true.");
-	fi_param_define(&rxr_prov, "mr_max_cached_count", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "mr_max_cached_count", FI_PARAM_SIZE_T,
 			"Sets the maximum number of memory registrations that can be cached at any time.");
-	fi_param_define(&rxr_prov, "mr_max_cached_size", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "mr_max_cached_size", FI_PARAM_SIZE_T,
 			"Sets the maximum amount of memory that cached memory registrations can hold onto at any time.");
-	fi_param_define(&rxr_prov, "max_memcpy_size", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "max_memcpy_size", FI_PARAM_SIZE_T,
 			"Threshold size switch between using memory copy into a pre-registered bounce buffer and memory registration on the user buffer. (Default: 4096)");
-	fi_param_define(&rxr_prov, "mtu_size", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "mtu_size", FI_PARAM_SIZE_T,
 			"Override the MTU size of the device.");
-	fi_param_define(&rxr_prov, "tx_size", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "tx_size", FI_PARAM_SIZE_T,
 			"Set the maximum number of transmit operations before the provider returns -FI_EAGAIN. For only the RDM endpoint, this parameter will cause transmit operations to be queued when this value is set higher than the default and the transmit queue is full.");
-	fi_param_define(&rxr_prov, "rx_size", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "rx_size", FI_PARAM_SIZE_T,
 			"Set the maximum number of receive operations before the provider returns -FI_EAGAIN.");
-	fi_param_define(&rxr_prov, "tx_iov_limit", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "tx_iov_limit", FI_PARAM_SIZE_T,
 			"Maximum transmit iov_limit.");
-	fi_param_define(&rxr_prov, "rx_iov_limit", FI_PARAM_INT,
+	fi_param_define(&rxr_prov, "rx_iov_limit", FI_PARAM_SIZE_T,
 			"Maximum receive iov_limit.");
 	fi_param_define(&rxr_prov, "rx_copy_unexp", FI_PARAM_BOOL,
 			"Enables the use of a separate pool of bounce-buffers to copy unexpected messages out of the pre-posted receive buffers. (Default: 1)");
@@ -474,11 +625,23 @@ EFA_INI
 			"Set the maximum timeout (us) for backoff to a peer after a receiver not ready error. (Default: 1000000)");
 	fi_param_define(&rxr_prov, "timeout_interval", FI_PARAM_INT,
 			"Set the time interval (us) for the base timeout to use for exponential backoff to a peer after a receiver not ready error. (Default: 0 [random])");
+	fi_param_define(&rxr_prov, "efa_cq_read_size", FI_PARAM_SIZE_T,
+			"Set the number of EFA completion entries to read for one loop for one iteration of the progress engine. (Default: 50)");
+	fi_param_define(&rxr_prov, "shm_cq_read_size", FI_PARAM_SIZE_T,
+			"Set the number of SHM completion entries to read for one loop for one iteration of the progress engine. (Default: 50)");
 	rxr_init_env();
 
+#if HAVE_EFA_DL
+	ofi_mem_init();
+	ofi_monitor_init();
+#endif
+
 	lower_efa_prov = init_lower_efa_prov();
 	if (!lower_efa_prov)
 		return NULL;
 
+	if (rxr_env.enable_shm_transfer && rxr_get_local_gids(lower_efa_prov))
+		return NULL;
+
 	return &rxr_prov;
 }
diff --git a/prov/efa/src/rxr/rxr_rma.c b/prov/efa/src/rxr/rxr_rma.c
index d02032d..a41db00 100644
--- a/prov/efa/src/rxr/rxr_rma.c
+++ b/prov/efa/src/rxr/rxr_rma.c
@@ -35,9 +35,37 @@
 #include <string.h>
 #include <ofi_mem.h>
 #include <ofi_iov.h>
+#include "efa.h"
 #include "rxr.h"
 #include "rxr_rma.h"
 
+char *rxr_rma_init_rts_hdr(struct rxr_ep *ep,
+			   struct rxr_tx_entry *tx_entry,
+			   struct rxr_pkt_entry *pkt_entry,
+			   char *hdr)
+{
+	int rmalen;
+	struct rxr_rts_hdr *rts_hdr;
+
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+	rts_hdr->rma_iov_count = 0;
+	assert (tx_entry->cq_entry.flags & FI_RMA);
+	if (tx_entry->op == ofi_op_write) {
+		rts_hdr->flags |= RXR_WRITE;
+	} else {
+		assert(tx_entry->op == ofi_op_read_req);
+		rts_hdr->flags |= RXR_READ_REQ;
+	}
+
+	rmalen = tx_entry->rma_iov_count * sizeof(struct fi_rma_iov);
+	rts_hdr->rma_iov_count = tx_entry->rma_iov_count;
+	memcpy(hdr, tx_entry->rma_iov, rmalen);
+	hdr += rmalen;
+	pkt_entry->pkt_size += rmalen;
+
+	return hdr;
+}
+
 int rxr_rma_verified_copy_iov(struct rxr_ep *ep, struct fi_rma_iov *rma,
 			      size_t count, uint32_t flags, struct iovec *iov)
 {
@@ -65,13 +93,156 @@ int rxr_rma_verified_copy_iov(struct rxr_ep *ep, struct fi_rma_iov *rma,
 	return 0;
 }
 
+char *rxr_rma_read_rts_hdr(struct rxr_ep *ep,
+			   struct rxr_rx_entry *rx_entry,
+			   struct rxr_pkt_entry *pkt_entry,
+			   char *rma_hdr)
+{
+	uint32_t rma_access;
+	struct fi_rma_iov *rma_iov = NULL;
+	struct rxr_rts_hdr *rts_hdr;
+	int ret;
+
+	rma_iov = (struct fi_rma_iov *)rma_hdr;
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+	if (rts_hdr->flags & RXR_READ_REQ) {
+		rma_access = FI_SEND;
+		rx_entry->cq_entry.flags |= (FI_RMA | FI_READ);
+	} else {
+		assert(rts_hdr->flags & RXR_WRITE);
+		rma_access = FI_RECV;
+		rx_entry->cq_entry.flags |= (FI_RMA | FI_WRITE);
+	}
+
+	assert(rx_entry->iov_count == 0);
+
+	rx_entry->iov_count = rts_hdr->rma_iov_count;
+	ret = rxr_rma_verified_copy_iov(ep, rma_iov, rts_hdr->rma_iov_count,
+					rma_access, rx_entry->iov);
+	if (ret) {
+		FI_WARN(&rxr_prov, FI_LOG_CQ, "RMA address verify failed!\n");
+		rxr_cq_handle_cq_error(ep, -FI_EIO);
+	}
+
+	rx_entry->cq_entry.len = ofi_total_iov_len(&rx_entry->iov[0],
+						   rx_entry->iov_count);
+	rx_entry->cq_entry.buf = rx_entry->iov[0].iov_base;
+	return rma_hdr + rts_hdr->rma_iov_count * sizeof(struct fi_rma_iov);
+}
+
+int rxr_rma_proc_write_rts(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_rx_entry *rx_entry;
+	struct rxr_rts_hdr *rts_hdr;
+	uint64_t tag = ~0;
+	char *rma_hdr;
+	char *data;
+	size_t data_size;
+
+	/*
+	 * rma is one sided operation, match is not expected
+	 * we need to create a rx entry upon receiving a rts
+	 */
+	rx_entry = rxr_ep_get_rx_entry(ep, NULL, 0, tag, 0, NULL, pkt_entry->addr, ofi_op_write, 0);
+	if (OFI_UNLIKELY(!rx_entry)) {
+		FI_WARN(&rxr_prov, FI_LOG_CQ,
+			"RX entries exhausted.\n");
+		rxr_eq_write_error(ep, FI_ENOBUFS, -FI_ENOBUFS);
+		return -FI_ENOBUFS;
+	}
+
+	rx_entry->bytes_done = 0;
+
+	rts_hdr = rxr_get_rts_hdr(pkt_entry->pkt);
+	rma_hdr = rxr_cq_read_rts_hdr(ep, rx_entry, pkt_entry);
+	data = rxr_rma_read_rts_hdr(ep, rx_entry, pkt_entry, rma_hdr);
+	data_size = rxr_get_rts_data_size(ep, rts_hdr);
+	return rxr_cq_handle_rts_with_data(ep, rx_entry,
+					   pkt_entry, data,
+					   data_size);
+}
+
+int rxr_rma_init_read_rts(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
+			  struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_rma_read_info *read_info;
+	char *hdr;
+
+	hdr = rxr_ep_init_rts_hdr(ep, tx_entry, pkt_entry);
+	hdr = rxr_rma_init_rts_hdr(ep, tx_entry, pkt_entry, hdr);
+
+	/* no data to send, but need to send rx_id and window */
+	read_info = (struct rxr_rma_read_info *)hdr;
+	read_info->rma_initiator_rx_id = tx_entry->rma_loc_rx_id;
+	read_info->window = tx_entry->rma_window;
+	hdr += sizeof(struct rxr_rma_read_info);
+	pkt_entry->pkt_size += sizeof(struct rxr_rma_read_info);
+
+	assert(pkt_entry->pkt_size <= ep->mtu_size);
+	pkt_entry->addr = tx_entry->addr;
+	pkt_entry->x_entry = (void *)tx_entry;
+	return 0;
+}
+
+int rxr_rma_proc_read_rts(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_rx_entry *rx_entry;
+	struct rxr_tx_entry *tx_entry;
+	uint64_t tag = ~0;
+	int err = 0;
+	char *hdr;
+	struct rxr_rma_read_info *read_info;
+	/*
+	 * rma is one sided operation, match is not expected
+	 * we need to create a rx entry upon receiving a rts
+	 */
+	rx_entry = rxr_ep_get_rx_entry(ep, NULL, 0, tag, 0, NULL, pkt_entry->addr, ofi_op_read_rsp, 0);
+	if (OFI_UNLIKELY(!rx_entry)) {
+		FI_WARN(&rxr_prov, FI_LOG_CQ,
+			"RX entries exhausted.\n");
+		rxr_eq_write_error(ep, FI_ENOBUFS, -FI_ENOBUFS);
+		return -FI_ENOBUFS;
+	}
+
+	rx_entry->bytes_done = 0;
+
+	hdr = (char *)rxr_cq_read_rts_hdr(ep, rx_entry, pkt_entry);
+	hdr = (char *)rxr_rma_read_rts_hdr(ep, rx_entry, pkt_entry, hdr);
+	read_info = (struct rxr_rma_read_info *)hdr;
+
+	rx_entry->rma_initiator_rx_id = read_info->rma_initiator_rx_id;
+	rx_entry->window = read_info->window;
+	assert(rx_entry->window > 0);
+
+	tx_entry = rxr_rma_alloc_readrsp_tx_entry(ep, rx_entry);
+	assert(tx_entry);
+	/* the only difference between a read response packet and
+	 * a data packet is that read response packet has remote EP tx_id
+	 * which initiator EP rx_entry need to send CTS back
+	 */
+	err = rxr_ep_post_ctrl_or_queue(ep, RXR_TX_ENTRY, tx_entry, RXR_READRSP_PKT, 0);
+	if (OFI_UNLIKELY(err)) {
+		if (rxr_cq_handle_tx_error(ep, tx_entry, err))
+			assert(0 && "failed to write err cq entry");
+		rxr_release_tx_entry(ep, tx_entry);
+		rxr_release_rx_entry(ep, rx_entry);
+	} else {
+		rx_entry->state = RXR_RX_WAIT_READ_FINISH;
+	}
+
+	rxr_release_rx_pkt_entry(ep, pkt_entry);
+	return err;
+}
+
 /* Upon receiving a read request, Remote EP call this function to create
  * a tx entry for sending data back.
  */
-struct rxr_tx_entry *rxr_readrsp_tx_entry_init(struct rxr_ep *rxr_ep,
-					       struct rxr_rx_entry *rx_entry)
+struct rxr_tx_entry *
+rxr_rma_alloc_readrsp_tx_entry(struct rxr_ep *rxr_ep,
+			       struct rxr_rx_entry *rx_entry)
 {
 	struct rxr_tx_entry *tx_entry;
+	struct fi_msg msg;
 
 	tx_entry = ofi_buf_alloc(rxr_ep->readrsp_tx_entry_pool);
 	if (OFI_UNLIKELY(!tx_entry)) {
@@ -84,13 +255,18 @@ struct rxr_tx_entry *rxr_readrsp_tx_entry_init(struct rxr_ep *rxr_ep,
 	dlist_insert_tail(&tx_entry->tx_entry_entry, &rxr_ep->tx_entry_list);
 #endif
 
+	msg.msg_iov = rx_entry->iov;
+	msg.iov_count = rx_entry->iov_count;
+	msg.addr = rx_entry->addr;
+	msg.desc = NULL;
+	msg.context = NULL;
+	msg.data = 0;
+
 	/*
 	 * this tx_entry works similar to a send tx_entry thus its op was
 	 * set to ofi_op_msg. Note this tx_entry will not write a completion
 	 */
-	rxr_generic_tx_entry_init(rxr_ep, tx_entry, rx_entry->iov,
-				  rx_entry->iov_count, NULL, 0, rx_entry->addr,
-				  0, 0, NULL, ofi_op_msg, 0);
+	rxr_tx_entry_init(rxr_ep, tx_entry, &msg, ofi_op_msg, 0);
 
 	tx_entry->cq_entry.flags |= FI_READ;
 	/* rma_loc_rx_id is for later retrieve of rx_entry
@@ -109,33 +285,304 @@ struct rxr_tx_entry *rxr_readrsp_tx_entry_init(struct rxr_ep *rxr_ep,
 	return tx_entry;
 }
 
-ssize_t rxr_generic_rma(struct fid_ep *ep,
-			const struct iovec *iov, size_t iov_count,
-			const struct fi_rma_iov *rma_iov, size_t rma_iov_count,
-			fi_addr_t addr, uint64_t data, void *context, uint32_t op,
-			uint64_t flags)
+int rxr_rma_init_readrsp_pkt(struct rxr_ep *ep,
+			     struct rxr_tx_entry *tx_entry,
+			     struct rxr_pkt_entry *pkt_entry)
 {
-	assert(iov_count <= RXR_IOV_LIMIT && rma_iov_count <= RXR_IOV_LIMIT);
-	int tag = 0; // RMA is not tagged
+	struct rxr_readrsp_pkt *readrsp_pkt;
+	struct rxr_readrsp_hdr *readrsp_hdr;
+	size_t mtu = ep->mtu_size;
+
+	readrsp_pkt = (struct rxr_readrsp_pkt *)pkt_entry->pkt;
+	readrsp_hdr = &readrsp_pkt->hdr;
+	readrsp_hdr->type = RXR_READRSP_PKT;
+	readrsp_hdr->version = RXR_PROTOCOL_VERSION;
+	readrsp_hdr->flags = 0;
+	readrsp_hdr->tx_id = tx_entry->tx_id;
+	readrsp_hdr->rx_id = tx_entry->rx_id;
+	readrsp_hdr->seg_size = ofi_copy_from_iov(readrsp_pkt->data,
+						  mtu - RXR_READRSP_HDR_SIZE,
+						  tx_entry->iov,
+						  tx_entry->iov_count, 0);
+	pkt_entry->pkt_size = RXR_READRSP_HDR_SIZE + readrsp_hdr->seg_size;
+	pkt_entry->addr = tx_entry->addr;
+	pkt_entry->x_entry = tx_entry;
+	return 0;
+}
 
-	return rxr_tx(ep, iov, iov_count, rma_iov, rma_iov_count, addr,
-		      tag, data, context, op, flags);
+void rxr_rma_handle_readrsp_sent(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry)
+{
+	struct rxr_tx_entry *tx_entry;
+	size_t data_len;
+
+	tx_entry = (struct rxr_tx_entry *)pkt_entry->x_entry;
+	data_len = rxr_get_readrsp_hdr(pkt_entry->pkt)->seg_size;
+	tx_entry->state = RXR_TX_SENT_READRSP;
+	tx_entry->bytes_sent += data_len;
+	tx_entry->window -= data_len;
+	assert(tx_entry->window >= 0);
+	if (tx_entry->bytes_sent < tx_entry->total_len) {
+		if (efa_mr_cache_enable && rxr_ep_mr_local(ep))
+			rxr_inline_mr_reg(rxr_ep_domain(ep), tx_entry);
+
+		tx_entry->state = RXR_TX_SEND;
+		dlist_insert_tail(&tx_entry->entry,
+				  &ep->tx_pending_list);
+	}
 }
 
-ssize_t rxr_read(struct fid_ep *ep, void *buf, size_t len, void *desc,
-		 fi_addr_t src_addr, uint64_t addr, uint64_t key,
-		 void *context)
+/* EOR packet functions */
+int rxr_rma_init_eor_pkt(struct rxr_ep *ep, struct rxr_rx_entry *rx_entry, struct rxr_pkt_entry *pkt_entry)
 {
-	struct iovec iov;
+	struct rxr_eor_hdr *eor_hdr;
+
+	eor_hdr = (struct rxr_eor_hdr *)pkt_entry->pkt;
+	eor_hdr->type = RXR_EOR_PKT;
+	eor_hdr->version = RXR_PROTOCOL_VERSION;
+	eor_hdr->flags = 0;
+	eor_hdr->tx_id = rx_entry->tx_id;
+	eor_hdr->rx_id = rx_entry->rx_id;
+	pkt_entry->pkt_size = sizeof(struct rxr_eor_hdr);
+	pkt_entry->addr = rx_entry->addr;
+	pkt_entry->x_entry = rx_entry;
+	return 0;
+}
 
-	iov.iov_base = (void *)buf;
-	iov.iov_len = len;
-	return rxr_readv(ep, &iov, &desc, 1, src_addr, addr, key, context);
+void rxr_rma_handle_eor_sent(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry)
+{
+}
+
+struct rxr_tx_entry *
+rxr_rma_alloc_tx_entry(struct rxr_ep *rxr_ep,
+		       const struct fi_msg_rma *msg_rma,
+		       uint32_t op,
+		       uint64_t flags)
+{
+	struct rxr_tx_entry *tx_entry;
+	struct fi_msg msg;
+
+	tx_entry = ofi_buf_alloc(rxr_ep->tx_entry_pool);
+	if (OFI_UNLIKELY(!tx_entry)) {
+		FI_WARN(&rxr_prov, FI_LOG_EP_CTRL, "TX entries exhausted.\n");
+		return NULL;
+	}
+
+	msg.addr = msg_rma->addr;
+	msg.msg_iov = msg_rma->msg_iov;
+	msg.context = msg_rma->context;
+	msg.iov_count = msg_rma->iov_count;
+	msg.data = msg_rma->data;
+	msg.desc = msg_rma->desc;
+	rxr_tx_entry_init(rxr_ep, tx_entry, &msg, op, flags);
+
+	assert(msg_rma->rma_iov_count > 0);
+	assert(msg_rma->rma_iov);
+	tx_entry->rma_iov_count = msg_rma->rma_iov_count;
+	memcpy(tx_entry->rma_iov, msg_rma->rma_iov,
+	       sizeof(struct fi_rma_iov) * msg_rma->rma_iov_count);
+
+#if ENABLE_DEBUG
+	dlist_insert_tail(&tx_entry->tx_entry_entry, &rxr_ep->tx_entry_list);
+#endif
+	return tx_entry;
+}
+
+size_t rxr_rma_post_shm_rma(struct rxr_ep *rxr_ep, struct rxr_tx_entry *tx_entry)
+{
+	struct rxr_pkt_entry *pkt_entry;
+	struct fi_msg_rma msg;
+	struct rxr_rma_context_pkt *rma_context_pkt;
+	struct rxr_peer *peer;
+	fi_addr_t shm_fiaddr;
+	int ret;
+
+	tx_entry->state = RXR_TX_SHM_RMA;
+
+	peer = rxr_ep_get_peer(rxr_ep, tx_entry->addr);
+	shm_fiaddr = peer->shm_fiaddr;
+	pkt_entry = rxr_get_pkt_entry(rxr_ep, rxr_ep->tx_pkt_shm_pool);
+	if (OFI_UNLIKELY(!pkt_entry))
+		return -FI_EAGAIN;
+
+	pkt_entry->x_entry = (void *)tx_entry;
+	rma_context_pkt = (struct rxr_rma_context_pkt *)pkt_entry->pkt;
+	rma_context_pkt->type = RXR_RMA_CONTEXT_PKT;
+	rma_context_pkt->version = RXR_PROTOCOL_VERSION;
+	rma_context_pkt->tx_id = tx_entry->tx_id;
+
+	msg.msg_iov = tx_entry->iov;
+	msg.iov_count = tx_entry->iov_count;
+	msg.addr = shm_fiaddr;
+	msg.rma_iov = tx_entry->rma_iov;
+	msg.rma_iov_count = tx_entry->rma_iov_count;
+	msg.context = pkt_entry;
+
+	if (tx_entry->cq_entry.flags & FI_READ) {
+		rma_context_pkt->rma_context_type = RXR_SHM_RMA_READ;
+		msg.data = 0;
+		ret = fi_readmsg(rxr_ep->shm_ep, &msg, tx_entry->fi_flags);
+	} else {
+		rma_context_pkt->rma_context_type = RXR_SHM_RMA_WRITE;
+		msg.data = tx_entry->cq_entry.data;
+		ret = fi_writemsg(rxr_ep->shm_ep, &msg, tx_entry->fi_flags);
+	}
+
+	if (OFI_UNLIKELY(ret)) {
+		if (ret == -FI_EAGAIN) {
+			tx_entry->state = RXR_TX_QUEUED_SHM_RMA;
+			dlist_insert_tail(&tx_entry->queued_entry,
+					  &rxr_ep->tx_entry_queued_list);
+			return 0;
+		}
+		rxr_release_tx_entry(rxr_ep, tx_entry);
+	}
+
+	return ret;
+}
+
+/* rma_read functions */
+ssize_t rxr_rma_post_efa_read(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry)
+{
+	int err, window, credits;
+	struct rxr_peer *peer;
+	struct rxr_rx_entry *rx_entry;
+
+	/* create a rx_entry to receve data
+	 * use ofi_op_msg for its op.
+	 * it does not write a rx completion.
+	 */
+	rx_entry = rxr_ep_get_rx_entry(ep, tx_entry->iov,
+				       tx_entry->iov_count,
+				       0, ~0, NULL,
+				       tx_entry->addr, ofi_op_msg, 0);
+	if (!rx_entry) {
+		rxr_release_tx_entry(ep, tx_entry);
+		FI_WARN(&rxr_prov, FI_LOG_CQ,
+			"RX entries exhausted for read.\n");
+		rxr_ep_progress_internal(ep);
+		return -FI_EAGAIN;
+	}
+
+	/*
+	 * this rx_entry does not know its tx_id, because remote
+	 * tx_entry has not been created yet.
+	 * set tx_id to -1, and the correct one will be filled in
+	 * rxr_cq_handle_readrsp()
+	 */
+	assert(rx_entry);
+	rx_entry->tx_id = -1;
+	rx_entry->cq_entry.flags |= FI_READ;
+	rx_entry->total_len = rx_entry->cq_entry.len;
+
+	/*
+	 * there will not be a CTS for fi_read, we calculate CTS
+	 * window here, and send it via RTS.
+	 * meanwhile set rx_entry->state to RXR_RX_RECV so that
+	 * this rx_entry is ready to receive.
+	 */
+
+	/* But if there is no available buffer, we do not even proceed.
+	 * call rxr_ep_progress_internal() might release some buffer
+	 */
+	if (ep->available_data_bufs == 0) {
+		rxr_release_tx_entry(ep, tx_entry);
+		rxr_release_rx_entry(ep, rx_entry);
+		rxr_ep_progress_internal(ep);
+		return -FI_EAGAIN;
+	}
+
+	peer = rxr_ep_get_peer(ep, tx_entry->addr);
+	assert(peer);
+	rxr_ep_calc_cts_window_credits(ep, peer,
+				       tx_entry->total_len,
+				       tx_entry->credit_request,
+				       &window,
+				       &credits);
+
+	rx_entry->window = window;
+	rx_entry->credit_cts = credits;
+
+	rx_entry->state = RXR_RX_RECV;
+	/* rma_loc_tx_id is used in rxr_cq_handle_rx_completion()
+	 * to locate the tx_entry for tx completion.
+	 */
+	rx_entry->rma_loc_tx_id = tx_entry->tx_id;
+#if ENABLE_DEBUG
+	dlist_insert_tail(&rx_entry->rx_pending_entry,
+			  &ep->rx_pending_list);
+	ep->rx_pending++;
+#endif
+	/*
+	 * this tx_entry does not need a rx_id, because it does not
+	 * send any data.
+	 * the rma_loc_rx_id and rma_window will be sent to remote EP
+	 * via RTS
+	 */
+	tx_entry->rma_loc_rx_id = rx_entry->rx_id;
+	tx_entry->rma_window = rx_entry->window;
+	tx_entry->msg_id = (peer->next_msg_id != ~0) ?
+			    peer->next_msg_id++ : ++peer->next_msg_id;
+
+	err = rxr_ep_post_ctrl_or_queue(ep, RXR_TX_ENTRY, tx_entry, RXR_RTS_PKT, 0);
+	if (OFI_UNLIKELY(err)) {
+		rxr_release_tx_entry(ep, tx_entry);
+		peer->next_msg_id--;
+	}
+
+	return err;
 }
 
-ssize_t rxr_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
-		  size_t iov_count, fi_addr_t src_addr, uint64_t addr,
-		  uint64_t key, void *context)
+ssize_t rxr_rma_readmsg(struct fid_ep *ep, const struct fi_msg_rma *msg, uint64_t flags)
+{
+	ssize_t err;
+	struct rxr_ep *rxr_ep;
+	struct rxr_peer *peer;
+	struct rxr_tx_entry *tx_entry;
+
+	FI_DBG(&rxr_prov, FI_LOG_EP_DATA,
+	       "read iov_len: %lu flags: %lx\n",
+	       ofi_total_iov_len(msg->msg_iov, msg->iov_count),
+	       flags);
+
+	rxr_ep = container_of(ep, struct rxr_ep, util_ep.ep_fid.fid);
+
+	assert(msg->iov_count <= rxr_ep->tx_iov_limit);
+
+	rxr_perfset_start(rxr_ep, perf_rxr_tx);
+	fastlock_acquire(&rxr_ep->util_ep.lock);
+
+	if (OFI_UNLIKELY(is_tx_res_full(rxr_ep)))
+		return -FI_EAGAIN;
+
+	tx_entry = rxr_rma_alloc_tx_entry(rxr_ep, msg, ofi_op_read_req, flags);
+	if (OFI_UNLIKELY(!tx_entry)) {
+		rxr_ep_progress_internal(rxr_ep);
+		return -FI_EAGAIN;
+	}
+
+	peer = rxr_ep_get_peer(rxr_ep, msg->addr);
+	assert(peer);
+	if (rxr_env.enable_shm_transfer && peer->is_local) {
+		err = rxr_rma_post_shm_rma(rxr_ep, tx_entry);
+	} else {
+		err = rxr_ep_set_tx_credit_request(rxr_ep, tx_entry);
+		if (OFI_UNLIKELY(err)) {
+			rxr_release_tx_entry(rxr_ep, tx_entry);
+			goto out;
+		}
+
+		err = rxr_rma_post_efa_read(rxr_ep, tx_entry);
+	}
+
+out:
+	fastlock_release(&rxr_ep->util_ep.lock);
+	rxr_perfset_end(rxr_ep, perf_rxr_tx);
+	return err;
+}
+
+ssize_t rxr_rma_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
+		      size_t iov_count, fi_addr_t src_addr, uint64_t addr,
+		      uint64_t key, void *context)
 {
 	struct fi_rma_iov rma_iov;
 	struct fi_msg_rma msg;
@@ -153,31 +600,79 @@ ssize_t rxr_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
 	msg.rma_iov = &rma_iov;
 	msg.rma_iov_count = 1;
 
-	return rxr_readmsg(ep, &msg, 0);
+	return rxr_rma_readmsg(ep, &msg, 0);
 }
 
-ssize_t rxr_readmsg(struct fid_ep *ep, const struct fi_msg_rma *msg, uint64_t flags)
-{
-	return rxr_generic_rma(ep, msg->msg_iov, msg->iov_count,
-			       msg->rma_iov, msg->rma_iov_count,
-			       msg->addr, msg->data, msg->context,
-			       ofi_op_read_req, flags);
-}
-
-ssize_t rxr_write(struct fid_ep *ep, const void *buf, size_t len, void *desc,
-		  fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-		  void *context)
+ssize_t rxr_rma_read(struct fid_ep *ep, void *buf, size_t len, void *desc,
+		     fi_addr_t src_addr, uint64_t addr, uint64_t key,
+		     void *context)
 {
 	struct iovec iov;
 
 	iov.iov_base = (void *)buf;
 	iov.iov_len = len;
-	return rxr_writev(ep, &iov, &desc, 1, dest_addr, addr, key, context);
+	return rxr_rma_readv(ep, &iov, &desc, 1, src_addr, addr, key, context);
 }
 
-ssize_t rxr_writev(struct fid_ep *ep, const struct iovec *iov, void **desc,
-		   size_t iov_count, fi_addr_t dest_addr, uint64_t addr,
-		   uint64_t key, void *context)
+/* rma_write functions */
+ssize_t rxr_rma_writemsg(struct fid_ep *ep,
+			 const struct fi_msg_rma *msg,
+			 uint64_t flags)
+{
+	ssize_t err;
+	struct rxr_ep *rxr_ep;
+	struct rxr_peer *peer;
+	struct rxr_tx_entry *tx_entry;
+
+	FI_DBG(&rxr_prov, FI_LOG_EP_DATA,
+	       "write iov_len %lu flags: %lx\n",
+	       ofi_total_iov_len(msg->msg_iov, msg->iov_count),
+	       flags);
+
+	rxr_ep = container_of(ep, struct rxr_ep, util_ep.ep_fid.fid);
+	assert(msg->iov_count <= rxr_ep->tx_iov_limit);
+
+	rxr_perfset_start(rxr_ep, perf_rxr_tx);
+	fastlock_acquire(&rxr_ep->util_ep.lock);
+
+	peer = rxr_ep_get_peer(rxr_ep, msg->addr);
+	assert(peer);
+
+	tx_entry = rxr_rma_alloc_tx_entry(rxr_ep, msg, ofi_op_write, flags);
+	if (OFI_UNLIKELY(!tx_entry)) {
+		rxr_ep_progress_internal(rxr_ep);
+		err = -FI_EAGAIN;
+		goto out;
+	}
+
+	if (rxr_env.enable_shm_transfer && peer->is_local) {
+		err = rxr_rma_post_shm_rma(rxr_ep, tx_entry);
+	}  else {
+		err = rxr_ep_set_tx_credit_request(rxr_ep, tx_entry);
+		if (OFI_UNLIKELY(err)) {
+			rxr_release_tx_entry(rxr_ep, tx_entry);
+			goto out;
+		}
+
+		tx_entry->msg_id = (peer->next_msg_id != ~0) ?
+				    peer->next_msg_id++ : ++peer->next_msg_id;
+
+		err = rxr_ep_post_ctrl_or_queue(rxr_ep, RXR_TX_ENTRY, tx_entry, RXR_RTS_PKT, 0);
+		if (OFI_UNLIKELY(err)) {
+			rxr_release_tx_entry(rxr_ep, tx_entry);
+			peer->next_msg_id--;
+		}
+	}
+
+out:
+	fastlock_release(&rxr_ep->util_ep.lock);
+	rxr_perfset_end(rxr_ep, perf_rxr_tx);
+	return err;
+}
+
+ssize_t rxr_rma_writev(struct fid_ep *ep, const struct iovec *iov, void **desc,
+		       size_t iov_count, fi_addr_t dest_addr, uint64_t addr,
+		       uint64_t key, void *context)
 {
 	struct fi_rma_iov rma_iov;
 	struct fi_msg_rma msg;
@@ -195,32 +690,23 @@ ssize_t rxr_writev(struct fid_ep *ep, const struct iovec *iov, void **desc,
 	msg.rma_iov = &rma_iov;
 	msg.rma_iov_count = 1;
 
-	return rxr_writemsg(ep, &msg, 0);
+	return rxr_rma_writemsg(ep, &msg, 0);
 }
 
-ssize_t rxr_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
-		     uint64_t flags)
+ssize_t rxr_rma_write(struct fid_ep *ep, const void *buf, size_t len, void *desc,
+		      fi_addr_t dest_addr, uint64_t addr, uint64_t key,
+		      void *context)
 {
-	ssize_t ret = 0;
-
-	if (msg->data == 0) {
-		ret = rxr_generic_rma(ep, msg->msg_iov, msg->iov_count,
-				      msg->rma_iov, msg->rma_iov_count,
-				      msg->addr, 0, NULL, ofi_op_write, 0);
-	} else {
-		ret = rxr_generic_rma(ep, msg->msg_iov, msg->iov_count,
-				      msg->rma_iov, msg->rma_iov_count,
-				      msg->addr, msg->data,
-				      msg->context, ofi_op_write,
-				      FI_REMOTE_CQ_DATA);
-	}
+	struct iovec iov;
 
-	return ret;
+	iov.iov_base = (void *)buf;
+	iov.iov_len = len;
+	return rxr_rma_writev(ep, &iov, &desc, 1, dest_addr, addr, key, context);
 }
 
-ssize_t rxr_writedata(struct fid_ep *ep, const void *buf, size_t len,
-		      void *desc, uint64_t data, fi_addr_t dest_addr,
-		      uint64_t addr, uint64_t key, void *context)
+ssize_t rxr_rma_writedata(struct fid_ep *ep, const void *buf, size_t len,
+			  void *desc, uint64_t data, fi_addr_t dest_addr,
+			  uint64_t addr, uint64_t key, void *context)
 {
 	struct iovec iov;
 	struct fi_rma_iov rma_iov;
@@ -242,12 +728,13 @@ ssize_t rxr_writedata(struct fid_ep *ep, const void *buf, size_t len,
 	msg.rma_iov_count = 1;
 	msg.data = data;
 
-	return rxr_writemsg(ep, &msg, 0);
+	return rxr_rma_writemsg(ep, &msg, FI_REMOTE_CQ_DATA);
 }
 
-ssize_t rxr_inject(struct fid_ep *ep, const void *buf, size_t len,
-		   fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+ssize_t rxr_rma_inject_write(struct fid_ep *ep, const void *buf, size_t len,
+			     fi_addr_t dest_addr, uint64_t addr, uint64_t key)
 {
+	struct fi_msg_rma msg;
 	struct iovec iov;
 	struct fi_rma_iov rma_iov;
 
@@ -256,15 +743,22 @@ ssize_t rxr_inject(struct fid_ep *ep, const void *buf, size_t len,
 	rma_iov.addr = addr;
 	rma_iov.len  = len;
 	rma_iov.key = key;
-	return rxr_generic_rma(ep, &iov, 1, &rma_iov, 1, dest_addr,
-			       0, NULL, ofi_op_write, FI_INJECT |
-			       RXR_NO_COMPLETION);
+
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_iov = &iov;
+	msg.iov_count = 1;
+	msg.rma_iov = &rma_iov;
+	msg.rma_iov_count = 1;
+	msg.addr = dest_addr;
+
+	return rxr_rma_writemsg(ep, &msg, FI_INJECT | RXR_NO_COMPLETION);
 }
 
-ssize_t rxr_inject_data(struct fid_ep *ep, const void *buf, size_t len,
-			uint64_t data, fi_addr_t dest_addr, uint64_t addr,
-			uint64_t key)
+ssize_t rxr_rma_inject_writedata(struct fid_ep *ep, const void *buf, size_t len,
+				 uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+				 uint64_t key)
 {
+	struct fi_msg_rma msg;
 	struct iovec iov;
 	struct fi_rma_iov rma_iov;
 
@@ -273,20 +767,28 @@ ssize_t rxr_inject_data(struct fid_ep *ep, const void *buf, size_t len,
 	rma_iov.addr = addr;
 	rma_iov.len  = len;
 	rma_iov.key = key;
-	return rxr_generic_rma(ep, &iov, 1, &rma_iov, 1, dest_addr,
-			       data, NULL, ofi_op_write, FI_INJECT |
-			       RXR_NO_COMPLETION | FI_REMOTE_CQ_DATA);
+
+	memset(&msg, 0, sizeof(msg));
+	msg.msg_iov = &iov;
+	msg.iov_count = 1;
+	msg.rma_iov = &rma_iov;
+	msg.rma_iov_count = 1;
+	msg.addr = dest_addr;
+	msg.data = data;
+
+	return rxr_rma_writemsg(ep, &msg, FI_INJECT | RXR_NO_COMPLETION |
+				FI_REMOTE_CQ_DATA);
 }
 
 struct fi_ops_rma rxr_ops_rma = {
 	.size = sizeof(struct fi_ops_rma),
-	.read = rxr_read,
-	.readv = rxr_readv,
-	.readmsg = rxr_readmsg,
-	.write = rxr_write,
-	.writev = rxr_writev,
-	.writemsg = rxr_writemsg,
-	.inject = rxr_inject,
-	.writedata = rxr_writedata,
-	.injectdata = rxr_inject_data,
+	.read = rxr_rma_read,
+	.readv = rxr_rma_readv,
+	.readmsg = rxr_rma_readmsg,
+	.write = rxr_rma_write,
+	.writev = rxr_rma_writev,
+	.writemsg = rxr_rma_writemsg,
+	.inject = rxr_rma_inject_write,
+	.writedata = rxr_rma_writedata,
+	.injectdata = rxr_rma_inject_writedata,
 };
diff --git a/prov/efa/src/rxr/rxr_rma.h b/prov/efa/src/rxr/rxr_rma.h
index c337820..3da3933 100644
--- a/prov/efa/src/rxr/rxr_rma.h
+++ b/prov/efa/src/rxr/rxr_rma.h
@@ -39,43 +39,84 @@
 
 #include <rdma/fi_rma.h>
 
+struct rxr_readrsp_hdr {
+	uint8_t type;
+	uint8_t version;
+	uint16_t flags;
+	/* end of rxr_base_hdr */
+	uint8_t pad[4];
+	uint32_t rx_id;
+	uint32_t tx_id;
+	uint64_t seg_size;
+};
+
+struct rxr_readrsp_pkt {
+	struct rxr_readrsp_hdr hdr;
+	char data[];
+};
+
+static inline struct rxr_readrsp_hdr *rxr_get_readrsp_hdr(void *pkt)
+{
+	return (struct rxr_readrsp_hdr *)pkt;
+}
+
+#define RXR_READRSP_HDR_SIZE	(sizeof(struct rxr_readrsp_hdr))
+
+#if defined(static_assert) && defined(__x86_64__)
+static_assert(sizeof(struct rxr_readrsp_hdr) == sizeof(struct rxr_data_hdr), "rxr_readrsp_hdr check");
+#endif
+
+struct rxr_rma_read_info {
+	uint64_t rma_initiator_rx_id;
+	uint64_t window;
+};
+
+#if defined(static_assert) && defined(__x86_64__)
+static_assert(sizeof(struct rxr_rma_read_info) == 16, "rxr_rma_read_hdr check");
+#endif
+
+char *rxr_rma_init_rts_hdr(struct rxr_ep *ep,
+			   struct rxr_tx_entry *tx_entry,
+			   struct rxr_pkt_entry *pkt_entry,
+			   char *hdr);
+
 int rxr_rma_verified_copy_iov(struct rxr_ep *ep, struct fi_rma_iov *rma,
 			      size_t count, uint32_t flags, struct iovec *iov);
 
-struct rxr_tx_entry *rxr_readrsp_tx_entry_init(struct rxr_ep *rxr_ep,
-					       struct rxr_rx_entry *rx_entry);
+char *rxr_rma_read_rts_hdr(struct rxr_ep *ep,
+			   struct rxr_rx_entry *rx_entry,
+			   struct rxr_pkt_entry *pkt_entry,
+			   char *hdr);
 
-ssize_t rxr_read(struct fid_ep *ep, void *buf, size_t len, void *desc,
-		 fi_addr_t src_addr, uint64_t addr, uint64_t key,
-		 void *context);
+int rxr_rma_proc_write_rts(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry);
 
-ssize_t rxr_readv(struct fid_ep *ep, const struct iovec *iov, void **desc,
-		  size_t iov_count, fi_addr_t src_addr, uint64_t addr,
-		  uint64_t key, void *context);
+int rxr_rma_init_read_rts(struct rxr_ep *ep, struct rxr_tx_entry *tx_entry,
+			  struct rxr_pkt_entry *pkt_entry);
 
-ssize_t rxr_readmsg(struct fid_ep *ep, const struct fi_msg_rma *msg, uint64_t flags);
+int rxr_rma_proc_read_rts(struct rxr_ep *ep, struct rxr_pkt_entry *pkt_entry);
 
-ssize_t rxr_write(struct fid_ep *ep, const void *buf, size_t len, void *desc,
-		  fi_addr_t dest_addr, uint64_t addr, uint64_t key,
-		  void *context);
+/* read response related functions */
+struct rxr_tx_entry *
+rxr_rma_alloc_readrsp_tx_entry(struct rxr_ep *rxr_ep,
+			       struct rxr_rx_entry *rx_entry);
 
-ssize_t rxr_writev(struct fid_ep *ep, const struct iovec *iov, void **desc,
-		   size_t iov_count, fi_addr_t dest_addr, uint64_t addr,
-		   uint64_t key, void *context);
+int rxr_rma_init_readrsp_pkt(struct rxr_ep *ep,
+			     struct rxr_tx_entry *tx_entry,
+			     struct rxr_pkt_entry *pkt_entry);
 
-ssize_t rxr_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg,
-		     uint64_t flags);
+void rxr_rma_handle_readrsp_sent(struct rxr_ep *ep,
+				 struct rxr_pkt_entry *pkt_entry);
 
-ssize_t rxr_writedata(struct fid_ep *ep, const void *buf, size_t len,
-		      void *desc, uint64_t data, fi_addr_t dest_addr,
-		      uint64_t addr, uint64_t key, void *context);
+/* EOR related functions */
+int rxr_rma_init_eor_pkt(struct rxr_ep *ep,
+			 struct rxr_rx_entry *rx_entry,
+			 struct rxr_pkt_entry *pkt_entry);
 
-ssize_t rxr_inject(struct fid_ep *ep, const void *buf, size_t len,
-		   fi_addr_t dest_addr, uint64_t addr, uint64_t key);
+void rxr_rma_handle_eor_sent(struct rxr_ep *ep,
+			     struct rxr_pkt_entry *pkt_entry);
 
-ssize_t rxr_inject_data(struct fid_ep *ep, const void *buf, size_t len,
-			uint64_t data, fi_addr_t dest_addr, uint64_t addr,
-			uint64_t key);
+size_t rxr_rma_post_shm_rma(struct rxr_ep *rxr_ep,
+			    struct rxr_tx_entry *tx_entry);
 
 extern struct fi_ops_rma rxr_ops_rma;
 
diff --git a/prov/gni/src/gnix_fabric.c b/prov/gni/src/gnix_fabric.c
index 9330413..b04346b 100644
--- a/prov/gni/src/gnix_fabric.c
+++ b/prov/gni/src/gnix_fabric.c
@@ -724,7 +724,7 @@ static void gnix_fini(void)
 struct fi_provider gnix_prov = {
 	.name = gnix_prov_name,
 	.version = FI_VERSION(GNI_MAJOR_VERSION, GNI_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = gnix_getinfo,
 	.fabric = gnix_fabric_open,
 	.cleanup = gnix_fini
diff --git a/prov/gni/src/gnix_msg.c b/prov/gni/src/gnix_msg.c
index 08b93fa..6cfcd5a 100644
--- a/prov/gni/src/gnix_msg.c
+++ b/prov/gni/src/gnix_msg.c
@@ -2012,7 +2012,6 @@ static int __smsg_eager_msg_w_data(void *data, void *msg)
 	struct gnix_tag_storage *unexp_queue;
 	struct gnix_tag_storage *posted_queue;
 	int tagged;
-	bool multi_recv = false;
 
 	GNIX_DBG_TRACE(FI_LOG_EP_DATA, "\n");
 
@@ -2033,7 +2032,6 @@ static int __smsg_eager_msg_w_data(void *data, void *msg)
 			if (req == NULL) {
 				return -FI_ENOMEM;
 			}
-			multi_recv = true;
 		}
 
 		req->addr = vc->peer_addr;
@@ -2057,14 +2055,10 @@ static int __smsg_eager_msg_w_data(void *data, void *msg)
 		GNIX_DEBUG(FI_LOG_EP_DATA, "Freeing req: %p\n", req);
 
 		/*
-		 * Dequeue and free the request if not
-		 * matching a FI_MULTI_RECV buffer.
+		 * Dequeue and free the request.
 		 */
-		if (multi_recv == false) {
-			_gnix_remove_tag(posted_queue, req);
-			_gnix_fr_free(ep, req);
-		}
-
+		_gnix_remove_tag(posted_queue, req);
+		_gnix_fr_free(ep, req);
 	} else {
 		/* Add new unexpected receive request. */
 		req = _gnix_fr_alloc(ep);
@@ -2178,7 +2172,6 @@ static int __smsg_rndzv_start(void *data, void *msg)
 	struct gnix_tag_storage *unexp_queue;
 	struct gnix_tag_storage *posted_queue;
 	int tagged;
-	bool multi_recv = false;
 
 	GNIX_DBG_TRACE(FI_LOG_EP_DATA, "\n");
 
@@ -2198,7 +2191,6 @@ static int __smsg_rndzv_start(void *data, void *msg)
 			if (req == NULL) {
 				return -FI_ENOMEM;
 			}
-			multi_recv = true;
 		}
 
 		req->addr = vc->peer_addr;
@@ -2246,8 +2238,7 @@ static int __smsg_rndzv_start(void *data, void *msg)
 			  req, req->msg.recv_info[0].recv_addr,
 			  req->msg.send_info[0].send_len);
 
-		if (multi_recv == false)
-			_gnix_remove_tag(posted_queue, req);
+		_gnix_remove_tag(posted_queue, req);
 
 		/* Queue request to initiate pull of source data. */
 		ret = _gnix_vc_queue_work_req(req);
diff --git a/prov/hook/hook_debug/include/hook_debug.h b/prov/hook/hook_debug/include/hook_debug.h
index fd7e462..483d2ef 100644
--- a/prov/hook/hook_debug/include/hook_debug.h
+++ b/prov/hook/hook_debug/include/hook_debug.h
@@ -51,6 +51,7 @@ struct hook_debug_config {
 struct hook_debug_eq {
 	struct hook_eq hook_eq;
 	ofi_atomic64_t event_cntr[HOOK_DEBUG_EQ_EVENT_MAX];
+	size_t eagain_count;
 };
 
 struct hook_debug_cq {
diff --git a/prov/hook/hook_debug/src/hook_debug.c b/prov/hook/hook_debug/src/hook_debug.c
index 66ebc0b..b626d35 100644
--- a/prov/hook/hook_debug/src/hook_debug.c
+++ b/prov/hook/hook_debug/src/hook_debug.c
@@ -96,19 +96,47 @@ static void hook_debug_trace_exit(struct fid *fid, struct fid *hfid,
 	if (ret != -FI_EAGAIN || !eagain_count ||
 	    !((*eagain_count)++ % HOOK_DEBUG_EAGAIN_LOG))
 		FI_TRACE(hook_to_hprov(fid), subsys, "%s (fid: %p) returned: "
-			 "%zd (%s)\n", fn, fid, ret, fi_strerror(-ret));
+			 "%zd (%s)\n", fn, hfid, ret, fi_strerror(-ret));
 out:
 	if (eagain_count && ret != -FI_EAGAIN)
 		*eagain_count = 0;
 }
 
+static void
+hook_debug_trace_exit_eq(struct hook_debug_eq *eq, const char *fn, ssize_t ret)
+{
+	return hook_debug_trace_exit(&eq->hook_eq.eq.fid, &eq->hook_eq.heq->fid,
+				     FI_LOG_EQ, fn, ret, &eq->eagain_count);
+}
+
+static void
+hook_debug_trace_exit_cq(struct hook_debug_cq *cq, const char *fn, ssize_t ret)
+{
+	hook_debug_trace_exit(&cq->hook_cq.cq.fid, &cq->hook_cq.hcq->fid,
+			      FI_LOG_CQ, fn, ret, &cq->eagain_count);
+}
+
+static void
+hook_debug_trace_exit_cntr(struct hook_cntr *cntr, const char *fn, ssize_t ret)
+{
+	hook_debug_trace_exit(&cntr->cntr.fid, &cntr->hcntr->fid,
+			      FI_LOG_CNTR, fn, ret, NULL);
+}
+
+static void
+hook_debug_trace_exit_ep(struct hook_debug_ep *ep, const char *fn, ssize_t ret,
+			 size_t *eagain_count)
+{
+	hook_debug_trace_exit(&ep->hook_ep.ep.fid, &ep->hook_ep.hep->fid,
+			      FI_LOG_EP_DATA, fn, ret, eagain_count);
+}
+
 static void hook_debug_rx_end(struct hook_debug_ep *ep, char *fn,
 			      ssize_t ret, void *mycontext)
 {
 	struct hook_debug_txrx_entry *rx_entry;
 
-	hook_debug_trace_exit(&ep->hook_ep.ep.fid, &ep->hook_ep.hep->fid,
-			      FI_LOG_EP_DATA, fn, ret, &ep->rx_eagain_count);
+	hook_debug_trace_exit_ep(ep, fn, ret, &ep->rx_eagain_count);
 
 	if (config.track_recvs) {
 		if (!ret) {
@@ -203,8 +231,7 @@ static void hook_debug_tx_end(struct hook_debug_ep *ep, char *fn,
 {
 	struct hook_debug_txrx_entry *tx_entry;
 
-	hook_debug_trace_exit(&ep->hook_ep.ep.fid, &ep->hook_ep.hep->fid,
-			      FI_LOG_EP_DATA, fn, ret, &ep->tx_eagain_count);
+	hook_debug_trace_exit_ep(ep, fn, ret, &ep->tx_eagain_count);
 
 	if (mycontext && config.track_sends) {
 		if (!ret) {
@@ -478,8 +505,7 @@ static void hook_debug_cq_process_entry(struct hook_debug_cq *mycq,
 	struct fi_cq_tagged_entry *cq_entry;
 	int i;
 
-	hook_debug_trace_exit(&mycq->hook_cq.cq.fid, &mycq->hook_cq.hcq->fid,
-			      FI_LOG_CQ, fn, ret, &mycq->eagain_count);
+	hook_debug_trace_exit_cq(mycq, fn, ret);
 
 	for (i = 0; i < ret; i++, buf += mycq->entry_size) {
 		cq_entry = (struct fi_cq_tagged_entry *)buf;
@@ -527,6 +553,18 @@ static ssize_t hook_debug_cq_read(struct fid_cq *cq, void *buf, size_t count)
 	return ret;
 }
 
+static ssize_t hook_debug_cq_readfrom(struct fid_cq *cq, void *buf, size_t count,
+				      fi_addr_t *src_addr)
+{
+	struct hook_debug_cq *mycq = container_of(cq, struct hook_debug_cq,
+						  hook_cq.cq);
+	ssize_t ret;
+
+	ret = fi_cq_readfrom(mycq->hook_cq.hcq, buf, count, src_addr);
+	hook_debug_cq_process_entry(mycq, "fi_cq_readfrom", ret, buf);
+	return ret;
+}
+
 int hook_debug_cq_close(struct fid *fid)
 {
 	struct hook_debug_cq *mycq =
@@ -594,6 +632,9 @@ int hook_debug_cq_open(struct fid_domain *domain_fid, struct fi_cq_attr *attr,
 	if (ret)
 		goto err;
 
+	FI_TRACE(hook_fabric_to_hprov(mycq->hook_cq.domain->fabric), FI_LOG_CQ,
+		 "cq opened, fid: %p\n", &mycq->hook_cq.hcq->fid);
+
 	mycq->hook_cq.cq.fid.ops = &hook_debug_cq_fid_ops;
 	mycq->hook_cq.cq.ops = &hook_debug_cq_ops;
 	mycq->format = attr->format;
@@ -630,15 +671,22 @@ int hook_debug_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
 {
 	struct fid *hfid, *hbfid;
 	struct hook_cntr *cntr;
+	struct hook_cq *cq;
 
 	hfid = hook_to_hfid(fid);
 	hbfid = hook_to_hfid(bfid);
 	if (!hfid || !hbfid)
 		return -FI_EINVAL;
 
-	switch (fid->fclass) {
+	switch (bfid->fclass) {
+	case FI_CLASS_CQ:
+		cq = container_of(bfid, struct hook_cq, cq.fid);
+		HOOK_DEBUG_TRACE(cq->domain->fabric, FI_LOG_EP_CTRL,
+				 "cq: %p bind flags: %s\n", cq->hcq,
+				 fi_tostr(&flags, FI_TYPE_CAPS));
+		break;
 	case FI_CLASS_CNTR:
-		cntr = container_of(fid, struct hook_cntr, cntr.fid);
+		cntr = container_of(bfid, struct hook_cntr, cntr.fid);
 		HOOK_DEBUG_TRACE(cntr->domain->fabric, FI_LOG_EP_CTRL,
 				 "cntr: %p bind flags: %s\n", cntr->hcntr,
 				 fi_tostr(&flags, FI_TYPE_CAPS));
@@ -760,6 +808,7 @@ static ssize_t hook_debug_eq_read(struct fid_eq *eq, uint32_t *event,
 	if (ret > 0)
 		ofi_atomic_inc64(&myeq->event_cntr[*event]);
 
+	hook_debug_trace_exit_eq(myeq, "fi_eq_read", (ssize_t)ret);
 	return ret;
 }
 
@@ -775,6 +824,7 @@ static ssize_t hook_debug_eq_sread(struct fid_eq *eq, uint32_t *event,
 	if (ret > 0)
 		ofi_atomic_inc64(&myeq->event_cntr[*event]);
 
+	hook_debug_trace_exit_eq(myeq, "fi_eq_sread", (ssize_t)ret);
 	return ret;
 }
 
@@ -868,8 +918,7 @@ static uint64_t hook_debug_cntr_read(struct fid_cntr *cntr)
 	uint64_t ret;
 
 	ret = fi_cntr_read(mycntr->hcntr);
-	hook_debug_trace_exit(&mycntr->cntr.fid, &mycntr->hcntr->fid,
-			      FI_LOG_CNTR, "fi_cntr_read", (ssize_t)ret, NULL);
+	hook_debug_trace_exit_cntr(mycntr, "fi_cntr_read", (ssize_t)ret);
 	return ret;
 }
 
@@ -885,8 +934,7 @@ static int hook_debug_cntr_wait(struct fid_cntr *cntr, uint64_t threshold, int t
 
 	ret = fi_cntr_wait(mycntr->hcntr, threshold, timeout);
 
-	hook_debug_trace_exit(&mycntr->cntr.fid, &mycntr->hcntr->fid,
-			      FI_LOG_CNTR, "fi_cntr_wait", (ssize_t)ret, NULL);
+	hook_debug_trace_exit_cntr(mycntr, "fi_cntr_wait", (ssize_t)ret);
 	return ret;
 }
 
@@ -933,7 +981,7 @@ HOOK_DEBUG_INI
 
 	hook_debug_cq_ops = hook_cq_ops;
 	hook_debug_cq_ops.read = hook_debug_cq_read;
-	hook_debug_cq_ops.readfrom = fi_no_cq_readfrom;
+	hook_debug_cq_ops.readfrom = hook_debug_cq_readfrom;
 	hook_debug_cq_ops.sread = fi_no_cq_sread;
 	hook_debug_cq_ops.sreadfrom = fi_no_cq_sreadfrom;
 
diff --git a/prov/mlx/Makefile.include b/prov/mlx/Makefile.include
deleted file mode 100644
index 260aeee..0000000
--- a/prov/mlx/Makefile.include
+++ /dev/null
@@ -1,34 +0,0 @@
-if HAVE_MLX
-_mlx_files = prov/mlx/src/mlx.h \
-    prov/mlx/src/mlx_av.c \
-    prov/mlx/src/mlx_cm.c \
-    prov/mlx/src/mlx_cq.c \
-    prov/mlx/src/mlx_domain.c \
-    prov/mlx/src/mlx_ep.c \
-    prov/mlx/src/mlx_init.c \
-    prov/mlx/src/mlx_tagged.c \
-    prov/mlx/src/mlx_fabric.c \
-    prov/mlx/src/mlx_callbacks.c
-
-
-if HAVE_MLX_DL
-pkglib_LTLIBRARIES += libmlx-fi.la
-libmlx_fi_la_CPPFLAGS = $(AM_CPPFLAGS) $(mlx_CPPFLAGS)
-libmlx_fi_la_SOURCES = $(_mlx_files) $(common_srcs)
-libmlx_fi_la_LDFLAGS = \
-	$(mlx_LDFLAGS) \
-	-module -avoid-version -shared -export-dynamic
-libmlx_fi_la_LIBADD = $(linkback) $(mlx_LIBS)
-libmlx_fi_la_DEPENDENCIES = $(linkback)
-else
-src_libfabric_la_SOURCES += $(_mlx_files)
-src_libfabric_la_CPPFLAGS += $(mlx_CPPFLAGS)
-src_libfabric_la_LDFLAGS += $(mlx_LDFLAGS)
-src_libfabric_la_LIBADD += $(mlx_LIBS)
-endif
-
-prov_install_man_pages += man/man7/fi_mlx.7
-
-endif #HAVE_MLX
-
-prov_dist_man_pages += man/man7/fi_mlx.7
diff --git a/prov/mlx/configure.m4 b/prov/mlx/configure.m4
deleted file mode 100644
index 1c13d58..0000000
--- a/prov/mlx/configure.m4
+++ /dev/null
@@ -1,26 +0,0 @@
-dnl Configury specific to the libfabrics mlx provider
-
-dnl Called to configure this provider
-dnl
-dnl Arguments:
-dnl
-dnl $1: action if configured successfully
-dnl $2: action if not configured successfully
-dnl
-AC_DEFUN([FI_MLX_CONFIGURE],[
-    # Determine if we can support the mxm provider
-    mlx_happy=0
-    AS_IF([test x"$enable_mlx" = x"yes"],
-              [FI_CHECK_PACKAGE([mlx],
-                    [ucp/api/ucp.h],
-                    [ucp],
-                    [ucp_get_version_string],
-                    [],
-                    [$mlx_PREFIX],
-                    [$mlx_LIBDIR],
-                    [mlx_happy=1],
-                    [mlx_happy=0])
-         ])
-    AS_IF([test $mlx_happy -eq 1], [$1], [$2])
-])
-
diff --git a/prov/mlx/src/mlx.h b/prov/mlx/src/mlx.h
deleted file mode 100644
index cdc0697..0000000
--- a/prov/mlx/src/mlx.h
+++ /dev/null
@@ -1,199 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#ifndef _FI_MLX_H
-#define _FI_MLX_H
-
-
-#ifdef __cplusplus
-extern "C" {
-#endif
-
-#include "config.h"
-#include <ucp/api/ucp.h>
-#include <ucm/api/ucm.h>
-
-#include <errno.h>
-#include <stdio.h>
-#include <stdlib.h>
-#include <string.h>
-#include <unistd.h>
-#include <rdma/fabric.h>
-#include <rdma/providers/fi_prov.h>
-#include <rdma/fi_domain.h>
-#include <rdma/fi_endpoint.h>
-#include <rdma/fi_tagged.h>
-#include <rdma/fi_rma.h>
-#include <rdma/fi_cm.h>
-#include <rdma/fi_errno.h>
-#include <rdma/providers/fi_log.h>
-#include <ofi.h>
-#include <ofi_lock.h>
-#include <ofi_list.h>
-#include "ofi_enosys.h"
-#include <ofi_mem.h>
-#include <ofi_atom.h>
-#include <ofi_util.h>
-#include <ofi_prov.h>
-
-#include <arpa/inet.h>
-#include <netdb.h>
-#include <sys/socket.h>
-#include <ifaddrs.h>
-
-#define FI_MLX_FABRIC_NAME "mlx"
-#define FI_MLX_DEFAULT_INJECT_SIZE 1024
-#define FI_MLX_DEFAULT_NS_PORT 12345
-#define FI_MLX_DEF_CQ_SIZE (1024)
-#define FI_MLX_DEF_MR_CNT (1 << 16)
-
-#define FI_MLX_VERSION_MINOR 5
-#define FI_MLX_VERSION_MAJOR 1
-#define FI_MLX_VERSION (FI_VERSION(FI_MLX_VERSION_MAJOR, FI_MLX_VERSION_MINOR))
-
-#define FI_MLX_RKEY_MAX_LEN (256)
-
-#define FI_MLX_MAX_NAME_LEN (1024)
-
-#define FI_MLX_CAPS (FI_SEND | FI_RECV | FI_TAGGED)
-#define FI_MLX_MODE_REQUIRED (0ULL)
-#define FI_MLX_MODE_SUPPORTED (FI_CONTEXT | FI_ASYNC_IOV)
-#define FI_MLX_OP_FLAGS (FI_SEND | FI_RECV)
-#define FI_MLX_ANY_SERVICE (0)
-struct mlx_global_descriptor{
-	ucp_config_t *config;
-	int use_ns;
-	int ns_port;
-	struct util_ns name_serv;
-	char *localhost;
-};
-
-struct mlx_fabric {
-	struct util_fabric u_fabric;
-};
-
-struct mlx_domain {
-	struct util_domain u_domain;
-	ucp_context_h context;
-
-	struct ofi_bufpool *fast_path_pool;
-	fastlock_t fpp_lock;
-};
-
-
-struct mlx_ep {
-	struct util_ep ep;
-	struct mlx_av *av; /*until AV is not implemented via utils*/
-	ucp_worker_h worker;
-	short service;
-	void *addr;
-	size_t addr_len;
-};
-
-struct mlx_av {
-	struct fid_av av;
-	struct mlx_domain *domain;
-	struct mlx_ep *ep;
-	struct util_eq *eq;
-	int type;
-	int async;
-	size_t count;
-	size_t addr_len;
-};
-
-typedef enum mlx_req_type {
-	MLX_FI_REQ_UNINITIALIZED = 0,
-	MLX_FI_REQ_REGULAR = 0xFD,
-	MLX_FI_REQ_UNEXPECTED_ERR = 0xFE,
-	MLX_FI_REQ_UNEXPECTED = 0xFF,
-} mlx_req_type_t;
-
-struct mlx_request {
-	mlx_req_type_t type;
-
-	union {
-		struct fi_cq_tagged_entry tagged;
-		struct fi_cq_err_entry error;
-	} completion;
-
-	struct util_cq* cq;
-	struct mlx_ep* ep;
-};
-
-OFI_DECLARE_CIRQUE(struct fi_cq_tagged_entry, mlx_comp_cirq);
-
-extern int mlx_errcode_translation_table[];
-#define MLX_TRANSLATE_ERRCODE(X) mlx_errcode_translation_table[(-X)+1]
-extern struct fi_provider mlx_prov;
-extern struct mlx_global_descriptor mlx_descriptor;
-extern struct util_prov mlx_util_prov;
-
-extern struct fi_ops_cm mlx_cm_ops;
-extern struct fi_ops_tagged mlx_tagged_ops;
-extern struct fi_ops_mr mlx_mr_ops;
-extern struct fi_fabric_attr mlx_fabric_attrs;
-
-int mlx_fabric_open(
-		struct fi_fabric_attr *attr,
-		struct fid_fabric **fabric, 
-		void *context);
-
-int mlx_domain_open(
-		struct fid_fabric *fabric, struct fi_info *info,
-		struct fid_domain **fid, void *context);
-
-int mlx_ep_open(
-		struct fid_domain *domain, struct fi_info *info,
-		struct fid_ep **fid, void *context);
-
-int mlx_cq_open(
-		struct fid_domain *domain, struct fi_cq_attr *attr,
-		struct fid_cq **cq, void *context);
-
-int mlx_av_open(
-		struct fid_domain *domain, struct fi_av_attr *attr,
-		struct fid_av **av, void *context);
-
-int mlx_ns_is_service_wildcard(void *svc);
-int mlx_ns_service_cmp(void *svc1, void *svc2);
-/* Callbacks */
-void mlx_send_callback_no_compl( void *request, ucs_status_t status);
-void mlx_send_callback( void *request, ucs_status_t status);
-void mlx_recv_callback_no_compl(void *request, ucs_status_t status,
-				ucp_tag_recv_info_t *info);
-void mlx_recv_callback( void *request, ucs_status_t status,
-			ucp_tag_recv_info_t *info);
-#ifdef __cplusplus
-}
-#endif
-
-#endif
diff --git a/prov/mlx/src/mlx_av.c b/prov/mlx/src/mlx_av.c
deleted file mode 100644
index bb9e944..0000000
--- a/prov/mlx/src/mlx_av.c
+++ /dev/null
@@ -1,272 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "mlx.h"
-
-static int mlx_av_write_event(
-				struct mlx_av *av, uint64_t data,
-				int err, void *context)
-{
-	struct fi_eq_err_entry entry;
-	size_t size;
-	uint64_t flags;
-
-	entry.fid = &(av->av.fid);
-	entry.context = context;
-	entry.data = data;
-
-	if (err) {
-		entry.err = err;
-		size = sizeof(struct fi_eq_err_entry);
-		flags = UTIL_FLAG_ERROR;
-	} else {
-		size = sizeof(struct fi_eq_entry);
-		flags = 0;
-	}
-
-	fi_eq_write(
-		&(av->eq->eq_fid), FI_AV_COMPLETE,
-		&entry, size, flags);
-	return FI_SUCCESS;
-}
-
-static int mlx_av_remove(
-			struct fid_av *fi_av, fi_addr_t *fi_addr, size_t count,
-			uint64_t flags)
-{
-	struct mlx_av *av;
-	int i;
-
-	av = container_of(fi_av, struct mlx_av, av);
-	if ((av->async) && (!av->eq)) {
-		return -FI_ENOEQ;
-	}
-
-	for (i = 0; i < count; ++i) {
-		ucp_ep_destroy((ucp_ep_h)(fi_addr[i]));
-	}
-	return FI_SUCCESS;
-}
-
-
-static inline int mlx_av_resolve_if_addr(
-		const struct sockaddr *saddr,
-		char **address)
-{
-	char peer_host[INET_ADDRSTRLEN] = {0};
-	char peer_serv[INET_ADDRSTRLEN] = {0};
-	int intserv, peer_host_len, peer_serv_len;
-	peer_host_len = peer_serv_len = INET_ADDRSTRLEN;
-	int rv;
-
-	rv = getnameinfo(saddr, sizeof(struct sockaddr_in),
-		peer_host, peer_host_len,
-		peer_serv, peer_serv_len,
-		NI_NUMERICSERV|NI_NUMERICHOST);
-	if (0 != rv) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"Unable to resolve address: %s \n",
-			 gai_strerror(rv));
-		return -FI_EINVAL;
-	}
-
-	intserv = atoi(peer_serv);
-	(*address) = ofi_ns_resolve_name(
-		&mlx_descriptor.name_serv,
-		peer_host, &intserv);
-	if (!(*address)) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"Unable to resolve address: %s:%s\n",
-			peer_host, peer_serv);
-		return -FI_EINVAL;
-	}
-	return FI_SUCCESS;
-}
-
-static int mlx_av_insert(
-			struct fid_av *fi_av, const void *addr, size_t count,
-			fi_addr_t *fi_addr, uint64_t flags, void *context)
-{
-	struct mlx_av *av;
-	struct mlx_ep *ep;
-	size_t i;
-	ucs_status_t status = UCS_OK;
-	int added = 0;
-
-	av = container_of(fi_av, struct mlx_av, av);
-	ep = av->ep;
-
-	if ((av->async) && (!av->eq)) {
-		return -FI_ENOEQ;
-	}
-
-	for (i = 0; i < count ; ++i) {
-		ucp_ep_params_t ep_params = { 0 };
-
-		if (mlx_descriptor.use_ns) {
-			if (mlx_av_resolve_if_addr(
-				(struct sockaddr*)
-				  (&(((struct sockaddr_in *) addr)[i])),
-				(char**) &ep_params.address) != FI_SUCCESS)
-				break;
-		} else {
-			ep_params.address = (const ucp_address_t *)
-				(&(((const char *) addr)[i * av->addr_len]));
-		}
-
-		ep_params.field_mask = UCP_EP_PARAM_FIELD_REMOTE_ADDRESS;
-		FI_WARN(&mlx_prov, FI_LOG_CORE,
-			"Try to insert address #%zd, offset=%zd (size=%zd)"
-			" fi_addr=%p \naddr = %s\n",
-			i, i * av->addr_len, count,
-			fi_addr, &(((const char *) addr)[i * av->addr_len]));
-
-		status = ucp_ep_create(ep->worker, &ep_params,
-				       (ucp_ep_h *)(&(fi_addr[i])));
-		if (mlx_descriptor.use_ns) {
-			free((void *) ep_params.address);
-		}
-		if (status == UCS_OK) {
-			FI_WARN(&mlx_prov, FI_LOG_CORE, "address inserted\n");
-			added++;
-		} else {
-			if (av->eq) {
-				mlx_av_write_event( av, i,
-					MLX_TRANSLATE_ERRCODE(status),
-					context);
-			}
-			break;
-		}
-	}
-
-	if (av->eq) {
-		mlx_av_write_event(av, added, 0, context);
-		count = 0;
-	} else {
-		count = added;
-	}
-	return count;
-}
-
-
-static int mlx_av_close(fid_t fid)
-{
-	struct mlx_av *fid_av;
-	fid_av = container_of(fid, struct mlx_av, av);
-	free (fid_av);
-	return FI_SUCCESS;
-}
-
-static int mlx_av_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
-{
-	struct mlx_av *av;
-	struct util_eq *eq;
-
-	av = container_of(fid, struct mlx_av, av.fid);
-	if ((!(av->async)) || (bfid->fclass != FI_CLASS_EQ)){
-		FI_WARN( &mlx_prov, FI_LOG_EP_CTRL,
-			"Try to bind not a EQ to AV, "
-			"or attemt to bind EQ and syncronious AV\n");
-		return -FI_EINVAL;
-	}
-	eq = container_of(bfid, struct util_eq, eq_fid.fid);
-	av->eq = eq;
-	return FI_SUCCESS;
-}
-
-static struct fi_ops mlx_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = mlx_av_close,
-	.bind = mlx_av_bind,
-};
-
-static struct fi_ops_av mlx_av_ops = {
-	.size = sizeof(struct fi_ops_av),
-	.insert = mlx_av_insert,
-	.remove = mlx_av_remove,
-};
-
-int mlx_av_open(
-		struct fid_domain *fi_domain, struct fi_av_attr *attr,
-		struct fid_av **fi_av, void *context)
-{
-	struct mlx_domain *domain;
-	struct mlx_av *av;
-	int type = FI_AV_MAP;
-	size_t count = 64;
-	domain = container_of(fi_domain, struct mlx_domain, u_domain.domain_fid);
-
-	int is_async = 0;
-	if (attr) {
-		switch (attr->type) {
-		case FI_AV_MAP:
-			type = attr->type;
-			break;
-		case FI_AV_UNSPEC:
-			/* Set FI_AV_MAP by default */
-			type = FI_AV_MAP;
-			break;
-		default:
-			return -EINVAL;
-		}
-		if (attr->flags & FI_EVENT){
-			is_async = 1;
-		}
-		count = attr->count;
-	}
-
-	av = (struct mlx_av *)calloc(1, sizeof(struct mlx_av));
-	if (!av)
-		return -ENOMEM;
-
-	av->domain = domain;
-	av->async = is_async;
-	av->type = type;
-	av->eq = NULL;
-
-	if (mlx_descriptor.use_ns) {
-		av->addr_len = sizeof(struct sockaddr_in);
-	} else {
-		av->addr_len = FI_MLX_MAX_NAME_LEN;
-	}
-
-	av->count = count;
-	av->av.fid.fclass = FI_CLASS_AV;
-	av->av.fid.context = context;
-	av->av.fid.ops = &mlx_fi_ops;
-	av->av.ops = &mlx_av_ops;
-
-	*fi_av = &av->av;
-	return FI_SUCCESS;
-}
-
-
diff --git a/prov/mlx/src/mlx_callbacks.c b/prov/mlx/src/mlx_callbacks.c
deleted file mode 100644
index ab1abc9..0000000
--- a/prov/mlx/src/mlx_callbacks.c
+++ /dev/null
@@ -1,167 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "mlx.h"
-
-/*using for fi_tinject path*/
-/*Using for selective completions scenario*/
-void mlx_send_callback_no_compl(void *request, ucs_status_t status)
-{
-	ucp_request_release(request);
-}
-
-void mlx_send_callback(void *request,
-		       ucs_status_t status)
-{
-	struct util_cq *cq;
-	struct mlx_request *mlx_req = request;
-	struct fi_cq_tagged_entry *t_entry;
-	struct util_cq_oflow_err_entry *err;
-
-	cq = mlx_req->cq;
-
-	if (status == UCS_ERR_CANCELED) {
-		ucp_request_release(request);
-		return;
-	}
-
-	fastlock_acquire(&cq->cq_lock);
-
-	t_entry = ofi_cirque_tail(cq->cirq);
-	*t_entry = (mlx_req->completion.tagged);
-	ofi_cirque_commit(cq->cirq);
-
-	if (status != UCS_OK){
-		t_entry->flags |= UTIL_FLAG_ERROR;
-		err = calloc(1, sizeof(struct util_cq_oflow_err_entry));
-		if (!err) {
-			FI_WARN(&mlx_prov, FI_LOG_CQ,
-				"out of memory, cannot report CQ error\n");
-			goto fn;
-		}
-
-		err->comp = (mlx_req->completion.error);
-		err->comp.prov_errno = (int)status;
-		err->comp.err = MLX_TRANSLATE_ERRCODE(status);
-		err->comp.olen = 0;
-		slist_insert_tail(&err->list_entry, &cq->oflow_err_list);
-	}
-fn:
-	mlx_req->type = MLX_FI_REQ_UNINITIALIZED;
-	fastlock_release(&cq->cq_lock);
-	ucp_request_release(request);
-}
-
-/*Using for selective completions scenario*/
-void mlx_recv_callback_no_compl(void *request,
-				ucs_status_t status,
-				ucp_tag_recv_info_t *info)
-{
-	ucp_request_release(request);
-}
-
-void mlx_recv_callback(void *request,
-		       ucs_status_t status,
-		       ucp_tag_recv_info_t *info)
-{
-	struct util_cq *cq;
-	struct mlx_request *mlx_req;
-
-	mlx_req = (struct mlx_request*)request;
-	if (status == UCS_ERR_CANCELED) {
-		ucp_request_release(request);
-		return;
-	}
-
-	cq = mlx_req->cq;
-
-	mlx_req->completion.tagged.tag = info->sender_tag;
-	mlx_req->completion.tagged.len = info->length;
-
-	if (status != UCS_OK) {
-		mlx_req->completion.error.prov_errno = (int)status;
-		mlx_req->completion.error.err = MLX_TRANSLATE_ERRCODE(status);
-	}
-
-	fastlock_acquire(&cq->cq_lock);
-	if (mlx_req->type == MLX_FI_REQ_UNINITIALIZED) {
-		if (status != UCS_OK) {
-			mlx_req->completion.error.olen = info->length;
-			mlx_req->type = MLX_FI_REQ_UNEXPECTED_ERR;
-		} else {
-			mlx_req->type = MLX_FI_REQ_UNEXPECTED;
-		}
-		fastlock_release(&cq->cq_lock);
-		return;
-	} else {
-		if (status != UCS_OK) {
-			mlx_req->completion.error.olen = info->length -
-						mlx_req->completion.error.len;
-		}
-
-		struct fi_cq_tagged_entry *t_entry;
-		t_entry = ofi_cirque_tail(cq->cirq);
-		*t_entry = (mlx_req->completion.tagged);
-
-		if (status != UCS_OK) {
-			struct util_cq_oflow_err_entry *err;
-			t_entry->flags |= UTIL_FLAG_ERROR;
-
-			err = calloc(1, sizeof(struct util_cq_oflow_err_entry));
-			if (!err) {
-				FI_WARN(&mlx_prov, FI_LOG_CQ,
-					"out of memory, cannot report CQ error\n");
-				mlx_req->type = MLX_FI_REQ_UNINITIALIZED;
-				goto fn;
-			}
-
-			err->comp = (mlx_req->completion.error);
-			slist_insert_tail(&err->list_entry, &cq->oflow_err_list);
-		}
-
-		if (cq->src){
-			cq->src[ofi_cirque_windex((struct mlx_comp_cirq*)(cq->cirq))] =
-					FI_ADDR_NOTAVAIL;
-		}
-
-		if (cq->wait) {
-			cq->wait->signal(cq->wait);
-		}
-
-		mlx_req->type = MLX_FI_REQ_UNINITIALIZED;
-		ofi_cirque_commit(cq->cirq);
-	}
-fn:
-	fastlock_release(&cq->cq_lock);
-	ucp_request_release(request);
-}
-
diff --git a/prov/mlx/src/mlx_cm.c b/prov/mlx/src/mlx_cm.c
deleted file mode 100644
index c0b7668..0000000
--- a/prov/mlx/src/mlx_cm.c
+++ /dev/null
@@ -1,166 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include "mlx.h"
-#include <inttypes.h>
-
-static int mlx_cm_getname_mlx_format(
-			fid_t fid,
-			void *addr,
-			size_t *addrlen)
-{
-	ucs_status_t status = UCS_OK;
-	void *addr_local = NULL;
-	size_t addr_len_local;
-	struct mlx_ep* ep;
-	int ofi_status = FI_SUCCESS;
-
-	ep = container_of(fid, struct mlx_ep, ep.ep_fid.fid); 
-
-	status = ucp_worker_get_address( ep->worker,
-					(ucp_address_t **)&addr_local,
-					(size_t*) &addr_len_local );
-	if (status != UCS_OK) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"ucp_worker_get_address error!!!\n");
-		return MLX_TRANSLATE_ERRCODE(status);
-	}
-
-	if (addr_len_local > FI_MLX_MAX_NAME_LEN) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"Address returned by UCX is too long %"PRIu64"\n",
-			 addr_len_local);
-		return -FI_EINVAL;
-	}
-
-	if ((*addrlen) < FI_MLX_MAX_NAME_LEN) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"Buffer storage for ep address is too small %"PRIu64
-			" instead of %d [%s]\n",
-			*addrlen, FI_MLX_MAX_NAME_LEN, (char *)addr_local);
-		ofi_status = -FI_ETOOSMALL;
-	}
-	FI_INFO(&mlx_prov, FI_LOG_CORE, 
-		"Loaded UCP address: [%"PRIu64"]%s\n",
-		addr_len_local, (char *)addr_local);
-
-	if (addr_local != NULL)
-		memcpy(addr, addr_local, (((*addrlen) < addr_len_local) ?
-					  (*addrlen) : addr_len_local));
-
-	*addrlen = FI_MLX_MAX_NAME_LEN;
-	ucp_worker_release_address(
-				ep->worker,
-				(ucp_address_t *)addr_local);
-	return ofi_status;
-}
-
-static int mlx_cm_getname_ai_format(
-			fid_t fid,
-			void *addr,
-			size_t *addrlen)
-{
-	int ofi_status = FI_SUCCESS;
-	struct mlx_ep* ep = container_of(fid, struct mlx_ep, ep.ep_fid.fid);
-
-	if (ep->addr) {
-		if (ep->addr_len > *addrlen) {
-			ofi_status = -FI_ETOOSMALL;
-			FI_WARN(&mlx_prov, FI_LOG_EP_CTRL,
-				"addrlen expected: %"PRIu64", got: %"PRIu64"\n",
-				ep->addr_len, *addrlen);
-		} else {
-			memcpy(addr, ep->addr, ep->addr_len);
-		}
-		*addrlen = ep->addr_len;
-	} else {
-		char *hostname = mlx_descriptor.localhost;
-		int service = (((getpid() & 0xFFFF)));
-		struct addrinfo hints = {
-			.ai_family = AF_INET,
-			.ai_socktype = SOCK_STREAM,
-			.ai_protocol = IPPROTO_TCP,
-		};
-		struct addrinfo *res;
-
-		if (getaddrinfo(hostname, NULL, &hints, &res) != 0) {
-			FI_WARN(&mlx_prov, FI_LOG_CORE,
-				"Unable to resolve hostname:%s\n", hostname);
-			return -FI_EAVAIL;
-		}
-		FI_INFO(&mlx_prov, FI_LOG_CORE,
-			"Loaded IPv4 address: [%jd]%s:%d\n",
-			(intmax_t) res->ai_addrlen, hostname, service);
-
-		if (res->ai_addrlen > *addrlen) {
-			ofi_status = -FI_ETOOSMALL;
-			FI_WARN(&mlx_prov, FI_LOG_EP_CTRL,
-				"addrlen expected: %jd, got: %"PRIu64"\n",
-				(intmax_t) res->ai_addrlen, *addrlen);
-		} else {
-			memcpy(addr, res->ai_addr, res->ai_addrlen);
-			((struct sockaddr_in *)addr)->sin_port = htons((short)service);
-		}
-
-		*addrlen = res->ai_addrlen;
-
-		freeaddrinfo(res);
-	}
-
-	return ofi_status;
-}
-
-static int mlx_cm_getname(
-			fid_t fid,
-			void *addr,
-			size_t *addrlen)
-{
-	int ofi_status = FI_SUCCESS;
-	if (mlx_descriptor.use_ns) {
-		ofi_status = mlx_cm_getname_ai_format(fid, addr, addrlen);
-	} else {
-		ofi_status = mlx_cm_getname_mlx_format(fid, addr, addrlen);
-	}
-	return ofi_status;
-}
-
-
-
-struct fi_ops_cm mlx_cm_ops = {
-	.size = sizeof(struct fi_ops_cm),
-	.getname = mlx_cm_getname,
-	.getpeer = fi_no_getpeer,
-	.connect = fi_no_connect,
-	.listen = fi_no_listen,
-	.accept = fi_no_accept,
-	.reject = fi_no_reject,
-	.shutdown = fi_no_shutdown,
-};
diff --git a/prov/mlx/src/mlx_cq.c b/prov/mlx/src/mlx_cq.c
deleted file mode 100644
index a0e9a5e..0000000
--- a/prov/mlx/src/mlx_cq.c
+++ /dev/null
@@ -1,58 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include <assert.h>
-#include "mlx.h"
-
-int mlx_cq_open (
-		struct fid_domain *domain, struct fi_cq_attr *attr,
-		struct fid_cq **cq_fid, void *context)
-{
-	int status = FI_SUCCESS;
-	struct util_cq *u_cq;
-
-	u_cq = calloc(1, sizeof(struct util_cq));
-	if (!u_cq) {
-		return -FI_ENOMEM;
-	}
-
-	status = ofi_cq_init(
-			&mlx_prov, domain, 
-			attr, u_cq, &ofi_cq_progress, context);
-	if (status) {
-		free(u_cq);
-		return status;
-	}
-
-	*cq_fid = &(u_cq->cq_fid);
-	return FI_SUCCESS;
-}
-
diff --git a/prov/mlx/src/mlx_domain.c b/prov/mlx/src/mlx_domain.c
deleted file mode 100644
index e20f95f..0000000
--- a/prov/mlx/src/mlx_domain.c
+++ /dev/null
@@ -1,143 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include "mlx.h"
-
-static int mlx_domain_close(fid_t fid)
-{
-	struct mlx_domain *domain;
-	int status;
-
-	domain = container_of( fid,
-				struct mlx_domain,
-				u_domain.domain_fid.fid);
-
-	ucp_cleanup(domain->context);
-	status = ofi_domain_close( &(domain->u_domain));
-	if (!status) {
-		ofi_bufpool_destroy(domain->fast_path_pool);
-		free(domain);
-	}
-	return status;
-}
-
-static struct fi_ops mlx_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = mlx_domain_close,
-};
-
-struct fi_ops_domain mlx_domain_ops = {
-	.size = sizeof(struct fi_ops_domain),
-	.av_open = mlx_av_open,
-	.cq_open = mlx_cq_open,
-	.endpoint = mlx_ep_open,
-	.poll_open = fi_poll_create,
-};
-
-
-struct fi_ops_mr mlx_mr_ops = {
-	.size = sizeof(struct fi_ops_mr),
-	.reg = fi_no_mr_reg,
-	.regv = fi_no_mr_regv,
-	.regattr = fi_no_mr_regattr,
-};
-
-int mlx_domain_open(struct fid_fabric *fabric, struct fi_info *info,
-                     struct fid_domain **fid, void *context)
-{
-	ucs_status_t status = UCS_OK;
-	int ofi_status;
-	struct mlx_domain* domain;
-	const ucp_params_t params = {
-		.features = UCP_FEATURE_TAG,
-		.request_size = sizeof(struct mlx_request),
-		.request_init = NULL,
-		.request_cleanup = NULL,
-		.field_mask = UCP_PARAM_FIELD_FEATURES |
-			      UCP_PARAM_FIELD_REQUEST_SIZE,
-	};
-
-	if (!info->domain_attr->name ||
-	    strcmp(info->domain_attr->name, FI_MLX_FABRIC_NAME)) {
-		return -FI_EINVAL;
-	}
-
-	ofi_status = ofi_prov_check_info(&mlx_util_prov,
-					 fabric->api_version,
-					 info);
-	if (ofi_status) {
-		return ofi_status;
-	}
-
-	domain = calloc(1, sizeof(struct mlx_domain));
-	if (!domain) {
-		return -ENOMEM;
-	}
-
-	ofi_status = ofi_domain_init(fabric, info,
-				     &(domain->u_domain), context);
-	if (ofi_status) {
-		goto domain_free;
-	}
-
-	status = ucp_init(&params, mlx_descriptor.config,
-			  &(domain->context));
-	if (status != UCS_OK) {
-		ofi_status = MLX_TRANSLATE_ERRCODE(status);
-		goto destroy_domain;
-	}
-	fastlock_init(&(domain->fpp_lock));
-
-	ofi_status = ofi_bufpool_create(&domain->fast_path_pool,
-					sizeof(struct mlx_request),
-					16, 0, 1024, 0);
-	if (ofi_status)
-		goto cleanup_mlx;
-
-	domain->u_domain.domain_fid.fid.ops = &mlx_fi_ops;
-	domain->u_domain.domain_fid.ops = &mlx_domain_ops;
-	domain->u_domain.domain_fid.mr = &mlx_mr_ops;
-
-	*fid = &(domain->u_domain.domain_fid);
-	return FI_SUCCESS;
-
-cleanup_mlx:
-	ucp_cleanup(domain->context);
-destroy_domain:
-	ofi_domain_close(&(domain->u_domain));
-domain_free:
-	free(domain);
-	if (!ofi_status) {
-		ofi_status = FI_ENETUNREACH;
-	}
-	return ofi_status;
-}
-
diff --git a/prov/mlx/src/mlx_ep.c b/prov/mlx/src/mlx_ep.c
deleted file mode 100644
index 6fef94b..0000000
--- a/prov/mlx/src/mlx_ep.c
+++ /dev/null
@@ -1,239 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include "mlx.h"
-
-static void mlx_ep_progress( struct util_ep *util_ep)
-{
-	struct mlx_ep *ep;
-	ep = container_of(util_ep, struct mlx_ep, ep);
-	ucp_worker_progress(ep->worker);
-}
-
-
-static ssize_t mlx_ep_cancel( fid_t fid, void *ctx)
-{
-	struct mlx_ep *ep;
-	void *req;
-	struct fi_context *context = (struct fi_context*)ctx;
-
-	ep = container_of( fid, struct mlx_ep, ep.ep_fid.fid);
-	if (!ep->ep.domain)
-		return -EBADF;
-	if (!context)
-		return -EINVAL;
-	if (context->internal[0] == NULL)
-		return -FI_EINVAL;
-
-	req = context->internal[0];
-	ucp_request_cancel(ep->worker, req);
-
-	return FI_SUCCESS;
-}
-
-static int mlx_ep_getopt( fid_t fid, int level, int optname,
-			void *optval, size_t *optlen)
-{
-	return -ENOSYS;
-}
-
-static int mlx_ep_setopt(fid_t fid, int level, int optname,
-		const void *optval, size_t optlen)
-{
-	return FI_SUCCESS;
-}
-
-static int mlx_ep_close(fid_t fid)
-{
-	struct mlx_ep *ep;
-	ucs_status_t status = UCS_OK;
-	void *addr_local = NULL;
-	size_t addr_len_local;
-
-	ep = container_of(fid, struct mlx_ep, ep.ep_fid.fid);
-
-	if (mlx_descriptor.use_ns) {
-		status = ucp_worker_get_address( ep->worker,
-						(ucp_address_t **)&addr_local,
-						(size_t*) &addr_len_local );
-		if (status != UCS_OK)
-			return MLX_TRANSLATE_ERRCODE(status);
-
-		ofi_ns_del_local_name(&mlx_descriptor.name_serv,
-					  &ep->service, addr_local);
-
-		ucp_worker_release_address(
-					ep->worker,
-					(ucp_address_t *)addr_local);
-	}
-
-	ucp_worker_flush(ep->worker);
-	ucp_worker_destroy(ep->worker);
-
-	ofi_endpoint_close(&ep->ep);
-	free(ep);
-	return FI_SUCCESS;
-}
-
-static int mlx_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
-{
-	struct mlx_ep *ep;
-	struct util_cq *cq;
-
-	ep = container_of(fid, struct mlx_ep, ep.ep_fid.fid);
-	int status = FI_SUCCESS;
-
-	switch (bfid->fclass) {
-	case FI_CLASS_CQ:
-		cq = container_of(bfid, struct util_cq, cq_fid.fid);
-		status = ofi_ep_bind_cq(&ep->ep, cq, flags);
-		break;
-	case FI_CLASS_AV:
-		if (ep->av) {
-			FI_WARN( &mlx_prov, FI_LOG_EP_CTRL,
-				"AV already binded\n");
-			status = -FI_EINVAL;
-			break;
-		}
-		ep->av = container_of(bfid, struct mlx_av, av.fid);
-		ep->av->ep = ep;
-		break;
-	default:
-		status = -FI_EINVAL;
-		break;
-	}
-	return status;
-}
-
-
-static int mlx_ep_control(fid_t fid, int command, void *arg)
-{
-
-	struct mlx_ep *ep;
-
-	ep = container_of(fid, struct mlx_ep, ep.ep_fid.fid);
-	switch (command) {
-	case FI_ENABLE:
-		if (!ep->ep.rx_cq || !ep->ep.tx_cq)
-			return -FI_ENOCQ;
-		if (!ep->av)
-			return -FI_EOPBADSTATE; /* TODO: Add FI_ENOAV */
-		break;
-	default:
-		return -FI_ENOSYS;
-	}
-	return FI_SUCCESS;
-}
-
-struct fi_ops_ep mlx_ep_ops = {
-	.size = sizeof(struct fi_ops_ep),
-	.cancel = mlx_ep_cancel,
-	.getopt = mlx_ep_getopt,
-	.setopt = mlx_ep_setopt,
-};
-
-static struct fi_ops mlx_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = mlx_ep_close,
-	.bind = mlx_ep_bind,
-	.control = mlx_ep_control,
-};
-
-int mlx_ep_open( struct fid_domain *domain, struct fi_info *info,
-		struct fid_ep **fid, void *context)
-{
-	struct mlx_ep     *ep;
-	struct mlx_domain *u_domain;
-	int ofi_status = FI_SUCCESS;
-	ucs_status_t status = UCS_OK;
-	ucp_worker_params_t worker_params = { };
-	worker_params.field_mask = UCP_WORKER_PARAM_FIELD_THREAD_MODE;
-	worker_params.thread_mode = UCS_THREAD_MODE_SINGLE;
-	u_domain = container_of( domain, struct mlx_domain, u_domain.domain_fid);
-
-	void *addr_local = NULL;
-	size_t addr_len_local;
-
-
-	ep = (struct mlx_ep *) calloc(1, sizeof (struct mlx_ep));
-	if (!ep) {
-		return -ENOMEM;
-	}
-
-	ofi_status = ofi_endpoint_init(domain, &mlx_util_prov, info,
-				       &ep->ep, context, mlx_ep_progress);
-	if (ofi_status) {
-		goto free_ep;
-	}
-
-	status = ucp_worker_create( u_domain->context,
-				&worker_params,
-				&(ep->worker));
-	if (status != UCS_OK) {
-		ofi_status = MLX_TRANSLATE_ERRCODE(status);
-		ofi_atomic_dec32(&(u_domain->u_domain.ref));
-		goto free_ep;
-	}
-
-	if (mlx_descriptor.use_ns) {
-		char tmpb [FI_MLX_MAX_NAME_LEN]={0};
-		status = ucp_worker_get_address( ep->worker,
-			(ucp_address_t **)&addr_local,
-			(size_t*) &addr_len_local );
-		if (status != UCS_OK)
-			return MLX_TRANSLATE_ERRCODE(status);
-		ep->service = (short)((getpid() & 0xFFFF ));
-		memcpy(tmpb,addr_local,addr_len_local);
-		FI_INFO(&mlx_prov, FI_LOG_CORE,
-			"PUBLISHED UCP address(size=%zd): [%hu] %s\n",
-			addr_len_local,ep->service,(char*)(addr_local));
-
-		ofi_ns_add_local_name(&mlx_descriptor.name_serv,
-			&ep->service, tmpb);
-
-		ucp_worker_release_address( ep->worker,
-			(ucp_address_t *)addr_local);
-	}
-
-	ep->ep.ep_fid.fid.ops = &mlx_fi_ops;
-	ep->ep.ep_fid.ops = &mlx_ep_ops;
-	ep->ep.ep_fid.cm = &mlx_cm_ops;
-	ep->ep.ep_fid.tagged = &mlx_tagged_ops;
-	ep->ep.flags = info->mode;
-	ep->ep.caps = u_domain->u_domain.info_domain_caps;
-
-	*fid = &(ep->ep.ep_fid);
-
-	return FI_SUCCESS;
-free_ep:
-	free(ep);
-	return ofi_status;
-}
diff --git a/prov/mlx/src/mlx_fabric.c b/prov/mlx/src/mlx_fabric.c
deleted file mode 100644
index f443da7..0000000
--- a/prov/mlx/src/mlx_fabric.c
+++ /dev/null
@@ -1,204 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-
-#include "mlx.h"
-
-int mlx_fabric_close(struct fid *fid)
-{
-	int status;
-
-	if (mlx_descriptor.use_ns)
-		ofi_ns_stop_server (&mlx_descriptor.name_serv);
-
-	status = ofi_fabric_close(
-			container_of(fid, struct util_fabric, fabric_fid.fid));
-	return status;
-}
-
-static struct fi_ops mlx_fabric_fi_ops = {
-	.size = sizeof(struct fi_ops),
-	.close = mlx_fabric_close,
-	.bind = fi_no_bind,
-	.control = fi_no_control,
-	.ops_open = fi_no_ops_open,
-};
-
-static struct fi_ops_fabric mlx_fabric_ops = {
-	.size = sizeof(struct fi_ops_fabric),
-	.domain = mlx_domain_open,
-	.passive_ep = fi_no_passive_ep,
-	.eq_open = ofi_eq_create,
-	.wait_open = ofi_wait_fd_open,
-	.trywait = fi_no_trywait,
-};
-
-int mlx_ns_service_cmp(void *svc1, void *svc2)
-{
-	int service1 = *(int *)svc1, service2 = *(int *)svc2;
-	if (service1 == FI_MLX_ANY_SERVICE ||
-	    service2 == FI_MLX_ANY_SERVICE)
-		return 0;
-	return (service1 < service2) ?
-		-1 : (service1 > service2);
-}
-
-int mlx_ns_is_service_wildcard(void *svc)
-{
-	return (*(int *)svc == FI_MLX_ANY_SERVICE);
-}
-
-#define MLX_IGNORED_LO_ADDR "127.0.0.1"
-static char* mlx_local_host_resolve()
-{
-	int status;
-	struct ifaddrs *ifaddr, *ifa;
-	char host[NI_MAXHOST];
-	char *iface = NULL;
-	char *result = NULL;
-
-	status = fi_param_get( &mlx_prov, "ns_iface",
-		&iface);
-	if (!status) {
-		iface = NULL;
-	}
-
-	if (-1 == getifaddrs(&ifaddr)) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"Unable to resolve local host address");
-		return NULL;
-	}
-
-	for (ifa = ifaddr; ifa != NULL; ifa = ifa->ifa_next) {
-		/*Ignore not IPv$ ifaces*/
-		if ((ifa->ifa_addr == NULL) ||
-				(ifa->ifa_addr->sa_family != AF_INET)) {
-			continue;
-		}
-
-		if (getnameinfo(ifa->ifa_addr, sizeof(struct sockaddr_in),
-				host, NI_MAXHOST,
-				NULL, 0, NI_NUMERICHOST) != 0) {
-			host[0] = '\0';
-			continue;
-		}
-
-		/*Skip loopback device*/
-		if (strncmp(host, MLX_IGNORED_LO_ADDR,
-				strlen(MLX_IGNORED_LO_ADDR))==0) {
-			host[0] = '\0';
-			continue;
-		}
-
-		/* If iface name is specified */
-		if (iface && strcmp(iface, ifa->ifa_name)!=0) {
-			host[0] = '\0';
-			continue;
-		}
-
-		result = strdup(host);
-		break;
-	}
-	if (result == NULL) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"No IPv4-compatible interface was found. (match mask:%s)",
-			iface?iface:"*");
-	}
-	freeifaddrs(ifaddr);
-	return result;
-}
-
-int mlx_ns_start ()
-{
-	if (!mlx_descriptor.localhost)
-		mlx_descriptor.localhost = mlx_local_host_resolve();
-
-	if (!mlx_descriptor.localhost) {
-		FI_INFO(&mlx_prov, FI_LOG_CORE,
-			"Unable to resolve local host address:\n"
-			"\t - unable to start NS\n"
-			"\t - Please try MLX-address format");
-		return -FI_EINVAL;
-	}
-
-	mlx_descriptor.name_serv.hostname = mlx_descriptor.localhost;
-	mlx_descriptor.name_serv.port = (int) mlx_descriptor.ns_port;
-	mlx_descriptor.name_serv.name_len = FI_MLX_MAX_NAME_LEN;
-	mlx_descriptor.name_serv.service_len = sizeof(short);
-	mlx_descriptor.name_serv.service_cmp = mlx_ns_service_cmp;
-	mlx_descriptor.name_serv.is_service_wildcard = mlx_ns_is_service_wildcard;
-
-	ofi_ns_init(&mlx_descriptor.name_serv);
-	ofi_ns_start_server(&mlx_descriptor.name_serv);
-
-	return FI_SUCCESS;
-}
-
-int mlx_fabric_open(
-		struct fi_fabric_attr *attr,
-		struct fid_fabric **fabric,
-		void *context)
-{
-	struct mlx_fabric *fabric_priv;
-	int status;
-
-	FI_INFO( &mlx_prov, FI_LOG_CORE, "\n" );
-
-	if (strcmp(attr->name, FI_MLX_FABRIC_NAME))
-		return -FI_ENODATA;
-
-	fabric_priv = calloc(1, sizeof(struct mlx_fabric));
-	if (!fabric_priv) {
-		return -FI_ENOMEM;
-	}
-
-	status = ofi_fabric_init(&mlx_prov, &mlx_fabric_attrs, attr,
-			 &(fabric_priv->u_fabric), context);
-	if (status) {
-		FI_INFO( &mlx_prov, FI_LOG_CORE,
-			"Error in ofi_fabric_init: %d\n", status);
-		free(fabric_priv);
-		return status;
-	}
-
-	fabric_priv->u_fabric.fabric_fid.fid.ops = &mlx_fabric_fi_ops;
-	fabric_priv->u_fabric.fabric_fid.ops = &mlx_fabric_ops;
-	*fabric = &(fabric_priv->u_fabric.fabric_fid);
-
-	if (mlx_descriptor.use_ns) {
-		if(mlx_ns_start() != FI_SUCCESS) {
-			free(fabric_priv);
-			return status;
-		}
-	}
-
-	return FI_SUCCESS;
-}
diff --git a/prov/mlx/src/mlx_init.c b/prov/mlx/src/mlx_init.c
deleted file mode 100644
index 99e3f89..0000000
--- a/prov/mlx/src/mlx_init.c
+++ /dev/null
@@ -1,293 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include "mlx.h"
-
-
-int mlx_errcode_translation_table[(-UCS_ERR_LAST)+2] = { -FI_EOTHER };
-
-struct mlx_global_descriptor mlx_descriptor = {
-	.config = NULL,
-	.use_ns = 0,
-	.ns_port = FI_MLX_DEFAULT_NS_PORT,
-	.localhost = NULL,
-};
-
-static int mlx_init_errcodes()
-{
-	MLX_TRANSLATE_ERRCODE (UCS_OK)                  = -FI_SUCCESS;
-	MLX_TRANSLATE_ERRCODE (UCS_INPROGRESS)          = -FI_EINPROGRESS;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_NO_MESSAGE)      = -FI_ENOMSG;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_NO_RESOURCE)     = -FI_EINVAL;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_IO_ERROR)        = -FI_EIO;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_NO_MEMORY)       = -FI_ENOMEM;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_INVALID_PARAM)   = -FI_EINVAL;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_UNREACHABLE)     = -FI_ENETUNREACH;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_INVALID_ADDR)    = -FI_EINVAL;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_NOT_IMPLEMENTED) = -FI_ENOSYS;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_MESSAGE_TRUNCATED) = -FI_EMSGSIZE;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_NO_PROGRESS)     = -FI_EAGAIN;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_BUFFER_TOO_SMALL)= -FI_ETOOSMALL;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_NO_ELEM)         = -FI_ENOENT;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_SOME_CONNECTS_FAILED)   = -FI_EIO;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_NO_DEVICE)       = -FI_ENODEV;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_BUSY)            = -FI_EBUSY;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_CANCELED)        = -FI_ECANCELED;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_SHMEM_SEGMENT)   = -FI_EINVAL;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_ALREADY_EXISTS)  = -EEXIST;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_OUT_OF_RANGE)    = -FI_EINVAL;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_TIMED_OUT)       = -FI_ETIMEDOUT;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_EXCEEDS_LIMIT)   = -FI_E2BIG;
-	MLX_TRANSLATE_ERRCODE (UCS_ERR_UNSUPPORTED)     = -FI_ENOSYS;
-	return 0;
-}
-
-
-struct fi_domain_attr mlx_domain_attrs = {
-	.domain = NULL,
-	.name = FI_MLX_FABRIC_NAME,
-	.threading = FI_THREAD_SAFE,
-	.control_progress = FI_PROGRESS_AUTO,
-	.data_progress = FI_PROGRESS_MANUAL,
-	.resource_mgmt = FI_RM_DISABLED,
-	.av_type = FI_AV_UNSPEC,
-	.mr_mode = OFI_MR_BASIC_MAP | FI_MR_BASIC,
-	.mr_key_size = -1, /*Should be setup after init*/
-	.tx_ctx_cnt = 1,
-	.rx_ctx_cnt = 1,
-	.max_ep_tx_ctx = 1,
-	.max_ep_rx_ctx = 1,
-	.mr_cnt = FI_MLX_DEF_MR_CNT,
-};
-
-struct fi_rx_attr mlx_rx_attrs = {
-	.caps = FI_MLX_CAPS,
-	.mode = FI_MLX_MODE_REQUIRED,
-	.op_flags = FI_MLX_OP_FLAGS,
-	.msg_order = FI_ORDER_SAS,
-	.comp_order = FI_ORDER_NONE,
-	.total_buffered_recv = ~(0ULL),
-	.size = UINT64_MAX,
-	.iov_limit = 1
-};
-
-struct fi_tx_attr mlx_tx_attrs = {
-	.caps = FI_MLX_CAPS,
-	.mode = FI_MLX_MODE_REQUIRED,
-	.op_flags = FI_MLX_OP_FLAGS,
-	.msg_order = FI_ORDER_SAS,
-	.comp_order = FI_ORDER_NONE,
-	.inject_size = FI_MLX_DEFAULT_INJECT_SIZE, /*Should be setup after init*/
-	.size = UINT64_MAX,
-	.iov_limit = 1,
-	.rma_iov_limit = 0
-};
-
-struct fi_fabric_attr mlx_fabric_attrs = {
-	.name = FI_MLX_FABRIC_NAME,
-	.prov_version = FI_MLX_VERSION,
-	.fabric = NULL
-};
-
-struct fi_ep_attr mlx_ep_attrs = {
-	.type = FI_EP_RDM,
-	.protocol = FI_PROTO_MLX,
-#if defined(UCP_API_RELEASE) && (UCP_API_RELEASE <= 2947)
-#warning "HPCX 1.9.7 have an issue with UCP_API_VERSION macro"
-	.protocol_version = (((UCP_API_MAJOR) << UCP_VERSION_MAJOR_SHIFT)|
-			((UCP_API_MINOR) << UCP_VERSION_MINOR_SHIFT)),
-#else
-	.protocol_version = (UCP_API_VERSION),
-#endif
-	.max_msg_size = 0xFFFFFFFF,
-	.mem_tag_format = 0x0,
-	.tx_ctx_cnt = 1,
-	.rx_ctx_cnt = 1,
-};
-
-
-struct fi_info mlx_info = {
-	.caps = FI_MLX_CAPS,
-	.mode = FI_MLX_MODE_REQUIRED,
-	.addr_format = FI_ADDR_MLX,
-	.src_addrlen = 0,
-	.dest_addr = 0,
-	.tx_attr = &mlx_tx_attrs,
-	.rx_attr = &mlx_rx_attrs,
-	.ep_attr = &mlx_ep_attrs,
-	.domain_attr = &mlx_domain_attrs,
-	.fabric_attr = &mlx_fabric_attrs
-};
-
-struct util_prov mlx_util_prov = {
-	.prov = &mlx_prov,
-	.info = &mlx_info,
-	.flags = 0,
-};
-
-
-static int mlx_getinfo (
-			uint32_t version, const char *node,
-			const char *service, uint64_t flags,
-			const struct fi_info *hints, struct fi_info **info)
-{
-	int status = -ENODATA;
-	char *configfile_name = NULL;
-	int inject_thresh = -1;
-
-	mlx_descriptor.config = NULL;
-
-	status = fi_param_get( &mlx_prov,
-				"tinject_limit",
-				&inject_thresh);
-	if (!status)
-		inject_thresh = FI_MLX_DEFAULT_INJECT_SIZE;
-
-	FI_INFO( &mlx_prov, FI_LOG_CORE,
-		"used inject size = %d \n", inject_thresh);
-
-	status = fi_param_get( &mlx_prov, "config", &configfile_name);
-	if (!status) {
-		configfile_name = NULL;
-	}
-
-	/* NS is disabled by default */
-	status = fi_param_get( &mlx_prov, "ns_enable",
-			&mlx_descriptor.use_ns);
-	if (!status) {
-		mlx_descriptor.use_ns = 0;
-	}
-	status = fi_param_get( &mlx_prov, "ns_port",
-			&mlx_descriptor.ns_port);
-	if (!status) {
-		mlx_descriptor.ns_port = FI_MLX_DEFAULT_NS_PORT;
-	}
-
-
-
-	status = ucp_config_read( NULL,
-			status? NULL: configfile_name,
-			&mlx_descriptor.config);
-	if (status != UCS_OK) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"MLX error: invalid config file\n\t%d (%s)\n",
-			status, ucs_status_string(status));
-	}
-
-	/*Setup some presets*/
-	status = ucm_config_modify("MALLOC_HOOKS", "no");
-	if (status != UCS_OK) {
-		FI_WARN( &mlx_prov, FI_LOG_CORE,
-			"MLX error: failed to switch off UCM memory hooks:\t%d (%s)\n",
-			status, ucs_status_string(status));
-	}
-
-	FI_INFO( &mlx_prov, FI_LOG_CORE,
-		"Loaded MLX version %s\n",
-		ucp_get_version_string());
-
-#if ENABLE_DEBUG
-	if (mlx_descriptor.config &&
-			fi_log_enabled( &mlx_prov, FI_LOG_INFO, FI_LOG_CORE)) {
-		ucp_config_print( mlx_descriptor.config,
-			stderr, "Used MLX configuration", (1<<4)-1);
-	}
-#endif
-
-	*info = NULL;
-	if (node || service) {
-		FI_WARN(&mlx_prov, FI_LOG_CORE,
-		"fi_getinfo with \"node != NULL \" or \"service != NULL \" is temporary not supported\n");
-		node = service = NULL;
-		flags = 0;
-	}
-
-	/* Only Pure MLX address and IPv4 are supported */
-	if (hints) {
-		if (hints->addr_format <= FI_SOCKADDR_IN) {
-			mlx_descriptor.use_ns = 1;
-			mlx_info.addr_format = FI_SOCKADDR_IN;
-		} else {
-			mlx_info.addr_format = FI_ADDR_MLX;
-		}
-	}
-	
-
-	status = util_getinfo( &mlx_util_prov, version,
-				service, node, flags, hints, info);
-
-	return status;
-}
-
-void mlx_cleanup(void)
-{
-	FI_INFO(&mlx_prov, FI_LOG_CORE, "provider goes cleanup sequence\n");
-	if (mlx_descriptor.config) {
-		ucp_config_release(mlx_descriptor.config);
-		mlx_descriptor.config = NULL;
-	}
-}
-
-
-struct fi_provider mlx_prov = {
-	.name = FI_MLX_FABRIC_NAME,
-	.version = FI_MLX_VERSION,
-	.fi_version = FI_VERSION(1, 8),
-	.getinfo = mlx_getinfo,
-	.fabric = mlx_fabric_open,
-	.cleanup = mlx_cleanup,
-};
-
-
-MLX_INI
-{
-	mlx_init_errcodes();
-	fi_param_define( &mlx_prov,
-			"config", FI_PARAM_STRING,
-			"MLX configuration file name");
-
-	fi_param_define(&mlx_prov,
-			"tinject_limit", FI_PARAM_INT,
-			"Maximal tinject message size");
-
-	fi_param_define(&mlx_prov,
-			"ns_port", FI_PARAM_INT,
-			"MLX Name server port");
-
-	fi_param_define(&mlx_prov,
-			"ns_enable",FI_PARAM_BOOL,
-			"Enforce usage of name server for MLX provider");
-
-	fi_param_define(&mlx_prov,
-			"ns_iface",FI_PARAM_STRING,
-			"Specify IPv4 network interface for MLX provider's name server'");
-	return &mlx_prov;
-}
diff --git a/prov/mlx/src/mlx_tagged.c b/prov/mlx/src/mlx_tagged.c
deleted file mode 100644
index afb3f09..0000000
--- a/prov/mlx/src/mlx_tagged.c
+++ /dev/null
@@ -1,360 +0,0 @@
-/*
- * Copyright (c) 2016 Intel Corporation. All rights reserved.
- *
- * This software is available to you under a choice of one of two
- * licenses.  You may choose to be licensed under the terms of the GNU
- * General Public License (GPL) Version 2, available from the file
- * COPYING in the main directory of this source tree, or the
- * OpenFabrics.org BSD license below:
- *
- *     Redistribution and use in source and binary forms, with or
- *     without modification, are permitted provided that the following
- *     conditions are met:
- *
- *      - Redistributions of source code must retain the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer.
- *
- *      - Redistributions in binary form must reproduce the above
- *        copyright notice, this list of conditions and the following
- *        disclaimer in the documentation and/or other materials
- *        provided with the distribution.
- *
- * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
- * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
- * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
- * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
- * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
- * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
- * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
- * SOFTWARE.
- */
-#include "mlx.h"
-
-#define __mlx_get_dstep_from_fi_addr(EP, ADDR) ((ucp_ep_h)(ADDR))
-
-static ssize_t mlx_tagged_recvmsg(
-				struct fid_ep *ep,
-				const struct fi_msg_tagged *msg,
-				uint64_t flags)
-{
-	ucs_status_ptr_t status = NULL;
-	ucp_tag_recv_callback_t cbf;
-	struct mlx_ep *u_ep;
-	struct mlx_request *req;
-	struct util_cq *cq;
-	u_ep = container_of(ep, struct mlx_ep, ep.ep_fid);
-
-	if (flags & FI_REMOTE_CQ_DATA) {
-		return -FI_EBADFLAGS;
-	}
-
-	cbf = ((!(u_ep->ep.rx_op_flags & FI_SELECTIVE_COMPLETION)) 
-			|| (flags & FI_COMPLETION)) ? 
-				mlx_recv_callback : mlx_recv_callback_no_compl;
-
-	if (msg->iov_count == 1) {
-		status = ucp_tag_recv_nb(u_ep->worker, msg->msg_iov[0].iov_base,
-					 msg->msg_iov[0].iov_len,
-					 ucp_dt_make_contig(1),
-					 msg->tag, (~(msg->ignore)), cbf);
-	} else {
-		return -FI_EINVAL; /*Do not return IOV for a while*/
-	}
-
-	if (UCS_PTR_IS_ERR(status)) {
-		FI_DBG( &mlx_prov,FI_LOG_CORE,
-			"Send operation returns error: %s",
-			ucs_status_string(*(ucs_status_t*)status));
-		return MLX_TRANSLATE_ERRCODE(*(ucs_status_t*)status);
-	}
-
-	req = (struct mlx_request *)status;
-	cq = u_ep->ep.rx_cq;
-	req->cq = cq;
-	req->ep =u_ep;
-
-	if (msg->context) {
-		struct fi_context *_ctx =
-			((struct fi_context *)(msg->context));
-		_ctx->internal[0] = (void*)req;
-	}
-	req->completion.tagged.op_context = msg->context;
-	req->completion.tagged.flags = FI_RECV;
-	req->completion.tagged.buf = msg->msg_iov[0].iov_base;
-	req->completion.tagged.data = 0;
-
-	if (req->type == MLX_FI_REQ_UNINITIALIZED) {
-		req->type = MLX_FI_REQ_REGULAR;
-		req->completion.tagged.tag = msg->tag;
-		req->completion.tagged.len = msg->msg_iov[0].iov_len;
-		goto fence;
-	}
-
-	/*Unexpected path*/
-	struct fi_cq_tagged_entry *t_entry;
-	fastlock_acquire(&cq->cq_lock);
-	t_entry = ofi_cirque_tail(cq->cirq);
-	*t_entry = (req->completion.tagged);
-
-	if (req->type == MLX_FI_REQ_UNEXPECTED_ERR) {
-		struct util_cq_oflow_err_entry* err;
-		req->completion.error.olen -= req->completion.tagged.len;
-		t_entry->flags |= UTIL_FLAG_ERROR;
-
-		err = calloc(1, sizeof(struct util_cq_oflow_err_entry));
-		if (!err) {
-			FI_WARN(&mlx_prov, FI_LOG_CQ,
-				"out of memory, cannot report CQ error\n");
-			fastlock_release(&cq->cq_lock);
-			return -FI_ENOMEM;
-		}
-		err->comp = (req->completion.error);
-		slist_insert_tail(&err->list_entry, &cq->oflow_err_list);
-	}
-
-	ofi_cirque_commit(cq->cirq);
-	fastlock_release(&cq->cq_lock);
-
-fence:
-	if (flags & FI_FENCE) {
-		ucs_status_t cstatus;
-		cstatus = ucp_worker_flush(u_ep->worker);
-		if (status != UCS_OK)
-			return MLX_TRANSLATE_ERRCODE(cstatus);
-	}
-	return FI_SUCCESS;
-}
-
-static ssize_t mlx_tagged_sendmsg(
-				struct fid_ep *ep,
-				const struct fi_msg_tagged *msg,
-				uint64_t flags)
-{
-	struct mlx_ep* u_ep;
-	ucp_send_callback_t cbf;
-	ucp_ep_h dst_ep;
-	ucs_status_ptr_t status = NULL;
-	ucs_status_t cstatus;
-	struct util_cq *cq;
-	ucp_tag_recv_info_t info;
-
-	u_ep = container_of(ep, struct mlx_ep, ep.ep_fid);
-	dst_ep = __mlx_get_dstep_from_fi_addr(u_ep, msg->addr);
-	cq = u_ep->ep.tx_cq;
-
-	if(flags & FI_REMOTE_CQ_DATA) {
-		return -FI_EBADFLAGS;
-	}
-
-	cbf = ((!(u_ep->ep.tx_op_flags & FI_SELECTIVE_COMPLETION)) 
-			|| (flags & FI_COMPLETION)) ? 
-				mlx_send_callback : mlx_send_callback_no_compl;
-	if (msg->iov_count == 1) {
-		if (flags & FI_TRANSMIT_COMPLETE) {
-			status = ucp_tag_send_sync_nb (
-						dst_ep,
-						msg->msg_iov[0].iov_base,
-						msg->msg_iov[0].iov_len,
-						ucp_dt_make_contig(1),
-						msg->tag, cbf);
-		} else {
-			status = ucp_tag_send_nb(
-						dst_ep,
-						msg->msg_iov[0].iov_base,
-						msg->msg_iov[0].iov_len,
-						ucp_dt_make_contig(1),
-						msg->tag, cbf);
-		}
-	} else {
-		return -FI_EINVAL; /*Do not return IOV for a while*/
-	}
-
-	if (UCS_PTR_IS_ERR(status)) {
-		FI_DBG( &mlx_prov,FI_LOG_CORE,
-			"Send operation returns error: %s",
-			ucs_status_string(*(ucs_status_t*)status));
-		return MLX_TRANSLATE_ERRCODE(*(ucs_status_t*)status);
-	}
-
-	if ((flags & FI_INJECT) && (UCS_PTR_STATUS(status) == UCS_OK)) {
-		while (ucp_request_test(status, &info) != UCS_INPROGRESS)
-			ucp_worker_progress(u_ep->worker);
-		goto fence;
-	}
-
-	if((u_ep->ep.tx_op_flags & FI_SELECTIVE_COMPLETION)
-			&& !(flags & FI_COMPLETION)) {
-		goto fence;
-	}
-
-	if (msg->context) {
-		struct fi_context* _ctx =
-			((struct fi_context*)(msg->context));
-		_ctx->internal[0] = status;
-	}
-
-	if (UCS_PTR_STATUS(status) != UCS_OK) {
-		struct mlx_request *req;
-		req = (struct mlx_request *) status;
-		req->cq = cq;
-		req->ep = u_ep;
-		req->type = MLX_FI_REQ_REGULAR;
-		req->completion.tagged.op_context = msg->context;
-		req->completion.tagged.flags = FI_SEND;
-		req->completion.tagged.len = msg->msg_iov[0].iov_len;
-		req->completion.tagged.buf = msg->msg_iov[0].iov_base;
-		req->completion.tagged.data = 0;
-		req->completion.tagged.tag = msg->tag;
-	} else {
-		struct fi_cq_tagged_entry *t_entry;
-		fastlock_acquire(&cq->cq_lock);
-		t_entry = ofi_cirque_tail(cq->cirq);
-		t_entry->op_context = msg->context;
-		t_entry->flags = FI_SEND;
-		t_entry->len = msg->msg_iov[0].iov_len;
-		t_entry->buf = msg->msg_iov[0].iov_base;
-		t_entry->data = 0;
-		t_entry->tag = msg->tag;
-		ofi_cirque_commit(cq->cirq);
-		fastlock_release(&cq->cq_lock);
-	}
-
-fence:
-	if(flags & FI_FENCE) {
-		cstatus = ucp_worker_flush(u_ep->worker);
-		if(status != UCS_OK) {
-			return MLX_TRANSLATE_ERRCODE(cstatus);
-		}
-	}
-	return FI_SUCCESS;
-}
-
-
-static ssize_t mlx_tagged_inject(
-			struct fid_ep *ep, const void *buf, size_t len,
-			fi_addr_t dest_addr, uint64_t tag)
-{
-	struct mlx_ep* u_ep;
-	ucp_ep_h dst_ep;
-	ucs_status_ptr_t status = NULL;
-	ucp_tag_recv_info_t info;
-
-	u_ep = container_of(ep, struct mlx_ep, ep.ep_fid);
-	dst_ep = __mlx_get_dstep_from_fi_addr(u_ep, dest_addr);
-
-	status = ucp_tag_send_nb(dst_ep, buf, len,
-				 ucp_dt_make_contig(1),
-				 tag, mlx_send_callback_no_compl);
-	if (UCS_PTR_STATUS(status) == UCS_OK)
-		return FI_SUCCESS;
-
-	if (UCS_PTR_IS_ERR(status)) {
-		FI_DBG( &mlx_prov,FI_LOG_CORE,
-			"Send operation returns error: %s",
-			ucs_status_string(*(ucs_status_t*)status));
-		return MLX_TRANSLATE_ERRCODE(*(ucs_status_t*)status);
-	}
-
-	/* `info` is left unitialized, because this is send operation */
-	while (ucp_request_test(status, &info) != UCS_INPROGRESS)
-		ucp_worker_progress(u_ep->worker);
-
-	return FI_SUCCESS;
-}
-
-static ssize_t mlx_tagged_send(
-				struct fid_ep *ep, const void *buf,
-				size_t len, void *desc,
-				fi_addr_t dest_addr,
-				uint64_t tag, void *context)
-{
-	struct iovec iov = {
-		.iov_base = (void*)buf,
-		.iov_len = len,
-	};
-
-	struct fi_msg_tagged msg = {
-		.msg_iov = &iov,
-		.desc = desc,
-		.iov_count = 1,
-		.addr = dest_addr,
-		.tag = tag,
-		.context = context,
-	};
-
-	return mlx_tagged_sendmsg( ep, &msg, 0);
-}
-
-static ssize_t mlx_tagged_sendv(
-				struct fid_ep *ep, const struct iovec *iov,
-				void **desc,
-				size_t count, fi_addr_t dest_addr,
-				uint64_t tag, void *context)
-{
-	struct fi_msg_tagged msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = dest_addr,
-		.tag = tag,
-		.context = context,
-	};
-
-	return mlx_tagged_sendmsg( ep, &msg, 0);
-}
-
-static ssize_t mlx_tagged_recvv(
-			struct fid_ep *ep, const struct iovec *iov, void **desc,
-			size_t count, fi_addr_t src_addr,
-			uint64_t tag, uint64_t ignore, void *context)
-{
-	struct fi_msg_tagged msg = {
-		.msg_iov = iov,
-		.desc = desc,
-		.iov_count = count,
-		.addr = src_addr,
-		.tag = tag,
-		.ignore = ignore,
-		.context = context,
-	};
-	return mlx_tagged_recvmsg(ep, &msg, 0);
-}
-
-static ssize_t mlx_tagged_recv(
-			struct fid_ep *ep, void *buf, size_t len, void *desc,
-			fi_addr_t src_addr,
-			uint64_t tag,
-			uint64_t ignore,
-			void *context)
-{
-	struct iovec iov = {
-		.iov_base = buf,
-		.iov_len = len,
-	};
-
-	struct fi_msg_tagged msg = {
-		.msg_iov = &iov,
-		.desc = desc,
-		.iov_count = 1,
-		.addr = src_addr,
-		.tag = tag,
-		.ignore = ignore,
-		.context = context,
-	};
-	return mlx_tagged_recvmsg(ep, &msg, 0);
-}
-
-struct fi_ops_tagged mlx_tagged_ops = {
-	.size = sizeof(struct fi_ops_tagged),
-	.recv = mlx_tagged_recv,
-	.recvv = mlx_tagged_recvv,
-	.recvmsg = mlx_tagged_recvmsg,
-	.send = mlx_tagged_send,
-	.senddata = fi_no_tagged_senddata,
-	.sendv = mlx_tagged_sendv,
-	.inject = mlx_tagged_inject,
-	.sendmsg = mlx_tagged_sendmsg,
-	.injectdata = fi_no_tagged_injectdata,
-};
-
diff --git a/prov/mrail/src/TODO b/prov/mrail/src/TODO
deleted file mode 100644
index ec6f166..0000000
--- a/prov/mrail/src/TODO
+++ /dev/null
@@ -1,28 +0,0 @@
-TODO:
------
-
-Feature / issue				Status
-----------------------------------------------------
-CQ					in-progress
-AV					in-progress
-EP					in-progress
-small msgs (un-ordered)			in-progress
-support for multiple layering		-
-(above is needed for multi-rail
- over ofi_rxm provider)
-OFI_MULTI_RAIL env var			-
-fi_dupinfo issue			-
-App mode bit to make it aware		-
-of list of rails in fi_info
-addressing:				-
-	- FI_ADDR_STRV
-	- primary/failover
-small msg ordering:			-
-	- bounce buffers
-large msg support:			-
-	- use FI_VARIABLE_MSG
-Memory registration			-
-RMA					-
-rail failure handling			-
-rail selection / striping algorithm	-
-Atomics					-
diff --git a/prov/mrail/src/mrail_init.c b/prov/mrail/src/mrail_init.c
index bc58b28..b08ba56 100644
--- a/prov/mrail/src/mrail_init.c
+++ b/prov/mrail/src/mrail_init.c
@@ -101,17 +101,26 @@ static int mrail_parse_env_vars(void)
 		mrail_num_config = i;
 	}
 
-	fi_param_define(&mrail_prov, "addr_strc", FI_PARAM_STRING, "List of rail"
-			" addresses of format FI_ADDR_STR delimited by comma");
-	ret = fi_param_get_str(&mrail_prov, "addr_strc", &addr_strc);
+	fi_param_define(&mrail_prov, "addr_strc", FI_PARAM_STRING, "Deprecated. "
+			"Replaced by FI_OFI_MRAIL_ADDR.");
+
+	fi_param_define(&mrail_prov, "addr", FI_PARAM_STRING, "Comma separated list "
+			"of rail addresses (FI_ADDR_STR, host name, IP address, or "
+			"netdev interface name)");
+
+	ret = fi_param_get_str(&mrail_prov, "addr", &addr_strc);
+	if (ret)
+		ret = fi_param_get_str(&mrail_prov, "addr_strc", &addr_strc);
 	if (ret) {
-		FI_WARN(&mrail_prov, FI_LOG_CORE, "Unable to read "
-			"OFI_MRAIL_ADDR_STRC env variable\n");
+		FI_INFO(&mrail_prov, FI_LOG_CORE, "unable to read "
+			"FI_OFI_MRAIL_ADDR env variable\n");
 		return ret;
 	}
 	mrail_addr_strv = mrail_split_addr_strc(addr_strc);
-	if (!mrail_addr_strv)
+	if (!mrail_addr_strv) {
+		FI_WARN(&mrail_prov, FI_LOG_CORE, "unable to alloc memory\n");
 		return -FI_ENOMEM;
+	}
 
 	/*
 	 * Local rank is used to set the default tx rail when fixed mapping
@@ -271,10 +280,13 @@ static int mrail_get_core_info(uint32_t version, const char *node, const char *s
 	size_t i;
 	int ret = 0;
 	int num_rails;
+	enum fi_log_level level = ((hints && hints->fabric_attr &&
+				    hints->fabric_attr->prov_name) ?
+				   FI_LOG_WARN : FI_LOG_INFO);
 
 	if (!mrail_addr_strv) {
-		FI_WARN(&mrail_prov, FI_LOG_FABRIC,
-			"OFI_MRAIL_ADDR_STRC env variable not set!\n");
+		FI_LOG(&mrail_prov, level, FI_LOG_FABRIC,
+		       "OFI_MRAIL_ADDR_STRC env variable not set!\n");
 		return -FI_ENODATA;
 	}
 
@@ -485,7 +497,7 @@ static void mrail_fini(void)
 struct fi_provider mrail_prov = {
 	.name = OFI_UTIL_PREFIX "mrail",
 	.version = FI_VERSION(MRAIL_MAJOR_VERSION, MRAIL_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = mrail_getinfo,
 	.fabric = mrail_fabric_open,
 	.cleanup = mrail_fini
diff --git a/prov/netdir/src/netdir_init.c b/prov/netdir/src/netdir_init.c
index 1af1eca..c646d26 100644
--- a/prov/netdir/src/netdir_init.c
+++ b/prov/netdir/src/netdir_init.c
@@ -48,7 +48,7 @@ const char ofi_nd_prov_name[] = "netdir";
 struct fi_provider ofi_nd_prov = {
 	.name = ofi_nd_prov_name,
 	.version = FI_VERSION(OFI_ND_MAJOR_VERSION, OFI_ND_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = ofi_nd_getinfo,
 	.fabric = ofi_nd_fabric,
 	.cleanup = ofi_nd_fini
diff --git a/prov/psm/src/psmx.h b/prov/psm/src/psmx.h
index 85bebc6..be493e8 100644
--- a/prov/psm/src/psmx.h
+++ b/prov/psm/src/psmx.h
@@ -76,7 +76,7 @@ extern struct fi_provider psmx_prov;
 
 extern int psmx_am_compat_mode;
 
-#define PSMX_VERSION	(FI_VERSION(1, 8))
+#define PSMX_VERSION	(OFI_VERSION_LATEST)
 
 #define PSMX_OP_FLAGS	(FI_INJECT | FI_MULTI_RECV | FI_COMPLETION | \
 			 FI_TRIGGER | FI_INJECT_COMPLETE | \
diff --git a/prov/psm2/src/psmx2.h b/prov/psm2/src/psmx2.h
index 655636b..20b8ee9 100644
--- a/prov/psm2/src/psmx2.h
+++ b/prov/psm2/src/psmx2.h
@@ -83,7 +83,7 @@ extern "C" {
 
 extern struct fi_provider psmx2_prov;
 
-#define PSMX2_VERSION	(FI_VERSION(1, 8))
+#define PSMX2_VERSION	(OFI_VERSION_LATEST)
 
 #define PSMX2_OP_FLAGS	(FI_INJECT | FI_MULTI_RECV | FI_COMPLETION | \
 			 FI_TRIGGER | FI_INJECT_COMPLETE | \
@@ -827,9 +827,6 @@ struct psmx2_env {
 	int	prog_interval;
 	char	*prog_affinity;
 	int	multi_ep;
-	int	max_trx_ctxt;
-	int	free_trx_ctxt;
-	int	num_devunits;
 	int	inject_size;
 	int	lock_level;
 	int	lazy_conn;
@@ -839,6 +836,19 @@ struct psmx2_env {
 #endif
 };
 
+#define PSMX2_MAX_UNITS	4
+struct psmx2_hfi_info {
+	int max_trx_ctxt;
+	int free_trx_ctxt;
+	int num_units;
+	int num_active_units;
+	int active_units[PSMX2_MAX_UNITS];
+	int unit_is_active[PSMX2_MAX_UNITS];
+	int unit_nctxts[PSMX2_MAX_UNITS];
+	int unit_nfreectxts[PSMX2_MAX_UNITS];
+	char default_domain_name[PSMX2_MAX_UNITS * 8]; /* hfi1_0;hfi1_1;...;hfi1_n */
+};
+
 extern struct fi_ops_mr		psmx2_mr_ops;
 extern struct fi_ops_cm		psmx2_cm_ops;
 extern struct fi_ops_tagged	psmx2_tagged_ops;
@@ -863,6 +873,7 @@ extern struct fi_ops_msg	psmx2_msg2_ops;
 extern struct fi_ops_rma	psmx2_rma_ops;
 extern struct fi_ops_atomic	psmx2_atomic_ops;
 extern struct psmx2_env		psmx2_env;
+extern struct psmx2_hfi_info	psmx2_hfi_info;
 extern struct psmx2_fid_fabric	*psmx2_active_fabric;
 
 /*
@@ -1211,6 +1222,14 @@ static inline void psmx2_am_poll(struct psmx2_trx_ctxt *trx_ctxt)
 	}
 }
 
+static inline int psmx2_peer_match(struct dlist_entry *item, const void *arg)
+{
+	struct psmx2_epaddr_context *peer;
+
+	peer = container_of(item, struct psmx2_epaddr_context, entry);
+	return  (peer->epaddr == arg);
+}
+
 #ifdef __cplusplus
 }
 #endif
diff --git a/prov/psm2/src/psmx2_atomic.c b/prov/psm2/src/psmx2_atomic.c
index 108735f..576e922 100644
--- a/prov/psm2/src/psmx2_atomic.c
+++ b/prov/psm2/src/psmx2_atomic.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
diff --git a/prov/psm2/src/psmx2_attr.c b/prov/psm2/src/psmx2_attr.c
index 9f6ba04..accd09b 100644
--- a/prov/psm2/src/psmx2_attr.c
+++ b/prov/psm2/src/psmx2_attr.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -72,9 +72,9 @@ static struct fi_ep_attr psmx2_ep_attr = {
 	.type			= FI_EP_RDM, /* FI_EP_DGRAM */
 	.protocol		= FI_PROTO_PSMX2,
 	.protocol_version	= PSM2_VERNO,
-	.max_msg_size		= PSMX2_MAX_MSG_SIZE,
+	.max_msg_size		= PSMX2_MAX_MSG_SIZE & ~0x0FFF,
 	.msg_prefix_size	= 0,
-	.max_order_raw_size	= PSMX2_MAX_MSG_SIZE,
+	.max_order_raw_size	= PSMX2_RMA_ORDER_SIZE,
 	.max_order_war_size	= PSMX2_RMA_ORDER_SIZE,
 	.max_order_waw_size	= PSMX2_RMA_ORDER_SIZE,
 	.mem_tag_format		= FI_TAG_GENERIC, /* >>= 4 */
@@ -97,11 +97,11 @@ static struct fi_domain_attr psmx2_domain_attr = {
 	.cq_data_size		= 0, /* 4, 8 */
 	.cq_cnt			= 65535,
 	.ep_cnt			= 65535,
-	.tx_ctx_cnt		= 1, /* psmx2_env.free_trx_ctxt */
-	.rx_ctx_cnt		= 1, /* psmx2_env.free_trx_ctxt */
-	.max_ep_tx_ctx		= 1, /* psmx2_env.max_trx_ctxt */
-	.max_ep_rx_ctx		= 1, /* psmx2_env.max_trx_ctxt */
-	.max_ep_stx_ctx		= 1, /* psmx2_env.max_trx_ctxt */
+	.tx_ctx_cnt		= 1, /* psmx2_hfi_info.free_trx_ctxt */
+	.rx_ctx_cnt		= 1, /* psmx2_hfi_info.free_trx_ctxt */
+	.max_ep_tx_ctx		= 1, /* psmx2_hfi_info.max_trx_ctxt */
+	.max_ep_rx_ctx		= 1, /* psmx2_hfi_info.max_trx_ctxt */
+	.max_ep_stx_ctx		= 1, /* psmx2_hfi_info.max_trx_ctxt */
 	.max_ep_srx_ctx		= 0,
 	.cntr_cnt		= 65535,
 	.mr_iov_limit		= 65535,
@@ -182,7 +182,7 @@ int psmx2_init_prov_info(const struct fi_info *hints, struct fi_info **info)
 	}
 
 	if (hints->domain_attr && hints->domain_attr->name &&
-	    strcasecmp(hints->domain_attr->name, domain_attr->name)) {
+	    strncasecmp(hints->domain_attr->name, domain_attr->name, strlen(PSMX2_DOMAIN_NAME))) {
 		FI_INFO(&psmx2_prov, FI_LOG_CORE, "Unknown domain name\n");
 		FI_INFO_NAME(&psmx2_prov, domain_attr, hints->domain_attr);
 		return -FI_ENODATA;
@@ -304,22 +304,78 @@ static void psmx2_dup_addr(int format, struct psmx2_ep_name *addr,
 	}
 }
 
+static void psmx2_expand_default_unit(struct fi_info *info)
+{
+	struct fi_info *p, *next;
+	struct psmx2_ep_name *src_addr;
+	int i;
+
+	p = info;
+	while (p) {
+		next = p->next;
+		src_addr = p->src_addr;
+		if (src_addr->unit == PSMX2_DEFAULT_UNIT) {
+			if (psmx2_hfi_info.num_active_units == 1) {
+				src_addr->unit = psmx2_hfi_info.active_units[0];
+			} else {
+				for (i = 0; i < psmx2_hfi_info.num_active_units; i++) {
+					p->next = fi_dupinfo(p);
+					if (!p->next) {
+						FI_WARN(&psmx2_prov, FI_LOG_CORE,
+							"Failed to duplicate info for HFI unit %d\n",
+							psmx2_hfi_info.active_units[i]);
+						break;
+					}
+					p = p->next;
+					src_addr = p->src_addr;
+					src_addr->unit = psmx2_hfi_info.active_units[i];
+				}
+			}
+		}
+		p->next = next;
+		p = next;
+	}
+}
+
 void psmx2_update_prov_info(struct fi_info *info,
 			    struct psmx2_ep_name *src_addr,
 			    struct psmx2_ep_name *dest_addr)
 {
-	for ( ; info; info = info->next) {
-		psmx2_dup_addr(info->addr_format, src_addr,
-			       &info->src_addr, &info->src_addrlen);
-		psmx2_dup_addr(info->addr_format, dest_addr,
-			       &info->dest_addr, &info->dest_addrlen);
-
-		info->domain_attr->tx_ctx_cnt = psmx2_env.free_trx_ctxt;
-		info->domain_attr->rx_ctx_cnt = psmx2_env.free_trx_ctxt;
-		info->domain_attr->max_ep_tx_ctx = psmx2_env.max_trx_ctxt;
-		info->domain_attr->max_ep_rx_ctx = psmx2_env.max_trx_ctxt;
-		info->domain_attr->max_ep_stx_ctx = psmx2_env.max_trx_ctxt;
-		info->tx_attr->inject_size = psmx2_env.inject_size;
+	struct fi_info *p;
+
+	for (p = info; p; p = p->next) {
+		psmx2_dup_addr(p->addr_format, src_addr,
+			       &p->src_addr, &p->src_addrlen);
+		psmx2_dup_addr(p->addr_format, dest_addr,
+			       &p->dest_addr, &p->dest_addrlen);
+	}
+
+	psmx2_expand_default_unit(info);
+
+	for (p = info; p; p = p->next) {
+		int unit = ((struct psmx2_ep_name *)p->src_addr)->unit;
+
+		if (unit == PSMX2_DEFAULT_UNIT || !psmx2_env.multi_ep) {
+			p->domain_attr->tx_ctx_cnt = psmx2_hfi_info.free_trx_ctxt;
+			p->domain_attr->rx_ctx_cnt = psmx2_hfi_info.free_trx_ctxt;
+			p->domain_attr->max_ep_tx_ctx = psmx2_hfi_info.max_trx_ctxt;
+			p->domain_attr->max_ep_rx_ctx = psmx2_hfi_info.max_trx_ctxt;
+			p->domain_attr->max_ep_stx_ctx = psmx2_hfi_info.max_trx_ctxt;
+		} else {
+			p->domain_attr->tx_ctx_cnt = psmx2_hfi_info.unit_nfreectxts[unit];
+			p->domain_attr->rx_ctx_cnt = psmx2_hfi_info.unit_nfreectxts[unit];
+			p->domain_attr->max_ep_tx_ctx = psmx2_hfi_info.unit_nctxts[unit];
+			p->domain_attr->max_ep_rx_ctx = psmx2_hfi_info.unit_nctxts[unit];
+			p->domain_attr->max_ep_stx_ctx = psmx2_hfi_info.unit_nctxts[unit];
+		}
+
+		free(p->domain_attr->name);
+		if (unit == PSMX2_DEFAULT_UNIT)
+			p->domain_attr->name = strdup(psmx2_hfi_info.default_domain_name);
+		else
+			asprintf(&p->domain_attr->name, "hfi1_%d", unit);
+
+		p->tx_attr->inject_size = psmx2_env.inject_size;
 	}
 }
 
diff --git a/prov/psm2/src/psmx2_av.c b/prov/psm2/src/psmx2_av.c
index bb4fd61..ee499c5 100644
--- a/prov/psm2/src/psmx2_av.c
+++ b/prov/psm2/src/psmx2_av.c
@@ -169,12 +169,14 @@ static void psmx2_set_epaddr_context(struct psmx2_trx_ctxt *trx_ctxt,
 				     psm2_epid_t epid, psm2_epaddr_t epaddr)
 {
 	struct psmx2_epaddr_context *context;
+	struct psmx2_epaddr_context *old_context = NULL;
 
 	context = (void *)psm2_epaddr_getctxt(epaddr);
 	if (context) {
 		if (context->trx_ctxt != trx_ctxt || context->epid != epid) {
 			FI_WARN(&psmx2_prov, FI_LOG_AV,
 				"trx_ctxt or epid doesn't match\n");
+			old_context = context;
 			context = NULL;
 		}
 	}
@@ -193,6 +195,7 @@ static void psmx2_set_epaddr_context(struct psmx2_trx_ctxt *trx_ctxt,
 	context->epid = epid;
 	context->epaddr = epaddr;
 	psm2_epaddr_setctxt(epaddr, context);
+	free(old_context);
 
 	trx_ctxt->domain->peer_lock_fn(&trx_ctxt->peer_lock, 2);
 	dlist_insert_before(&context->entry, &trx_ctxt->peer_list);
@@ -620,6 +623,7 @@ static int psmx2_av_disconnect_addr(int trx_ctxt_id, psm2_epid_t epid,
 				    psm2_epaddr_t epaddr)
 {
 	struct psmx2_epaddr_context *epaddr_context;
+	struct psmx2_trx_ctxt *trx_ctxt;
 	psm2_error_t errors;
 	int err;
 
@@ -633,15 +637,24 @@ static int psmx2_av_disconnect_addr(int trx_ctxt_id, psm2_epid_t epid,
 	if (!epaddr_context)
 		return -FI_EINVAL;
 
-	if (trx_ctxt_id != epaddr_context->trx_ctxt->id)
+	trx_ctxt = epaddr_context->trx_ctxt;
+	if (trx_ctxt_id != trx_ctxt->id)
 		return -FI_EINVAL;
 
 	if (epid != epaddr_context->epid)
 		return -FI_EINVAL;
 
-	err = psm2_ep_disconnect2(epaddr_context->trx_ctxt->psm2_ep, 1, &epaddr,
+	trx_ctxt->domain->peer_lock_fn(&trx_ctxt->peer_lock, 2);
+	dlist_remove_first_match(&trx_ctxt->peer_list,
+				 psmx2_peer_match, epaddr);
+	trx_ctxt->domain->peer_unlock_fn(&trx_ctxt->peer_lock, 2);
+
+	psm2_epaddr_setctxt(epaddr, NULL);
+
+	err = psm2_ep_disconnect2(trx_ctxt->psm2_ep, 1, &epaddr,
 				  NULL, &errors, PSM2_EP_DISCONNECT_FORCE, 0);
 
+	free(epaddr_context);
 	return psmx2_errno(err);
 }
 
@@ -919,6 +932,7 @@ static int psmx2_av_close(fid_t fid)
 		free(av->hdr);
 	}
 
+	free(av->sep_info);
 out:
 	free(av);
 	return 0;
@@ -1036,7 +1050,7 @@ int psmx2_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 	if (av_type == FI_AV_MAP)
 		conn_size = 0;
 	else
-		conn_size = psmx2_env.max_trx_ctxt * sizeof(struct psmx2_av_conn);
+		conn_size = psmx2_hfi_info.max_trx_ctxt * sizeof(struct psmx2_av_conn);
 
 	av_priv = (struct psmx2_fid_av *) calloc(1, sizeof(*av_priv) + conn_size);
 	if (!av_priv)
@@ -1099,7 +1113,7 @@ init_lock:
 	av_priv->count = count;
 	av_priv->flags = flags;
 	av_priv->rx_ctx_bits = rx_ctx_bits;
-	av_priv->max_trx_ctxt = psmx2_env.max_trx_ctxt;
+	av_priv->max_trx_ctxt = psmx2_hfi_info.max_trx_ctxt;
 	av_priv->addr_format = domain_priv->addr_format;
 	av_priv->type = av_type;
 
diff --git a/prov/psm2/src/psmx2_cntr.c b/prov/psm2/src/psmx2_cntr.c
index 0e77aa8..d8ce11e 100644
--- a/prov/psm2/src/psmx2_cntr.c
+++ b/prov/psm2/src/psmx2_cntr.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
diff --git a/prov/psm2/src/psmx2_cq.c b/prov/psm2/src/psmx2_cq.c
index f3d877b..bc3e25e 100644
--- a/prov/psm2/src/psmx2_cq.c
+++ b/prov/psm2/src/psmx2_cq.c
@@ -1820,6 +1820,12 @@ static int psmx2_cq_close(fid_t fid)
 		free(item);
 	}
 
+	while (!slist_empty(&cq->event_queue)) {
+		entry = slist_remove_head(&cq->event_queue);
+		item = container_of(entry, struct psmx2_cq_event, list_entry);
+		free(item);
+	}
+
 	fastlock_destroy(&cq->lock);
 
 	if (cq->wait) {
diff --git a/prov/psm2/src/psmx2_domain.c b/prov/psm2/src/psmx2_domain.c
index c99ef95..0965626 100644
--- a/prov/psm2/src/psmx2_domain.c
+++ b/prov/psm2/src/psmx2_domain.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -309,7 +309,7 @@ int psmx2_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 				   util_fabric.fabric_fid);
 
 	if (!info->domain_attr->name ||
-	    strcmp(info->domain_attr->name, PSMX2_DOMAIN_NAME)) {
+	    strncmp(info->domain_attr->name, PSMX2_DOMAIN_NAME, strlen(PSMX2_DOMAIN_NAME))) {
 		err = -FI_EINVAL;
 		goto err_out;
 	}
diff --git a/prov/psm2/src/psmx2_ep.c b/prov/psm2/src/psmx2_ep.c
index 20d4c71..6569796 100644
--- a/prov/psm2/src/psmx2_ep.c
+++ b/prov/psm2/src/psmx2_ep.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -949,18 +949,18 @@ int psmx2_sep_open(struct fid_domain *domain, struct fi_info *info,
 		goto errout;
 
 	if (info && info->ep_attr) {
-		if (info->ep_attr->tx_ctx_cnt > psmx2_env.max_trx_ctxt) {
+		if (info->ep_attr->tx_ctx_cnt > psmx2_hfi_info.max_trx_ctxt) {
 			FI_WARN(&psmx2_prov, FI_LOG_EP_CTRL,
 				"tx_ctx_cnt %"PRIu64" exceed limit %d.\n",
 				info->ep_attr->tx_ctx_cnt,
-				psmx2_env.max_trx_ctxt);
+				psmx2_hfi_info.max_trx_ctxt);
 			goto errout;
 		}
-		if (info->ep_attr->rx_ctx_cnt > psmx2_env.max_trx_ctxt) {
+		if (info->ep_attr->rx_ctx_cnt > psmx2_hfi_info.max_trx_ctxt) {
 			FI_WARN(&psmx2_prov, FI_LOG_EP_CTRL,
 				"rx_ctx_cnt %"PRIu64" exceed limit %d.\n",
 				info->ep_attr->rx_ctx_cnt,
-				psmx2_env.max_trx_ctxt);
+				psmx2_hfi_info.max_trx_ctxt);
 			goto errout;
 		}
 		ctxt_cnt = info->ep_attr->tx_ctx_cnt;
diff --git a/prov/psm2/src/psmx2_init.c b/prov/psm2/src/psmx2_init.c
index 168773d..db5f857 100644
--- a/prov/psm2/src/psmx2_init.c
+++ b/prov/psm2/src/psmx2_init.c
@@ -39,6 +39,8 @@ static int psmx2_init_count = 0;
 static int psmx2_lib_initialized = 0;
 static pthread_mutex_t psmx2_lib_mutex;
 
+struct psmx2_hfi_info psmx2_hfi_info;
+
 struct psmx2_env psmx2_env = {
 	.name_server	= 1,
 	.tagged_rma	= 1,
@@ -49,9 +51,6 @@ struct psmx2_env psmx2_env = {
 	.prog_interval	= -1,
 	.prog_affinity	= NULL,
 	.multi_ep	= 0,
-	.max_trx_ctxt	= 1,
-	.free_trx_ctxt	= 1,
-	.num_devunits	= 1,
 	.inject_size	= 64,
 	.lock_level	= 2,
 	.lazy_conn	= 0,
@@ -251,8 +250,8 @@ out:
 	return ret;
 }
 
-#if !HAVE_PSM2_INFO_QUERY
 #define PSMX2_SYSFS_PATH "/sys/class/infiniband/hfi1"
+#if !HAVE_PSM2_INFO_QUERY
 static int psmx2_read_sysfs_int(int unit, char *entry)
 {
 	char path[64];
@@ -276,27 +275,40 @@ static int psmx2_unit_active(int unit)
 }
 #endif
 
-#define PSMX2_MAX_UNITS	4
-static int psmx2_active_units[PSMX2_MAX_UNITS];
-static int psmx2_num_active_units;
-
-static void psmx2_update_hfi_info(void)
+static int psmx2_update_hfi_info(void)
 {
-	int i;
+	unsigned short i;
 	int nctxts = 0;
 	int nfreectxts = 0;
 	int hfi_unit = -1;
 	int multirail = 0;
 	char *s;
+	char unit_name[8];
+	uint32_t cnt = 0;
+	int tmp_nctxts, tmp_nfreectxts;
 
 #if HAVE_PSM2_INFO_QUERY
 	int unit_active;
 	int ret;
-	int tmp_cnt;
 	psm2_info_query_arg_t args[1];
 #endif
 
-	assert(psmx2_env.num_devunits <= PSMX2_MAX_UNITS);
+	if (psmx2_hfi_info.num_units > 0)
+		return 0;
+
+#if HAVE_PSM2_INFO_QUERY
+	if (psm2_info_query(PSM2_INFO_QUERY_NUM_UNITS, &cnt, 0, NULL) || !cnt)
+#else
+	if (psm2_ep_num_devunits(&cnt) || !cnt)
+#endif
+	{
+		FI_INFO(&psmx2_prov, FI_LOG_CORE,
+			"no PSM2 device is found.\n");
+		return -FI_ENODEV;
+	}
+	psmx2_hfi_info.num_units = cnt;
+
+	assert(psmx2_hfi_info.num_units <= PSMX2_MAX_UNITS);
 
 	s = getenv("HFI_UNIT");
 	if (s)
@@ -306,8 +318,8 @@ static void psmx2_update_hfi_info(void)
 	if (s)
 		multirail = atoi(s);
 
-	psmx2_num_active_units = 0;
-	for (i = 0; i < psmx2_env.num_devunits; i++) {
+	psmx2_hfi_info.num_active_units = 0;
+	for (i = 0; i < psmx2_hfi_info.num_units; i++) {
 #if HAVE_PSM2_INFO_QUERY
 		args[0].unit = i;
 		ret = psm2_info_query(PSM2_INFO_QUERY_UNIT_STATUS, &unit_active, 1, args);
@@ -333,24 +345,22 @@ static void psmx2_update_hfi_info(void)
 		}
 
 		if (PSM2_OK != psm2_info_query(PSM2_INFO_QUERY_NUM_FREE_CONTEXTS,
-						&tmp_cnt, 1, args) || (tmp_cnt < 0))
+						&tmp_nfreectxts, 1, args) || (tmp_nfreectxts < 0))
 		{
 			FI_WARN(&psmx2_prov, FI_LOG_CORE,
 				"Failed to read number of free contexts from HFI unit %d\n",
 				i);
 			continue;
 		}
-		nfreectxts += tmp_cnt;
 
 		if (PSM2_OK != psm2_info_query(PSM2_INFO_QUERY_NUM_CONTEXTS,
-						&tmp_cnt, 1, args) || (tmp_cnt < 0))
+						&tmp_nctxts, 1, args) || (tmp_nctxts < 0))
 		{
 			FI_WARN(&psmx2_prov, FI_LOG_CORE,
 				"Failed to read number of contexts from HFI unit %d\n",
 				i);
 			continue;
 		}
-		nctxts += tmp_cnt;
 #else
 		if (!psmx2_unit_active(i)) {
 			FI_INFO(&psmx2_prov, FI_LOG_CORE,
@@ -365,10 +375,22 @@ static void psmx2_update_hfi_info(void)
 			continue;
 		}
 
-		nctxts += psmx2_read_sysfs_int(i, "nctxts");
-		nfreectxts += psmx2_read_sysfs_int(i, "nfreectxts");
+		tmp_nctxts = psmx2_read_sysfs_int(i, "nctxts");
+		tmp_nfreectxts = psmx2_read_sysfs_int(i, "nfreectxts");
 #endif
-		psmx2_active_units[psmx2_num_active_units++] = i;
+
+		nctxts += tmp_nctxts;
+		nfreectxts += tmp_nfreectxts;
+
+		psmx2_hfi_info.unit_is_active[i] = 1;
+		psmx2_hfi_info.unit_nctxts[i] = tmp_nctxts;
+		psmx2_hfi_info.unit_nfreectxts[i] = tmp_nfreectxts;
+		psmx2_hfi_info.active_units[psmx2_hfi_info.num_active_units++] = i;
+
+		sprintf(unit_name, "hfi1_%hu", i);
+		if (psmx2_hfi_info.num_active_units > 1)
+			strcat(psmx2_hfi_info.default_domain_name, ";");
+		strcat(psmx2_hfi_info.default_domain_name, unit_name);
 
 		if (multirail)
 			break;
@@ -377,28 +399,91 @@ static void psmx2_update_hfi_info(void)
 	FI_INFO(&psmx2_prov, FI_LOG_CORE,
 		"hfi1 units: total %d, active %d; "
 		"hfi1 contexts: total %d, free %d\n",
-		psmx2_env.num_devunits, psmx2_num_active_units,
+		psmx2_hfi_info.num_units, psmx2_hfi_info.num_active_units,
 		nctxts, nfreectxts);
 
 	if (psmx2_env.multi_ep) {
-		psmx2_env.max_trx_ctxt = nctxts;
-		psmx2_env.free_trx_ctxt = nfreectxts;
-	} else if (nfreectxts == 0) {
-		psmx2_env.free_trx_ctxt = nfreectxts;
+		psmx2_hfi_info.max_trx_ctxt = nctxts;
+		psmx2_hfi_info.free_trx_ctxt = nfreectxts;
+	} else {
+		psmx2_hfi_info.max_trx_ctxt = 1;
+		psmx2_hfi_info.free_trx_ctxt = (nfreectxts == 0) ? 0 : 1;
 	}
 
 	FI_INFO(&psmx2_prov, FI_LOG_CORE,
 		"Tx/Rx contexts: %d in total, %d available.\n",
-		psmx2_env.max_trx_ctxt, psmx2_env.free_trx_ctxt);
+		psmx2_hfi_info.max_trx_ctxt, psmx2_hfi_info.free_trx_ctxt);
+
+	return 0;
 }
 
 int psmx2_get_round_robin_unit(int idx)
 {
-	return psmx2_num_active_units ?
-			psmx2_active_units[idx % psmx2_num_active_units] :
+	return psmx2_hfi_info.num_active_units ?
+			psmx2_hfi_info.active_units[idx % psmx2_hfi_info.num_active_units] :
 			-1;
 }
 
+static void psmx2_update_hfi_nic_info(struct fi_info *info)
+{
+        char *path;
+	char buffer[80];
+	char *s;
+	ssize_t n;
+	int a, b, c, d;
+	int unit;
+
+	for ( ; info; info = info->next) {
+		unit = ((struct psmx2_ep_name *)info->src_addr)->unit;
+
+		if (unit == PSMX2_DEFAULT_UNIT)
+			continue;
+
+		if (!info->nic) {
+			info->nic = ofi_nic_dup(NULL);
+			if (!info->nic) {
+				FI_WARN(&psmx2_prov, FI_LOG_CORE,
+					"Failed to allocate nic info for HFI unit %d\n", unit);
+				continue;
+			}
+		}
+
+		if (asprintf(&path, "%s_%d/%s", PSMX2_SYSFS_PATH, unit, "device") < 0) {
+			FI_WARN(&psmx2_prov, FI_LOG_CORE,
+				"Failed to read nic info for HFI unit %d\n", unit);
+			continue;
+		}
+
+		n = readlink(path, buffer, 80);
+		free(path);
+
+		if (n < 0) {
+			FI_WARN(&psmx2_prov, FI_LOG_CORE,
+				"Failed to read nic info for HFI unit %d\n", unit);
+			continue;
+		}
+
+		buffer[n] = '\0';
+		if ((s = strrchr(buffer, '/')))
+			s++;
+		else
+			s = buffer;
+
+		n = sscanf(s, "%x:%x:%x.%x", &a, &b, &c, &d);
+		if (n < 4) {
+			FI_WARN(&psmx2_prov, FI_LOG_CORE,
+				"Failed to read nic info for HFI unit %d\n", unit);
+			continue;
+		}
+
+		info->nic->bus_attr->bus_type = FI_BUS_PCI;
+		info->nic->bus_attr->attr.pci.domain_id = a;
+		info->nic->bus_attr->attr.pci.bus_id = b;
+		info->nic->bus_attr->attr.pci.device_id = c;
+		info->nic->bus_attr->attr.pci.function_id = d;
+	}
+}
+
 static int psmx2_getinfo(uint32_t api_version, const char *node,
 			 const char *service, uint64_t flags,
 			 const struct fi_info *hints, struct fi_info **info)
@@ -410,7 +495,6 @@ static int psmx2_getinfo(uint32_t api_version, const char *node,
 	size_t len;
 	void *addr;
 	uint32_t fmt;
-	uint32_t cnt = 0;
 
 	FI_INFO(&psmx2_prov, FI_LOG_CORE,"\n");
 
@@ -420,20 +504,10 @@ static int psmx2_getinfo(uint32_t api_version, const char *node,
 	if (psmx2_init_lib())
 		goto err_out;
 
-#if HAVE_PSM2_INFO_QUERY
-	if (psm2_info_query(PSM2_INFO_QUERY_NUM_UNITS, &cnt, 0, NULL) || !cnt)
-#else
-	if (psm2_ep_num_devunits(&cnt) || !cnt)
-#endif
-	{
-		FI_INFO(&psmx2_prov, FI_LOG_CORE,
-			"no PSM2 device is found.\n");
+	if (psmx2_update_hfi_info())
 		goto err_out;
-	}
-	psmx2_env.num_devunits = cnt;
-	psmx2_update_hfi_info();
 
-	if (!psmx2_num_active_units) {
+	if (!psmx2_hfi_info.num_active_units) {
 		FI_INFO(&psmx2_prov, FI_LOG_CORE,
 			"no PSM2 device is active.\n");
 		goto err_out;
@@ -483,6 +557,20 @@ static int psmx2_getinfo(uint32_t api_version, const char *node,
 		}
 	}
 
+	/* Check that the src address contains valid unit */
+	if (src_addr->unit != PSMX2_DEFAULT_UNIT) {
+		if (src_addr->unit < 0 || src_addr->unit > PSMX2_MAX_UNITS) {
+			FI_INFO(&psmx2_prov, FI_LOG_CORE,
+				"invalid source address: unit %d out of range\n", src_addr->unit);
+			goto err_out;
+		}
+		if (!psmx2_hfi_info.unit_is_active[src_addr->unit]) {
+			FI_INFO(&psmx2_prov, FI_LOG_CORE,
+				"invalid source address: unit %d is inactive\n", src_addr->unit);
+			goto err_out;
+		}
+	}
+
 	/* Resovle dest address using "node", "service" pair */
 	if (!dest_addr && node && !(flags & FI_SOURCE)) {
 		psm2_uuid_t uuid;
@@ -513,7 +601,7 @@ static int psmx2_getinfo(uint32_t api_version, const char *node,
 		}
 	}
 
-	/* Update prov info with resovled addresses and environment settings */
+	/* Update prov info with resovled addresses and hfi info */
 	psmx2_update_prov_info(prov_info, src_addr, dest_addr);
 
 	/* Remove prov info that don't match the hints */
@@ -522,7 +610,13 @@ static int psmx2_getinfo(uint32_t api_version, const char *node,
 
 	/* Apply hints to the prov info */
 	psmx2_alter_prov_info(api_version, hints, prov_info);
+
+	/* Set fi_nic struture */
+	psmx2_update_hfi_nic_info(prov_info);
+
 	*info = prov_info;
+	free(src_addr);
+	free(dest_addr);
 	return 0;
 
 err_out:
@@ -558,7 +652,7 @@ static void psmx2_fini(void)
 struct fi_provider psmx2_prov = {
 	.name = PSMX2_PROV_NAME,
 	.version = PSMX2_VERSION,
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = psmx2_getinfo,
 	.fabric = psmx2_fabric,
 	.cleanup = psmx2_fini
diff --git a/prov/psm2/src/psmx2_msg.c b/prov/psm2/src/psmx2_msg.c
index 52ae718..50a03f4 100644
--- a/prov/psm2/src/psmx2_msg.c
+++ b/prov/psm2/src/psmx2_msg.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
diff --git a/prov/psm2/src/psmx2_rma.c b/prov/psm2/src/psmx2_rma.c
index eec369a..84928fb 100644
--- a/prov/psm2/src/psmx2_rma.c
+++ b/prov/psm2/src/psmx2_rma.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
diff --git a/prov/psm2/src/psmx2_tagged.c b/prov/psm2/src/psmx2_tagged.c
index 4c16773..65fc795 100644
--- a/prov/psm2/src/psmx2_tagged.c
+++ b/prov/psm2/src/psmx2_tagged.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
diff --git a/prov/psm2/src/psmx2_trx_ctxt.c b/prov/psm2/src/psmx2_trx_ctxt.c
index 74fbb52..a4233b8 100644
--- a/prov/psm2/src/psmx2_trx_ctxt.c
+++ b/prov/psm2/src/psmx2_trx_ctxt.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -51,18 +51,11 @@ struct disconnect_args {
 	psm2_epaddr_t		epaddr;
 };
 
-static int psmx2_peer_match(struct dlist_entry *item, const void *arg)
-{
-	struct psmx2_epaddr_context *peer;
-
-	peer = container_of(item, struct psmx2_epaddr_context, entry);
-	return  (peer->epaddr == arg);
-}
-
 static void *disconnect_func(void *args)
 {
 	struct disconnect_args *disconn = args;
 	struct psmx2_trx_ctxt *trx_ctxt = disconn->trx_ctxt;
+	struct psmx2_epaddr_context *epaddr_context;
 	psm2_error_t errors;
 
 	FI_INFO(&psmx2_prov, FI_LOG_CORE,
@@ -75,8 +68,13 @@ static void *disconnect_func(void *args)
 	if (trx_ctxt->ep && trx_ctxt->ep->av)
 		psmx2_av_remove_conn(trx_ctxt->ep->av, trx_ctxt, disconn->epaddr);
 
+	epaddr_context = psm2_epaddr_getctxt(disconn->epaddr);
+	psm2_epaddr_setctxt(disconn->epaddr, NULL);
+	free(epaddr_context);
+
 	psm2_ep_disconnect2(trx_ctxt->psm2_ep, 1, &disconn->epaddr, NULL,
 			    &errors, PSM2_EP_DISCONNECT_FORCE, 0);
+
 	free(args);
 	return NULL;
 }
@@ -144,9 +142,11 @@ void psmx2_trx_ctxt_disconnect_peers(struct psmx2_trx_ctxt *trx_ctxt)
 
 	dlist_foreach_safe(&peer_list, item, tmp) {
 		peer = container_of(item, struct psmx2_epaddr_context, entry);
-		FI_INFO(&psmx2_prov, FI_LOG_CORE, "epaddr: %p\n", peer->epaddr);
-		psm2_am_request_short(peer->epaddr, PSMX2_AM_TRX_CTXT_HANDLER,
-				      &arg, 1, NULL, 0, 0, NULL, NULL);
+		if (psmx2_env.disconnect) {
+			FI_INFO(&psmx2_prov, FI_LOG_CORE, "epaddr: %p\n", peer->epaddr);
+			psm2_am_request_short(peer->epaddr, PSMX2_AM_TRX_CTXT_HANDLER,
+					      &arg, 1, NULL, 0, 0, NULL, NULL);
+		}
 		psm2_epaddr_setctxt(peer->epaddr, NULL);
 		free(peer);
 	}
@@ -189,8 +189,7 @@ void psmx2_trx_ctxt_free(struct psmx2_trx_ctxt *trx_ctxt, int usage_flags)
 	dlist_remove(&trx_ctxt->entry);
 	trx_ctxt->domain->trx_ctxt_unlock_fn(&trx_ctxt->domain->trx_ctxt_lock, 1);
 
-	if (psmx2_env.disconnect)
-		psmx2_trx_ctxt_disconnect_peers(trx_ctxt);
+	psmx2_trx_ctxt_disconnect_peers(trx_ctxt);
 
 	if (trx_ctxt->am_initialized)
 		psmx2_am_fini(trx_ctxt);
@@ -258,10 +257,10 @@ struct psmx2_trx_ctxt *psmx2_trx_ctxt_alloc(struct psmx2_fid_domain *domain,
 		domain->trx_ctxt_unlock_fn(&domain->trx_ctxt_lock, 1);
 	}
 
-	if (psmx2_trx_ctxt_cnt >= psmx2_env.max_trx_ctxt) {
+	if (psmx2_trx_ctxt_cnt >= psmx2_hfi_info.max_trx_ctxt) {
 		FI_WARN(&psmx2_prov, FI_LOG_CORE,
 			"number of Tx/Rx contexts exceeds limit (%d).\n",
-			psmx2_env.max_trx_ctxt);
+			psmx2_hfi_info.max_trx_ctxt);
 		return NULL;
 	}
 
diff --git a/prov/psm2/src/psmx2_wait.c b/prov/psm2/src/psmx2_wait.c
index c530242..62df2d6 100644
--- a/prov/psm2/src/psmx2_wait.c
+++ b/prov/psm2/src/psmx2_wait.c
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
diff --git a/prov/psm2/src/version.h b/prov/psm2/src/version.h
index 5018797..f99d4cc 100644
--- a/prov/psm2/src/version.h
+++ b/prov/psm2/src/version.h
@@ -1,5 +1,5 @@
 /*
- * Copyright (c) 2013-2018 Intel Corporation. All rights reserved.
+ * Copyright (c) 2013-2019 Intel Corporation. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -47,7 +47,7 @@
 #endif
 
 #define PSMX2_PROV_NAME		"psm2"
-#define PSMX2_DOMAIN_NAME	"psm2"
+#define PSMX2_DOMAIN_NAME	"hfi1"
 #define PSMX2_FABRIC_NAME	"psm2"
 
 #define PSMX2_DEFAULT_UUID	"00FF00FF-0000-0000-0000-00FF00FF00FF"
diff --git a/prov/rstream/src/rstream_init.c b/prov/rstream/src/rstream_init.c
index 2d20bde..f627731 100644
--- a/prov/rstream/src/rstream_init.c
+++ b/prov/rstream/src/rstream_init.c
@@ -163,7 +163,7 @@ static void rstream_fini(void)
 struct fi_provider rstream_prov = {
 	.name = OFI_UTIL_PREFIX "rstream",
 	.version = FI_VERSION(1 ,0),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = rstream_getinfo,
 	.fabric = rstream_fabric_open,
 	.cleanup = rstream_fini
diff --git a/prov/rxd/src/rxd.h b/prov/rxd/src/rxd.h
index 82e70f9..4b58556 100644
--- a/prov/rxd/src/rxd.h
+++ b/prov/rxd/src/rxd.h
@@ -67,7 +67,6 @@
 
 #define RXD_MAX_TX_BITS 	10
 #define RXD_MAX_RX_BITS 	10
-#define RXD_DEFAULT_AV_SIZE	1024
 
 #define RXD_BUF_POOL_ALIGNMENT	16
 #define RXD_TX_POOL_CHUNK_CNT	1024
diff --git a/prov/rxd/src/rxd_av.c b/prov/rxd/src/rxd_av.c
index d817c94..1d9231e 100644
--- a/prov/rxd/src/rxd_av.c
+++ b/prov/rxd/src/rxd_av.c
@@ -255,7 +255,6 @@ static int rxd_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr, size_t count
 	fi_addr_t rxd_addr;
 	struct rxd_av *av;
 	uint8_t addr[RXD_NAME_LENGTH];
-	struct ofi_rbnode *node;
 
 	av = container_of(av_fid, struct rxd_av, util_av.av_fid);
 	fastlock_acquire(&av->util_av.lock);
@@ -268,12 +267,10 @@ static int rxd_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr, size_t count
 		if (ret)
 			goto err;
 		
-		node = ofi_rbmap_find(&av->rbmap, (void *) addr);
-		if (!node)
+		ret = ofi_rbmap_find_delete(&av->rbmap, (void *) addr);
+		if (ret)
 			goto err;
 
-		ofi_rbmap_delete(&av->rbmap, node);
-
 		ret = fi_av_remove(av->dg_av, &av->rxd_addr_table[rxd_addr].dg_addr,
 				   1, flags);
 		if (ret)
@@ -374,8 +371,9 @@ int rxd_av_create(struct fid_domain *domain_fid, struct fi_av_attr *attr,
 	if (attr->name)
 		return -FI_ENOSYS;
 
+	//TODO implement dynamic AV sizing
 	attr->count = roundup_power_of_two(attr->count ?
-					   attr->count : RXD_DEFAULT_AV_SIZE);
+					   attr->count : rxd_env.max_peers);
 	domain = container_of(domain_fid, struct rxd_domain, util_domain.domain_fid);
 	av = calloc(1, sizeof(*av));
 	if (!av)
diff --git a/prov/rxd/src/rxd_ep.c b/prov/rxd/src/rxd_ep.c
index 2dfb6a5..f362d0e 100644
--- a/prov/rxd/src/rxd_ep.c
+++ b/prov/rxd/src/rxd_ep.c
@@ -1001,7 +1001,7 @@ static int rxd_buf_region_alloc_fn(struct ofi_bufpool_region *region)
 
 	ret = fi_mr_reg(rxd_ep_domain(pool->rxd_ep)->dg_domain, region->mem_region,
 			region->pool->region_size,
-			FI_SEND | FI_RECV, 0, 0, 0, &mr, NULL);
+			FI_SEND | FI_RECV, 0, 0, OFI_MR_NOCACHE, &mr, NULL);
 
 	region->context = mr;
 	return ret;
diff --git a/prov/rxd/src/rxd_init.c b/prov/rxd/src/rxd_init.c
index 2662a85..8a539be 100644
--- a/prov/rxd/src/rxd_init.c
+++ b/prov/rxd/src/rxd_init.c
@@ -127,7 +127,7 @@ static void rxd_fini(void)
 struct fi_provider rxd_prov = {
 	.name = OFI_UTIL_PREFIX "rxd",
 	.version = FI_VERSION(RXD_MAJOR_VERSION, RXD_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = rxd_getinfo,
 	.fabric = rxd_fabric,
 	.cleanup = rxd_fini
diff --git a/prov/rxm/src/rxm.h b/prov/rxm/src/rxm.h
index ab1898f..721dc23 100644
--- a/prov/rxm/src/rxm.h
+++ b/prov/rxm/src/rxm.h
@@ -132,6 +132,7 @@ extern size_t rxm_msg_tx_size;
 extern size_t rxm_msg_rx_size;
 extern size_t rxm_def_univ_size;
 extern size_t rxm_cm_progress_interval;
+extern int force_auto_progress;
 
 /*
  * Connection Map
@@ -149,7 +150,6 @@ enum rxm_cmap_signal {
 	FUNC(RXM_CMAP_IDLE),		\
 	FUNC(RXM_CMAP_CONNREQ_SENT),	\
 	FUNC(RXM_CMAP_CONNREQ_RECV),	\
-	FUNC(RXM_CMAP_CONNECTED_NOTIFY),\
 	FUNC(RXM_CMAP_CONNECTED),	\
 	FUNC(RXM_CMAP_SHUTDOWN),	\
 
@@ -189,8 +189,6 @@ struct rxm_cmap_peer {
 
 struct rxm_cmap_attr {
 	void 				*name;
-	/* user guarantee for serializing access to cmap objects */
-	uint8_t				serial_access;
 };
 
 struct rxm_cmap {
@@ -250,8 +248,6 @@ union rxm_cm_data {
 struct rxm_cmap_handle *rxm_cmap_key2handle(struct rxm_cmap *cmap, uint64_t key);
 int rxm_cmap_update(struct rxm_cmap *cmap, const void *addr, fi_addr_t fi_addr);
 
-void rxm_cmap_process_conn_notify(struct rxm_cmap *cmap,
-				  struct rxm_cmap_handle *handle);
 void rxm_cmap_process_reject(struct rxm_cmap *cmap,
 			     struct rxm_cmap_handle *handle,
 			     enum rxm_cmap_reject_reason cm_reject_reason);
@@ -281,6 +277,7 @@ struct rxm_domain {
 	struct util_domain util_domain;
 	struct fid_domain *msg_domain;
 	size_t max_atomic_size;
+	uint64_t mr_key;
 	uint8_t mr_local;
 };
 
@@ -372,7 +369,7 @@ union rxm_sar_ctrl_data {
 		enum rxm_sar_seg_type {
 			RXM_SAR_SEG_FIRST	= 1,
 			RXM_SAR_SEG_MIDDLE	= 2,
-			RXM_SAR_SEG_LAST	= 3,	
+			RXM_SAR_SEG_LAST	= 3,
 		} seg_type : 2;
 		uint32_t offset;
 	};
@@ -645,6 +642,14 @@ struct rxm_msg_eq_entry {
 #define RXM_CM_ENTRY_SZ (sizeof(struct fi_eq_cm_entry) + \
 			 sizeof(union rxm_cm_data))
 
+struct rxm_handle_txrx_ops {
+	int (*comp_eager_tx)(struct rxm_ep *rxm_ep,
+				    struct rxm_tx_eager_buf *tx_eager_buf);
+	ssize_t (*handle_eager_rx)(struct rxm_rx_buf *rx_buf);
+	ssize_t (*handle_rndv_rx)(struct rxm_rx_buf *rx_buf);
+	ssize_t (*handle_seg_data_rx)(struct rxm_rx_buf *rx_buf);
+};
+
 struct rxm_ep {
 	struct util_ep 		util_ep;
 	struct fi_info 		*rxm_info;
@@ -656,6 +661,7 @@ struct rxm_ep {
 	uint64_t		msg_cq_last_poll;
 	struct fid_ep 		*srx_ctx;
 	size_t 			comp_per_progress;
+	ofi_atomic32_t		atomic_tx_credits;
 	int			msg_mr_local;
 	int			rxm_mr_local;
 	size_t			min_multi_recv_size;
@@ -673,6 +679,8 @@ struct rxm_ep {
 
 	struct rxm_recv_queue	recv_queue;
 	struct rxm_recv_queue	trecv_queue;
+
+	struct rxm_handle_txrx_ops *txrx_ops;
 };
 
 struct rxm_conn {
@@ -692,9 +700,6 @@ struct rxm_conn {
 	struct dlist_entry sar_rx_msg_list;
 	struct dlist_entry sar_deferred_rx_msg_list;
 
-	/* This is saved MSG EP fid, that hasn't been closed during
-	 * handling of CONN_RECV in RXM_CMAP_CONNREQ_SENT for passive side */
-	struct fid_ep *saved_msg_ep;
 	uint32_t rndv_tx_credits;
 };
 
@@ -727,8 +732,16 @@ int rxm_conn_cmap_alloc(struct rxm_ep *rxm_ep);
 void rxm_cq_write_error(struct util_cq *cq, struct util_cntr *cntr,
 			void *op_context, int err);
 void rxm_ep_progress(struct util_ep *util_ep);
+void rxm_ep_progress_coll(struct util_ep *util_ep);
 void rxm_ep_do_progress(struct util_ep *util_ep);
 
+ssize_t rxm_cq_handle_eager(struct rxm_rx_buf *rx_buf);
+ssize_t rxm_cq_handle_coll_eager(struct rxm_rx_buf *rx_buf);
+ssize_t rxm_cq_handle_rndv(struct rxm_rx_buf *rx_buf);
+ssize_t rxm_cq_handle_seg_data(struct rxm_rx_buf *rx_buf);
+int rxm_finish_eager_send(struct rxm_ep *rxm_ep, struct rxm_tx_eager_buf *tx_eager_buf);
+int rxm_finish_coll_eager_send(struct rxm_ep *rxm_ep, struct rxm_tx_eager_buf *tx_eager_buf);
+
 int rxm_msg_ep_prepost_recv(struct rxm_ep *rxm_ep, struct fid_ep *msg_ep);
 
 int rxm_ep_query_atomic(struct fid_domain *domain, enum fi_datatype datatype,
@@ -800,65 +813,13 @@ rxm_ep_dequeue_deferred_tx_queue(struct rxm_deferred_tx_entry *tx_entry)
 
 int rxm_conn_process_eq_events(struct rxm_ep *rxm_ep);
 
-static inline void rxm_ep_msg_mr_closev(struct fid_mr **mr, size_t count)
-{
-	int ret;
-	size_t i;
-
-	for (i = 0; i < count; i++) {
-		if (mr[i]) {
-			ret = fi_close(&mr[i]->fid);
-			if (ret)
-				FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
-					"Unable to close msg mr: %zu\n", i);
-			mr[i] = NULL;
-		}
-	}
-}
-
-static inline int
-rxm_ep_msg_mr_regv(struct rxm_ep *rxm_ep, const struct iovec *iov, size_t count,
-		   uint64_t access, struct fid_mr **mr)
-{
-	int ret;
-	size_t i;
-	struct rxm_domain *rxm_domain =
-		container_of(rxm_ep->util_ep.domain, struct rxm_domain, util_domain);
- 
-	for (i = 0; i < count; i++) {
-		ret = fi_mr_reg(rxm_domain->msg_domain, iov[i].iov_base,
-				iov[i].iov_len, access, 0, 0, 0, &mr[i], NULL);
-		if (ret)
-			goto err;
-	}
-	return 0;
-err:
-	rxm_ep_msg_mr_closev(mr, count);
-	return ret;
-}
-
-static inline int
-rxm_ep_msg_mr_regv_lim(struct rxm_ep *rxm_ep, const struct iovec *iov, size_t count,
-		       size_t total_reg_len, uint64_t access, struct fid_mr **mr)
-{
-	int ret;
-	size_t i;
-	struct rxm_domain *rxm_domain =
-		container_of(rxm_ep->util_ep.domain, struct rxm_domain, util_domain);
- 
-	for (i = 0; i < count && total_reg_len; i++) {
-		size_t len = MIN(iov[i].iov_len, total_reg_len);
-		ret = fi_mr_reg(rxm_domain->msg_domain, iov[i].iov_base,
-				len, access, 0, 0, 0, &mr[i], NULL);
-		if (ret)
-			goto err;
-		total_reg_len -= len;
-	}
-	return 0;
-err:
-	rxm_ep_msg_mr_closev(mr, count);
-	return ret;
-}
+void rxm_msg_mr_closev(struct fid_mr **mr, size_t count);
+int rxm_msg_mr_regv(struct rxm_ep *rxm_ep, const struct iovec *iov,
+		    size_t count, size_t reg_limit, uint64_t access,
+		    struct fid_mr **mr);
+int rxm_msg_mr_reg_internal(struct rxm_domain *rxm_domain, const void *buf,
+			    size_t len, uint64_t acs, uint64_t flags,
+			    struct fid_mr **mr);
 
 static inline void rxm_cntr_incerr(struct util_cntr *cntr)
 {
@@ -974,7 +935,7 @@ rxm_process_recv_entry(struct rxm_recv_queue *recv_queue,
 
 static inline ssize_t
 rxm_ep_prepare_tx(struct rxm_ep *rxm_ep, fi_addr_t dest_addr,
-		 struct rxm_conn **rxm_conn)
+		  struct rxm_conn **rxm_conn)
 {
 	ssize_t ret;
 
diff --git a/prov/rxm/src/rxm_atomic.c b/prov/rxm/src/rxm_atomic.c
index 1f0df30..c15c226 100644
--- a/prov/rxm/src/rxm_atomic.c
+++ b/prov/rxm/src/rxm_atomic.c
@@ -135,12 +135,18 @@ rxm_ep_atomic_common(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
 		return -FI_EINVAL;
 	}
 
+	if (ofi_atomic_dec32(&rxm_ep->atomic_tx_credits) < 0) {
+		ret = -FI_EAGAIN;
+		goto restore_credit;
+	}
+
 	tx_buf = (struct rxm_tx_atomic_buf *)
 		 rxm_tx_buf_alloc(rxm_ep, RXM_BUF_POOL_TX_ATOMIC);
 	if (OFI_UNLIKELY(!tx_buf)) {
 		FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
 			"Ran out of buffers from Atomic buffer pool\n");
-		return -FI_EAGAIN;
+		ret = -FI_EAGAIN;
+		goto restore_credit;
 	}
 
 	rxm_ep_format_atomic_pkt_hdr(rxm_conn, tx_buf, tot_len, op,
@@ -163,8 +169,12 @@ rxm_ep_atomic_common(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
 			       datatype_sz);
 
 	ret = rxm_ep_send_atomic_req(rxm_ep, rxm_conn, tx_buf, tot_len);
-	if (ret)
-		ofi_buf_free(tx_buf);
+	if (OFI_LIKELY(!ret))
+		return ret;
+
+	ofi_buf_free(tx_buf);
+restore_credit:
+	ofi_atomic_inc32(&rxm_ep->atomic_tx_credits);
 	return ret;
 }
 
diff --git a/prov/rxm/src/rxm_attr.c b/prov/rxm/src/rxm_attr.c
index 0fe7606..9cc6f0f 100644
--- a/prov/rxm/src/rxm_attr.c
+++ b/prov/rxm/src/rxm_attr.c
@@ -103,7 +103,7 @@ struct fi_fabric_attr rxm_fabric_attr = {
 };
 
 struct fi_info rxm_info = {
-	.caps = RXM_EP_CAPS | RXM_DOMAIN_CAPS | FI_MULTI_RECV,
+	.caps = RXM_EP_CAPS | RXM_DOMAIN_CAPS | FI_MULTI_RECV | FI_COLLECTIVE,
 	.addr_format = FI_SOCKADDR,
 	.tx_attr = &rxm_tx_attr,
 	.rx_attr = &rxm_rx_attr,
diff --git a/prov/rxm/src/rxm_av.c b/prov/rxm/src/rxm_av.c
index 18c12c9..2667c9f 100644
--- a/prov/rxm/src/rxm_av.c
+++ b/prov/rxm/src/rxm_av.c
@@ -30,6 +30,8 @@
  * SOFTWARE.
  */
 
+#include <ofi_coll.h>
+
 #include "rxm.h"
 
 static int rxm_av_remove(struct fid_av *av_fid, fi_addr_t *fi_addr,
@@ -190,6 +192,7 @@ static struct fi_ops_av rxm_av_ops = {
 	.remove = rxm_av_remove,
 	.lookup = rxm_av_lookup,
 	.straddr = rxm_av_straddr,
+	.av_set = ofi_av_set
 };
 
 int rxm_av_open(struct fid_domain *domain_fid, struct fi_av_attr *attr,
diff --git a/prov/rxm/src/rxm_conn.c b/prov/rxm/src/rxm_conn.c
index 3d14773..79bfdc8 100644
--- a/prov/rxm/src/rxm_conn.c
+++ b/prov/rxm/src/rxm_conn.c
@@ -40,10 +40,7 @@
 #include "rxm.h"
 
 static struct rxm_cmap_handle *rxm_conn_alloc(struct rxm_cmap *cmap);
-static void rxm_conn_connected_handler(struct rxm_cmap_handle *handle);
-static void rxm_conn_close_saved(struct rxm_cmap_handle *handle);
 static void rxm_conn_close(struct rxm_cmap_handle *handle);
-static void rxm_conn_save(struct rxm_cmap_handle *handle);
 static int
 rxm_conn_connect(struct util_ep *util_ep, struct rxm_cmap_handle *handle,
 		 const void *addr);
@@ -277,18 +274,6 @@ static void rxm_conn_free(struct rxm_cmap_handle *handle)
 	struct rxm_conn *rxm_conn =
 		container_of(handle, struct rxm_conn, handle);
 
-	/* This handles case when saved_msg_ep wasn't closed */
-	if (rxm_conn->saved_msg_ep) {
-		if (fi_close(&rxm_conn->saved_msg_ep->fid)) {
-			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-				"Unable to close saved msg_ep\n");
-		} else {
-			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-			       "Closed saved msg_ep\n");
-		}
-		rxm_conn->saved_msg_ep = NULL;
-	}
-
 	if (rxm_conn->msg_ep) {
 		if (fi_close(&rxm_conn->msg_ep->fid)) {
 			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
@@ -453,15 +438,6 @@ void rxm_cmap_process_shutdown(struct rxm_cmap *cmap,
 	}
 }
 
-void rxm_cmap_process_conn_notify(struct rxm_cmap *cmap,
-				  struct rxm_cmap_handle *handle)
-{
-	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-	       "Processing connection notification for handle: %p.\n", handle);
-	RXM_CM_UPDATE_STATE(handle, RXM_CMAP_CONNECTED);
-	rxm_conn_connected_handler(handle);
-}
-
 void rxm_cmap_process_connect(struct rxm_cmap *cmap,
 			      struct rxm_cmap_handle *handle,
 			      union rxm_cm_data *cm_data)
@@ -469,7 +445,7 @@ void rxm_cmap_process_connect(struct rxm_cmap *cmap,
 	struct rxm_conn *rxm_conn = container_of(handle, struct rxm_conn, handle);
 
 	FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-	       "Processing connect for handle: %p\n", handle);
+	       "processing FI_CONNECTED event for handle: %p\n", handle);
 	if (cm_data) {
 		assert(handle->state == RXM_CMAP_CONNREQ_SENT);
 		handle->remote_key = cm_data->accept.server_conn_id;
@@ -477,7 +453,7 @@ void rxm_cmap_process_connect(struct rxm_cmap *cmap,
 	} else {
 		assert(handle->state == RXM_CMAP_CONNREQ_RECV);
 	}
-	RXM_CM_UPDATE_STATE(handle, RXM_CMAP_CONNECTED_NOTIFY);
+	RXM_CM_UPDATE_STATE(handle, RXM_CMAP_CONNECTED);
 
 	/* Set the remote key to the inject packets */
 	if (cmap->ep->domain->threading != FI_THREAD_SAFE) {
@@ -497,11 +473,7 @@ void rxm_cmap_process_reject(struct rxm_cmap *cmap,
 	switch (handle->state) {
 	case RXM_CMAP_CONNREQ_RECV:
 	case RXM_CMAP_CONNECTED:
-	case RXM_CMAP_CONNECTED_NOTIFY:
 		/* Handle is being re-used for incoming connection request */
-		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
-			"Connection handle is being re-used. Close saved connection\n");
-		rxm_conn_close_saved(handle);
 		break;
 	case RXM_CMAP_CONNREQ_SENT:
 		if (reject_reason == RXM_CMAP_REJECT_GENUINE) {
@@ -555,7 +527,6 @@ int rxm_cmap_process_connreq(struct rxm_cmap *cmap, void *addr,
 	}
 
 	switch (handle->state) {
-	case RXM_CMAP_CONNECTED_NOTIFY:
 	case RXM_CMAP_CONNECTED:
 		FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
 			"Connection already present.\n");
@@ -580,7 +551,7 @@ int rxm_cmap_process_connreq(struct rxm_cmap *cmap, void *addr,
 				"Re-using handle: %p to accept remote "
 				"connection\n", handle);
 			*reject_reason = RXM_CMAP_REJECT_GENUINE;
-			rxm_conn_save(handle);
+			rxm_conn_close(handle);
 		} else {
 			FI_DBG(cmap->av->prov, FI_LOG_EP_CTRL,
 				"Endpoint connects to itself\n");
@@ -647,9 +618,6 @@ int rxm_cmap_connect(struct rxm_ep *rxm_ep, fi_addr_t fi_addr,
 	int ret = FI_SUCCESS;
 
 	switch (handle->state) {
-	case RXM_CMAP_CONNECTED_NOTIFY:
-		rxm_cmap_process_conn_notify(rxm_ep->cmap, handle);
-		break;
 	case RXM_CMAP_IDLE:
 		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "initiating MSG_EP connect "
 		       "for fi_addr: %" PRIu64 "\n", fi_addr);
@@ -780,7 +748,8 @@ int rxm_cmap_alloc(struct rxm_ep *rxm_ep, struct rxm_cmap_attr *attr)
 
 	rxm_ep->cmap = cmap;
 
-	if (ep->domain->data_progress == FI_PROGRESS_AUTO) {
+	if (ep->domain->data_progress == FI_PROGRESS_AUTO || force_auto_progress) {
+		assert(ep->domain->threading == FI_THREAD_SAFE);
 		if (pthread_create(&cmap->cm_thread, 0,
 				   rxm_ep->rxm_info->caps & FI_ATOMIC ?
 				   rxm_conn_atomic_progress :
@@ -878,73 +847,16 @@ static void rxm_conn_close(struct rxm_cmap_handle *handle)
 	if (!rxm_conn->msg_ep)
 		return;
 
-	if (handle->cmap->attr.serial_access) {
-		if (fi_close(&rxm_conn->msg_ep->fid)) {
-			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-				"Unable to close msg_ep\n");
-		} else {
-			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-			       "Closed msg_ep\n");
-		}
+	if (fi_close(&rxm_conn->msg_ep->fid)) {
+		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
+			"unable to close msg_ep\n");
 	} else {
-		rxm_conn->saved_msg_ep = rxm_conn->msg_ep;
 		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-		       "Saved MSG EP fid for further deletion in main thread\n");
+		       "closed msg_ep\n");
 	}
 	rxm_conn->msg_ep = NULL;
 }
 
-static void rxm_conn_save(struct rxm_cmap_handle *handle)
-{
-	struct rxm_conn *rxm_conn =
-		container_of(handle, struct rxm_conn, handle);
-
-	if (!rxm_conn->msg_ep)
-		return;
-
-	rxm_conn->saved_msg_ep = rxm_conn->msg_ep;
-	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-	       "Saved MSG EP fid for further deletion\n");
-	rxm_conn->msg_ep = NULL;
-}
-
-static void rxm_conn_close_saved(struct rxm_cmap_handle *handle)
-{
-	struct rxm_conn *rxm_conn =
-		container_of(handle, struct rxm_conn, handle);
-
-	if (!rxm_conn->saved_msg_ep)
-		return;
-
-	/* If user doesn't guarantee for serializing access to cmap
-	 * objects, postpone the closing of the saved MSG EP for
-	 * further deletion in main thread  */
-	if (handle->cmap->attr.serial_access) {
-		if (fi_close(&rxm_conn->saved_msg_ep->fid)) {
-			FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-				"Unable to close saved msg_ep\n");
-		} else {
-			FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-			       "Closed saved msg_ep\n");
-		}
-		rxm_conn->saved_msg_ep = NULL;
-	}
-}
-
-static void rxm_conn_connected_handler(struct rxm_cmap_handle *handle)
-{
-	struct rxm_conn *rxm_conn = container_of(handle, struct rxm_conn, handle);
-
-	if (!rxm_conn->saved_msg_ep)
-		return;
-	/* Assuming fi_close also shuts down the connection gracefully if the
-	 * endpoint is in connected state */
-	if (fi_close(&rxm_conn->saved_msg_ep->fid))
-		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL, "Unable to close saved msg_ep\n");
-	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL, "Closed saved msg_ep\n");
-	rxm_conn->saved_msg_ep = NULL;
-}
-
 static int rxm_conn_reprocess_directed_recvs(struct rxm_recv_queue *recv_queue)
 {
 	struct rxm_rx_buf *rx_buf;
@@ -1111,7 +1023,7 @@ rxm_msg_process_connreq(struct rxm_ep *rxm_ep, struct fi_info *msg_info,
 	};
 	struct rxm_cmap_handle *handle;
 	struct sockaddr_storage remote_pep_addr;
-	int ret, rv;
+	int ret;
 
 	assert(sizeof(uint32_t) == sizeof(cm_data.accept.rx_size));
 	assert(msg_info->rx_attr->size <= (uint32_t)-1);
@@ -1158,14 +1070,10 @@ err2:
 	rxm_cmap_del_handle(&rxm_conn->handle);
 err1:
 	FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-	       "Rejecting incoming connection request (reject reason: %d)\n",
+	       "rejecting incoming connection request (reject reason: %d)\n",
 	       (enum rxm_cmap_reject_reason)reject_cm_data.reject.reason);
-	rv = fi_reject(rxm_ep->msg_pep, msg_info->handle,
-		      &reject_cm_data.reject, sizeof(reject_cm_data.reject));
-	if (rv)
-		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-			"Unable to reject incoming connection: %s (%d)\n",
-			fi_strerror(-rv), -rv);
+	fi_reject(rxm_ep->msg_pep, msg_info->handle,
+		  &reject_cm_data.reject, sizeof(reject_cm_data.reject));
 	return ret;
 }
 
@@ -1276,7 +1184,7 @@ rxm_conn_handle_event(struct rxm_ep *rxm_ep, struct rxm_msg_eq_entry *entry)
 	case FI_CONNECTED:
 		assert(entry->cm_entry.fid->context);
 		FI_DBG(&rxm_prov, FI_LOG_EP_CTRL,
-		       "Connection successful\n");
+		       "connection successful\n");
 		cm_data = (void *)entry->cm_entry.data;
 		rxm_cmap_process_connect(rxm_ep->cmap,
 					 entry->cm_entry.fid->context,
@@ -1307,6 +1215,11 @@ static ssize_t rxm_eq_sread(struct rxm_ep *rxm_ep, size_t len,
 	int once = 1;
 
 	do {
+		/* TODO convert this to poll + fi_eq_read so that we can grab
+		 * rxm_ep lock before reading the EQ. This is needed to avoid
+		 * processing events / error entries from closed MSG EPs. This
+		 * can be done only for non-Windows OSes as Windows doesn't
+		 * have poll for a generic file descriptor. */
 		rd = fi_eq_sread(rxm_ep->msg_eq, &entry->event, &entry->cm_entry,
 				 len, -1, 0);
 		if (rd >= 0)
@@ -1319,11 +1232,15 @@ static ssize_t rxm_eq_sread(struct rxm_ep *rxm_ep, size_t len,
 
 	if (rd != -FI_EAVAIL) {
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
-			"Unable to fi_eq_sread: %zu\n", rd);
+			"unable to fi_eq_sread: %s (%zd)\n",
+			fi_strerror(-rd), -rd);
 		return rd;
 	}
 
-	return rxm_eq_readerr(rxm_ep, entry);
+	ofi_ep_lock_acquire(&rxm_ep->util_ep);
+	rd = rxm_eq_readerr(rxm_ep, entry);
+	ofi_ep_lock_release(&rxm_ep->util_ep);
+	return rd;
 }
 
 static inline int rxm_conn_eq_event(struct rxm_ep *rxm_ep,
@@ -1374,7 +1291,11 @@ rxm_conn_auto_progress_eq(struct rxm_ep *rxm_ep, struct rxm_msg_eq_entry *entry)
 {
 	while (1) {
 		memset(entry, 0, RXM_MSG_EQ_ENTRY_SZ);
+
+		ofi_ep_lock_acquire(&rxm_ep->util_ep);
 		entry->rd = rxm_eq_read(rxm_ep, RXM_CM_ENTRY_SZ, entry);
+		ofi_ep_lock_release(&rxm_ep->util_ep);
+
 		if (OFI_UNLIKELY(!entry->rd || entry->rd == -FI_EAGAIN))
 			return FI_SUCCESS;
 		if (entry->rd < 0 &&
@@ -1445,7 +1366,7 @@ static int rxm_conn_atomic_progress_eq_cq(struct rxm_ep *rxm_ep,
 				goto exit;
 		}
 		if (again || fds[1].revents & POLLIN)
-			rxm_ep_progress(&rxm_ep->util_ep);
+			rxm_ep->util_ep.progress(&rxm_ep->util_ep);
 	}
 exit:
 	return -1;
@@ -1609,12 +1530,6 @@ int rxm_conn_cmap_alloc(struct rxm_ep *rxm_ep)
 
 	attr.name		= name;
 
-	if (rxm_ep->util_ep.domain->threading == FI_THREAD_DOMAIN &&
-	    rxm_ep->util_ep.domain->data_progress == FI_PROGRESS_MANUAL)
-		attr.serial_access = 1;
-	else
-		attr.serial_access = 0;
-
 	ret = rxm_cmap_alloc(rxm_ep, &attr);
 	if (ret)
 		FI_WARN(&rxm_prov, FI_LOG_EP_CTRL,
diff --git a/prov/rxm/src/rxm_cq.c b/prov/rxm/src/rxm_cq.c
index 0c38f6f..6986745 100644
--- a/prov/rxm/src/rxm_cq.c
+++ b/prov/rxm/src/rxm_cq.c
@@ -39,6 +39,7 @@
 #include "ofi.h"
 #include "ofi_iov.h"
 #include "ofi_atomic.h"
+#include <ofi_coll.h>
 
 #include "rxm.h"
 
@@ -276,15 +277,16 @@ static inline int rxm_finish_rma(struct rxm_ep *rxm_ep, struct rxm_rma_buf *rma_
 	else
 		ofi_ep_rd_cntr_inc(&rxm_ep->util_ep);
 
-	if (!(rma_buf->flags & FI_INJECT) && !rxm_ep->rxm_mr_local && rxm_ep->msg_mr_local) {
-		rxm_ep_msg_mr_closev(rma_buf->mr.mr, rma_buf->mr.count);
+	if (!(rma_buf->flags & FI_INJECT) && !rxm_ep->rxm_mr_local &&
+	    rxm_ep->msg_mr_local) {
+		rxm_msg_mr_closev(rma_buf->mr.mr, rma_buf->mr.count);
 	}
 
 	ofi_buf_free(rma_buf);
 	return ret;
 }
 
-static inline int rxm_finish_eager_send(struct rxm_ep *rxm_ep, struct rxm_tx_eager_buf *tx_buf)
+int rxm_finish_eager_send(struct rxm_ep *rxm_ep, struct rxm_tx_eager_buf *tx_buf)
 {
 	int ret = rxm_cq_tx_comp_write(rxm_ep, ofi_tx_cq_flags(tx_buf->pkt.hdr.op),
 				       tx_buf->app_context, tx_buf->flags);
@@ -333,7 +335,7 @@ static inline int rxm_finish_send_rndv_ack(struct rxm_rx_buf *rx_buf)
 	}
 
 	if (!rx_buf->ep->rxm_mr_local)
-		rxm_ep_msg_mr_closev(rx_buf->mr, rx_buf->recv_entry->rxm_iov.count);
+		rxm_msg_mr_closev(rx_buf->mr, rx_buf->recv_entry->rxm_iov.count);
 
 	return rxm_finish_recv(rx_buf, rx_buf->recv_entry->total_len);
 }
@@ -345,7 +347,7 @@ static int rxm_rndv_tx_finish(struct rxm_ep *rxm_ep, struct rxm_tx_rndv_buf *tx_
 	RXM_UPDATE_STATE(FI_LOG_CQ, tx_buf, RXM_RNDV_FINISH);
 
 	if (!rxm_ep->rxm_mr_local)
-		rxm_ep_msg_mr_closev(tx_buf->mr, tx_buf->count);
+		rxm_msg_mr_closev(tx_buf->mr, tx_buf->count);
 
 	ret = rxm_cq_tx_comp_write(rxm_ep, ofi_tx_cq_flags(tx_buf->pkt.hdr.op),
 				   tx_buf->app_context, tx_buf->flags);
@@ -434,7 +436,6 @@ ssize_t rxm_cq_copy_seg_data(struct rxm_rx_buf *rx_buf, int *done)
 	}
 }
 
-static inline
 ssize_t rxm_cq_handle_seg_data(struct rxm_rx_buf *rx_buf)
 {
 	int done;
@@ -493,7 +494,6 @@ rxm_cq_rndv_read_prepare_deferred(struct rxm_deferred_tx_entry **def_tx_entry, s
 	return 0;
 }
 
-static inline
 ssize_t rxm_cq_handle_rndv(struct rxm_rx_buf *rx_buf)
 {
 	size_t i, index = 0, offset = 0, count, total_recv_len;
@@ -531,11 +531,10 @@ ssize_t rxm_cq_handle_rndv(struct rxm_rx_buf *rx_buf)
 	if (!rx_buf->ep->rxm_mr_local) {
 		total_recv_len = MIN(rx_buf->recv_entry->total_len,
 				     rx_buf->pkt.hdr.size);
-		ret = rxm_ep_msg_mr_regv_lim(rx_buf->ep,
-					     rx_buf->recv_entry->rxm_iov.iov,
-					     rx_buf->recv_entry->rxm_iov.count,
-					     total_recv_len,
-					     FI_READ, rx_buf->mr);
+		ret = rxm_msg_mr_regv(rx_buf->ep,
+				      rx_buf->recv_entry->rxm_iov.iov,
+				      rx_buf->recv_entry->rxm_iov.count,
+				      total_recv_len, FI_READ, rx_buf->mr);
 		if (OFI_UNLIKELY(ret))
 			return ret;
 
@@ -597,7 +596,6 @@ readv_err:
 	return ret;
 }
 
-static inline
 ssize_t rxm_cq_handle_eager(struct rxm_rx_buf *rx_buf)
 {
 	uint64_t done_len = ofi_copy_to_iov(rx_buf->recv_entry->rxm_iov.iov,
@@ -607,15 +605,31 @@ ssize_t rxm_cq_handle_eager(struct rxm_rx_buf *rx_buf)
 	return rxm_finish_recv(rx_buf, done_len);
 }
 
+ssize_t rxm_cq_handle_coll_eager(struct rxm_rx_buf *rx_buf)
+{
+	uint64_t done_len = ofi_copy_to_iov(rx_buf->recv_entry->rxm_iov.iov,
+					    rx_buf->recv_entry->rxm_iov.count,
+					    0, rx_buf->pkt.data,
+					    rx_buf->pkt.hdr.size);
+	if(rx_buf->pkt.hdr.tag & OFI_COLL_TAG_FLAG) {
+		ofi_coll_handle_xfer_comp(rx_buf->pkt.hdr.tag,
+				rx_buf->recv_entry->context);
+		rxm_recv_entry_release(rx_buf->recv_entry->recv_queue,
+				rx_buf->recv_entry);
+		return FI_SUCCESS;
+	}
+	return rxm_finish_recv(rx_buf, done_len);
+}
+
 ssize_t rxm_cq_handle_rx_buf(struct rxm_rx_buf *rx_buf)
 {
 	switch (rx_buf->pkt.ctrl_hdr.type) {
 	case rxm_ctrl_eager:
-		return rxm_cq_handle_eager(rx_buf);
+		return rx_buf->ep->txrx_ops->handle_eager_rx(rx_buf);
 	case rxm_ctrl_rndv:
-		return rxm_cq_handle_rndv(rx_buf);
+		return rx_buf->ep->txrx_ops->handle_rndv_rx(rx_buf);
 	case rxm_ctrl_seg:
-		return rxm_cq_handle_seg_data(rx_buf);
+		return rx_buf->ep->txrx_ops->handle_seg_data_rx(rx_buf);
 	default:
 		FI_WARN(&rxm_prov, FI_LOG_CQ, "Unknown message type\n");
 		assert(0);
@@ -728,7 +742,7 @@ ssize_t rxm_sar_handle_segment(struct rxm_rx_buf *rx_buf)
 		return rxm_handle_recv_comp(rx_buf);
 	rx_buf->recv_entry =
 		container_of(sar_entry, struct rxm_recv_entry, sar.entry);
-	return rxm_cq_handle_seg_data(rx_buf);
+	return rx_buf->ep->txrx_ops->handle_seg_data_rx(rx_buf);
 }
 
 static ssize_t rxm_rndv_send_ack_inject(struct rxm_rx_buf *rx_buf)
@@ -930,6 +944,8 @@ static inline void rxm_do_atomic(struct rxm_pkt *pkt, void *dst, void *src,
 							    count);
 		break;
 	case ofi_op_atomic_compare:
+		assert(op >= OFI_SWAP_OP_START &&
+		       op < OFI_SWAP_OP_START + OFI_SWAP_OP_LAST);
 		ofi_atomic_swap_handlers[op - OFI_SWAP_OP_START][datatype](dst,
 						src, cmp, res, count);
 		break;
@@ -1082,10 +1098,28 @@ static inline ssize_t rxm_handle_atomic_resp(struct rxm_ep *rxm_ep,
 err:
 	rxm_rx_buf_finish(rx_buf);
 	ofi_buf_free(tx_buf);
+	ofi_atomic_inc32(&rxm_ep->atomic_tx_credits);
+	assert(ofi_atomic_get32(&rxm_ep->atomic_tx_credits) <=
+				rxm_ep->rxm_info->tx_attr->size);
 
 	return ret;
 }
 
+int rxm_finish_coll_eager_send(struct rxm_ep *rxm_ep, struct rxm_tx_eager_buf *tx_eager_buf)
+{
+	int ret;
+
+	if (tx_eager_buf->pkt.hdr.tag & OFI_COLL_TAG_FLAG) {
+		ofi_coll_handle_xfer_comp(tx_eager_buf->pkt.hdr.tag,
+				tx_eager_buf->app_context);
+		ret = FI_SUCCESS;
+	} else {
+		ret = rxm_finish_eager_send(rxm_ep, tx_eager_buf);
+	}
+
+	return ret;
+};
+
 static ssize_t rxm_cq_handle_comp(struct rxm_ep *rxm_ep,
 				  struct fi_cq_data_entry *comp)
 {
@@ -1107,8 +1141,7 @@ static ssize_t rxm_cq_handle_comp(struct rxm_ep *rxm_ep,
 	switch (RXM_GET_PROTO_STATE(comp->op_context)) {
 	case RXM_TX:
 		tx_eager_buf = comp->op_context;
-		assert(comp->flags & FI_SEND);
-		ret = rxm_finish_eager_send(rxm_ep, tx_eager_buf);
+		ret = rxm_ep->txrx_ops->comp_eager_tx(rxm_ep, tx_eager_buf);
 		ofi_buf_free(tx_eager_buf);
 		return ret;
 	case RXM_SAR_TX:
@@ -1438,6 +1471,15 @@ void rxm_ep_progress(struct util_ep *util_ep)
 	ofi_ep_lock_release(util_ep);
 }
 
+void rxm_ep_progress_coll(struct util_ep *util_ep)
+{
+	ofi_ep_lock_acquire(util_ep);
+	rxm_ep_do_progress(util_ep);
+	ofi_ep_lock_release(util_ep);
+
+	ofi_coll_ep_progress(&util_ep->ep_fid);
+}
+
 static int rxm_cq_close(struct fid *fid)
 {
 	struct util_cq *util_cq;
diff --git a/prov/rxm/src/rxm_domain.c b/prov/rxm/src/rxm_domain.c
index 6c9162c..0f53645 100644
--- a/prov/rxm/src/rxm_domain.c
+++ b/prov/rxm/src/rxm_domain.c
@@ -158,6 +158,62 @@ static struct fi_ops rxm_mr_ops = {
 	.ops_open = fi_no_ops_open,
 };
 
+int rxm_msg_mr_reg_internal(struct rxm_domain *rxm_domain, const void *buf,
+	size_t len, uint64_t acs, uint64_t flags, struct fid_mr **mr)
+{
+	int ret, tries = 0;
+
+	/* If we can't get a key within 1024 tries, give up */
+	do {
+		ret = fi_mr_reg(rxm_domain->msg_domain, buf, len, acs, 0,
+				rxm_domain->mr_key++ | FI_PROV_SPECIFIC,
+				flags, mr, NULL);
+	} while (ret == -FI_ENOKEY && tries++ < 1024);
+
+	return ret;
+}
+
+void rxm_msg_mr_closev(struct fid_mr **mr, size_t count)
+{
+	int ret;
+	size_t i;
+
+	for (i = 0; i < count; i++) {
+		if (mr[i]) {
+			ret = fi_close(&mr[i]->fid);
+			if (ret)
+				FI_WARN(&rxm_prov, FI_LOG_EP_DATA,
+					"Unable to close msg mr: %zu\n", i);
+			mr[i] = NULL;
+		}
+	}
+}
+
+int rxm_msg_mr_regv(struct rxm_ep *rxm_ep, const struct iovec *iov,
+		    size_t count, size_t reg_limit, uint64_t access,
+		    struct fid_mr **mr)
+{
+	struct rxm_domain *rxm_domain;
+	size_t i;
+	int ret;
+
+	rxm_domain = container_of(rxm_ep->util_ep.domain, struct rxm_domain,
+				  util_domain);
+
+	for (i = 0; i < count && reg_limit; i++) {
+		size_t len = MIN(iov[i].iov_len, reg_limit);
+		ret = rxm_msg_mr_reg_internal(rxm_domain, iov[i].iov_base,
+					      len, access, 0, &mr[i]);
+		if (ret)
+			goto err;
+		reg_limit -= len;
+	}
+	return 0;
+err:
+	rxm_msg_mr_closev(mr, count);
+	return ret;
+}
+
 static uint64_t
 rxm_mr_get_msg_access(struct rxm_domain *rxm_domain, uint64_t access)
 {
@@ -316,13 +372,6 @@ int rxm_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 	if (ret)
 		goto err1;
 
-	/* Force core provider to supply MR key */
-	if (FI_VERSION_LT(fabric->api_version, FI_VERSION(1, 5)) ||
-	    (msg_info->domain_attr->mr_mode & (FI_MR_BASIC | FI_MR_SCALABLE)))
-		msg_info->domain_attr->mr_mode = FI_MR_BASIC;
-	else
-		msg_info->domain_attr->mr_mode |= FI_MR_PROV_KEY;
-
 	ret = fi_domain(rxm_fabric->msg_fabric, msg_info,
 			&rxm_domain->msg_domain, context);
 	if (ret)
@@ -333,9 +382,10 @@ int rxm_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 		goto err3;
 	}
 
-	/* We maintain an RMA key to MR map used for emulated atomic access
-	 * and bounds validation. We turn off the map mode bit FI_MR_PROV_KEY
-	 * since we specify the key used by MSG_EP provider. */
+	/* We turn off the mr map mode bit FI_MR_PROV_KEY.  We always use the
+	 * key returned by the MSG provider.  That key may be generated by the
+	 * MSG provider, or will be provided as input by the rxm provider.
+	 */
 	rxm_domain->util_domain.mr_map.mode &= ~FI_MR_PROV_KEY;
 
 	rxm_domain->max_atomic_size = rxm_ep_max_atomic_size(info);
diff --git a/prov/rxm/src/rxm_ep.c b/prov/rxm/src/rxm_ep.c
index 0ac88fe..b08e3ec 100644
--- a/prov/rxm/src/rxm_ep.c
+++ b/prov/rxm/src/rxm_ep.c
@@ -34,8 +34,10 @@
 #include <math.h>
 
 #include <rdma/fabric.h>
+#include <rdma/fi_collective.h>
 #include "ofi.h"
 #include <ofi_util.h>
+#include <ofi_coll.h>
 
 #include "rxm.h"
 
@@ -103,41 +105,23 @@ static int rxm_match_unexp_msg_tag_addr(struct dlist_entry *item, const void *ar
 		ofi_match_tag(attr->tag, attr->ignore, unexp_msg->tag);
 }
 
-static inline int
-rxm_mr_buf_reg(struct rxm_ep *rxm_ep, void *addr, size_t len, void **context)
-{
-	int ret = FI_SUCCESS;
-	struct fid_mr *mr;
-	struct rxm_domain *rxm_domain = container_of(rxm_ep->util_ep.domain,
-						     struct rxm_domain, util_domain);
-
-	*context = NULL;
-	if (rxm_ep->msg_mr_local) {
-		struct fid_domain *msg_domain =
-			(struct fid_domain *)rxm_domain->msg_domain;
-
-		ret = fi_mr_reg(msg_domain, addr, len,
-				FI_SEND | FI_RECV | FI_READ | FI_WRITE,
-				0, 0, 0, &mr, NULL);
-		*context = mr;
-	}
-
-	return ret;
-}
-
 static int rxm_buf_reg(struct ofi_bufpool_region *region)
 {
 	struct rxm_buf_pool *pool = region->pool->attr.context;
+	struct rxm_domain *rxm_domain;
 	int ret;
 
-	if ((pool->type != RXM_BUF_POOL_TX_INJECT) &&
-	    pool->rxm_ep->msg_mr_local) {
-		ret = rxm_mr_buf_reg(pool->rxm_ep, region->mem_region,
-				     region->pool->region_size,
-				     &region->context);
-	} else {
-		ret = 0;
-	}
+	if ((pool->type == RXM_BUF_POOL_TX_INJECT) ||
+	    !pool->rxm_ep->msg_mr_local)
+		return 0;
+
+	rxm_domain = container_of(pool->rxm_ep->util_ep.domain,
+				  struct rxm_domain, util_domain);
+	ret = rxm_msg_mr_reg_internal(rxm_domain, region->mem_region,
+				      region->pool->region_size,
+				      FI_SEND | FI_RECV | FI_READ | FI_WRITE,
+				      OFI_MR_NOCACHE,
+				      (struct fid_mr **) &region->context);
 
 	return ret;
 }
@@ -359,7 +343,7 @@ static int rxm_ep_txrx_pool_create(struct rxm_ep *rxm_ep)
 		[RXM_BUF_POOL_TX_SAR] = rxm_ep->msg_info->tx_attr->size,
 		[RXM_BUF_POOL_RMA] = rxm_ep->msg_info->tx_attr->size,
 	};
-	size_t entry_sizes[] = {		
+	size_t entry_sizes[] = {
 		[RXM_BUF_POOL_RX] = rxm_eager_limit +
 				    sizeof(struct rxm_rx_buf),
 		[RXM_BUF_POOL_TX] = rxm_eager_limit +
@@ -390,8 +374,9 @@ static int rxm_ep_txrx_pool_create(struct rxm_ep *rxm_ep)
 			continue;
 
 		ret = rxm_buf_pool_create(rxm_ep, entry_sizes[i],
-					  (i == RXM_BUF_POOL_RX ? 0 :
-					   rxm_ep->rxm_info->tx_attr->size),
+					  (i == RXM_BUF_POOL_RX ||
+					   i == RXM_BUF_POOL_TX_ATOMIC) ? 0 :
+					  rxm_ep->rxm_info->tx_attr->size,
 					  queue_sizes[i],
 					  &rxm_ep->buf_pools[i], i);
 		if (ret)
@@ -468,6 +453,18 @@ static int rxm_getname(fid_t fid, void *addr, size_t *addrlen)
 	return fi_getname(&rxm_ep->msg_pep->fid, addr, addrlen);
 }
 
+static int rxm_join_coll(struct fid_ep *ep, const void *addr, uint64_t flags,
+		    struct fid_mc **mc, void *context)
+{
+	if((flags & FI_COLLECTIVE) == 0) {
+		return -FI_ENOSYS;
+	}
+
+	struct fi_collective_addr *c_addr = (struct fi_collective_addr *) addr;
+	return ofi_join_collective(ep, c_addr->coll_addr, c_addr->set, flags,
+				mc, context);
+}
+
 static struct fi_ops_cm rxm_ops_cm = {
 	.size = sizeof(struct fi_ops_cm),
 	.setname = rxm_setname,
@@ -478,7 +475,21 @@ static struct fi_ops_cm rxm_ops_cm = {
 	.accept = fi_no_accept,
 	.reject = fi_no_reject,
 	.shutdown = fi_no_shutdown,
-	.join = fi_no_join,
+	.join = rxm_join_coll,
+};
+
+static struct rxm_handle_txrx_ops rxm_rx_ops = {
+	.comp_eager_tx = rxm_finish_eager_send,
+	.handle_eager_rx = rxm_cq_handle_eager,
+	.handle_rndv_rx = rxm_cq_handle_rndv,
+	.handle_seg_data_rx =rxm_cq_handle_seg_data,
+};
+
+static struct rxm_handle_txrx_ops rxm_coll_rx_ops = {
+	.comp_eager_tx = rxm_finish_coll_eager_send,
+	.handle_eager_rx = rxm_cq_handle_coll_eager,
+	.handle_rndv_rx = rxm_cq_handle_rndv,
+	.handle_seg_data_rx =rxm_cq_handle_seg_data,
 };
 
 static int rxm_ep_cancel_recv(struct rxm_ep *rxm_ep,
@@ -953,8 +964,8 @@ rxm_ep_alloc_rndv_tx_res(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn, void
 	tx_buf->count = count;
 
 	if (!rxm_ep->rxm_mr_local) {
-		ret = rxm_ep_msg_mr_regv(rxm_ep, iov, tx_buf->count,
-					 FI_REMOTE_READ, tx_buf->mr);
+		ret = rxm_msg_mr_regv(rxm_ep, iov, tx_buf->count, data_len,
+				      FI_REMOTE_READ, tx_buf->mr);
 		if (ret)
 			goto err;
 		mr_iov = tx_buf->mr;
@@ -1005,7 +1016,7 @@ err:
 	FI_DBG(&rxm_prov, FI_LOG_EP_DATA,
 	       "Transmit for MSG provider failed\n");
 	if (!rxm_ep->rxm_mr_local)
-		rxm_ep_msg_mr_closev(tx_buf->mr, tx_buf->count);
+		rxm_msg_mr_closev(tx_buf->mr, tx_buf->count);
 	ofi_buf_free(tx_buf);
 	return ret;
 }
@@ -1105,7 +1116,7 @@ rxm_ep_sar_tx_send(struct rxm_ep *rxm_ep, struct rxm_conn *rxm_conn,
 	struct rxm_deferred_tx_entry *def_tx_entry;
 	uint64_t msg_id = 0;
 
-	assert(segs_cnt >= 2);	
+	assert(segs_cnt >= 2);
 
 	first_tx_buf = rxm_ep_sar_tx_prepare_segment(rxm_ep, rxm_conn, context, data_len,
 						     rxm_eager_limit, 0, data, flags,
@@ -1603,7 +1614,7 @@ static ssize_t rxm_ep_senddata(struct fid_ep *ep_fid, const void *buf, size_t le
 	if (OFI_UNLIKELY(ret))
 		goto unlock;
 
-	ret = rxm_ep_send_common(rxm_ep, rxm_conn, &iov, desc, 1, context, data,
+	ret = rxm_ep_send_common(rxm_ep, rxm_conn, &iov, &desc, 1, context, data,
 				  rxm_ep_tx_flags(rxm_ep) | FI_REMOTE_CQ_DATA,
 				  0, ofi_op_msg, rxm_conn->inject_data_pkt);
 unlock:
@@ -1844,7 +1855,7 @@ static ssize_t rxm_ep_tsenddata(struct fid_ep *ep_fid, const void *buf, size_t l
 	if (OFI_UNLIKELY(ret))
 		goto unlock;
 
-	ret = rxm_ep_send_common(rxm_ep, rxm_conn, &iov, desc, 1, context, data,
+	ret = rxm_ep_send_common(rxm_ep, rxm_conn, &iov, &desc, 1, context, data,
 				  rxm_ep_tx_flags(rxm_ep) | FI_REMOTE_CQ_DATA,
 				  tag, ofi_op_tagged, rxm_conn->tinject_data_pkt);
 unlock:
@@ -1918,6 +1929,34 @@ static struct fi_ops_tagged rxm_ops_tagged_thread_unsafe = {
 	.injectdata = rxm_ep_tinjectdata_fast,
 };
 
+static struct fi_ops_collective rxm_ops_collective = {
+	.size = sizeof(struct fi_ops_collective),
+	.barrier = ofi_ep_barrier,
+	.broadcast = fi_coll_no_broadcast,
+	.alltoall = fi_coll_no_alltoall,
+	.allreduce = ofi_ep_allreduce,
+	.allgather = fi_coll_no_allgather,
+	.reduce_scatter = fi_coll_no_reduce_scatter,
+	.reduce = fi_coll_no_reduce,
+	.scatter = fi_coll_no_scatter,
+	.gather = fi_coll_no_gather,
+	.msg = fi_coll_no_msg,
+};
+
+static struct fi_ops_collective rxm_ops_collective_none = {
+	.size = sizeof(struct fi_ops_collective),
+	.barrier = fi_coll_no_barrier,
+	.broadcast = fi_coll_no_broadcast,
+	.alltoall = fi_coll_no_alltoall,
+	.allreduce = fi_coll_no_allreduce,
+	.allgather = fi_coll_no_allgather,
+	.reduce_scatter = fi_coll_no_reduce_scatter,
+	.reduce = fi_coll_no_reduce,
+	.scatter = fi_coll_no_scatter,
+	.gather = fi_coll_no_gather,
+	.msg = fi_coll_no_msg,
+};
+
 static int rxm_ep_msg_res_close(struct rxm_ep *rxm_ep)
 {
 	int ret, retv = 0;
@@ -2155,6 +2194,8 @@ static void rxm_ep_settings_init(struct rxm_ep *rxm_ep)
 			   rxm_ep->msg_info->rx_attr->size) / 2;
 	rxm_ep->comp_per_progress = (rxm_ep->comp_per_progress > max_prog_val) ?
 				    max_prog_val : rxm_ep->comp_per_progress;
+	ofi_atomic_initialize32(&rxm_ep->atomic_tx_credits,
+				rxm_ep->rxm_info->tx_attr->size);
 
 	rxm_ep->msg_mr_local = ofi_mr_local(rxm_ep->msg_info);
 	rxm_ep->rxm_mr_local = ofi_mr_local(rxm_ep->rxm_info);
@@ -2418,8 +2459,16 @@ int rxm_endpoint(struct fid_domain *domain, struct fi_info *info,
 			     (int *)&rxm_ep->comp_per_progress))
 		rxm_ep->comp_per_progress = 1;
 
-	ret = ofi_endpoint_init(domain, &rxm_util_prov, info, &rxm_ep->util_ep,
-				context, &rxm_ep_progress);
+	if (rxm_ep->rxm_info->caps & FI_COLLECTIVE) {
+		ret = ofi_endpoint_init(domain, &rxm_util_prov, info,
+					&rxm_ep->util_ep, context,
+					&rxm_ep_progress_coll);
+	} else {
+		ret = ofi_endpoint_init(domain, &rxm_util_prov, info,
+					&rxm_ep->util_ep, context,
+					&rxm_ep_progress);
+	}
+
 	if (ret)
 		goto err1;
 
@@ -2432,7 +2481,16 @@ int rxm_endpoint(struct fid_domain *domain, struct fi_info *info,
 	*ep_fid = &rxm_ep->util_ep.ep_fid;
 	(*ep_fid)->fid.ops = &rxm_ep_fi_ops;
 	(*ep_fid)->ops = &rxm_ops_ep;
-	(*ep_fid)->cm = &rxm_ops_cm;
+		(*ep_fid)->cm = &rxm_ops_cm;
+
+	if(rxm_ep->rxm_info->caps & FI_COLLECTIVE) {
+		(*ep_fid)->collective = &rxm_ops_collective;
+		rxm_ep->txrx_ops = &rxm_coll_rx_ops;
+	} else {
+		(*ep_fid)->collective = &rxm_ops_collective_none;
+		rxm_ep->txrx_ops = &rxm_rx_ops;
+	}
+
 	if (rxm_ep->util_ep.domain->threading != FI_THREAD_SAFE) {
 		(*ep_fid)->msg = &rxm_ops_msg_thread_unsafe;
 		(*ep_fid)->tagged = &rxm_ops_tagged_thread_unsafe;
diff --git a/prov/rxm/src/rxm_init.c b/prov/rxm/src/rxm_init.c
index bb3f0aa..9b58fc4 100644
--- a/prov/rxm/src/rxm_init.c
+++ b/prov/rxm/src/rxm_init.c
@@ -38,8 +38,10 @@
 #include <ofi_prov.h>
 #include "rxm.h"
 
-#define RXM_ATOMIC_UNSUPPORTED_MSG_ORDER (OFI_ORDER_RAR_SET | OFI_ORDER_RAW_SET | \
-					  OFI_ORDER_WAR_SET | OFI_ORDER_WAW_SET | \
+#define RXM_ATOMIC_UNSUPPORTED_MSG_ORDER (FI_ORDER_RAW | FI_ORDER_ATOMIC_RAW | \
+					  FI_ORDER_RAR | FI_ORDER_ATOMIC_RAR | \
+					  FI_ORDER_WAW | FI_ORDER_ATOMIC_WAW | \
+					  FI_ORDER_WAR | FI_ORDER_ATOMIC_WAR | \
 					  FI_ORDER_SAR | FI_ORDER_SAW)
 
 #define RXM_PASSTHRU_CAPS (FI_MSG | FI_RMA | FI_SEND | FI_RECV |	\
@@ -50,6 +52,7 @@ size_t rxm_msg_tx_size		= 128;
 size_t rxm_msg_rx_size		= 128;
 size_t rxm_def_univ_size	= 256;
 size_t rxm_eager_limit		= RXM_BUF_SIZE - sizeof(struct rxm_pkt);
+int force_auto_progress		= 0;
 
 char *rxm_proto_state_str[] = {
 	RXM_PROTO_STATES(OFI_STR)
@@ -59,30 +62,29 @@ char *rxm_proto_state_str[] = {
  * - Support FI_MR_LOCAL/FI_LOCAL_MR as ofi_rxm can handle it.
  * - The RxM FI_RMA implementation is pass-through but the provider can handle
  *   FI_MR_PROV_KEY and FI_MR_VIRT_ADDR in its large message transfer rendezvous
- *   protocol.
+ *   protocol.  We can set FI_MR_PROV_KEY and FI_MR_VIRT_ADDR only if the app
+ *   is not using RMA.
  * - fi_alter_domain_attr should correctly set the mr_mode in return fi_info
  *   based on hints.
  */
 void rxm_info_to_core_mr_modes(uint32_t version, const struct fi_info *hints,
 			       struct fi_info *core_info)
 {
-	/* We handle FI_MR_BASIC and FI_MR_SCALABLE irrespective of version */
 	if (hints && hints->domain_attr &&
 	    (hints->domain_attr->mr_mode & (FI_MR_SCALABLE | FI_MR_BASIC))) {
-		core_info->mode = FI_LOCAL_MR;
+		core_info->mode |= FI_LOCAL_MR;
 		core_info->domain_attr->mr_mode = hints->domain_attr->mr_mode;
 	} else if (FI_VERSION_LT(version, FI_VERSION(1, 5))) {
 		core_info->mode |= FI_LOCAL_MR;
-		/* Specify FI_MR_UNSPEC (instead of FI_MR_BASIC) so that
-		 * providers that support only FI_MR_SCALABLE aren't dropped */
 		core_info->domain_attr->mr_mode = FI_MR_UNSPEC;
 	} else {
 		core_info->domain_attr->mr_mode |= FI_MR_LOCAL;
-		if (!hints || !ofi_rma_target_allowed(hints->caps))
+		if (!hints || !hints->domain_attr ||
+		    !ofi_rma_target_allowed(hints->caps))
 			core_info->domain_attr->mr_mode |= OFI_MR_BASIC_MAP;
-		else if (hints->domain_attr)
+		else
 			core_info->domain_attr->mr_mode |=
-				hints->domain_attr->mr_mode & OFI_MR_BASIC_MAP;
+				hints->domain_attr->mr_mode;
 	}
 }
 
@@ -266,7 +268,8 @@ static void rxm_alter_info(const struct fi_info *hints, struct fi_info *info)
 					hints->ep_attr->mem_tag_format;
 			}
 		}
-		if (cur->domain_attr->data_progress == FI_PROGRESS_AUTO)
+		if (cur->domain_attr->data_progress == FI_PROGRESS_AUTO ||
+		    force_auto_progress)
 			cur->domain_attr->threading = FI_THREAD_SAFE;
 	}
 }
@@ -346,7 +349,7 @@ static void rxm_fini(void)
 struct fi_provider rxm_prov = {
 	.name = OFI_UTIL_PREFIX "rxm",
 	.version = FI_VERSION(RXM_MAJOR_VERSION, RXM_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = rxm_getinfo,
 	.fabric = rxm_fabric,
 	.cleanup = rxm_fini
@@ -410,6 +413,10 @@ RXM_INI
 			"decrease noise during cq polling, but may result in "
 			"longer connection establishment times. (default: 10000).");
 
+	fi_param_define(&rxm_prov, "data_auto_progress", FI_PARAM_BOOL,
+			"Force auto-progress for data transfers even if app "
+			"requested manual progress (default: false/no) \n");
+
 	fi_param_get_size_t(&rxm_prov, "tx_size", &rxm_info.tx_attr->size);
 	fi_param_get_size_t(&rxm_prov, "rx_size", &rxm_info.rx_attr->size);
 	fi_param_get_size_t(&rxm_prov, "msg_tx_size", &rxm_msg_tx_size);
@@ -418,6 +425,12 @@ RXM_INI
 	if (fi_param_get_int(&rxm_prov, "cm_progress_interval",
 				(int *) &rxm_cm_progress_interval))
 		rxm_cm_progress_interval = 10000;
+	fi_param_get_bool(&rxm_prov, "data_auto_progress", &force_auto_progress);
+
+	if (force_auto_progress)
+		FI_INFO(&rxm_prov, FI_LOG_CORE, "auto-progress for data requested "
+			"(FI_OFI_RXM_DATA_AUTO_PROGRESS = 1), domain threading "
+			"level would be set to FI_THREAD_SAFE\n");
 
 	if (rxm_init_info()) {
 		FI_WARN(&rxm_prov, FI_LOG_CORE, "Unable to initialize rxm_info\n");
diff --git a/prov/rxm/src/rxm_rma.c b/prov/rxm/src/rxm_rma.c
index 45e70dc..0b86951 100644
--- a/prov/rxm/src/rxm_rma.c
+++ b/prov/rxm/src/rxm_rma.c
@@ -40,16 +40,14 @@ rxm_ep_rma_reg_iov(struct rxm_ep *rxm_ep, const struct iovec *msg_iov,
 		   void **desc, void **desc_storage, size_t iov_count,
 		   uint64_t comp_flags, struct rxm_rma_buf *rma_buf)
 {
-	size_t i;
+	size_t i, ret;
 
 	if (!rxm_ep->msg_mr_local)
 		return FI_SUCCESS;
 
 	if (!rxm_ep->rxm_mr_local) {
-		ssize_t ret =
-			rxm_ep_msg_mr_regv(rxm_ep, msg_iov, iov_count,
-					   comp_flags & (FI_WRITE | FI_READ),
-					   rma_buf->mr.mr);
+		ret = rxm_msg_mr_regv(rxm_ep, msg_iov, iov_count, SIZE_MAX,
+				      comp_flags, rma_buf->mr.mr);
 		if (OFI_UNLIKELY(ret))
 			return ret;
 
@@ -104,7 +102,7 @@ rxm_ep_rma_common(struct rxm_ep *rxm_ep, const struct fi_msg_rma *msg, uint64_t
 		goto unlock;
 
 	if ((rxm_ep->msg_mr_local) && (!rxm_ep->rxm_mr_local))
-		rxm_ep_msg_mr_closev(rma_buf->mr.mr, rma_buf->mr.count);
+		rxm_msg_mr_closev(rma_buf->mr.mr, rma_buf->mr.count);
 release:
 	ofi_buf_free(rma_buf);
 unlock:
diff --git a/prov/shm/Makefile.include b/prov/shm/Makefile.include
index 84285be..fbd5ac5 100644
--- a/prov/shm/Makefile.include
+++ b/prov/shm/Makefile.include
@@ -13,6 +13,7 @@ _shm_files = \
 	prov/shm/src/smr_fabric.c	\
 	prov/shm/src/smr_init.c		\
 	prov/shm/src/smr_av.c		\
+	prov/shm/src/smr_signal.h	\
 	prov/shm/src/smr.h
 
 if HAVE_SHM_DL
diff --git a/prov/shm/src/smr.h b/prov/shm/src/smr.h
index 8b86541..e7afd9f 100644
--- a/prov/shm/src/smr.h
+++ b/prov/shm/src/smr.h
@@ -107,7 +107,7 @@ struct smr_ep_entry {
 
 struct smr_ep;
 typedef int (*smr_rx_comp_func)(struct smr_ep *ep, void *context, uint32_t op,
-		uint16_t flags, size_t len, void *buf, void *addr,
+		uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		uint64_t tag, uint64_t data, uint64_t err);
 typedef int (*smr_tx_comp_func)(struct smr_ep *ep, void *context, uint32_t op,
 		uint16_t flags, uint64_t err);
@@ -227,19 +227,19 @@ int smr_tx_comp(struct smr_ep *ep, void *context, uint32_t op,
 int smr_tx_comp_signal(struct smr_ep *ep, void *context, uint32_t op,
 		uint16_t flags, uint64_t err);
 int smr_complete_rx(struct smr_ep *ep, void *context, uint32_t op,
-		uint16_t flags, size_t len, void *buf, void *addr,
+		uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		uint64_t tag, uint64_t data, uint64_t err);
 int smr_rx_comp(struct smr_ep *ep, void *context, uint32_t op,
-		uint16_t flags, size_t len, void *buf, void *addr,
+		uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		uint64_t tag, uint64_t data, uint64_t err);
 int smr_rx_src_comp(struct smr_ep *ep, void *context, uint32_t op,
-		uint16_t flags, size_t len, void *buf, void *addr,
+		uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		uint64_t tag, uint64_t data, uint64_t err);
 int smr_rx_comp_signal(struct smr_ep *ep, void *context, uint32_t op,
-		uint16_t flags, size_t len, void *buf, void *addr,
+		uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		uint64_t tag, uint64_t data, uint64_t err);
 int smr_rx_src_comp_signal(struct smr_ep *ep, void *context, uint32_t op,
-		uint16_t flags, size_t len, void *buf, void *addr,
+		uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		uint64_t tag, uint64_t data, uint64_t err);
 
 uint64_t smr_rx_cq_flags(uint32_t op, uint16_t op_flags);
diff --git a/prov/shm/src/smr_atomic.c b/prov/shm/src/smr_atomic.c
index 2d1de2d..e2fc1bf 100644
--- a/prov/shm/src/smr_atomic.c
+++ b/prov/shm/src/smr_atomic.c
@@ -158,7 +158,7 @@ static void smr_post_fetch_resp(struct smr_ep *ep, struct smr_cmd *cmd,
 	assert(!ofi_cirque_isfull(smr_resp_queue(ep->region)));
 	resp = ofi_cirque_tail(smr_resp_queue(ep->region));
 
-	cmd->msg.hdr.data = (uint64_t) ((char **) resp -
+	cmd->msg.hdr.data = (uintptr_t) ((char **) resp -
 			    (char **) ep->region);
 
 	pend = freestack_pop(ep->pend_fs);
diff --git a/prov/shm/src/smr_attr.c b/prov/shm/src/smr_attr.c
index 917de5b..a88f026 100644
--- a/prov/shm/src/smr_attr.c
+++ b/prov/shm/src/smr_attr.c
@@ -34,7 +34,7 @@
 
 #define SMR_TX_CAPS (OFI_TX_MSG_CAPS | FI_TAGGED | OFI_TX_RMA_CAPS | FI_ATOMICS)
 #define SMR_RX_CAPS (FI_SOURCE | FI_RMA_EVENT | OFI_RX_MSG_CAPS | FI_TAGGED | \
-		     OFI_RX_RMA_CAPS | FI_ATOMICS)
+		     OFI_RX_RMA_CAPS | FI_ATOMICS | FI_DIRECTED_RECV)
 #define SMR_TX_OP_FLAGS (FI_REMOTE_CQ_DATA | FI_COMPLETION | \
 			 FI_INJECT_COMPLETE | FI_TRANSMIT_COMPLETE | \
 			 /* TODO: support for delivery complete */ \
@@ -81,11 +81,11 @@ struct fi_domain_attr smr_domain_attr = {
 	.data_progress = FI_PROGRESS_MANUAL,
 	.resource_mgmt = FI_RM_ENABLED,
 	.av_type = FI_AV_UNSPEC,
-	.mr_mode = FI_MR_SCALABLE,
+	.mr_mode = FI_MR_BASIC | FI_MR_SCALABLE,
 	.mr_key_size = sizeof_field(struct fi_rma_iov, key),
 	.cq_data_size = sizeof_field(struct smr_msg_hdr, data),
 	.cq_cnt = (1 << 10),
-	.ep_cnt = (1 << 10),
+	.ep_cnt = SMR_MAX_PEERS,
 	.tx_ctx_cnt = (1 << 10),
 	.rx_ctx_cnt = (1 << 10),
 	.max_ep_tx_ctx = 1,
diff --git a/prov/shm/src/smr_av.c b/prov/shm/src/smr_av.c
index b046542..2eb7195 100644
--- a/prov/shm/src/smr_av.c
+++ b/prov/shm/src/smr_av.c
@@ -212,7 +212,7 @@ int smr_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 	if (!smr_av)
 		return -FI_ENOMEM;
 
-	util_attr.addrlen = SMR_NAME_SIZE;
+	util_attr.addrlen = NAME_MAX;
 	util_attr.flags = 0;
 	if (attr->count > SMR_MAX_PEERS) {
 		ret = -FI_ENOSYS;
diff --git a/prov/shm/src/smr_comp.c b/prov/shm/src/smr_comp.c
index e336735..10b6dff 100644
--- a/prov/shm/src/smr_comp.c
+++ b/prov/shm/src/smr_comp.c
@@ -89,7 +89,7 @@ int smr_tx_comp_signal(struct smr_ep *ep, void *context, uint32_t op,
 }
 
 int smr_complete_rx(struct smr_ep *ep, void *context, uint32_t op, uint16_t flags,
-		    size_t len, void *buf, void *addr, uint64_t tag, uint64_t data,
+		    size_t len, void *buf, fi_addr_t addr, uint64_t tag, uint64_t data,
 		    uint64_t err)
 {
 	ofi_ep_rx_cntr_inc_func(&ep->util_ep, op);
@@ -102,7 +102,7 @@ int smr_complete_rx(struct smr_ep *ep, void *context, uint32_t op, uint16_t flag
 }
 
 int smr_rx_comp(struct smr_ep *ep, void *context, uint32_t op,
-		uint16_t flags, size_t len, void *buf, void *addr,
+		uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		uint64_t tag, uint64_t data, uint64_t err)
 {
 	struct fi_cq_tagged_entry *comp;
@@ -133,17 +133,16 @@ int smr_rx_comp(struct smr_ep *ep, void *context, uint32_t op,
 }
 
 int smr_rx_src_comp(struct smr_ep *ep, void *context, uint32_t op,
-		    uint16_t flags, size_t len, void *buf, void *addr,
+		    uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		    uint64_t tag, uint64_t data, uint64_t err)
 {
-	ep->util_ep.rx_cq->src[ofi_cirque_windex(ep->util_ep.rx_cq->cirq)] =
-		(uint32_t) (uintptr_t) addr;
+	ep->util_ep.rx_cq->src[ofi_cirque_windex(ep->util_ep.rx_cq->cirq)] = addr;
 	return smr_rx_comp(ep, context, op, flags, len, buf, addr, tag,
 			   data, err);
 }
 
 int smr_rx_comp_signal(struct smr_ep *ep, void *context, uint32_t op,
-		       uint16_t flags, size_t len, void *buf, void *addr,
+		       uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 		       uint64_t tag, uint64_t data, uint64_t err)
 {
 	int ret;
@@ -156,7 +155,7 @@ int smr_rx_comp_signal(struct smr_ep *ep, void *context, uint32_t op,
 }
 
 int smr_rx_src_comp_signal(struct smr_ep *ep, void *context, uint32_t op,
-			   uint16_t flags, size_t len, void *buf, void *addr,
+			   uint16_t flags, size_t len, void *buf, fi_addr_t addr,
 			   uint64_t tag, uint64_t data, uint64_t err)
 {
 	int ret;
diff --git a/prov/shm/src/smr_ep.c b/prov/shm/src/smr_ep.c
index 5614977..df586cd 100644
--- a/prov/shm/src/smr_ep.c
+++ b/prov/shm/src/smr_ep.c
@@ -70,7 +70,7 @@ int smr_getname(fid_t fid, void *addr, size_t *addrlen)
 	if (!addr || *addrlen == 0 ||
 	    snprintf(addr, *addrlen, "%s", ep->name) >= *addrlen)
 		ret = -FI_ETOOSMALL;
-	*addrlen = sizeof(struct smr_addr);
+	*addrlen = strlen(ep->name);
 	return ret;
 }
 
@@ -138,7 +138,7 @@ static int smr_ep_cancel_recv(struct smr_ep *ep, struct smr_queue *queue,
 		recv_entry = container_of(entry, struct smr_ep_entry, entry);
 		ret = smr_complete_rx(ep, (void *) recv_entry->context, ofi_op_msg,
 				  recv_entry->flags, 0,
-				  NULL, (void *) recv_entry->addr,
+				  NULL, recv_entry->addr,
 				  recv_entry->tag, 0, FI_ECANCELED);
 		freestack_push(ep->recv_fs, recv_entry);
 		ret = ret ? ret : 1;
@@ -288,7 +288,7 @@ void smr_format_iov(struct smr_cmd *cmd, fi_addr_t peer_id,
 {
 	smr_generic_format(cmd, peer_id, op, tag, 0, 0, data, op_flags);
 	cmd->msg.hdr.op_src = smr_src_iov;
-	cmd->msg.hdr.src_data = (uint64_t) ((char **) resp - (char **) smr);
+	cmd->msg.hdr.src_data = (uintptr_t) ((char **) resp - (char **) smr);
 	cmd->msg.data.iov_count = count;
 	cmd->msg.hdr.size = total_len;
 	cmd->msg.hdr.msg_id = (uint64_t) (uintptr_t) context;
@@ -424,16 +424,16 @@ static int smr_endpoint_name(char *name, char *addr, size_t addrlen,
 			     int dom_idx, int ep_idx)
 {
 	const char *start;
-	memset(name, 0, SMR_NAME_SIZE);
-	if (!addr || addrlen > SMR_NAME_SIZE)
+	memset(name, 0, NAME_MAX);
+	if (!addr || addrlen > NAME_MAX)
 		return -FI_EINVAL;
 
 	start = smr_no_prefix((const char *) addr);
 	if (strstr(addr, SMR_PREFIX) || dom_idx || ep_idx)
-		snprintf(name, SMR_NAME_SIZE, "%s:%d:%d", start, dom_idx,
+		snprintf(name, NAME_MAX, "%s:%d:%d:%d", start, getuid(), dom_idx,
 			 ep_idx);
 	else
-		snprintf(name, SMR_NAME_SIZE, "%s", start);
+		snprintf(name, NAME_MAX, "%s", start);
 
 	return 0;
 }
@@ -444,7 +444,7 @@ int smr_endpoint(struct fid_domain *domain, struct fi_info *info,
 	struct smr_ep *ep;
 	struct smr_domain *smr_domain;
 	int ret, ep_idx;
-	char name[SMR_NAME_SIZE];
+	char name[NAME_MAX];
 
 	ep = calloc(1, sizeof(*ep));
 	if (!ep)
@@ -460,7 +460,7 @@ int smr_endpoint(struct fid_domain *domain, struct fi_info *info,
 	if (ret)
 		goto err2;
 
-	ret = smr_setname(&ep->util_ep.ep_fid.fid, name, SMR_NAME_SIZE);
+	ret = smr_setname(&ep->util_ep.ep_fid.fid, name, NAME_MAX);
 	if (ret)
 		goto err2;
 
diff --git a/prov/shm/src/smr_init.c b/prov/shm/src/smr_init.c
index a90d242..0a9392a 100644
--- a/prov/shm/src/smr_init.c
+++ b/prov/shm/src/smr_init.c
@@ -34,26 +34,27 @@
 
 #include <ofi_prov.h>
 #include "smr.h"
+#include "smr_signal.h"
 
 
 static void smr_resolve_addr(const char *node, const char *service,
 			     char **addr, size_t *addrlen)
 {
-	char temp_name[SMR_NAME_SIZE];
+	char temp_name[NAME_MAX];
 
 	if (service) {
 		if (node)
-			snprintf(temp_name, SMR_NAME_SIZE, "%s%s:%s",
+			snprintf(temp_name, NAME_MAX, "%s%s:%s",
 				 SMR_PREFIX_NS, node, service);
 		else
-			snprintf(temp_name, SMR_NAME_SIZE, "%s%s",
+			snprintf(temp_name, NAME_MAX, "%s%s",
 				 SMR_PREFIX_NS, service);
 	} else {
 		if (node)
-			snprintf(temp_name, SMR_NAME_SIZE, "%s%s",
+			snprintf(temp_name, NAME_MAX, "%s%s",
 				 SMR_PREFIX, node);
 		else
-			snprintf(temp_name, SMR_NAME_SIZE, "%s%d",
+			snprintf(temp_name, NAME_MAX, "%s%d",
 				 SMR_PREFIX, getpid());
 	}
 
@@ -61,6 +62,30 @@ static void smr_resolve_addr(const char *node, const char *service,
 	*addrlen = strlen(*addr);
 }
 
+static int smr_get_ptrace_scope(void)
+{
+	FILE *file;
+	int scope, ret;
+
+	scope = 0;
+	file = fopen("/proc/sys/kernel/yama/ptrace_scope", "r");
+	if (file) {
+		ret = fscanf(file, "%d", &scope);
+		if (ret != 1) {
+			FI_WARN(&smr_prov, FI_LOG_CORE,
+				"Error getting value from ptrace_scope\n");
+			return -FI_EINVAL;
+		}
+		ret = fclose(file);
+		if (ret) {
+			FI_WARN(&smr_prov, FI_LOG_CORE,
+				"Error closing ptrace_scope file\n");
+			return -FI_EINVAL;
+		}
+	}
+	return scope;
+}
+
 static int smr_getinfo(uint32_t version, const char *node, const char *service,
 		       uint64_t flags, const struct fi_info *hints,
 		       struct fi_info **info)
@@ -68,7 +93,7 @@ static int smr_getinfo(uint32_t version, const char *node, const char *service,
 	struct fi_info *cur;
 	uint64_t mr_mode, msg_order;
 	int fast_rma;
-	int ret;
+	int ptrace_scope, ret;
 
 	mr_mode = hints && hints->domain_attr ? hints->domain_attr->mr_mode :
 						FI_MR_VIRT_ADDR;
@@ -80,6 +105,8 @@ static int smr_getinfo(uint32_t version, const char *node, const char *service,
 	if (ret)
 		return ret;
 
+	ptrace_scope = smr_get_ptrace_scope();
+
 	for (cur = *info; cur; cur = cur->next) {
 		if (!(flags & FI_SOURCE) && !cur->dest_addr)
 			smr_resolve_addr(node, service, (char **) &cur->dest_addr,
@@ -100,19 +127,27 @@ static int smr_getinfo(uint32_t version, const char *node, const char *service,
 			cur->ep_attr->max_order_waw_size = 0;
 			cur->ep_attr->max_order_war_size = 0;
 		}
+		if (ptrace_scope != 0)
+			cur->ep_attr->max_msg_size = SMR_INJECT_SIZE;
 	}
 	return 0;
 }
 
 static void smr_fini(void)
 {
-	/* yawn */
+	struct smr_ep_name *ep_name;
+	struct dlist_entry *tmp;
+
+	dlist_foreach_container_safe(&ep_name_list, struct smr_ep_name,
+				     ep_name, entry, tmp) {
+		free(ep_name);
+	}
 }
 
 struct fi_provider smr_prov = {
 	.name = "shm",
 	.version = FI_VERSION(SMR_MAJOR_VERSION, SMR_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = smr_getinfo,
 	.fabric = smr_fabric,
 	.cleanup = smr_fini
@@ -126,5 +161,13 @@ struct util_prov smr_util_prov = {
 
 SHM_INI
 {
+	dlist_init(&ep_name_list);
+
+	/* Signal handlers to cleanup tmpfs files on an unclean shutdown */
+	smr_reg_sig_hander(SIGBUS);
+	smr_reg_sig_hander(SIGSEGV);
+	smr_reg_sig_hander(SIGTERM);
+	smr_reg_sig_hander(SIGINT);
+
 	return &smr_prov;
 }
diff --git a/prov/shm/src/smr_msg.c b/prov/shm/src/smr_msg.c
index f2f4e5c..0a877cd 100644
--- a/prov/shm/src/smr_msg.c
+++ b/prov/shm/src/smr_msg.c
@@ -50,7 +50,8 @@ static inline uint16_t smr_convert_rx_flags(uint64_t fi_flags)
 	return flags;
 }
 
-static inline struct smr_ep_entry *smr_get_recv_entry(struct smr_ep *ep, uint64_t flags)
+static inline struct smr_ep_entry *smr_get_recv_entry(struct smr_ep *ep,
+		fi_addr_t addr, uint64_t flags)
 {
 	struct smr_ep_entry *entry;
 
@@ -63,6 +64,7 @@ static inline struct smr_ep_entry *smr_get_recv_entry(struct smr_ep *ep, uint64_
 	entry->ignore = 0; /* does this need to be set? */
 	entry->err = 0;
 	entry->flags = smr_convert_rx_flags(flags);
+	entry->addr = ep->util_ep.caps & FI_DIRECTED_RECV ? addr : FI_ADDR_UNSPEC;
 
 	return entry;
 }
@@ -79,7 +81,7 @@ ssize_t smr_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
 
 	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
 	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
-	entry = smr_get_recv_entry(ep, flags | ep->util_ep.rx_msg_flags);
+	entry = smr_get_recv_entry(ep, msg->addr, flags | ep->util_ep.rx_msg_flags);
 	if (!entry) {
 		ret = -FI_EAGAIN;
 		goto out;
@@ -89,7 +91,6 @@ ssize_t smr_recvmsg(struct fid_ep *ep_fid, const struct fi_msg *msg,
 	memcpy(&entry->iov, msg->msg_iov, sizeof(*msg->msg_iov) * msg->iov_count);
 
 	entry->context = msg->context;
-	entry->addr = msg->addr;
 
 	dlist_insert_tail(&entry->entry, &ep->recv_queue.list);
 out:
@@ -109,7 +110,7 @@ ssize_t smr_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
 	assert(!(smr_ep_rx_flags(ep) & FI_MULTI_RECV) || count == 1);
 
 	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
-	entry = smr_get_recv_entry(ep, smr_ep_rx_flags(ep));
+	entry = smr_get_recv_entry(ep, src_addr, smr_ep_rx_flags(ep));
 	if (!entry) {
 		ret = -FI_EAGAIN;
 		goto out;
@@ -119,7 +120,6 @@ ssize_t smr_recvv(struct fid_ep *ep_fid, const struct iovec *iov, void **desc,
 	memcpy(&entry->iov, iov, sizeof(*iov) * count);
 
 	entry->context = context;
-	entry->addr = src_addr;
 
 	dlist_insert_tail(&entry->entry, &ep->recv_queue.list);
 out:
@@ -136,7 +136,7 @@ ssize_t smr_recv(struct fid_ep *ep_fid, void *buf, size_t len, void *desc,
 
 	ep = container_of(ep_fid, struct smr_ep, util_ep.ep_fid.fid);
 	fastlock_acquire(&ep->util_ep.rx_cq->cq_lock);
-	entry = smr_get_recv_entry(ep, smr_ep_rx_flags(ep));
+	entry = smr_get_recv_entry(ep, src_addr, smr_ep_rx_flags(ep));
 	if (!entry) {
 		ret = -FI_EAGAIN;
 		goto out;
@@ -147,7 +147,6 @@ ssize_t smr_recv(struct fid_ep *ep_fid, void *buf, size_t len, void *desc,
 	entry->iov[0].iov_len = len;
 
 	entry->context = context;
-	entry->addr = src_addr;
 
 	dlist_insert_tail(&entry->entry, &ep->recv_queue.list);
 out:
diff --git a/prov/shm/src/smr_progress.c b/prov/shm/src/smr_progress.c
index af302d9..a998bc9 100644
--- a/prov/shm/src/smr_progress.c
+++ b/prov/shm/src/smr_progress.c
@@ -208,8 +208,8 @@ static int smr_progress_multi_recv(struct smr_ep *ep, struct smr_queue *queue,
 	left = entry->iov[0].iov_len - len;
 	if (left < ep->min_multi_recv_size) {
 		ret = smr_complete_rx(ep, entry->context, ofi_op_msg,
-				      SMR_MULTI_RECV |entry->flags, 0, 0,
-				      &entry->addr, 0, 0, 0);
+				      SMR_MULTI_RECV | entry->flags, 0, 0,
+				      entry->addr, 0, 0, 0);
 		freestack_push(ep->recv_fs, entry);
 		return ret;
 	}
@@ -328,7 +328,6 @@ static int smr_progress_cmd_msg(struct smr_ep *ep, struct smr_cmd *cmd)
 	struct dlist_entry *dlist_entry;
 	struct smr_ep_entry *entry;
 	struct smr_unexp_msg *unexp;
-	fi_addr_t addr;
 	size_t total_len = 0;
 	int err, ret = 0;
 
@@ -383,9 +382,9 @@ static int smr_progress_cmd_msg(struct smr_ep *ep, struct smr_cmd *cmd)
 		err = -FI_EINVAL;
 	}
 	ret = smr_complete_rx(ep, entry->context, cmd->msg.hdr.op,
-			  cmd->msg.hdr.op_flags | (entry->flags & ~SMR_MULTI_RECV),
-			  total_len, entry->iov[0].iov_base, &addr, cmd->msg.hdr.tag,
-			  cmd->msg.hdr.data, err);
+			cmd->msg.hdr.op_flags | (entry->flags & ~SMR_MULTI_RECV),
+			total_len, entry->iov[0].iov_base, cmd->msg.hdr.addr,
+			cmd->msg.hdr.tag, cmd->msg.hdr.data, err);
 	if (ret) {
 		FI_WARN(&smr_prov, FI_LOG_EP_CTRL,
 			"unable to process rx completion\n");
@@ -459,10 +458,9 @@ static int smr_progress_cmd_rma(struct smr_ep *ep, struct smr_cmd *cmd)
 		err = -FI_EINVAL;
 	}
 	ret = smr_complete_rx(ep, (void *) cmd->msg.hdr.msg_id,
-			  cmd->msg.hdr.op, cmd->msg.hdr.op_flags,
-			  total_len, iov_count ? iov[0].iov_base : NULL,
-			  &cmd->msg.hdr.addr, 0,
-			  cmd->msg.hdr.data, err);
+			cmd->msg.hdr.op, cmd->msg.hdr.op_flags,
+			total_len, iov_count ? iov[0].iov_base : NULL,
+			cmd->msg.hdr.addr, 0, cmd->msg.hdr.data, err);
 	if (ret) {
 		FI_WARN(&smr_prov, FI_LOG_EP_CTRL,
 			"unable to process rx completion\n");
@@ -535,8 +533,7 @@ static int smr_progress_cmd_atomic(struct smr_ep *ep, struct smr_cmd *cmd)
 
 	ret = smr_complete_rx(ep, NULL, cmd->msg.hdr.op, cmd->msg.hdr.op_flags,
 			      total_len, ioc_count ? ioc[0].addr : NULL,
-			      &cmd->msg.hdr.addr, 0,
-			      cmd->msg.hdr.data, err);
+			      cmd->msg.hdr.addr, 0, cmd->msg.hdr.data, err);
 	if (ret)
 		return ret;
 
@@ -650,9 +647,10 @@ int smr_progress_unexp(struct smr_ep *ep, struct smr_ep_entry *entry)
 	}
 
 	ret = smr_complete_rx(ep, entry->context, unexp_msg->cmd.msg.hdr.op,
-			  unexp_msg->cmd.msg.hdr.op_flags | entry->flags,
-			  total_len, entry->iov[0].iov_base, &entry->addr, entry->tag,
-			  unexp_msg->cmd.msg.hdr.data, entry->err);
+			unexp_msg->cmd.msg.hdr.op_flags | entry->flags,
+			total_len, entry->iov[0].iov_base,
+			unexp_msg->cmd.msg.hdr.addr, entry->tag,
+			unexp_msg->cmd.msg.hdr.data, entry->err);
 	if (ret) {
 		FI_WARN(&smr_prov, FI_LOG_EP_CTRL,
 			"unable to process rx completion\n");
diff --git a/prov/shm/src/smr_signal.h b/prov/shm/src/smr_signal.h
new file mode 100644
index 0000000..d1e6995
--- /dev/null
+++ b/prov/shm/src/smr_signal.h
@@ -0,0 +1,75 @@
+/*
+ * Copyright (c) 2019 Amazon.com, Inc. or its affiliates.
+ * All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#ifndef _SMR_SIGNAL_H_
+#define _SMR_SIGNAL_H_
+#include <signal.h>
+#include <ofi_shm.h>
+
+struct sigaction old_action;
+
+static void smr_handle_signal(int signum, siginfo_t *info, void *ucontext)
+{
+	struct smr_ep_name *ep_name;
+	int ret;
+
+	dlist_foreach_container(&ep_name_list, struct smr_ep_name,
+				ep_name, entry) {
+		shm_unlink(ep_name->name);
+	}
+
+	/* Register the original signum handler, SIG_DFL or otherwise */
+	ret = sigaction(signum, &old_action, NULL);
+	if (ret)
+		return;
+
+	/* Raise signum to execute the original handler */
+	raise(signum);
+}
+
+static void smr_reg_sig_hander(int signum)
+{
+	struct sigaction action;
+	int ret;
+
+	memset(&action, 0, sizeof(action));
+	action.sa_sigaction = smr_handle_signal;
+	action.sa_flags |= SA_SIGINFO;
+
+	ret = sigaction(signum, &action, &old_action);
+	if (ret)
+		FI_WARN(&smr_prov, FI_LOG_FABRIC,
+			"Unable to register handler for sig %d\n", signum);
+}
+
+#endif /* _SMR_SIGNAL_H_ */
diff --git a/prov/sockets/include/sock.h b/prov/sockets/include/sock.h
index 4fe87cf..e762d96 100644
--- a/prov/sockets/include/sock.h
+++ b/prov/sockets/include/sock.h
@@ -377,6 +377,7 @@ struct sock_av {
 	int    shared;
 	struct dlist_entry ep_list;
 	fastlock_t list_lock;
+	fastlock_t table_lock;
 };
 
 struct sock_fid_list {
diff --git a/prov/sockets/src/sock_av.c b/prov/sockets/src/sock_av.c
index e2760e2..e33e3b8 100644
--- a/prov/sockets/src/sock_av.c
+++ b/prov/sockets/src/sock_av.c
@@ -68,15 +68,19 @@ int sock_av_get_addr_index(struct sock_av *av, union ofi_sock_ip *addr)
 	int i;
 	struct sock_av_addr *av_addr;
 
+	fastlock_acquire(&av->table_lock);
 	for (i = 0; i < (int)av->table_hdr->size; i++) {
 		av_addr = &av->table[i];
 		if (!av_addr->valid)
 			continue;
 
 		 if (ofi_equals_sockaddr((const struct sockaddr *) addr,
-					 (const struct sockaddr *) &av_addr->addr))
+					 (const struct sockaddr *) &av_addr->addr)) {
+			fastlock_release(&av->table_lock);
 			return i;
+		 }
 	}
+	fastlock_release(&av->table_lock);
 	SOCK_LOG_DBG("failed to get index in AV\n");
 	return -1;
 }
@@ -86,13 +90,16 @@ int sock_av_compare_addr(struct sock_av *av,
 {
 	int index1, index2;
 	struct sock_av_addr *av_addr1, *av_addr2;
+	int ret;
 
 	index1 = ((uint64_t)addr1 & av->mask);
 	index2 = ((uint64_t)addr2 & av->mask);
 
+	fastlock_acquire(&av->table_lock);
 	if (index1 >= (int)av->table_hdr->size || index1 < 0 ||
 	    index2 >= (int)av->table_hdr->size || index2 < 0) {
 		SOCK_LOG_ERROR("requested rank is larger than av table\n");
+		fastlock_release(&av->table_lock);
 		return -1;
 	}
 
@@ -100,7 +107,9 @@ int sock_av_compare_addr(struct sock_av *av,
 	av_addr2 = &av->table[index2];
 
 	/* Return 0 if the addresses match */
-	return !ofi_equals_sockaddr(&av_addr1->addr.sa, &av_addr2->addr.sa);
+	ret = !ofi_equals_sockaddr(&av_addr1->addr.sa, &av_addr2->addr.sa);
+	fastlock_release(&av->table_lock);
+	return ret;
 }
 
 static inline void sock_av_report_success(struct sock_av *av, void *context,
@@ -160,6 +169,7 @@ static int sock_resize_av_table(struct sock_av *av)
 		new_addr = realloc(av->table_hdr, table_sz);
 		if (!new_addr)
 			return -1;
+		memset((char *) new_addr + old_sz, 0, table_sz - old_sz);
 	}
 
 	av->table_hdr = new_addr;
@@ -264,9 +274,15 @@ static int sock_av_insert(struct fid_av *av, const void *addr, size_t count,
 			  fi_addr_t *fi_addr, uint64_t flags, void *context)
 {
 	struct sock_av *_av;
+	int ret = 0;
+
 	_av = container_of(av, struct sock_av, av_fid);
-	return sock_check_table_in(_av, (const struct sockaddr *) addr,
+
+	fastlock_acquire(&_av->table_lock);
+	ret = sock_check_table_in(_av, (const struct sockaddr *) addr,
 				   fi_addr, count, flags, context);
+	fastlock_release(&_av->table_lock);
+	return ret;
 }
 
 static int sock_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
@@ -278,13 +294,17 @@ static int sock_av_lookup(struct fid_av *av, fi_addr_t fi_addr, void *addr,
 
 	_av = container_of(av, struct sock_av, av_fid);
 	index = ((uint64_t)fi_addr & _av->mask);
+
+	fastlock_acquire(&_av->table_lock);
 	if (index >= (int)_av->table_hdr->size || index < 0) {
 		SOCK_LOG_ERROR("requested address not inserted\n");
+		fastlock_release(&_av->table_lock);
 		return -EINVAL;
 	}
 
 	av_addr = &_av->table[index];
 	memcpy(addr, &av_addr->addr, MIN(*addrlen, (size_t)_av->addrlen));
+	fastlock_release(&_av->table_lock);
 	*addrlen = _av->addrlen;
 	return 0;
 }
@@ -313,8 +333,10 @@ static int _sock_av_insertsvc(struct fid_av *av, const char *node,
 		return -ret;
 	}
 
+	fastlock_acquire(&_av->table_lock);
 	ret = sock_check_table_in(_av, result->ai_addr,
 				  fi_addr, 1, flags, context);
+	fastlock_release(&_av->table_lock);
 	freeaddrinfo(result);
 	return ret;
 }
@@ -357,8 +379,9 @@ static int sock_av_insertsym(struct fid_av *av, const char *node, size_t nodecnt
 	else
 		fmt = offset;
 
-	assert((hostlen-offset) < FI_NAME_MAX);
-	strncpy(base_host, node, hostlen - (offset));
+	if (hostlen - offset >= FI_NAME_MAX)
+		return -FI_ETOOSMALL;
+	memcpy(base_host, node, hostlen - offset);
 	var_port = atoi(service);
 	var_host = atoi(node + hostlen - offset);
 
@@ -376,7 +399,7 @@ static int sock_av_insertsym(struct fid_av *av, const char *node, size_t nodecnt
 					err_code = ret;
 			} else {
 				SOCK_LOG_ERROR("Node/service value is not valid\n");
-				err_code = FI_ETOOSMALL;
+				err_code = -FI_ETOOSMALL;
 			}
 		}
 	}
@@ -403,7 +426,7 @@ static int sock_av_remove(struct fid_av *av, fi_addr_t *fi_addr, size_t count,
 		sock_ep = container_of(fid_entry->fid, struct sock_ep, ep.fid);
 		fastlock_acquire(&sock_ep->attr->cmap.lock);
 		for (i = 0; i < count; i++) {
-        		idx = fi_addr[i] & sock_ep->attr->av->mask;
+			idx = fi_addr[i] & sock_ep->attr->av->mask;
 			conn = ofi_idm_lookup(&sock_ep->attr->av_idm, idx);
 			if (conn) {
 				/* A peer may be using the connection, so leave
@@ -477,6 +500,7 @@ static int sock_av_close(struct fid *fid)
 
 	ofi_atomic_dec32(&av->domain->ref);
 	fastlock_destroy(&av->list_lock);
+	fastlock_destroy(&av->table_lock);
 	free(av);
 	return 0;
 }
@@ -625,6 +649,7 @@ int sock_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 	}
 	dlist_init(&_av->ep_list);
 	fastlock_init(&_av->list_lock);
+	fastlock_init(&_av->table_lock);
 	_av->rx_ctx_bits = attr->rx_ctx_bits;
 	_av->mask = attr->rx_ctx_bits ?
 		((uint64_t)1 << (64 - attr->rx_ctx_bits)) - 1 : ~0;
diff --git a/prov/sockets/src/sock_conn.c b/prov/sockets/src/sock_conn.c
index 5f1c59d..b29b43e 100644
--- a/prov/sockets/src/sock_conn.c
+++ b/prov/sockets/src/sock_conn.c
@@ -501,7 +501,9 @@ int sock_ep_connect(struct sock_ep_attr *ep_attr, fi_addr_t index,
 		addr = *ep_attr->dest_addr;
 		ofi_addr_set_port(&addr.sa, ep_attr->msg_dest_port);
 	} else {
+		fastlock_acquire(&ep_attr->av->table_lock);
 		addr = ep_attr->av->table[index].addr;
+		fastlock_release(&ep_attr->av->table_lock);
 	}
 
 do_connect:
diff --git a/prov/sockets/src/sock_ep.c b/prov/sockets/src/sock_ep.c
index d6eb127..0317bbf 100644
--- a/prov/sockets/src/sock_ep.c
+++ b/prov/sockets/src/sock_ep.c
@@ -1861,8 +1861,11 @@ int sock_ep_get_conn(struct sock_ep_attr *attr, struct sock_tx_ctx *tx_ctx,
 
 	if (attr->ep_type == FI_EP_MSG)
 		addr = attr->dest_addr;
-	else
+	else {
+		fastlock_acquire(&attr->av->table_lock);
 		addr = &attr->av->table[av_index].addr;
+		fastlock_release(&attr->av->table_lock);
+	}
 
 	fastlock_acquire(&attr->cmap.lock);
 	conn = sock_ep_lookup_conn(attr, av_index, addr);
diff --git a/prov/sockets/src/sock_fabric.c b/prov/sockets/src/sock_fabric.c
index 9e2e091..3a60310 100644
--- a/prov/sockets/src/sock_fabric.c
+++ b/prov/sockets/src/sock_fabric.c
@@ -692,7 +692,7 @@ static void fi_sockets_fini(void)
 struct fi_provider sock_prov = {
 	.name = sock_prov_name,
 	.version = FI_VERSION(SOCK_MAJOR_VERSION, SOCK_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = sock_getinfo,
 	.fabric = sock_fabric,
 	.cleanup = fi_sockets_fini
diff --git a/prov/tcp/src/tcpx.h b/prov/tcp/src/tcpx.h
index feca63b..bdaa5ae 100644
--- a/prov/tcp/src/tcpx.h
+++ b/prov/tcp/src/tcpx.h
@@ -68,7 +68,7 @@
 #define TCPX_HDR_VERSION	3
 #define TCPX_CTRL_HDR_VERSION	3
 
-#define TCPX_MAX_CM_DATA_SIZE	(1<<8)
+#define TCPX_MAX_CM_DATA_SIZE	(1 << 8)
 #define TCPX_IOV_LIMIT		(4)
 #define TCPX_MAX_INJECT_SZ	(64)
 
diff --git a/prov/tcp/src/tcpx_comm.c b/prov/tcp/src/tcpx_comm.c
index ff0fce6..2ce86bb 100644
--- a/prov/tcp/src/tcpx_comm.c
+++ b/prov/tcp/src/tcpx_comm.c
@@ -67,14 +67,14 @@ static ssize_t tcpx_read_from_buffer(struct stage_buf *sbuf,
 	assert(sbuf->len >= sbuf->off);
 	rem_size = sbuf->len - sbuf->off;
 	assert(rem_size);
-	ret = (rem_size >= len)? len : rem_size;
+	ret = (rem_size >= len) ? len : rem_size;
 	memcpy(buf, &sbuf->buf[sbuf->off], ret);
 	sbuf->off += ret;
 	return ret;
 }
 
-int tcpx_recv_rem_hdr(SOCKET sock, struct stage_buf *sbuf,
-		  struct tcpx_rx_detect *rx_detect)
+static int tcpx_recv_rem_hdr(SOCKET sock, struct stage_buf *sbuf,
+			     struct tcpx_rx_detect *rx_detect)
 {
 	void *rem_buf;
 	size_t rem_len;
@@ -83,13 +83,12 @@ int tcpx_recv_rem_hdr(SOCKET sock, struct stage_buf *sbuf,
 	rem_buf = (uint8_t *) &rx_detect->hdr + rx_detect->done_len;
 	rem_len = rx_detect->hdr_len - rx_detect->done_len;
 
-	if (sbuf->len != sbuf->off) {
+	if (sbuf->len != sbuf->off)
 		bytes_recvd = tcpx_read_from_buffer(sbuf, rem_buf, rem_len);
-	} else {
+	else
 		bytes_recvd = ofi_recv_socket(sock, rem_buf, rem_len, 0);
-	}
 	if (bytes_recvd <= 0)
-		return (bytes_recvd)? -ofi_sockerr(): -FI_ENOTCONN;
+		return bytes_recvd ? -ofi_sockerr(): -FI_ENOTCONN;
 
 	rx_detect->done_len += bytes_recvd;
 	return (rx_detect->done_len == rx_detect->hdr_len)?
@@ -106,13 +105,12 @@ int tcpx_recv_hdr(SOCKET sock, struct stage_buf *sbuf,
 	rem_buf = (uint8_t *) &rx_detect->hdr + rx_detect->done_len;
 	rem_len = rx_detect->hdr_len - rx_detect->done_len;
 
-	if (sbuf->len != sbuf->off) {
+	if (sbuf->len != sbuf->off)
 		bytes_recvd = tcpx_read_from_buffer(sbuf, rem_buf, rem_len);
-	} else {
+	else
 		bytes_recvd = ofi_recv_socket(sock, rem_buf, rem_len, 0);
-	}
 	if (bytes_recvd <= 0)
-		return (bytes_recvd)? -ofi_sockerr(): -FI_ENOTCONN;
+		return (bytes_recvd) ? -ofi_sockerr(): -FI_ENOTCONN;
 
 	rx_detect->done_len += bytes_recvd;
 
@@ -123,7 +121,7 @@ int tcpx_recv_hdr(SOCKET sock, struct stage_buf *sbuf,
 			return tcpx_recv_rem_hdr(sock, sbuf, rx_detect);
 	}
 
-	return (rx_detect->done_len == rx_detect->hdr_len)?
+	return (rx_detect->done_len == rx_detect->hdr_len) ?
 		FI_SUCCESS : -FI_EAGAIN;
 }
 
@@ -154,20 +152,22 @@ int tcpx_recv_msg_data(struct tcpx_xfer_entry *rx_entry)
 {
 	ssize_t bytes_recvd;
 
-	if (rx_entry->ep->stage_buf.len != rx_entry->ep->stage_buf.off) {
+	if (!rx_entry->iov_cnt || !rx_entry->iov[0].iov_len)
+		return FI_SUCCESS;
+
+	if (rx_entry->ep->stage_buf.len != rx_entry->ep->stage_buf.off)
 		bytes_recvd = tcpx_readv_from_buffer(&rx_entry->ep->stage_buf,
 						     rx_entry->iov,
 						     rx_entry->iov_cnt);
-	 }else {
+	else
 		bytes_recvd = ofi_readv_socket(rx_entry->ep->conn_fd,
 					       rx_entry->iov,
 					       rx_entry->iov_cnt);
-	}
 	if (bytes_recvd <= 0)
-		return (bytes_recvd)? -ofi_sockerr(): -FI_ENOTCONN;
+		return (bytes_recvd) ? -ofi_sockerr(): -FI_ENOTCONN;
 
 	ofi_consume_iov(rx_entry->iov, &rx_entry->iov_cnt, bytes_recvd);
-	return (rx_entry->iov_cnt && rx_entry->iov[0].iov_len)?
+	return (rx_entry->iov_cnt && rx_entry->iov[0].iov_len) ?
 		-FI_EAGAIN: FI_SUCCESS;
 }
 
@@ -178,7 +178,7 @@ int tcpx_read_to_buffer(SOCKET sock, struct stage_buf *stage_buf)
 	bytes_recvd = ofi_recv_socket(sock, stage_buf->buf,
 				      stage_buf->size, 0);
 	if (bytes_recvd <= 0)
-		return (bytes_recvd)? -ofi_sockerr(): -FI_ENOTCONN;
+		return (bytes_recvd) ? -ofi_sockerr(): -FI_ENOTCONN;
 
 	stage_buf->len = bytes_recvd;
 	stage_buf->off = 0;
diff --git a/prov/tcp/src/tcpx_conn_mgr.c b/prov/tcp/src/tcpx_conn_mgr.c
index 6be176f..898cc6e 100644
--- a/prov/tcp/src/tcpx_conn_mgr.c
+++ b/prov/tcp/src/tcpx_conn_mgr.c
@@ -42,21 +42,21 @@
 static int read_cm_data(SOCKET fd, struct tcpx_cm_context *cm_ctx,
 			struct ofi_ctrl_hdr *hdr)
 {
+	size_t data_sz;
+	ssize_t ret;
+
 	cm_ctx->cm_data_sz = ntohs(hdr->seg_size);
 	if (cm_ctx->cm_data_sz) {
-		size_t data_sz = MIN(cm_ctx->cm_data_sz,
-				     TCPX_MAX_CM_DATA_SIZE);
-		ssize_t ret = ofi_recv_socket(fd, cm_ctx->cm_data,
-					      data_sz, MSG_WAITALL);
+		data_sz = MIN(cm_ctx->cm_data_sz, TCPX_MAX_CM_DATA_SIZE);
+		ret = ofi_recv_socket(fd, cm_ctx->cm_data, data_sz, MSG_WAITALL);
 		if ((size_t) ret != data_sz)
 			return -FI_EIO;
+
 		cm_ctx->cm_data_sz = data_sz;
 
-		if (OFI_UNLIKELY(cm_ctx->cm_data_sz >
-					TCPX_MAX_CM_DATA_SIZE)) {
+		if (OFI_UNLIKELY(cm_ctx->cm_data_sz > TCPX_MAX_CM_DATA_SIZE))
 			ofi_discard_socket(fd, cm_ctx->cm_data_sz -
 					   TCPX_MAX_CM_DATA_SIZE);
-		}
 	}
 	return FI_SUCCESS;
 }
@@ -66,8 +66,7 @@ static int rx_cm_data(SOCKET fd, struct ofi_ctrl_hdr *hdr,
 {
 	ssize_t ret;
 
-	ret = ofi_recv_socket(fd, hdr,
-			      sizeof(*hdr), MSG_WAITALL);
+	ret = ofi_recv_socket(fd, hdr, sizeof(*hdr), MSG_WAITALL);
 	if (ret != sizeof(*hdr))
 		return -FI_EIO;
 
@@ -75,9 +74,8 @@ static int rx_cm_data(SOCKET fd, struct ofi_ctrl_hdr *hdr,
 		return -FI_ENOPROTOOPT;
 
 	ret = read_cm_data(fd, cm_ctx, hdr);
-	if (hdr->type != type) {
+	if (hdr->type != type)
 		ret = -FI_ECONNREFUSED;
-	}
 	return ret;
 }
 
@@ -145,8 +143,8 @@ static int proc_conn_resp(struct tcpx_cm_context *cm_ctx,
 	cm_entry->fid = cm_ctx->fid;
 	memcpy(cm_entry->data, cm_ctx->cm_data, cm_ctx->cm_data_sz);
 
-	ep->hdr_bswap = (conn_resp.conn_data == 1)?
-		tcpx_hdr_none:tcpx_hdr_bswap;
+	ep->hdr_bswap = (conn_resp.conn_data == 1) ?
+			tcpx_hdr_none : tcpx_hdr_bswap;
 
 	ret = tcpx_ep_msg_xfer_enable(ep);
 	if (ret)
@@ -207,12 +205,12 @@ err:
 	FI_DBG(&tcpx_prov, FI_LOG_EP_CTRL,
 	       "fi_eq_write the conn refused %"PRId64"\n", ret);
 	free(cm_ctx);
+
 	/* `err_entry.err_data` must live until it is passed to user */
 	ret = fi_eq_write(&ep->util_ep.eq->eq_fid, FI_NOTIFY,
 			  &err_entry, sizeof(err_entry), UTIL_FLAG_ERROR);
-	if (OFI_UNLIKELY(ret < 0)) {
+	if (OFI_UNLIKELY(ret < 0))
 		free(err_entry.err_data);
-	}
 }
 
 static void server_send_cm_accept(struct util_wait *wait,
@@ -233,9 +231,8 @@ static void server_send_cm_accept(struct util_wait *wait,
 	cm_entry.fid =  cm_ctx->fid;
 	ret = (int) fi_eq_write(&ep->util_ep.eq->eq_fid, FI_CONNECTED,
 				&cm_entry, sizeof(cm_entry), 0);
-	if (ret < 0) {
+	if (ret < 0)
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL, "Error writing to EQ\n");
-	}
 
 	ret = ofi_wait_fd_del(wait, ep->conn_fd);
 	if (ret) {
@@ -272,10 +269,7 @@ static void server_recv_connreq(struct util_wait *wait,
 	int ret;
 
 	assert(cm_ctx->fid->fclass == FI_CLASS_CONNREQ);
-
-	handle  = container_of(cm_ctx->fid,
-			       struct tcpx_conn_handle,
-			       handle);
+	handle  = container_of(cm_ctx->fid, struct tcpx_conn_handle, handle);
 
 	ret = rx_cm_data(handle->conn_fd, &conn_req, ofi_ctrl_connreq, cm_ctx);
 	if (ret)
@@ -386,8 +380,7 @@ static void server_sock_accept(struct util_wait *wait,
 
 	FI_DBG(&tcpx_prov, FI_LOG_EP_CTRL, "Received Connreq\n");
 	assert(cm_ctx->fid->fclass == FI_CLASS_PEP);
-	pep = container_of(cm_ctx->fid, struct tcpx_pep,
-			   util_pep.pep_fid.fid);
+	pep = container_of(cm_ctx->fid, struct tcpx_pep, util_pep.pep_fid.fid);
 
 	sock = accept(pep->sock, NULL, 0);
 	if (sock < 0) {
@@ -475,14 +468,11 @@ void tcpx_conn_mgr_run(struct util_eq *eq)
 	}
 
 	for ( i = 0; i < num_fds; i++) {
-
 		/* skip wake up signals */
 		if (&wait_fd->util_wait.wait_fid.fid == wait_contexts[i])
 			continue;
 
-		process_cm_ctx(eq->wait,
-			       (struct tcpx_cm_context *)
-			       wait_contexts[i]);
+		process_cm_ctx(eq->wait, (struct tcpx_cm_context *) wait_contexts[i]);
 	}
 	fastlock_release(&tcpx_eq->close_lock);
 }
diff --git a/prov/tcp/src/tcpx_cq.c b/prov/tcp/src/tcpx_cq.c
index 868285c..e4f0fb8 100644
--- a/prov/tcp/src/tcpx_cq.c
+++ b/prov/tcp/src/tcpx_cq.c
@@ -86,9 +86,8 @@ struct tcpx_xfer_entry *tcpx_xfer_entry_alloc(struct tcpx_cq *tcpx_cq,
 void tcpx_xfer_entry_release(struct tcpx_cq *tcpx_cq,
 			     struct tcpx_xfer_entry *xfer_entry)
 {
-	if (xfer_entry->ep->cur_rx_entry == xfer_entry) {
+	if (xfer_entry->ep->cur_rx_entry == xfer_entry)
 		xfer_entry->ep->cur_rx_entry = NULL;
-	}
 
 	xfer_entry->hdr.base_hdr.flags = 0;
 
@@ -179,13 +178,12 @@ static int tcpx_cq_control(struct fid *fid, int command, void *arg)
 
 		ret = fi_control(&cq->wait->wait_fid.fid,
 				 command, arg);
-		if (ret)
-			return ret;
-
-		return FI_SUCCESS;
+		break;
 	default:
 		return -FI_ENOSYS;
 	}
+
+	return ret;
 }
 
 static struct fi_ops tcpx_cq_fi_ops = {
diff --git a/prov/tcp/src/tcpx_domain.c b/prov/tcp/src/tcpx_domain.c
index 4d62334..fa27a71 100644
--- a/prov/tcp/src/tcpx_domain.c
+++ b/prov/tcp/src/tcpx_domain.c
@@ -130,7 +130,7 @@ static int tcpx_domain_close(fid_t fid)
 		return ret;
 
 	free(tcpx_domain);
-	return 0;
+	return FI_SUCCESS;
 }
 
 static struct fi_ops tcpx_domain_fi_ops = {
@@ -171,7 +171,7 @@ int tcpx_domain_open(struct fid_fabric *fabric, struct fi_info *info,
 	(*domain)->ops = &tcpx_domain_ops;
 	(*domain)->mr = &tcpx_domain_fi_ops_mr;
 
-	return 0;
+	return FI_SUCCESS;
 err:
 	free(tcpx_domain);
 	return ret;
diff --git a/prov/tcp/src/tcpx_ep.c b/prov/tcp/src/tcpx_ep.c
index 9ca5d1b..1ca7580 100644
--- a/prov/tcp/src/tcpx_ep.c
+++ b/prov/tcp/src/tcpx_ep.c
@@ -42,7 +42,10 @@
 extern struct fi_ops_rma tcpx_rma_ops;
 extern struct fi_ops_msg tcpx_msg_ops;
 
-void tcpx_hdr_none(struct tcpx_base_hdr *hdr) {}
+void tcpx_hdr_none(struct tcpx_base_hdr *hdr)
+{
+	/* no-op */
+}
 
 void tcpx_hdr_bswap(struct tcpx_base_hdr *hdr)
 {
@@ -179,9 +182,8 @@ static int tcpx_ep_shutdown(struct fid_ep *ep, uint64_t flags)
 	fastlock_acquire(&tcpx_ep->lock);
 	ret = tcpx_ep_shutdown_report(tcpx_ep, &ep->fid);
 	fastlock_release(&tcpx_ep->lock);
-	if (ret) {
+	if (ret)
 		FI_WARN(&tcpx_prov, FI_LOG_EP_DATA, "Error writing to EQ\n");
-	}
 
 	return ret;
 }
@@ -193,25 +195,22 @@ static int tcpx_bind_to_port_range(SOCKET sock, void* src_addr, size_t addrlen)
 	rand_port_number = rand() % (port_range.high + 1 - port_range.low) +
 			   port_range.low;
 
-	for (i = port_range.low; i <= port_range.high;
-	     i++, rand_port_number++) {
-		if (rand_port_number > port_range.high) {
+	for (i = port_range.low; i <= port_range.high; i++, rand_port_number++) {
+		if (rand_port_number > port_range.high)
 			rand_port_number = port_range.low;
-		}
+
 		ofi_addr_set_port(src_addr, rand_port_number);
 		ret = bind(sock, src_addr, (socklen_t) addrlen);
 		if (ret) {
-			if (errno == EADDRINUSE) {
+			if (errno == EADDRINUSE)
 				continue;
-			} else {
-				FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
-					"failed to bind listener: %s\n",
-					strerror(ofi_sockerr()));
-				return -errno;
-			}
-		} else {
-			break;
+
+			FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
+				"failed to bind listener: %s\n",
+				strerror(ofi_sockerr()));
+			return -errno;
 		}
+		break;
 	}
 	return (i <= port_range.high) ? FI_SUCCESS : -FI_EADDRNOTAVAIL;
 }
@@ -243,13 +242,12 @@ static int tcpx_pep_sock_create(struct tcpx_pep *pep)
 	if (ret) {
 		goto err;
 	}
-	if (ofi_addr_get_port(pep->info->src_addr) != 0 || port_range.high == 0) {
+	if (ofi_addr_get_port(pep->info->src_addr) != 0 || port_range.high == 0)
 		ret = bind(pep->sock, pep->info->src_addr,
 			  (socklen_t) pep->info->src_addrlen);
-	} else {
+	else
 		ret = tcpx_bind_to_port_range(pep->sock, pep->info->src_addr,
 					      pep->info->src_addrlen);
-	}
 
 	if (ret) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,
@@ -289,7 +287,7 @@ static int tcpx_ep_getpeer(struct fid_ep *ep, void *addr, size_t *addrlen)
 	if (ret)
 		return -ofi_sockerr();
 
-	return (addrlen_in < *addrlen)? -FI_ETOOSMALL: FI_SUCCESS;
+	return (addrlen_in < *addrlen) ? -FI_ETOOSMALL: FI_SUCCESS;
 }
 
 static struct fi_ops_cm tcpx_cm_ops = {
@@ -327,49 +325,32 @@ void tcpx_rx_msg_release(struct tcpx_xfer_entry *rx_entry)
 	}
 }
 
-static void tcpx_ep_tx_rx_queues_release(struct tcpx_ep *ep)
+static void tcpx_ep_release_queue(struct slist *queue,
+				  struct tcpx_cq *tcpx_cq)
 {
-	struct slist_entry *entry;
 	struct tcpx_xfer_entry *xfer_entry;
-	struct tcpx_cq *tcpx_cq;
-
-	fastlock_acquire(&ep->lock);
-	while (!slist_empty(&ep->tx_queue)) {
-		entry = ep->tx_queue.head;
-		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
-		slist_remove_head(&ep->tx_queue);
-		tcpx_cq = container_of(xfer_entry->ep->util_ep.tx_cq,
-				       struct tcpx_cq, util_cq);
-		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
-	}
 
-	while (!slist_empty(&ep->rx_queue)) {
-		entry = ep->rx_queue.head;
-		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
-		slist_remove_head(&ep->rx_queue);
-		tcpx_cq = container_of(xfer_entry->ep->util_ep.rx_cq,
-				       struct tcpx_cq, util_cq);
+	while (!slist_empty(queue)) {
+		xfer_entry = container_of(queue->head, struct tcpx_xfer_entry,
+					  entry);
+		slist_remove_head(queue);
+		tcpx_cq_report_error(&tcpx_cq->util_cq, xfer_entry, FI_ECANCELED);
 		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
 	}
+}
 
-	while (!slist_empty(&ep->rma_read_queue)) {
-		entry = ep->rma_read_queue.head;
-		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
-		slist_remove_head(&ep->rma_read_queue);
-		tcpx_cq = container_of(xfer_entry->ep->util_ep.tx_cq,
-				       struct tcpx_cq, util_cq);
-		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
-	}
+static void tcpx_ep_tx_rx_queues_release(struct tcpx_ep *ep)
+{
+	struct tcpx_cq *tcpx_cq;
 
-	while (!slist_empty(&ep->tx_rsp_pend_queue)) {
-		entry = ep->tx_rsp_pend_queue.head;
-		xfer_entry = container_of(entry, struct tcpx_xfer_entry, entry);
-		slist_remove_head(&ep->tx_rsp_pend_queue);
-		tcpx_cq = container_of(xfer_entry->ep->util_ep.tx_cq,
-				       struct tcpx_cq, util_cq);
-		tcpx_xfer_entry_release(tcpx_cq, xfer_entry);
-	}
+	fastlock_acquire(&ep->lock);
+	tcpx_cq = container_of(ep->util_ep.tx_cq, struct tcpx_cq, util_cq);
+	tcpx_ep_release_queue(&ep->tx_queue, tcpx_cq);
+	tcpx_ep_release_queue(&ep->rma_read_queue, tcpx_cq);
+	tcpx_ep_release_queue(&ep->tx_rsp_pend_queue, tcpx_cq);
 
+	tcpx_cq = container_of(ep->util_ep.rx_cq, struct tcpx_cq, util_cq);
+	tcpx_ep_release_queue(&ep->rx_queue, tcpx_cq);
 	fastlock_release(&ep->lock);
 }
 
@@ -384,18 +365,16 @@ static int tcpx_ep_close(struct fid *fid)
 
 	tcpx_ep_tx_rx_queues_release(ep);
 
-	/* eq->close_lock protects from processing stale ep connection
-	   events*/
+	/* eq->close_lock protects from processing stale connection events */
 	fastlock_acquire(&eq->close_lock);
 	if (ep->util_ep.rx_cq->wait)
-		ofi_wait_fd_del(ep->util_ep.rx_cq->wait,
-				ep->conn_fd);
+		ofi_wait_fd_del(ep->util_ep.rx_cq->wait, ep->conn_fd);
 
 	if (ep->util_ep.eq->wait)
 		ofi_wait_fd_del(ep->util_ep.eq->wait, ep->conn_fd);
+
 	fastlock_release(&eq->close_lock);
-	ofi_eq_remove_fid_events(ep->util_ep.eq,
-				  &ep->util_ep.ep_fid.fid);
+	ofi_eq_remove_fid_events(ep->util_ep.eq, &ep->util_ep.ep_fid.fid);
 	ofi_close_socket(ep->conn_fd);
 	ofi_endpoint_close(&ep->util_ep);
 	fastlock_destroy(&ep->lock);
@@ -417,7 +396,7 @@ static int tcpx_ep_ctrl(struct fid *fid, int command, void *arg)
 	default:
 		return -FI_ENOSYS;
 	}
-	return 0;
+	return FI_SUCCESS;
 }
 
 static int tcpx_ep_bind(struct fid *fid, struct fid *bfid, uint64_t flags)
@@ -490,11 +469,10 @@ int tcpx_ep_setopt(fid_t fid, int level, int optname,
 		return -FI_EINVAL;
 
 	ep = container_of(fid, struct tcpx_ep, util_ep.ep_fid.fid);
-	ep->min_multi_recv_size = *(size_t *)optval;
+	ep->min_multi_recv_size = *(size_t *) optval;
 
 	FI_INFO(&tcpx_prov, FI_LOG_EP_CTRL,
-		"FI_OPT_MIN_MULTI_RECV set to %zu\n",
-		ep->min_multi_recv_size);
+		"FI_OPT_MIN_MULTI_RECV set to %zu\n", ep->min_multi_recv_size);
 	return FI_SUCCESS;
 }
 
@@ -511,6 +489,7 @@ static struct fi_ops_ep tcpx_ep_ops = {
 
 static void tcpx_empty_progress(struct tcpx_ep *ep)
 {
+	/* no-op */
 }
 
 int tcpx_endpoint(struct fid_domain *domain, struct fi_info *info,
@@ -682,7 +661,7 @@ static int tcpx_pep_getname(fid_t fid, void *addr, size_t *addrlen)
 	if (ret)
 		return -ofi_sockerr();
 
-	return (addrlen_in < *addrlen)? -FI_ETOOSMALL: FI_SUCCESS;
+	return (addrlen_in < *addrlen) ? -FI_ETOOSMALL: FI_SUCCESS;
 }
 
 static int tcpx_pep_listen(struct fid_pep *pep)
diff --git a/prov/tcp/src/tcpx_eq.c b/prov/tcp/src/tcpx_eq.c
index 8cedf37..4808d14 100644
--- a/prov/tcp/src/tcpx_eq.c
+++ b/prov/tcp/src/tcpx_eq.c
@@ -61,8 +61,7 @@ static int tcpx_eq_close(struct fid *fid)
 	if (ret)
 		return ret;
 
-	eq = container_of(fid, struct tcpx_eq,
-			  util_eq.eq_fid.fid);
+	eq = container_of(fid, struct tcpx_eq, util_eq.eq_fid.fid);
 
 	fastlock_destroy(&eq->close_lock);
 	free(eq);
diff --git a/prov/tcp/src/tcpx_init.c b/prov/tcp/src/tcpx_init.c
index 4eb729a..315f91d 100644
--- a/prov/tcp/src/tcpx_init.c
+++ b/prov/tcp/src/tcpx_init.c
@@ -82,7 +82,7 @@ static void tcpx_getinfo_ifs(struct fi_info **info)
 			continue;
 		}
 
-		cur->src_addr = mem_dup(&addr_entry->ipaddr.sa, addrlen);
+		cur->src_addr = mem_dup(&addr_entry->ipaddr, addrlen);
 		if (cur->src_addr) {
 			cur->src_addrlen = addrlen;
 			cur->addr_format = addr_format;
@@ -122,16 +122,16 @@ struct tcpx_port_range port_range = {
 	.high = 0,
 };
 
-static int tcpx_init_env(void)
+static void tcpx_init_env(void)
 {
 	srand(getpid());
 
 	fi_param_get_int(&tcpx_prov, "port_high_range", &port_range.high);
 	fi_param_get_int(&tcpx_prov, "port_low_range", &port_range.low);
 
-	if (port_range.high > TCPX_PORT_MAX_RANGE) {
+	if (port_range.high > TCPX_PORT_MAX_RANGE)
 		port_range.high = TCPX_PORT_MAX_RANGE;
-	}
+
 	if (port_range.low < 0 || port_range.high < 0 ||
 	    port_range.low > port_range.high) {
 		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,"User provided "
@@ -139,7 +139,6 @@ static int tcpx_init_env(void)
 		port_range.low  = 0;
 		port_range.high = 0;
 	}
-	return 0;
 }
 
 static void fi_tcp_fini(void)
@@ -150,7 +149,7 @@ static void fi_tcp_fini(void)
 struct fi_provider tcpx_prov = {
 	.name = "tcp",
 	.version = FI_VERSION(TCPX_MAJOR_VERSION,TCPX_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = tcpx_getinfo,
 	.fabric = tcpx_create_fabric,
 	.cleanup = fi_tcp_fini,
@@ -170,9 +169,6 @@ TCP_INI
 	fi_param_define(&tcpx_prov,"port_high_range", FI_PARAM_INT,
 			"define port high range");
 
-	if (tcpx_init_env()) {
-		FI_WARN(&tcpx_prov, FI_LOG_EP_CTRL,"Invalid info\n");
-		return NULL;
-	}
+	tcpx_init_env();
 	return &tcpx_prov;
 }
diff --git a/prov/tcp/src/tcpx_msg.c b/prov/tcp/src/tcpx_msg.c
index ce0f369..2e49d57 100644
--- a/prov/tcp/src/tcpx_msg.c
+++ b/prov/tcp/src/tcpx_msg.c
@@ -54,13 +54,12 @@ tcpx_alloc_recv_entry(struct tcpx_ep *tcpx_ep)
 	struct tcpx_xfer_entry *recv_entry;
 	struct tcpx_cq *tcpx_cq;
 
-	tcpx_cq = container_of(tcpx_ep->util_ep.rx_cq, struct tcpx_cq,
-			       util_cq);
+	tcpx_cq = container_of(tcpx_ep->util_ep.rx_cq, struct tcpx_cq, util_cq);
 
 	recv_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_MSG_RECV);
-	if (recv_entry) {
+	if (recv_entry)
 		recv_entry->ep = tcpx_ep;
-	}
+
 	return recv_entry;
 }
 
@@ -70,13 +69,12 @@ tcpx_alloc_send_entry(struct tcpx_ep *tcpx_ep)
 	struct tcpx_xfer_entry *send_entry;
 	struct tcpx_cq *tcpx_cq;
 
-	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
-			       util_cq);
+	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq, util_cq);
 
 	send_entry = tcpx_xfer_entry_alloc(tcpx_cq, TCPX_OP_MSG_SEND);
-	if (send_entry) {
+	if (send_entry)
 		send_entry->ep = tcpx_ep;
-	}
+
 	return send_entry;
 }
 
@@ -108,8 +106,8 @@ static ssize_t tcpx_recvmsg(struct fid_ep *ep, const struct fi_msg *msg,
 	memcpy(&recv_entry->iov[0], &msg->msg_iov[0],
 	       msg->iov_count * sizeof(struct iovec));
 
-	recv_entry->flags = (tcpx_ep->util_ep.rx_msg_flags | flags |
-			     FI_MSG | FI_RECV);
+	recv_entry->flags = tcpx_ep->util_ep.rx_msg_flags | flags |
+			    FI_MSG | FI_RECV;
 	recv_entry->context = msg->context;
 
 	tcpx_queue_recv(tcpx_ep, recv_entry);
@@ -132,9 +130,8 @@ static ssize_t tcpx_recv(struct fid_ep *ep, void *buf, size_t len, void *desc,
 	recv_entry->iov[0].iov_base = buf;
 	recv_entry->iov[0].iov_len = len;
 
-	recv_entry->flags = ((tcpx_ep->util_ep.rx_op_flags &
-			      (FI_COMPLETION | FI_MULTI_RECV)) |
-			     FI_MSG | FI_RECV);
+	recv_entry->flags = (tcpx_ep->util_ep.rx_op_flags &
+			     (FI_COMPLETION | FI_MULTI_RECV)) | FI_MSG | FI_RECV;
 	recv_entry->context = context;
 
 	tcpx_queue_recv(tcpx_ep, recv_entry);
@@ -159,9 +156,8 @@ static ssize_t tcpx_recvv(struct fid_ep *ep, const struct iovec *iov, void **des
 	recv_entry->iov_cnt = count;
 	memcpy(recv_entry->iov, iov, count * sizeof(*iov));
 
-	recv_entry->flags = ((tcpx_ep->util_ep.rx_op_flags &
-			      (FI_COMPLETION | FI_MULTI_RECV)) |
-			     FI_MSG | FI_RECV);
+	recv_entry->flags = (tcpx_ep->util_ep.rx_op_flags &
+			    (FI_COMPLETION | FI_MULTI_RECV)) | FI_MSG | FI_RECV;
 	recv_entry->context = context;
 
 	tcpx_queue_recv(tcpx_ep, recv_entry);
@@ -220,9 +216,8 @@ static ssize_t tcpx_sendmsg(struct fid_ep *ep, const struct fi_msg *msg,
 	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
 			    flags | FI_MSG | FI_SEND);
 
-	if (flags & (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) {
+	if (flags & (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE))
 		tx_entry->hdr.base_hdr.flags |= OFI_DELIVERY_COMPLETE;
-	}
 
 	tx_entry->ep = tcpx_ep;
 	tx_entry->context = msg->context;
@@ -247,10 +242,9 @@ static ssize_t tcpx_send(struct fid_ep *ep, const void *buf, size_t len,
 	if (!tx_entry)
 		return -FI_EAGAIN;
 
-	tx_entry->hdr.base_hdr.size =
-		(len + sizeof(tx_entry->hdr.base_hdr));
-	tx_entry->hdr.base_hdr.payload_off =
-		(uint8_t)sizeof(tx_entry->hdr.base_hdr);
+	tx_entry->hdr.base_hdr.size = len + sizeof(tx_entry->hdr.base_hdr);
+	tx_entry->hdr.base_hdr.payload_off = (uint8_t)
+					     sizeof(tx_entry->hdr.base_hdr);
 
 	tx_entry->iov[0].iov_base = (void *) &tx_entry->hdr;
 	tx_entry->iov[0].iov_len = sizeof(tx_entry->hdr.base_hdr);
@@ -260,13 +254,12 @@ static ssize_t tcpx_send(struct fid_ep *ep, const void *buf, size_t len,
 	tx_entry->iov_cnt = 2;
 	tx_entry->context = context;
 	tx_entry->rem_len = tx_entry->hdr.base_hdr.size;
-	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
-			   FI_MSG | FI_SEND);
+	tx_entry->flags = (tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			   FI_MSG | FI_SEND;
 
 	if (tcpx_ep->util_ep.tx_op_flags &
-	    (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) {
+	    (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE))
 		tx_entry->hdr.base_hdr.flags |= OFI_DELIVERY_COMPLETE;
-	}
 
 	tcpx_ep->hdr_bswap(&tx_entry->hdr.base_hdr);
 	fastlock_acquire(&tcpx_ep->lock);
@@ -291,10 +284,9 @@ static ssize_t tcpx_sendv(struct fid_ep *ep, const struct iovec *iov,
 
 	assert(count <= TCPX_IOV_LIMIT);
 	data_len = ofi_total_iov_len(iov, count);
-	tx_entry->hdr.base_hdr.size =
-		(data_len + sizeof(tx_entry->hdr.base_hdr));
-	tx_entry->hdr.base_hdr.payload_off =
-		(uint8_t)sizeof(tx_entry->hdr.base_hdr);
+	tx_entry->hdr.base_hdr.size = data_len + sizeof(tx_entry->hdr.base_hdr);
+	tx_entry->hdr.base_hdr.payload_off = (uint8_t)
+					     sizeof(tx_entry->hdr.base_hdr);
 
 	tx_entry->iov[0].iov_base = (void *) &tx_entry->hdr;
 	tx_entry->iov[0].iov_len = sizeof(tx_entry->hdr.base_hdr);
@@ -303,13 +295,12 @@ static ssize_t tcpx_sendv(struct fid_ep *ep, const struct iovec *iov,
 
 	tx_entry->context = context;
 	tx_entry->rem_len = tx_entry->hdr.base_hdr.size;
-	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
-			   FI_MSG | FI_SEND);
+	tx_entry->flags = (tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			   FI_MSG | FI_SEND;
 
 	if (tcpx_ep->util_ep.tx_op_flags &
-	    (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) {
+	    (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE))
 		tx_entry->hdr.base_hdr.flags |= OFI_DELIVERY_COMPLETE;
-	}
 
 	tcpx_ep->hdr_bswap(&tx_entry->hdr.base_hdr);
 	fastlock_acquire(&tcpx_ep->lock);
@@ -333,8 +324,7 @@ static ssize_t tcpx_inject(struct fid_ep *ep, const void *buf, size_t len,
 		return -FI_EAGAIN;
 
 	assert(len <= TCPX_MAX_INJECT_SZ);
-	tx_entry->hdr.base_hdr.size =
-		(len + sizeof(tx_entry->hdr.base_hdr));
+	tx_entry->hdr.base_hdr.size = len + sizeof(tx_entry->hdr.base_hdr);
 
 	offset = sizeof(tx_entry->hdr.base_hdr);
 	tx_entry->hdr.base_hdr.payload_off = (uint8_t) offset;
@@ -367,13 +357,13 @@ static ssize_t tcpx_senddata(struct fid_ep *ep, const void *buf, size_t len,
 		return -FI_EAGAIN;
 
 	tx_entry->hdr.cq_data_hdr.base_hdr.size =
-		(len + sizeof(tx_entry->hdr.cq_data_hdr));
+		len + sizeof(tx_entry->hdr.cq_data_hdr);
 	tx_entry->hdr.cq_data_hdr.base_hdr.flags = OFI_REMOTE_CQ_DATA;
 
 	tx_entry->hdr.cq_data_hdr.cq_data = data;
 
 	tx_entry->hdr.cq_data_hdr.base_hdr.payload_off =
-		(uint8_t)sizeof(tx_entry->hdr.cq_data_hdr);
+		(uint8_t) sizeof(tx_entry->hdr.cq_data_hdr);
 
 	tx_entry->iov[0].iov_base = (void *) &tx_entry->hdr;
 	tx_entry->iov[0].iov_len = sizeof(tx_entry->hdr.cq_data_hdr);
@@ -385,13 +375,12 @@ static ssize_t tcpx_senddata(struct fid_ep *ep, const void *buf, size_t len,
 
 	tx_entry->context = context;
 	tx_entry->rem_len = tx_entry->hdr.base_hdr.size;
-	tx_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
-			   FI_MSG | FI_SEND);
+	tx_entry->flags = (tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			   FI_MSG | FI_SEND;
 
 	if (tcpx_ep->util_ep.tx_op_flags &
-	    (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) {
+	    (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE))
 		tx_entry->hdr.base_hdr.flags |= OFI_DELIVERY_COMPLETE;
-	}
 
 	tcpx_ep->hdr_bswap(&tx_entry->hdr.base_hdr);
 	fastlock_acquire(&tcpx_ep->lock);
@@ -417,10 +406,9 @@ static ssize_t tcpx_injectdata(struct fid_ep *ep, const void *buf, size_t len,
 	tx_entry->hdr.cq_data_hdr.base_hdr.flags = OFI_REMOTE_CQ_DATA;
 	tx_entry->hdr.cq_data_hdr.cq_data = data;
 
-	tx_entry->hdr.base_hdr.size =
-		(len + sizeof(tx_entry->hdr.cq_data_hdr));
-	tx_entry->hdr.base_hdr.payload_off =
-		(uint8_t)sizeof(tx_entry->hdr.cq_data_hdr);
+	tx_entry->hdr.base_hdr.size = len + sizeof(tx_entry->hdr.cq_data_hdr);
+	tx_entry->hdr.base_hdr.payload_off = (uint8_t)
+					     sizeof(tx_entry->hdr.cq_data_hdr);
 
 	memcpy((uint8_t *) &tx_entry->hdr + sizeof(tx_entry->hdr.cq_data_hdr),
 	       (uint8_t *) buf, len);
diff --git a/prov/tcp/src/tcpx_progress.c b/prov/tcp/src/tcpx_progress.c
index 0c0af15..4ebda0a 100644
--- a/prov/tcp/src/tcpx_progress.c
+++ b/prov/tcp/src/tcpx_progress.c
@@ -51,8 +51,7 @@ static void tcpx_cq_report_xfer_fail(struct tcpx_ep *tcpx_ep, int err)
 	while (!slist_empty(&tcpx_ep->tx_rsp_pend_queue)) {
 		entry = slist_remove_head(&tcpx_ep->tx_rsp_pend_queue);
 		tx_entry = container_of(entry, struct tcpx_xfer_entry, entry);
-		tcpx_cq_report_error(tx_entry->ep->util_ep.tx_cq,
-				     tx_entry, -err);
+		tcpx_cq_report_error(tx_entry->ep->util_ep.tx_cq, tx_entry, -err);
 
 		tcpx_cq = container_of(tx_entry->ep->util_ep.tx_cq,
 				       struct tcpx_cq, util_cq);
@@ -80,6 +79,7 @@ int tcpx_ep_shutdown_report(struct tcpx_ep *ep, fid_t fid)
 
 	if (ep->cm_state == TCPX_EP_SHUTDOWN)
 		return FI_SUCCESS;
+
 	tcpx_cq_report_xfer_fail(ep, -FI_ENOTCONN);
 	ep->cm_state = TCPX_EP_SHUTDOWN;
 	cm_entry.fid = fid;
@@ -109,7 +109,7 @@ static void process_tx_entry(struct tcpx_xfer_entry *tx_entry)
 		tcpx_ep_shutdown_report(tx_entry->ep,
 					&tx_entry->ep->util_ep.ep_fid.fid);
 		tcpx_cq_report_error(tx_entry->ep->util_ep.tx_cq,
-				     tx_entry, ret);
+				     tx_entry, -ret);
 	} else {
 		if (tx_entry->hdr.base_hdr.flags &
 		    (OFI_DELIVERY_COMPLETE | OFI_COMMIT_COMPLETE)) {
@@ -173,16 +173,13 @@ static int process_rx_entry(struct tcpx_xfer_entry *rx_entry)
 
 		tcpx_ep_shutdown_report(rx_entry->ep,
 					&rx_entry->ep->util_ep.ep_fid.fid);
-		tcpx_cq_report_error(rx_entry->ep->util_ep.rx_cq,
-				     rx_entry, ret);
+		tcpx_cq_report_error(rx_entry->ep->util_ep.rx_cq, rx_entry, -ret);
 		rx_entry->rx_msg_release_fn(rx_entry);
-	} else 	if (rx_entry->hdr.base_hdr.flags & OFI_DELIVERY_COMPLETE) {
+	} else if (rx_entry->hdr.base_hdr.flags & OFI_DELIVERY_COMPLETE) {
 		if (tcpx_prepare_rx_entry_resp(rx_entry))
 			rx_entry->ep->cur_rx_proc_fn = tcpx_prepare_rx_entry_resp;
 	} else {
-		tcpx_cq_report_success(rx_entry->ep->util_ep.rx_cq,
-				       rx_entry);
-
+		tcpx_cq_report_success(rx_entry->ep->util_ep.rx_cq, rx_entry);
 		rx_entry->rx_msg_release_fn(rx_entry);
 	}
 	return ret;
@@ -194,7 +191,7 @@ static int tcpx_prepare_rx_write_resp(struct tcpx_xfer_entry *rx_entry)
 	struct tcpx_xfer_entry *resp_entry;
 
 	tcpx_tx_cq = container_of(rx_entry->ep->util_ep.tx_cq,
-			       struct tcpx_cq, util_cq);
+				  struct tcpx_cq, util_cq);
 
 	resp_entry = tcpx_xfer_entry_alloc(tcpx_tx_cq, TCPX_OP_MSG_RESP);
 	if (!resp_entry)
@@ -206,8 +203,8 @@ static int tcpx_prepare_rx_write_resp(struct tcpx_xfer_entry *rx_entry)
 
 	resp_entry->hdr.base_hdr.op = ofi_op_msg;
 	resp_entry->hdr.base_hdr.size = sizeof(resp_entry->hdr.base_hdr);
-	resp_entry->hdr.base_hdr.payload_off =
-		(uint8_t)sizeof(resp_entry->hdr.base_hdr);
+	resp_entry->hdr.base_hdr.payload_off = (uint8_t)
+						sizeof(resp_entry->hdr.base_hdr);
 
 	resp_entry->flags &= ~FI_COMPLETION;
 	resp_entry->context = NULL;
@@ -218,7 +215,7 @@ static int tcpx_prepare_rx_write_resp(struct tcpx_xfer_entry *rx_entry)
 
 	tcpx_cq_report_success(rx_entry->ep->util_ep.rx_cq, rx_entry);
 	tcpx_rx_cq = container_of(rx_entry->ep->util_ep.rx_cq,
-			       struct tcpx_cq, util_cq);
+				  struct tcpx_cq, util_cq);
 	tcpx_xfer_entry_release(tcpx_rx_cq, rx_entry);
 	return FI_SUCCESS;
 }
@@ -242,8 +239,7 @@ static void tcpx_pmem_commit(struct tcpx_xfer_entry *rx_entry)
 	rma_iov = (struct ofi_rma_iov *)((uint8_t *)&rx_entry->hdr + offset);
 
 	for (i = 0; i < rx_entry->hdr.base_hdr.rma_iov_cnt; i++) {
-		(*ofi_pmem_commit)((const void *) (uintptr_t)
-				   rma_iov[i].addr,
+		(*ofi_pmem_commit)((const void *) (uintptr_t) rma_iov[i].addr,
 				   rma_iov[i].len);
 	}
 }
@@ -264,8 +260,7 @@ static int process_rx_remote_write_entry(struct tcpx_xfer_entry *rx_entry)
 
 		tcpx_ep_shutdown_report(rx_entry->ep,
 					&rx_entry->ep->util_ep.ep_fid.fid);
-		tcpx_cq_report_error(rx_entry->ep->util_ep.rx_cq,
-				     rx_entry, ret);
+		tcpx_cq_report_error(rx_entry->ep->util_ep.rx_cq, rx_entry, -ret);
 		tcpx_cq = container_of(rx_entry->ep->util_ep.rx_cq,
 				       struct tcpx_cq, util_cq);
 		tcpx_xfer_entry_release(tcpx_cq, rx_entry);
@@ -279,8 +274,7 @@ static int process_rx_remote_write_entry(struct tcpx_xfer_entry *rx_entry)
 		if (tcpx_prepare_rx_write_resp(rx_entry))
 			rx_entry->ep->cur_rx_proc_fn = tcpx_prepare_rx_write_resp;
 	} else {
-		tcpx_cq_report_success(rx_entry->ep->util_ep.rx_cq,
-				       rx_entry);
+		tcpx_cq_report_success(rx_entry->ep->util_ep.rx_cq, rx_entry);
 		tcpx_cq = container_of(rx_entry->ep->util_ep.rx_cq,
 				       struct tcpx_cq, util_cq);
 		tcpx_xfer_entry_release(tcpx_cq, rx_entry);
@@ -302,8 +296,7 @@ static int process_rx_read_entry(struct tcpx_xfer_entry *rx_entry)
 			"msg recv Failed ret = %d\n", ret);
 		tcpx_ep_shutdown_report(rx_entry->ep,
 					&rx_entry->ep->util_ep.ep_fid.fid);
-		tcpx_cq_report_error(rx_entry->ep->util_ep.tx_cq, rx_entry,
-				     ret);
+		tcpx_cq_report_error(rx_entry->ep->util_ep.tx_cq, rx_entry, -ret);
 	} else {
 		tcpx_cq_report_success(rx_entry->ep->util_ep.tx_cq, rx_entry);
 	}
@@ -327,7 +320,7 @@ static void tcpx_copy_rma_iov_to_msg_iov(struct tcpx_xfer_entry *xfer_entry)
 	else
 		offset = sizeof(xfer_entry->hdr.base_hdr);
 
-	rma_iov = (struct ofi_rma_iov *)((uint8_t *)&xfer_entry->hdr + offset);
+	rma_iov = (struct ofi_rma_iov *) ((uint8_t *) &xfer_entry->hdr + offset);
 
 	xfer_entry->iov_cnt = xfer_entry->hdr.base_hdr.rma_iov_cnt;
 	for ( i = 0 ; i < xfer_entry->hdr.base_hdr.rma_iov_cnt; i++ ) {
@@ -344,8 +337,8 @@ static int tcpx_prepare_rx_remote_read_resp(struct tcpx_xfer_entry *resp_entry)
 	resp_entry->iov[0].iov_base = (void *) &resp_entry->hdr;
 	resp_entry->iov[0].iov_len = sizeof(resp_entry->hdr.base_hdr);
 
-	rma_iov = (struct ofi_rma_iov *)((uint8_t *)&resp_entry->hdr +
-					  sizeof(resp_entry->hdr.base_hdr));
+	rma_iov = (struct ofi_rma_iov *) ((uint8_t *)
+		  &resp_entry->hdr + sizeof(resp_entry->hdr.base_hdr));
 
 	resp_entry->iov_cnt = 1 + resp_entry->hdr.base_hdr.rma_iov_cnt;
 	resp_entry->hdr.base_hdr.size = resp_entry->iov[0].iov_len;
@@ -356,8 +349,8 @@ static int tcpx_prepare_rx_remote_read_resp(struct tcpx_xfer_entry *resp_entry)
 	}
 
 	resp_entry->hdr.base_hdr.op = ofi_op_read_rsp;
-	resp_entry->hdr.base_hdr.payload_off =
-		(uint8_t)sizeof(resp_entry->hdr.base_hdr);
+	resp_entry->hdr.base_hdr.payload_off = (uint8_t)
+						sizeof(resp_entry->hdr.base_hdr);
 
 	resp_entry->flags &= ~FI_COMPLETION;
 	resp_entry->context = NULL;
@@ -382,7 +375,7 @@ static int tcpx_validate_rx_rma_data(struct tcpx_xfer_entry *rx_entry,
 	else
 		offset = sizeof(rx_entry->hdr.base_hdr);
 
-	rma_iov = (struct ofi_rma_iov *)((uint8_t *)&rx_entry->hdr + offset);
+	rma_iov = (struct ofi_rma_iov *) ((uint8_t *) &rx_entry->hdr + offset);
 
 	for ( i = 0 ; i < rx_entry->hdr.base_hdr.rma_iov_cnt ; i++) {
 		ret = ofi_mr_verify(map, rma_iov[i].len,
@@ -451,9 +444,8 @@ int tcpx_get_rx_entry_op_msg(struct tcpx_ep *tcpx_ep)
 		rx_entry = container_of(tcpx_ep->rx_queue.head,
 					struct tcpx_xfer_entry, entry);
 
-		rx_entry->rem_len =
-			ofi_total_iov_len(rx_entry->iov, rx_entry->iov_cnt)-
-			msg_len;
+		rx_entry->rem_len = ofi_total_iov_len(rx_entry->iov,
+						      rx_entry->iov_cnt) - msg_len;
 
 		if (!(rx_entry->flags & FI_MULTI_RECV) ||
 		    rx_entry->rem_len < tcpx_ep->min_multi_recv_size) {
@@ -470,9 +462,7 @@ int tcpx_get_rx_entry_op_msg(struct tcpx_ep *tcpx_ep)
 	rx_entry->hdr.base_hdr.op_data = TCPX_OP_MSG_RECV;
 	rx_entry->mrecv_msg_start = rx_entry->iov[0].iov_base;
 
-	ret = ofi_truncate_iov(rx_entry->iov,
-			       &rx_entry->iov_cnt,
-			       msg_len);
+	ret = ofi_truncate_iov(rx_entry->iov, &rx_entry->iov_cnt, msg_len);
 	if (ret) {
 		FI_WARN(&tcpx_prov, FI_LOG_DOMAIN,
 			"posted rx buffer size is not big enough\n");
@@ -602,9 +592,7 @@ static inline int tcpx_get_next_rx_hdr(struct tcpx_ep *ep)
 	if (ep->rx_detect.hdr_len == ep->rx_detect.done_len)
 		return FI_SUCCESS;
 
-	ret = tcpx_recv_hdr(ep->conn_fd,
-			    &ep->stage_buf,
-			    &ep->rx_detect);
+	ret = tcpx_recv_hdr(ep->conn_fd, &ep->stage_buf, &ep->rx_detect);
 	if (ret)
 		return ret;
 
@@ -616,10 +604,8 @@ static void tcpx_process_rx_msg(struct tcpx_ep *ep)
 {
 	int ret;
 
-	if (!ep->cur_rx_entry &&
-	    (ep->stage_buf.len == ep->stage_buf.off)) {
-		ret = tcpx_read_to_buffer(ep->conn_fd,
-					  &ep->stage_buf);
+	if (!ep->cur_rx_entry && (ep->stage_buf.len == ep->stage_buf.off)) {
+		ret = tcpx_read_to_buffer(ep->conn_fd, &ep->stage_buf);
 		if (ret)
 			goto err;
 	}
@@ -720,8 +706,7 @@ int tcpx_cq_wait_ep_add(struct tcpx_ep *ep)
 
 	return ofi_wait_fd_add(ep->util_ep.rx_cq->wait,
 			       ep->conn_fd, FI_EPOLL_IN,
-			       tcpx_try_func, (void *)&ep->util_ep,
-			       NULL);
+			       tcpx_try_func, (void *) &ep->util_ep, NULL);
 }
 
 void tcpx_tx_queue_insert(struct tcpx_ep *tcpx_ep,
diff --git a/prov/tcp/src/tcpx_rma.c b/prov/tcp/src/tcpx_rma.c
index 8215d79..c046e61 100644
--- a/prov/tcp/src/tcpx_rma.c
+++ b/prov/tcp/src/tcpx_rma.c
@@ -57,7 +57,7 @@ static void tcpx_rma_read_send_entry_fill(struct tcpx_xfer_entry *send_entry,
 	size_t offset;
 
 	offset = sizeof(send_entry->hdr.base_hdr);
-	rma_iov = (struct ofi_rma_iov *)((uint8_t *)&send_entry->hdr + offset);
+	rma_iov = (struct ofi_rma_iov *) ((uint8_t *) &send_entry->hdr + offset);
 
 	send_entry->hdr.base_hdr.rma_iov_cnt = msg->rma_iov_count;
 	memcpy(rma_iov, msg->rma_iov,
@@ -185,7 +185,6 @@ static ssize_t tcpx_rma_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg
 	uint64_t *cq_data;
 	size_t offset;
 
-
 	tcpx_ep = container_of(ep, struct tcpx_ep, util_ep.ep_fid);
 	tcpx_cq = container_of(tcpx_ep->util_ep.tx_cq, struct tcpx_cq,
 			       util_cq);
@@ -214,8 +213,7 @@ static ssize_t tcpx_rma_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg
 	       msg->rma_iov_count * sizeof(msg->rma_iov[0]));
 	send_entry->hdr.base_hdr.rma_iov_cnt = msg->rma_iov_count;
 
-	offset += (send_entry->hdr.base_hdr.rma_iov_cnt *
-		   sizeof(*rma_iov));
+	offset += (send_entry->hdr.base_hdr.rma_iov_cnt * sizeof(*rma_iov));
 
 	send_entry->hdr.base_hdr.payload_off = (uint8_t)offset;
 	send_entry->hdr.base_hdr.size = data_len + offset;
@@ -235,16 +233,14 @@ static ssize_t tcpx_rma_writemsg(struct fid_ep *ep, const struct fi_msg_rma *msg
 	send_entry->iov[0].iov_base = (void *) &send_entry->hdr;
 	send_entry->iov[0].iov_len = offset;
 
-	send_entry->flags = ((tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
-			     flags | FI_RMA | FI_WRITE);
+	send_entry->flags = (tcpx_ep->util_ep.tx_op_flags & FI_COMPLETION) |
+			     flags | FI_RMA | FI_WRITE;
 
-	if (flags & (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE)) {
+	if (flags & (FI_TRANSMIT_COMPLETE | FI_DELIVERY_COMPLETE))
 		send_entry->hdr.base_hdr.flags |= OFI_DELIVERY_COMPLETE;
-	}
 
-	if (flags & FI_COMMIT_COMPLETE) {
+	if (flags & FI_COMMIT_COMPLETE)
 		send_entry->hdr.base_hdr.flags |= OFI_COMMIT_COMPLETE;
-	}
 
 	send_entry->ep = tcpx_ep;
 	send_entry->context = msg->context;
@@ -397,11 +393,12 @@ static ssize_t tcpx_rma_inject(struct fid_ep *ep, const void *buf, size_t len,
 				      0, addr, key, FI_INJECT);
 }
 
-static ssize_t tcpx_rma_injectdata(struct fid_ep *ep, const void *buf, size_t len,
-				   uint64_t data, fi_addr_t dest_addr, uint64_t addr, uint64_t key)
+static ssize_t
+tcpx_rma_injectdata(struct fid_ep *ep, const void *buf, size_t len,
+		    uint64_t data, fi_addr_t dest_addr, uint64_t addr,
+		    uint64_t key)
 {
-	return tcpx_rma_inject_common(ep, buf, len, dest_addr,
-				      data, addr, key,
+	return tcpx_rma_inject_common(ep, buf, len, dest_addr, data, addr, key,
 				      FI_INJECT | FI_REMOTE_CQ_DATA);
 }
 
diff --git a/prov/tcp/src/tcpx_shared_ctx.c b/prov/tcp/src/tcpx_shared_ctx.c
index 66b196b..3e34c93 100644
--- a/prov/tcp/src/tcpx_shared_ctx.c
+++ b/prov/tcp/src/tcpx_shared_ctx.c
@@ -76,10 +76,8 @@ tcpx_srx_next_xfer_entry(struct tcpx_rx_ctx *srx_ctx,
 
 	xfer_entry = container_of(srx_ctx->rx_queue.head,
 				  struct tcpx_xfer_entry, entry);
-	xfer_entry->rem_len =
-		ofi_total_iov_len(xfer_entry->iov, xfer_entry->iov_cnt)-
-		entry_size;
-
+	xfer_entry->rem_len = ofi_total_iov_len(xfer_entry->iov,
+						xfer_entry->iov_cnt) - entry_size;
 	if (!(xfer_entry->flags & FI_MULTI_RECV) &&
 	    xfer_entry->rem_len < ep->min_multi_recv_size) {
 		slist_remove_head(&srx_ctx->rx_queue);
diff --git a/prov/udp/src/udpx.h b/prov/udp/src/udpx.h
index ef2550d..f9c89e5 100644
--- a/prov/udp/src/udpx.h
+++ b/prov/udp/src/udpx.h
@@ -121,6 +121,7 @@ struct udpx_mc {
 	struct fid_mc		mc_fid;
 	union {
 		struct sockaddr_in	sin;
+		struct sockaddr_in6	sin6;
 	} addr;
 	struct udpx_ep		*ep;
 };
diff --git a/prov/udp/src/udpx_init.c b/prov/udp/src/udpx_init.c
index 5462cc2..8952147 100644
--- a/prov/udp/src/udpx_init.c
+++ b/prov/udp/src/udpx_init.c
@@ -81,7 +81,7 @@ static void udpx_getinfo_ifs(struct fi_info **info)
 			continue;
 		}
 
-		cur->src_addr = mem_dup(&addr_entry->ipaddr.sa, addrlen);
+		cur->src_addr = mem_dup(&addr_entry->ipaddr, addrlen);
 		if (cur->src_addr) {
 			cur->src_addrlen = addrlen;
 			cur->addr_format = addr_format;
@@ -121,7 +121,7 @@ static void udpx_fini(void)
 struct fi_provider udpx_prov = {
 	.name = "UDP",
 	.version = FI_VERSION(UDPX_MAJOR_VERSION, UDPX_MINOR_VERSION),
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = udpx_getinfo,
 	.fabric = udpx_fabric,
 	.cleanup = udpx_fini
diff --git a/prov/usnic/src/usdf_fabric.c b/prov/usnic/src/usdf_fabric.c
index 79d89c0..043d962 100644
--- a/prov/usnic/src/usdf_fabric.c
+++ b/prov/usnic/src/usdf_fabric.c
@@ -1248,7 +1248,7 @@ static void usdf_fini(void)
 struct fi_provider usdf_ops = {
 	.name = USDF_PROV_NAME,
 	.version = USDF_PROV_VERSION,
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = usdf_getinfo,
 	.fabric = usdf_fabric_open,
 	.cleanup =  usdf_fini
diff --git a/prov/util/src/util_attr.c b/prov/util/src/util_attr.c
index 54d27ad..5bee103 100644
--- a/prov/util/src/util_attr.c
+++ b/prov/util/src/util_attr.c
@@ -619,14 +619,14 @@ int ofi_check_domain_attr(const struct fi_provider *prov, uint32_t api_version,
 	return 0;
 }
 
-static int ofi_check_ep_type(const struct fi_provider *prov,
-			     const struct fi_ep_attr *prov_attr,
-			     const struct fi_ep_attr *user_attr)
+int ofi_check_ep_type(const struct fi_provider *prov,
+		      const struct fi_ep_attr *prov_attr,
+		      const struct fi_ep_attr *user_attr)
 {
 	if ((user_attr->type != FI_EP_UNSPEC) &&
 	    (prov_attr->type != FI_EP_UNSPEC) &&
 	    (user_attr->type != prov_attr->type)) {
-		FI_INFO(prov, FI_LOG_CORE, "Unsupported endpoint type\n");
+		FI_INFO(prov, FI_LOG_CORE, "unsupported endpoint type\n");
 		FI_INFO_CHECK(prov, prov_attr, user_attr, type, FI_TYPE_EP_TYPE);
 		return -FI_ENODATA;
 	}
diff --git a/prov/util/src/util_coll.c b/prov/util/src/util_coll.c
new file mode 100644
index 0000000..531f86c
--- /dev/null
+++ b/prov/util/src/util_coll.c
@@ -0,0 +1,985 @@
+/*
+ * Copyright (c) 2019 Intel Corporation. All rights reserved.
+ *
+ * This software is available to you under a choice of one of two
+ * licenses.  You may choose to be licensed under the terms of the GNU
+ * General Public License (GPL) Version 2, available from the file
+ * COPYING in the main directory of this source tree, or the
+ * BSD license below:
+ *
+ *     Redistribution and use in source and binary forms, with or
+ *     without modification, are permitted provided that the following
+ *     conditions are met:
+ *
+ *      - Redistributions of source code must retain the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer.
+ *
+ *      - Redistributions in binary form must reproduce the above
+ *        copyright notice, this list of conditions and the following
+ *        disclaimer in the documentation and/or other materials
+ *        provided with the distribution.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
+ * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
+ * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
+ * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+#include "config.h"
+
+#include <arpa/inet.h>
+#include <ctype.h>
+#include <stdlib.h>
+#include <stdio.h>
+#include <sys/socket.h>
+#include <sys/types.h>
+#include <netdb.h>
+#include <netinet/in.h>
+#include <inttypes.h>
+
+#if HAVE_GETIFADDRS
+#include <net/if.h>
+#include <ifaddrs.h>
+#endif
+
+#include <ofi_util.h>
+
+#include <rdma/fi_collective.h>
+#include <rdma/fi_cm.h>
+#include <ofi_list.h>
+#include <ofi_atomic.h>
+#include <ofi_coll.h>
+#include <ofi_osd.h>
+
+int ofi_av_set_union(struct fid_av_set *dst, const struct fid_av_set *src)
+{
+	struct util_av_set *src_av_set;
+	struct util_av_set *dst_av_set;
+	size_t temp_count;
+	int i,j;
+
+	src_av_set = container_of(src, struct util_av_set, av_set_fid);
+	dst_av_set = container_of(dst, struct util_av_set, av_set_fid);
+
+	assert(src_av_set->av == dst_av_set->av);
+	temp_count = dst_av_set->fi_addr_count;
+
+	for (i = 0; i < src_av_set->fi_addr_count; i++) {
+		for (j = 0; j < dst_av_set->fi_addr_count; j++) {
+			if (dst_av_set->fi_addr_array[j] ==
+			    src_av_set->fi_addr_array[i])
+				break;
+		}
+		if (j == dst_av_set->fi_addr_count) {
+			dst_av_set->fi_addr_array[temp_count++] =
+				src_av_set->fi_addr_array[i];
+		}
+	}
+
+	dst_av_set->fi_addr_count = temp_count;
+	return FI_SUCCESS;
+}
+
+int ofi_av_set_intersect(struct fid_av_set *dst, const struct fid_av_set *src)
+{
+	struct util_av_set *src_av_set;
+	struct util_av_set *dst_av_set;
+	int i,j, temp;
+
+	src_av_set = container_of(src, struct util_av_set, av_set_fid);
+	dst_av_set = container_of(dst, struct util_av_set, av_set_fid);
+
+	assert(src_av_set->av == dst_av_set->av);
+
+	temp = 0;
+	for (i = 0; i < src_av_set->fi_addr_count; i++) {
+		for (j = temp; j < dst_av_set->fi_addr_count; j++) {
+			if (dst_av_set->fi_addr_array[j] ==
+			    src_av_set->fi_addr_array[i]) {
+				dst_av_set->fi_addr_array[temp++] =
+					dst_av_set->fi_addr_array[j];
+				break;
+			}
+		}
+	}
+	dst_av_set->fi_addr_count = temp;
+	return FI_SUCCESS;
+}
+
+int ofi_av_set_diff(struct fid_av_set *dst, const struct fid_av_set *src)
+{
+
+	struct util_av_set *src_av_set;
+	struct util_av_set *dst_av_set;
+	int i,j, temp;
+
+	src_av_set = container_of(src, struct util_av_set, av_set_fid);
+	dst_av_set = container_of(dst, struct util_av_set, av_set_fid);
+
+	assert(src_av_set->av == dst_av_set->av);
+
+	temp = dst_av_set->fi_addr_count;
+	for (i = 0; i < src_av_set->fi_addr_count; i++) {
+		for (j = 0; j < temp; j++) {
+			if (dst_av_set->fi_addr_array[j] ==
+			    src_av_set->fi_addr_array[i]) {
+				dst_av_set->fi_addr_array[--temp] =
+					dst_av_set->fi_addr_array[j];
+				break;
+			}
+		}
+	}
+	dst_av_set->fi_addr_count = temp;
+	return FI_SUCCESS;
+}
+
+int ofi_av_set_insert(struct fid_av_set *set, fi_addr_t addr)
+{
+	struct util_av_set *av_set;
+	int i;
+
+	av_set = container_of(set, struct util_av_set, av_set_fid);
+
+	for (i = 0; i < av_set->fi_addr_count; i++) {
+		if (av_set->fi_addr_array[i] == addr)
+			return -FI_EINVAL;
+	}
+	av_set->fi_addr_array[av_set->fi_addr_count++] = addr;
+	return FI_SUCCESS;
+}
+
+int ofi_av_set_remove(struct fid_av_set *set, fi_addr_t addr)
+
+{
+	struct util_av_set *av_set;
+	int i;
+
+	av_set = container_of(set, struct util_av_set, av_set_fid);
+
+	for (i = 0; i < av_set->fi_addr_count; i++) {
+		if (av_set->fi_addr_array[i] == addr) {
+			av_set->fi_addr_array[i] =
+				av_set->fi_addr_array[--av_set->fi_addr_count];
+			return FI_SUCCESS;
+		}
+	}
+	return -FI_EINVAL;
+}
+
+int ofi_av_set_addr(struct fid_av_set *set, fi_addr_t *coll_addr)
+{
+	struct util_av_set *av_set;
+
+	av_set = container_of(set, struct util_av_set, av_set_fid);
+	*coll_addr = (uintptr_t)av_set->av->coll_mc;
+
+	return FI_SUCCESS;
+}
+
+static inline int util_coll_mc_alloc(struct util_coll_mc **coll_mc)
+{
+	*coll_mc = calloc(1, sizeof(**coll_mc));
+	if (!*coll_mc)
+		return -FI_ENOMEM;
+
+	return FI_SUCCESS;
+}
+
+static inline uint64_t util_coll_form_tag(uint32_t coll_id, uint32_t rank)
+{
+	uint64_t tag;
+	uint64_t src_rank = rank;
+
+	tag = coll_id;
+	tag |= (src_rank << 32);
+
+	return OFI_COLL_TAG_FLAG | tag;
+}
+
+static inline uint32_t util_coll_get_next_id(struct util_coll_mc *coll_mc)
+{
+	uint32_t cid = coll_mc->group_id;
+	return cid << 16 | coll_mc->seq++;
+}
+
+static inline int util_coll_op_create(struct util_coll_operation **coll_op,
+				    struct util_coll_mc *coll_mc,
+				    enum util_coll_op_type type, void *context,
+				    util_coll_comp_fn_t comp_fn)
+{
+	*coll_op = calloc(1, sizeof(**coll_op));
+	if (!(*coll_op))
+		return -FI_ENOMEM;
+
+	(*coll_op)->cid = util_coll_get_next_id(coll_mc);
+	(*coll_op)->mc = coll_mc;
+	(*coll_op)->type = type;
+	(*coll_op)->context = context;
+	(*coll_op)->comp_fn = comp_fn;
+	dlist_init(&(*coll_op)->work_queue);
+
+	return FI_SUCCESS;
+}
+
+static inline void util_coll_op_progress_work(struct util_ep *util_ep,
+				      struct util_coll_operation *coll_op)
+{
+	struct util_coll_work_item *next_ready = NULL;
+	struct util_coll_work_item *cur_item = NULL;
+	struct util_coll_work_item *prev_item = NULL;
+	struct dlist_entry *tmp = NULL;
+	int previous_is_head;
+
+	// clean up any completed items while searching for the next ready
+	dlist_foreach_container_safe(&coll_op->work_queue, struct util_coll_work_item,
+				     cur_item, waiting_entry, tmp)
+	{
+		previous_is_head = cur_item->waiting_entry.prev == &cur_item->coll_op->work_queue;
+		if (!previous_is_head) {
+			prev_item = container_of(cur_item->waiting_entry.prev,
+							struct util_coll_work_item,
+							waiting_entry);
+		}
+
+		if (cur_item->state == UTIL_COLL_COMPLETE) {
+			// if there is work before cur and cur is fencing, we can't complete
+			if (cur_item->fence && !previous_is_head)
+				continue;
+
+			dlist_remove(&cur_item->waiting_entry);
+			free(cur_item);
+
+			// if the work queue is empty, we're done
+			if (dlist_empty(&coll_op->work_queue)) {
+				free(coll_op);
+				return;
+			}
+			continue;
+		}
+
+		// we can't progress if prior work is fencing
+		if (!previous_is_head && prev_item && prev_item->fence) {
+			return;
+		}
+
+		// if the current item isn't waiting, it's not the next ready item
+		if (cur_item->state != UTIL_COLL_WAITING) {
+			continue;
+		}
+
+		next_ready = cur_item;
+		break;
+	}
+
+	if (!next_ready)
+		return;
+
+	next_ready->state = UTIL_COLL_PROCESSING;
+	slist_insert_tail(&next_ready->ready_entry, &util_ep->coll_ready_queue);
+}
+
+static inline void util_coll_op_bind_work(struct util_coll_operation *coll_op,
+					  struct util_coll_work_item *item)
+{
+	item->coll_op = coll_op;
+	dlist_insert_tail(&item->waiting_entry, &coll_op->work_queue);
+}
+
+static int util_coll_sched_send(struct util_coll_operation *coll_op, uint32_t dest,
+				void *buf, int count, enum fi_datatype datatype,
+				int fence)
+{
+	struct util_coll_xfer_item *xfer_item;
+
+	xfer_item = calloc(1, sizeof(*xfer_item));
+	if (!xfer_item)
+		return -FI_ENOMEM;
+
+	xfer_item->hdr.type = UTIL_COLL_SEND;
+	xfer_item->hdr.state = UTIL_COLL_WAITING;
+	xfer_item->hdr.fence = fence;
+	xfer_item->tag = util_coll_form_tag(coll_op->cid, coll_op->mc->local_rank);
+	xfer_item->buf = buf;
+	xfer_item->count = count;
+	xfer_item->datatype = datatype;
+	xfer_item->remote_rank = dest;
+
+	util_coll_op_bind_work(coll_op, &xfer_item->hdr);
+	return FI_SUCCESS;
+}
+
+static int util_coll_sched_recv(struct util_coll_operation *coll_op, uint32_t src,
+				void *buf, int count, enum fi_datatype datatype,
+				int fence)
+{
+	struct util_coll_xfer_item *xfer_item;
+
+	xfer_item = calloc(1, sizeof(*xfer_item));
+	if (!xfer_item)
+		return -FI_ENOMEM;
+
+	xfer_item->hdr.type = UTIL_COLL_RECV;
+	xfer_item->hdr.state = UTIL_COLL_WAITING;
+	xfer_item->hdr.fence = fence;
+	xfer_item->tag = util_coll_form_tag(coll_op->cid, src);
+	xfer_item->buf = buf;
+	xfer_item->count = count;
+	xfer_item->datatype = datatype;
+	xfer_item->remote_rank = src;
+
+	util_coll_op_bind_work(coll_op, &xfer_item->hdr);
+	return FI_SUCCESS;
+}
+
+static int util_coll_sched_reduce(struct util_coll_operation *coll_op, void *in_buf,
+				  void *inout_buf, int count, enum fi_datatype datatype,
+				  enum fi_op op, int fence)
+{
+	struct util_coll_reduce_item *reduce_item;
+
+	reduce_item = calloc(1, sizeof(*reduce_item));
+	if (!reduce_item)
+		return -FI_ENOMEM;
+
+	reduce_item->hdr.type = UTIL_COLL_REDUCE;
+	reduce_item->hdr.state = UTIL_COLL_WAITING;
+	reduce_item->hdr.fence = fence;
+	reduce_item->in_buf = in_buf;
+	reduce_item->inout_buf = inout_buf;
+	reduce_item->count = count;
+	reduce_item->datatype = datatype;
+	reduce_item->op = op;
+
+	util_coll_op_bind_work(coll_op, &reduce_item->hdr);
+	return FI_SUCCESS;
+}
+
+static int util_coll_sched_copy(struct util_coll_operation *coll_op, void *in_buf,
+				void *out_buf, int count, enum fi_datatype datatype,
+				int fence)
+{
+	struct util_coll_copy_item *copy_item;
+
+	copy_item = calloc(1, sizeof(*copy_item));
+	if (!copy_item)
+		return -FI_ENOMEM;
+
+	copy_item->hdr.type = UTIL_COLL_COPY;
+	copy_item->hdr.state = UTIL_COLL_WAITING;
+	copy_item->hdr.fence = fence;
+	copy_item->in_buf = in_buf;
+	copy_item->out_buf = out_buf;
+	copy_item->count = count;
+	copy_item->datatype = datatype;
+
+	util_coll_op_bind_work(coll_op, &copy_item->hdr);
+	return FI_SUCCESS;
+}
+
+static int util_coll_sched_comp(struct util_coll_operation *coll_op)
+{
+	struct util_coll_work_item *comp_item;
+
+	comp_item = calloc(1, sizeof(*comp_item));
+	if (!comp_item)
+		return -FI_ENOMEM;
+
+	comp_item->type = UTIL_COLL_COMP;
+	comp_item->state = UTIL_COLL_WAITING;
+	comp_item->fence = 1;
+
+	util_coll_op_bind_work(coll_op, comp_item);
+	return FI_SUCCESS;
+}
+
+/* TODO: when this fails, clean up the already scheduled work in this function */
+static int util_coll_allreduce(struct util_coll_operation *coll_op, const void *send_buf,
+			void *result, void* tmp_buf, int count, enum fi_datatype datatype,
+			enum fi_op op)
+{
+	uint64_t rem, pof2, my_new_id;
+	uint64_t local, remote, next_remote;
+	int ret;
+	uint64_t mask = 1;
+
+	pof2 = rounddown_power_of_two(coll_op->mc->av_set->fi_addr_count);
+	rem = coll_op->mc->av_set->fi_addr_count - pof2;
+	local = coll_op->mc->local_rank;
+
+	// copy initial send data to result
+	memcpy(result, send_buf, count * ofi_datatype_size(datatype));
+
+	if (local < 2 * rem) {
+		if (local % 2 == 0) {
+			ret = util_coll_sched_send(coll_op, local + 1, result, count,
+						   datatype, 1);
+			if (ret)
+				return ret;
+
+			my_new_id = -1;
+		} else {
+			ret = util_coll_sched_recv(coll_op, local - 1,
+						   tmp_buf, count, datatype, 1);
+			if (ret)
+				return ret;
+
+			my_new_id = local / 2;
+
+			ret = util_coll_sched_reduce(coll_op, tmp_buf, result,
+						     count, datatype, op, 1);
+			if (ret)
+				return ret;
+		}
+	} else {
+		my_new_id = local - rem;
+	}
+
+	if (my_new_id != -1) {
+		while (mask < pof2) {
+			next_remote = my_new_id ^ mask;
+			remote = (next_remote < rem) ? next_remote * 2 + 1 :
+				next_remote + rem;
+
+			// receive remote data into tmp buf
+			ret = util_coll_sched_recv(coll_op, remote, tmp_buf, count,
+						   datatype, 0);
+			if (ret)
+				return ret;
+
+			// send result buf, which has the current total
+			ret = util_coll_sched_send(coll_op, remote, result, count,
+						   datatype, 1);
+			if (ret)
+				return ret;
+
+			if (remote < local) {
+				// reduce received remote into result buf
+				ret = util_coll_sched_reduce(coll_op, tmp_buf, result,
+							     count, datatype, op, 1);
+				if (ret)
+					return ret;
+			} else {
+				// reduce local result into received data
+				ret = util_coll_sched_reduce(coll_op, result, tmp_buf,
+							     count, datatype, op, 1);
+				if (ret)
+					return ret;
+
+				// copy total into result
+				ret = util_coll_sched_copy(coll_op, tmp_buf, result,
+							   count, datatype, 1);
+				if (ret)
+					return ret;
+			}
+			mask <<= 1;
+		}
+	}
+
+	if (local < 2 * rem) {
+		if (local % 2) {
+			ret = util_coll_sched_send(coll_op, local - 1, result, count,
+						   datatype, 1);
+			if (ret)
+				return ret;
+		} else {
+			ret = util_coll_sched_recv(coll_op, local + 1, result, count,
+						   datatype, 1);
+			if (ret)
+				return ret;
+		}
+	}
+	return FI_SUCCESS;
+}
+
+static int util_coll_close(struct fid *fid)
+{
+	struct util_coll_mc *coll_mc;
+
+	coll_mc = container_of(fid, struct util_coll_mc, mc_fid.fid);
+
+	free(coll_mc);
+	return FI_SUCCESS;
+}
+
+static struct fi_ops util_coll_fi_ops = {
+	.size = sizeof(struct fi_ops),
+	.close = util_coll_close,
+	.bind = fi_no_bind,
+	.control = fi_no_control,
+	.ops_open = fi_no_ops_open,
+};
+
+/* TODO: Figure out requirements for using collectives.
+ * e.g. require local address to be in AV?
+ * Determine best way to handle first join request
+ */
+static int util_coll_find_local_rank(struct fid_ep *ep,
+				  struct util_coll_mc *coll_mc)
+{
+	size_t addrlen;
+	char *addr;
+	int ret, mem;
+
+	addrlen = sizeof(mem);
+	addr = (char *) &mem;
+
+	ret = fi_getname(&ep->fid, addr, &addrlen);
+	if (ret != -FI_ETOOSMALL) {
+		return ret;
+	}
+
+	addr = calloc(1, addrlen);
+	if (!addr)
+		return -FI_ENOMEM;
+
+	ret = fi_getname(&ep->fid, addr, &addrlen);
+	if (ret) {
+		free(addr);
+		return ret;
+	}
+	coll_mc->local_rank =
+		ofi_av_lookup_fi_addr(coll_mc->av_set->av, addr);
+
+	free(addr);
+
+	return FI_SUCCESS;
+}
+
+void util_coll_join_comp(struct util_coll_operation *coll_op)
+{
+	struct fi_eq_err_entry entry;
+	struct util_ep *ep = container_of(coll_op->mc->ep, struct util_ep, ep_fid);
+
+	coll_op->mc->seq = 0;
+	coll_op->mc->group_id = ofi_bitmask_get_lsbset(coll_op->data.join.data);
+	// mark the local mask bit
+	ofi_bitmask_unset(ep->coll_cid_mask, coll_op->mc->group_id);
+
+	/* write to the eq  */
+	memset(&entry, 0, sizeof(entry));
+	entry.fid = &coll_op->mc->mc_fid.fid;
+	entry.context = coll_op->mc->mc_fid.fid.context;
+
+	if (ofi_eq_write(&ep->eq->eq_fid, FI_JOIN_COMPLETE, &entry,
+			 sizeof(struct fi_eq_entry), FI_COLLECTIVE) < 0)
+		FI_WARN(ep->domain->fabric->prov, FI_LOG_DOMAIN,
+			"join collective - eq write failed\n");
+
+	ofi_bitmask_free(&coll_op->data.join.data);
+	ofi_bitmask_free(&coll_op->data.join.tmp);
+}
+
+void util_coll_collective_comp(struct util_coll_operation *coll_op)
+{
+	struct util_ep *ep;
+
+	ep = container_of(coll_op->mc->ep, struct util_ep, ep_fid);
+
+	if (ofi_cq_write(ep->tx_cq, coll_op->context, FI_COLLECTIVE, 0, 0, 0, 0))
+		FI_WARN(ep->domain->fabric->prov, FI_LOG_DOMAIN,
+			"barrier collective - cq write failed\n");
+
+	if(coll_op->type == UTIL_COLL_ALLREDUCE_OP)
+		free(coll_op->data.allreduce.data);
+}
+
+static int util_coll_proc_reduce_item(struct util_coll_reduce_item *reduce_item)
+{
+	if (FI_MIN <= reduce_item->op && FI_BXOR >= reduce_item->op) {
+		ofi_atomic_write_handlers[reduce_item->op]
+					 [reduce_item->datatype](
+						 reduce_item->inout_buf,
+						 reduce_item->in_buf,
+						 reduce_item->count);
+	} else {
+		return -FI_ENOSYS;
+	}
+	return FI_SUCCESS;
+}
+
+int util_coll_process_xfer_item(struct util_coll_xfer_item *item) {
+	struct iovec iov;
+	struct fi_msg_tagged msg;
+	struct util_coll_mc *mc = item->hdr.coll_op->mc;
+
+	msg.msg_iov = &iov;
+	msg.desc = NULL;
+	msg.iov_count = 1;
+	msg.ignore = 0;
+	msg.context = item;
+	msg.data = 0;
+	msg.tag = item->tag;
+	msg.addr = mc->av_set->fi_addr_array[item->remote_rank];
+
+	iov.iov_base = item->buf;
+	iov.iov_len = (item->count * ofi_datatype_size(item->datatype));
+
+	if (item->hdr.type == UTIL_COLL_SEND) {
+		return fi_tsendmsg(mc->ep, &msg, FI_COLLECTIVE);
+	} else if (item->hdr.type == UTIL_COLL_RECV) {
+		return fi_trecvmsg(mc->ep, &msg, FI_COLLECTIVE);
+	}
+
+	return -FI_ENOSYS;
+}
+
+int ofi_coll_ep_progress(struct fid_ep *ep)
+{
+	struct util_coll_work_item *work_item;
+	struct util_coll_reduce_item *reduce_item;
+	struct util_coll_copy_item *copy_item;
+	struct util_coll_xfer_item *xfer_item;
+	struct util_coll_operation *coll_op;
+	struct util_ep *util_ep;
+	int ret;
+
+	util_ep  = container_of(ep, struct util_ep, ep_fid);
+
+	while (!slist_empty(&util_ep->coll_ready_queue)) {
+		slist_remove_head_container(&util_ep->coll_ready_queue,
+					    struct util_coll_work_item, work_item,
+					    ready_entry);
+		coll_op = work_item->coll_op;
+		switch (work_item->type) {
+		case UTIL_COLL_SEND:
+			xfer_item = container_of(work_item, struct util_coll_xfer_item, hdr);
+			ret = util_coll_process_xfer_item(xfer_item);
+			if (ret && ret == -FI_EAGAIN) {
+				slist_insert_tail(&work_item->ready_entry,
+						  &util_ep->coll_ready_queue);
+				goto out;
+			}
+			break;
+		case UTIL_COLL_RECV:
+			xfer_item = container_of(work_item, struct util_coll_xfer_item, hdr);
+			ret = util_coll_process_xfer_item(xfer_item);
+			if (ret)
+				goto out;
+			break;
+		case UTIL_COLL_REDUCE:
+			reduce_item = container_of(work_item, struct util_coll_reduce_item, hdr);
+			ret = util_coll_proc_reduce_item(reduce_item);
+			if (ret)
+				goto out;
+
+			reduce_item->hdr.state = UTIL_COLL_COMPLETE;
+			break;
+		case UTIL_COLL_COPY:
+			copy_item = container_of(work_item, struct util_coll_copy_item, hdr);
+			memcpy(copy_item->out_buf, copy_item->in_buf,
+			       copy_item->count * ofi_datatype_size(copy_item->datatype));
+
+			copy_item->hdr.state = UTIL_COLL_COMPLETE;
+			break;
+		case UTIL_COLL_COMP:
+			if (work_item->coll_op->comp_fn)
+				work_item->coll_op->comp_fn(work_item->coll_op);
+
+			work_item->state = UTIL_COLL_COMPLETE;
+			break;
+		default:
+			ret = FI_ENOSYS;
+			goto out;
+		}
+
+		util_coll_op_progress_work(util_ep, coll_op);
+	}
+
+	ret = FI_SUCCESS;
+
+out:
+	return ret;
+}
+
+int ofi_join_collective(struct fid_ep *ep, fi_addr_t coll_addr,
+		       const struct fid_av_set *set,
+		       uint64_t flags, struct fid_mc **mc, void *context)
+{
+	struct util_coll_mc *new_coll_mc;
+	struct util_av_set *av_set;
+	struct util_coll_mc *coll_mc;
+	struct util_coll_operation *join_op;
+	struct util_ep *util_ep;
+	int ret;
+
+	av_set = container_of(set, struct util_av_set, av_set_fid);
+
+	if (coll_addr == FI_ADDR_NOTAVAIL) {
+		assert(av_set->av->coll_mc != NULL);
+		coll_mc = av_set->av->coll_mc;
+	} else {
+		coll_mc = (struct util_coll_mc*) ((uintptr_t) coll_addr);
+	}
+
+	ret = util_coll_mc_alloc(&new_coll_mc);
+	if (ret)
+		return ret;
+
+	util_ep = container_of(ep, struct util_ep, ep_fid);
+
+	// set up the new mc for future collectives
+	new_coll_mc->mc_fid.fid.fclass = FI_CLASS_MC;
+	new_coll_mc->mc_fid.fid.context = context;
+	new_coll_mc->mc_fid.fid.ops = &util_coll_fi_ops;
+	new_coll_mc->mc_fid.fi_addr = (uintptr_t) new_coll_mc;
+	new_coll_mc->av_set = av_set;
+	new_coll_mc->ep = ep;
+
+	coll_mc->ep = ep;
+
+	/* get the rank */
+	util_coll_find_local_rank(ep, new_coll_mc);
+	util_coll_find_local_rank(ep, coll_mc);
+
+	ret = util_coll_op_create(&join_op, coll_mc, UTIL_COLL_JOIN_OP, context,
+				util_coll_join_comp);
+	if (ret)
+		goto err1;
+
+	if (new_coll_mc->local_rank != FI_ADDR_NOTAVAIL) {
+		ret = ofi_bitmask_create(&join_op->data.join.data, OFI_MAX_GROUP_ID);
+		if (ret)
+			goto err2;
+
+		ret = ofi_bitmask_create(&join_op->data.join.tmp, OFI_MAX_GROUP_ID);
+		if (ret)
+			goto err3;
+
+	} else {
+		ofi_bitmask_set_all(&join_op->data.join.data);
+	}
+
+	ret = util_coll_allreduce(join_op, util_ep->coll_cid_mask->bytes,
+				  join_op->data.join.data.bytes,
+				  join_op->data.join.tmp.bytes,
+				  ofi_bitmask_bytesize(util_ep->coll_cid_mask),
+				  FI_UINT8, FI_BAND);
+	if (ret)
+		goto err4;
+
+	ret = util_coll_sched_comp(join_op);
+	if (ret)
+		goto err4;
+
+	util_coll_op_progress_work(util_ep, join_op);
+
+	*mc = &new_coll_mc->mc_fid;
+	return FI_SUCCESS;
+err4:
+	ofi_bitmask_free(&join_op->data.join.tmp);
+err3:
+	ofi_bitmask_free(&join_op->data.join.data);
+err2:
+	free(join_op);
+err1:
+	free(new_coll_mc);
+	return ret;
+}
+
+static struct fi_ops_av_set util_av_set_ops= {
+	.set_union	=	ofi_av_set_union,
+	.intersect	=	ofi_av_set_intersect,
+	.diff		=	ofi_av_set_diff,
+	.insert		=	ofi_av_set_insert,
+	.remove		=	ofi_av_set_remove,
+	.addr		=	ofi_av_set_addr
+};
+
+static int util_coll_copy_from_av(struct util_av *av, void *addr,
+			      fi_addr_t fi_addr, void *arg)
+{
+	struct util_av_set *av_set = (struct util_av_set *) arg;
+	av_set->fi_addr_array[av_set->fi_addr_count++] = fi_addr;
+	return FI_SUCCESS;
+}
+
+static int util_coll_av_init(struct util_av *av)
+{
+
+	struct util_coll_mc *coll_mc;
+	int ret;
+
+	assert(!av->coll_mc);
+
+	ret = util_coll_mc_alloc(&coll_mc);
+	if (ret)
+		return ret;
+
+	coll_mc->av_set = calloc(1, sizeof(*coll_mc->av_set));
+	if (!coll_mc->av_set) {
+		ret = -FI_ENOMEM;
+		goto err1;
+	}
+
+	coll_mc->av_set->fi_addr_array =
+		calloc(av->count, sizeof(*coll_mc->av_set->fi_addr_array));
+	if (!coll_mc->av_set->fi_addr_array) {
+		ret = -FI_ENOMEM;
+		goto err2;
+	}
+
+	ret = fastlock_init(&coll_mc->av_set->lock);
+	if (ret)
+		goto err3;
+
+	coll_mc->av_set->av = av;
+	ret = ofi_av_elements_iter(av, util_coll_copy_from_av,
+				   (void *)coll_mc->av_set);
+	if (ret)
+		goto err4;
+
+	coll_mc->av_set->av_set_fid.fid.fclass = FI_CLASS_AV_SET;
+	coll_mc->av_set->av_set_fid.ops = &util_av_set_ops;
+
+	coll_mc->mc_fid.fi_addr = (uintptr_t) coll_mc;
+	coll_mc->mc_fid.fid.fclass = FI_CLASS_MC;
+	coll_mc->mc_fid.fid.context = NULL;
+	coll_mc->mc_fid.fid.ops = &util_coll_fi_ops;
+	av->coll_mc = coll_mc;
+	return FI_SUCCESS;
+
+err4:
+	fastlock_destroy(&coll_mc->av_set->lock);
+err3:
+	free(coll_mc->av_set->fi_addr_array);
+err2:
+	free(coll_mc->av_set);
+err1:
+	free(coll_mc);
+	return ret;
+}
+
+int ofi_av_set(struct fid_av *av, struct fi_av_set_attr *attr,
+	       struct fid_av_set **av_set_fid, void * context)
+{
+	struct util_av *util_av = container_of(av, struct util_av, av_fid);
+	struct util_av_set *av_set;
+	int ret, iter;
+
+	if (!util_av->coll_mc) {
+		ret = util_coll_av_init(util_av);
+		if (ret)
+			return ret;
+	}
+
+	av_set = calloc(1,sizeof(*av_set));
+	if (!av_set)
+		return -FI_ENOMEM;
+
+	ret = fastlock_init(&av_set->lock);
+	if (ret)
+		goto err1;
+
+	av_set->fi_addr_array = calloc(util_av->count, sizeof(*av_set->fi_addr_array));
+	if (!av_set->fi_addr_array)
+		goto err2;
+
+	for (iter = 0; iter < attr->count; iter++) {
+		av_set->fi_addr_array[iter] =
+			util_av->coll_mc->av_set->fi_addr_array[iter * attr->stride];
+		av_set->fi_addr_count++;
+	}
+
+	av_set->av = util_av;
+	av_set->av_set_fid.ops = &util_av_set_ops;
+	av_set->av_set_fid.fid.fclass = FI_CLASS_AV_SET;
+	av_set->av_set_fid.fid.context = context;
+	(*av_set_fid) = &av_set->av_set_fid;
+	return FI_SUCCESS;
+err2:
+	fastlock_destroy(&av_set->lock);
+err1:
+	free(av_set);
+	return ret;
+}
+
+ssize_t ofi_ep_barrier(struct fid_ep *ep, fi_addr_t coll_addr, void *context)
+{
+	struct util_coll_mc *coll_mc;
+	struct util_coll_operation *barrier_op;
+	struct util_ep *util_ep;
+	uint64_t send;
+	int ret;
+
+	coll_mc = (struct util_coll_mc*) ((uintptr_t) coll_addr);
+
+	ret = util_coll_op_create(&barrier_op, coll_mc, UTIL_COLL_BARRIER_OP, context,
+			  util_coll_collective_comp);
+	if (ret)
+		return ret;
+
+	send = ~barrier_op->mc->local_rank;
+	ret = util_coll_allreduce(barrier_op, &send, &barrier_op->data.barrier.data,
+				  &barrier_op->data.barrier.tmp, 1, FI_UINT64, FI_BAND);
+	if (ret)
+		goto err1;
+
+	ret = util_coll_sched_comp(barrier_op);
+	if (ret)
+		goto err1;
+
+	util_ep = container_of(ep, struct util_ep, ep_fid);
+	util_coll_op_progress_work(util_ep, barrier_op);
+
+	return FI_SUCCESS;
+err1:
+	free(barrier_op);
+	return ret;
+}
+
+ssize_t ofi_ep_allreduce(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			 void *result, void *result_desc, fi_addr_t coll_addr,
+			 enum fi_datatype datatype, enum fi_op op, uint64_t flags,
+			 void *context)
+{
+	struct util_coll_mc *coll_mc;
+	struct util_coll_operation *allreduce_op;
+	struct util_ep *util_ep;
+	int ret;
+
+	coll_mc = (struct util_coll_mc *) ((uintptr_t) coll_addr);
+	ret = util_coll_op_create(&allreduce_op, coll_mc, UTIL_COLL_ALLREDUCE_OP, context,
+				  util_coll_collective_comp);
+	if (ret)
+		return ret;
+
+
+	allreduce_op->data.allreduce.size = count * ofi_datatype_size(datatype);
+	allreduce_op->data.allreduce.data = calloc(count, ofi_datatype_size(datatype));
+	if (!allreduce_op->data.allreduce.data)
+		goto err1;
+
+	ret = util_coll_allreduce(allreduce_op, buf, result, allreduce_op->data.allreduce.data, count,
+				  datatype, op);
+	if (ret)
+		goto err2;
+
+	ret = util_coll_sched_comp(allreduce_op);
+	if (ret)
+		goto err2;
+
+	util_ep = container_of(ep, struct util_ep, ep_fid);
+	util_coll_op_progress_work(util_ep, allreduce_op);
+
+	return FI_SUCCESS;
+err2:
+	free(allreduce_op->data.allreduce.data);
+err1:
+	free(allreduce_op);
+	return ret;
+}
+
+void ofi_coll_handle_xfer_comp(uint64_t tag, void *ctx)
+{
+	struct util_ep *util_ep;
+	struct util_coll_xfer_item *xfer_item = (struct util_coll_xfer_item *) ctx;
+	xfer_item->hdr.state = UTIL_COLL_COMPLETE;
+
+	util_ep = container_of(xfer_item->hdr.coll_op->mc->ep, struct util_ep, ep_fid);
+	util_coll_op_progress_work(util_ep, xfer_item->hdr.coll_op);
+}
diff --git a/prov/util/src/util_ep.c b/prov/util/src/util_ep.c
index c46d837..9163513 100644
--- a/prov/util/src/util_ep.c
+++ b/prov/util/src/util_ep.c
@@ -35,6 +35,7 @@
 
 #include <ofi_enosys.h>
 #include <ofi_util.h>
+#include <ofi_coll.h>
 
 int ofi_ep_bind_cq(struct util_ep *ep, struct util_cq *cq, uint64_t flags)
 {
@@ -190,6 +191,20 @@ int ofi_ep_bind(struct util_ep *util_ep, struct fid *fid, uint64_t flags)
 	return -FI_EINVAL;
 }
 
+static inline int util_coll_init_cid_mask(struct bitmask *mask)
+{
+	int err = ofi_bitmask_create(mask, OFI_MAX_GROUP_ID);
+	if (err)
+		return err;
+
+	ofi_bitmask_set_all(mask);
+
+	/* reserving the first bit in context id to whole av set */
+	ofi_bitmask_unset(mask, OFI_WORLD_GROUP_ID);
+
+	return FI_SUCCESS;
+}
+
 int ofi_endpoint_init(struct fid_domain *domain, const struct util_prov *util_prov,
 		      struct fi_info *info, struct util_ep *ep, void *context,
 		      ofi_ep_progress_func progress)
@@ -240,6 +255,15 @@ int ofi_endpoint_init(struct fid_domain *domain, const struct util_prov *util_pr
 		ep->lock_acquire = ofi_fastlock_acquire;
 		ep->lock_release = ofi_fastlock_release;
 	}
+	if (ep->caps & FI_COLLECTIVE) {
+		ep->coll_cid_mask = calloc(1, sizeof(*ep->coll_cid_mask));
+		if (!ep->coll_cid_mask)
+			return -FI_ENOMEM;
+		util_coll_init_cid_mask(ep->coll_cid_mask);
+	} else {
+		ep->coll_cid_mask = NULL;
+	}
+	slist_init(&ep->coll_ready_queue);
 	return 0;
 }
 
@@ -309,6 +333,11 @@ int ofi_endpoint_close(struct util_ep *util_ep)
 		ofi_atomic_dec32(&util_ep->av->ref);
 	}
 
+	if (util_ep->coll_cid_mask) {
+		ofi_bitmask_free(util_ep->coll_cid_mask);
+		free(util_ep->coll_cid_mask);
+	}
+
 	if (util_ep->eq)
 		ofi_atomic_dec32(&util_ep->eq->ref);
 	ofi_atomic_dec32(&util_ep->domain->ref);
diff --git a/prov/util/src/util_mem_hooks.c b/prov/util/src/util_mem_hooks.c
index 4f96b1b..33b4207 100644
--- a/prov/util/src/util_mem_hooks.c
+++ b/prov/util/src/util_mem_hooks.c
@@ -252,12 +252,12 @@ static void *ofi_intercept_dlopen(const char *filename, int flag)
 	if (!handle)
 		return NULL;
 
-	fastlock_acquire(&memhooks_monitor->lock);
+	pthread_mutex_lock(&memhooks_monitor->lock);
 	dlist_foreach_container(&memhooks.intercept_list, struct ofi_intercept,
 		intercept, entry) {
 		dl_iterate_phdr(ofi_intercept_phdr_handler, intercept);
 	}
-	fastlock_release(&memhooks_monitor->lock);
+	pthread_mutex_unlock(&memhooks_monitor->lock);
 	return handle;
 }
 
@@ -356,9 +356,9 @@ static int ofi_intercept_symbol(struct ofi_intercept *intercept, void **real_fun
 
 void ofi_intercept_handler(const void *addr, size_t len)
 {
-	fastlock_acquire(&memhooks_monitor->lock);
+	pthread_mutex_lock(&memhooks_monitor->lock);
 	ofi_monitor_notify(memhooks_monitor, addr, len);
-	fastlock_release(&memhooks_monitor->lock);
+	pthread_mutex_unlock(&memhooks_monitor->lock);
 }
 
 static void *ofi_intercept_mmap(void *start, size_t length,
@@ -472,7 +472,6 @@ int ofi_memhooks_init(void)
 {
 	int i, ret;
 
-	/* TODO: remove once cleanup is written */
 	if (memhooks_monitor->subscribe == ofi_memhooks_subscribe)
 		return 0;
 
@@ -553,6 +552,8 @@ int ofi_memhooks_init(void)
 void ofi_memhooks_cleanup(void)
 {
 	ofi_restore_intercepts();
+	memhooks_monitor->subscribe = NULL;
+	memhooks_monitor->unsubscribe = NULL;
 }
 
 #else
diff --git a/prov/util/src/util_mem_monitor.c b/prov/util/src/util_mem_monitor.c
index 47a5d7a..c69c342 100644
--- a/prov/util/src/util_mem_monitor.c
+++ b/prov/util/src/util_mem_monitor.c
@@ -33,6 +33,7 @@
  */
 
 #include <ofi_mr.h>
+#include <unistd.h>
 
 static struct ofi_uffd uffd;
 struct ofi_mem_monitor *uffd_monitor = &uffd.monitor;
@@ -40,15 +41,31 @@ struct ofi_mem_monitor *uffd_monitor = &uffd.monitor;
 struct ofi_mem_monitor *default_monitor;
 
 
+static size_t ofi_default_cache_size(void)
+{
+	long cpu_cnt;
+	size_t cache_size;
+
+	cpu_cnt = ofi_sysconf(_SC_NPROCESSORS_ONLN);
+	/* disable cache on error */
+	if (cpu_cnt <= 0)
+		return 0;
+
+	cache_size = ofi_get_mem_size() / (size_t) cpu_cnt / 2;
+	FI_INFO(&core_prov, FI_LOG_MR,
+		"default cache size=%zu\n", cache_size);
+	return cache_size;
+}
+
 /*
  * Initialize all available memory monitors
  */
 void ofi_monitor_init(void)
 {
-	fastlock_init(&uffd_monitor->lock);
+	pthread_mutex_init(&uffd_monitor->lock, NULL);
 	dlist_init(&uffd_monitor->list);
 
-	fastlock_init(&memhooks_monitor->lock);
+	pthread_mutex_init(&memhooks_monitor->lock, NULL);
 	dlist_init(&memhooks_monitor->list);
 
 #if HAVE_UFFD_UNMAP
@@ -64,7 +81,7 @@ void ofi_monitor_init(void)
 			" regions that may be tracked by the MR cache."
 			" Setting this will reduce the amount of memory"
 			" not actively in use that may be registered."
-			" (default: 0 no limit is enforced)");
+			" (default: total memory / number of cpu cores / 2)");
 	fi_param_define(NULL, "mr_cache_max_count", FI_PARAM_SIZE_T,
 			"Defines the total number of memory regions that"
 			" may be store in the cache.  Setting this will"
@@ -94,7 +111,7 @@ void ofi_monitor_init(void)
 	fi_param_get_str(NULL, "mr_cache_monitor", &cache_params.monitor);
 
 	if (!cache_params.max_size)
-		cache_params.max_size = SIZE_MAX;
+		cache_params.max_size = ofi_default_cache_size();
 
 	if (cache_params.monitor != NULL) {
 		if (!strcmp(cache_params.monitor, "userfaultfd") &&
@@ -110,10 +127,10 @@ void ofi_monitor_init(void)
 void ofi_monitor_cleanup(void)
 {
 	assert(dlist_empty(&uffd_monitor->list));
-	fastlock_destroy(&uffd_monitor->lock);
+	pthread_mutex_destroy(&uffd_monitor->lock);
 
 	assert(dlist_empty(&memhooks_monitor->list));
-	fastlock_destroy(&memhooks_monitor->lock);
+	pthread_mutex_destroy(&memhooks_monitor->lock);
 }
 
 int ofi_monitor_add_cache(struct ofi_mem_monitor *monitor,
@@ -124,7 +141,7 @@ int ofi_monitor_add_cache(struct ofi_mem_monitor *monitor,
 	if (!monitor)
 		return -FI_ENOSYS;
 
-	fastlock_acquire(&monitor->lock);
+	pthread_mutex_lock(&monitor->lock);
 	if (dlist_empty(&monitor->list)) {
 		if (monitor == uffd_monitor)
 			ret = ofi_uffd_init();
@@ -139,7 +156,7 @@ int ofi_monitor_add_cache(struct ofi_mem_monitor *monitor,
 	cache->monitor = monitor;
 	dlist_insert_tail(&cache->notify_entry, &monitor->list);
 out:
-	fastlock_release(&monitor->lock);
+	pthread_mutex_unlock(&monitor->lock);
 	return ret;
 }
 
@@ -148,7 +165,7 @@ void ofi_monitor_del_cache(struct ofi_mr_cache *cache)
 	struct ofi_mem_monitor *monitor = cache->monitor;
 
 	assert(monitor);
-	fastlock_acquire(&monitor->lock);
+	pthread_mutex_lock(&monitor->lock);
 	dlist_remove(&cache->notify_entry);
 
 	if (dlist_empty(&monitor->list)) {
@@ -158,7 +175,7 @@ void ofi_monitor_del_cache(struct ofi_mr_cache *cache)
 			ofi_memhooks_cleanup();
 	}
 
-	fastlock_release(&monitor->lock);
+	pthread_mutex_unlock(&monitor->lock);
 }
 
 /* Must be called holding monitor lock */
@@ -219,10 +236,10 @@ static void *ofi_uffd_handler(void *arg)
 		if (ret != 1)
 			break;
 
-		fastlock_acquire(&uffd.monitor.lock);
+		pthread_mutex_lock(&uffd.monitor.lock);
 		ret = read(uffd.fd, &msg, sizeof(msg));
 		if (ret != sizeof(msg)) {
-			fastlock_release(&uffd.monitor.lock);
+			pthread_mutex_unlock(&uffd.monitor.lock);
 			if (errno != EAGAIN)
 				break;
 			continue;
@@ -230,6 +247,11 @@ static void *ofi_uffd_handler(void *arg)
 
 		switch (msg.event) {
 		case UFFD_EVENT_REMOVE:
+			ofi_monitor_unsubscribe(&uffd.monitor,
+				(void *) (uintptr_t) msg.arg.remove.start,
+				(size_t) (msg.arg.remove.end -
+					  msg.arg.remove.start));
+			/* fall through */
 		case UFFD_EVENT_UNMAP:
 			ofi_monitor_notify(&uffd.monitor,
 				(void *) (uintptr_t) msg.arg.remove.start,
@@ -246,7 +268,7 @@ static void *ofi_uffd_handler(void *arg)
 				"Unhandled uffd event %d\n", msg.event);
 			break;
 		}
-		fastlock_release(&uffd.monitor.lock);
+		pthread_mutex_unlock(&uffd.monitor.lock);
 	}
 	return NULL;
 }
diff --git a/prov/util/src/util_mr_cache.c b/prov/util/src/util_mr_cache.c
index 939766b..64dd456 100644
--- a/prov/util/src/util_mr_cache.c
+++ b/prov/util/src/util_mr_cache.c
@@ -1,6 +1,7 @@
 /*
  * Copyright (c) 2016-2017 Cray Inc. All rights reserved.
  * Copyright (c) 2017-2019 Intel Corporation, Inc.  All rights reserved.
+ * Copyright (c) 2019 Amazon.com, Inc. or its affiliates. All rights reserved.
  *
  * This software is available to you under a choice of one of two
  * licenses.  You may choose to be licensed under the terms of the GNU
@@ -76,18 +77,7 @@ static void util_mr_free_entry(struct ofi_mr_cache *cache,
 	FI_DBG(cache->domain->prov, FI_LOG_MR, "free %p (len: %" PRIu64 ")\n",
 	       entry->info.iov.iov_base, entry->info.iov.iov_len);
 
-	assert(!entry->cached);
-	/* If regions are not being merged, then we can't safely
-	 * unsubscribe this region from the monitor.  Otherwise, we
-	 * might unsubscribe an address range in use by another region.
-	 * As a result, we remain subscribed.  This may result in extra
-	 * notification events, but is harmless to correct operation.
-	 */
-	if (entry->subscribed && cache_params.merge_regions) {
-		ofi_monitor_unsubscribe(cache->monitor, entry->info.iov.iov_base,
-					entry->info.iov.iov_len);
-		entry->subscribed = 0;
-	}
+	assert(!entry->storage_context);
 	cache->delete_region(cache, entry);
 	ofi_buf_free(entry);
 }
@@ -95,9 +85,13 @@ static void util_mr_free_entry(struct ofi_mr_cache *cache,
 static void util_mr_uncache_entry_storage(struct ofi_mr_cache *cache,
 					  struct ofi_mr_entry *entry)
 {
-	assert(entry->cached);
+	/* Without subscription context, we might unsubscribe from
+	 * an address range in use by another region. As a result,
+	 * we remain subscribed. This may result in extra
+	 * notification events, but is harmless to correct operation.
+	 */
+
 	cache->storage.erase(&cache->storage, entry);
-	entry->cached = 0;
 	cache->cached_cnt--;
 	cache->cached_size -= entry->info.iov.iov_len;
 }
@@ -116,7 +110,7 @@ static void util_mr_uncache_entry(struct ofi_mr_cache *cache,
 	}
 }
 
-/* Caller must hold ofi_mem_monitor lock */
+/* Caller must hold ofi_mem_monitor lock as well as unsubscribe from the region */
 void ofi_mr_cache_notify(struct ofi_mr_cache *cache, const void *addr, size_t len)
 {
 	struct ofi_mr_entry *entry;
@@ -129,12 +123,6 @@ void ofi_mr_cache_notify(struct ofi_mr_cache *cache, const void *addr, size_t le
 	for (entry = cache->storage.overlap(&cache->storage, &iov); entry;
 	     entry = cache->storage.overlap(&cache->storage, &iov))
 		util_mr_uncache_entry(cache, entry);
-
-	/* See comment in util_mr_free_entry.  If we're not merging address
-	 * ranges, we can only safely unsubscribe for the reported range.
-	 */
-	if (!cache_params.merge_regions)
-		ofi_monitor_unsubscribe(cache->monitor, addr, len);
 }
 
 static bool mr_cache_flush(struct ofi_mr_cache *cache)
@@ -159,9 +147,9 @@ bool ofi_mr_cache_flush(struct ofi_mr_cache *cache)
 {
 	bool empty;
 
-	fastlock_acquire(&cache->monitor->lock);
+	pthread_mutex_lock(&cache->monitor->lock);
 	empty = mr_cache_flush(cache);
-	fastlock_release(&cache->monitor->lock);
+	pthread_mutex_unlock(&cache->monitor->lock);
 	return empty;
 }
 
@@ -170,11 +158,11 @@ void ofi_mr_cache_delete(struct ofi_mr_cache *cache, struct ofi_mr_entry *entry)
 	FI_DBG(cache->domain->prov, FI_LOG_MR, "delete %p (len: %" PRIu64 ")\n",
 	       entry->info.iov.iov_base, entry->info.iov.iov_len);
 
-	fastlock_acquire(&cache->monitor->lock);
+	pthread_mutex_lock(&cache->monitor->lock);
 	cache->delete_cnt++;
 
 	if (--entry->use_cnt == 0) {
-		if (entry->cached) {
+		if (entry->storage_context) {
 			dlist_insert_tail(&entry->lru_entry, &cache->lru_list);
 		} else {
 			cache->uncached_cnt--;
@@ -182,7 +170,7 @@ void ofi_mr_cache_delete(struct ofi_mr_cache *cache, struct ofi_mr_entry *entry)
 			util_mr_free_entry(cache, entry);
 		}
 	}
-	fastlock_release(&cache->monitor->lock);
+	pthread_mutex_unlock(&cache->monitor->lock);
 }
 
 static int
@@ -198,6 +186,7 @@ util_mr_cache_create(struct ofi_mr_cache *cache, const struct iovec *iov,
 	if (OFI_UNLIKELY(!*entry))
 		return -FI_ENOMEM;
 
+	(*entry)->storage_context = NULL;
 	(*entry)->info.iov = *iov;
 	(*entry)->use_cnt = 1;
 
@@ -213,9 +202,8 @@ util_mr_cache_create(struct ofi_mr_cache *cache, const struct iovec *iov,
 		}
 	}
 
-	if ((cache->cached_cnt > cache_params.max_cnt) ||
-	    (cache->cached_size > cache_params.max_size)) {
-		(*entry)->cached = 0;
+	if ((cache->cached_cnt >= cache_params.max_cnt) ||
+	    (cache->cached_size >= cache_params.max_size)) {
 		cache->uncached_cnt++;
 		cache->uncached_size += iov->iov_len;
 	} else {
@@ -224,7 +212,6 @@ util_mr_cache_create(struct ofi_mr_cache *cache, const struct iovec *iov,
 			ret = -FI_ENOMEM;
 			goto err;
 		}
-		(*entry)->cached = 1;
 		cache->cached_cnt++;
 		cache->cached_size += iov->iov_len;
 
@@ -284,7 +271,7 @@ int ofi_mr_cache_search(struct ofi_mr_cache *cache, const struct fi_mr_attr *att
 	FI_DBG(cache->domain->prov, FI_LOG_MR, "search %p (len: %" PRIu64 ")\n",
 	       attr->mr_iov->iov_base, attr->mr_iov->iov_len);
 
-	fastlock_acquire(&cache->monitor->lock);
+	pthread_mutex_lock(&cache->monitor->lock);
 	cache->search_cnt++;
 
 	while (((cache->cached_cnt >= cache_params.max_cnt) ||
@@ -314,7 +301,80 @@ int ofi_mr_cache_search(struct ofi_mr_cache *cache, const struct fi_mr_attr *att
 		dlist_remove_init(&(*entry)->lru_entry);
 
 unlock:
-	fastlock_release(&cache->monitor->lock);
+	pthread_mutex_unlock(&cache->monitor->lock);
+	return ret;
+}
+
+struct ofi_mr_entry *ofi_mr_cache_find(struct ofi_mr_cache *cache,
+				       const struct fi_mr_attr *attr)
+{
+	struct ofi_mr_info info;
+	struct ofi_mr_entry *entry;
+
+	assert(attr->iov_count == 1);
+	FI_DBG(cache->domain->prov, FI_LOG_MR, "find %p (len: %" PRIu64 ")\n",
+	       attr->mr_iov->iov_base, attr->mr_iov->iov_len);
+
+	pthread_mutex_lock(&cache->monitor->lock);
+	cache->search_cnt++;
+
+	info.iov = *attr->mr_iov;
+	entry = cache->storage.find(&cache->storage, &info);
+	if (!entry) {
+		goto unlock;
+	}
+
+	if (!ofi_iov_within(attr->mr_iov, &entry->info.iov)) {
+		entry = NULL;
+		goto unlock;
+	}
+
+	cache->hit_cnt++;
+	if ((entry)->use_cnt++ == 0)
+		dlist_remove_init(&(entry)->lru_entry);
+
+unlock:
+	pthread_mutex_unlock(&cache->monitor->lock);
+	return entry;
+}
+
+int ofi_mr_cache_reg(struct ofi_mr_cache *cache, const struct fi_mr_attr *attr,
+		     struct ofi_mr_entry **entry)
+{
+	int ret;
+
+	assert(attr->iov_count == 1);
+	FI_DBG(cache->domain->prov, FI_LOG_MR, "reg %p (len: %" PRIu64 ")\n",
+	       attr->mr_iov->iov_base, attr->mr_iov->iov_len);
+
+	pthread_mutex_lock(&cache->monitor->lock);
+	*entry = ofi_buf_alloc(cache->entry_pool);
+	if (*entry) {
+		cache->uncached_cnt++;
+		cache->uncached_size += attr->mr_iov->iov_len;
+	} else {
+		ret = -FI_ENOMEM;
+		goto unlock;
+	}
+	pthread_mutex_unlock(&cache->monitor->lock);
+
+	(*entry)->info.iov = *attr->mr_iov;
+	(*entry)->use_cnt = 1;
+	(*entry)->storage_context = NULL;
+
+	ret = cache->add_region(cache, *entry);
+	if (ret)
+		goto buf_free;
+
+	return 0;
+
+buf_free:
+	pthread_mutex_lock(&cache->monitor->lock);
+	ofi_buf_free(*entry);
+	cache->uncached_cnt--;
+	cache->uncached_size -= attr->mr_iov->iov_len;
+unlock:
+	pthread_mutex_unlock(&cache->monitor->lock);
 	return ret;
 }
 
@@ -332,13 +392,13 @@ void ofi_mr_cache_cleanup(struct ofi_mr_cache *cache)
 		cache->search_cnt, cache->delete_cnt, cache->hit_cnt,
 		cache->notify_cnt);
 
-	fastlock_acquire(&cache->monitor->lock);
+	pthread_mutex_lock(&cache->monitor->lock);
 	dlist_foreach_container_safe(&cache->lru_list, struct ofi_mr_entry,
 				     entry, lru_entry, tmp) {
 		assert(entry->use_cnt == 0);
 		util_mr_uncache_entry(cache, entry);
 	}
-	fastlock_release(&cache->monitor->lock);
+	pthread_mutex_unlock(&cache->monitor->lock);
 
 	ofi_monitor_del_cache(cache);
 	cache->storage.destroy(&cache->storage);
@@ -384,18 +444,18 @@ static int ofi_mr_rbt_insert(struct ofi_mr_storage *storage,
 			     struct ofi_mr_info *key,
 			     struct ofi_mr_entry *entry)
 {
+	assert(!entry->storage_context);
 	return ofi_rbmap_insert(storage->storage, (void *) key, (void *) entry,
-				NULL);
+				(struct ofi_rbnode **) &entry->storage_context);
 }
 
 static int ofi_mr_rbt_erase(struct ofi_mr_storage *storage,
 			    struct ofi_mr_entry *entry)
 {
-	struct ofi_rbnode *node;
-
-	node = ofi_rbmap_find(storage->storage, &entry->info);
-	assert(node);
-	ofi_rbmap_delete(storage->storage, node);
+	assert(entry->storage_context);
+	ofi_rbmap_delete(storage->storage,
+			 (struct ofi_rbnode *) entry->storage_context);
+	entry->storage_context = NULL;
 	return 0;
 }
 
@@ -445,7 +505,7 @@ int ofi_mr_cache_init(struct util_domain *domain,
 	int ret;
 
 	assert(cache->add_region && cache->delete_region);
-	if (!cache_params.max_cnt)
+	if (!cache_params.max_cnt || !cache_params.max_size)
 		return -FI_ENOSPC;
 
 	dlist_init(&cache->lru_list);
diff --git a/prov/util/src/util_shm.c b/prov/util/src/util_shm.c
index 7508471..c6891d6 100644
--- a/prov/util/src/util_shm.c
+++ b/prov/util/src/util_shm.c
@@ -45,7 +45,7 @@
 
 static void smr_peer_addr_init(struct smr_addr *peer)
 {
-	memset(peer->name, 0, SMR_NAME_SIZE);
+	memset(peer->name, 0, NAME_MAX);
 	peer->addr = FI_ADDR_UNSPEC;
 }
 
@@ -53,18 +53,23 @@ static void smr_peer_addr_init(struct smr_addr *peer)
 int smr_create(const struct fi_provider *prov, struct smr_map *map,
 	       const struct smr_attr *attr, struct smr_region **smr)
 {
+	struct smr_ep_name *ep_name;
 	size_t total_size, cmd_queue_offset, peer_addr_offset;
 	size_t resp_queue_offset, inject_pool_offset, name_offset;
 	int fd, ret, i;
 	void *mapped_addr;
+	size_t tx_size, rx_size;
 
 	cmd_queue_offset = sizeof(**smr);
+
+	tx_size = roundup_power_of_two(attr->tx_count);
+	rx_size = roundup_power_of_two(attr->rx_count);
 	resp_queue_offset = cmd_queue_offset + sizeof(struct smr_cmd_queue) +
-			sizeof(struct smr_cmd) * attr->rx_count;
+			sizeof(struct smr_cmd) * rx_size;
 	inject_pool_offset = resp_queue_offset + sizeof(struct smr_resp_queue) +
-			sizeof(struct smr_resp) * attr->tx_count;
+			sizeof(struct smr_resp) * tx_size;
 	peer_addr_offset = inject_pool_offset + sizeof(struct smr_inject_pool) +
-			sizeof(struct smr_inject_pool_entry) * attr->rx_count;
+			sizeof(struct smr_inject_pool_entry) * rx_size;
 	name_offset = peer_addr_offset + sizeof(struct smr_addr) * SMR_MAX_PEERS;
 	total_size = name_offset + strlen(attr->name) + 1;
 	total_size = roundup_power_of_two(total_size);
@@ -75,6 +80,14 @@ int smr_create(const struct fi_provider *prov, struct smr_map *map,
 		goto err1;
 	}
 
+	ep_name = calloc(1, sizeof(*ep_name));
+	if (!ep_name) {
+		FI_WARN(prov, FI_LOG_EP_CTRL, "calloc error\n");
+		return -FI_ENOMEM;
+	}
+	strncpy(ep_name->name, (char *)attr->name, NAME_MAX);
+	dlist_insert_tail(&ep_name->entry, &ep_name_list);
+
 	ret = ftruncate(fd, total_size);
 	if (ret < 0) {
 		FI_WARN(prov, FI_LOG_EP_CTRL, "ftruncate error\n");
@@ -105,11 +118,11 @@ int smr_create(const struct fi_provider *prov, struct smr_map *map,
 	(*smr)->inject_pool_offset = inject_pool_offset;
 	(*smr)->peer_addr_offset = peer_addr_offset;
 	(*smr)->name_offset = name_offset;
-	(*smr)->cmd_cnt = attr->rx_count;
+	(*smr)->cmd_cnt = rx_size;
 
-	smr_cmd_queue_init(smr_cmd_queue(*smr), attr->rx_count);
-	smr_resp_queue_init(smr_resp_queue(*smr), attr->tx_count);
-	smr_inject_pool_init(smr_inject_pool(*smr), attr->rx_count);
+	smr_cmd_queue_init(smr_cmd_queue(*smr), rx_size);
+	smr_resp_queue_init(smr_resp_queue(*smr), tx_size);
+	smr_inject_pool_init(smr_inject_pool(*smr), rx_size);
 	for (i = 0; i < SMR_MAX_PEERS; i++)
 		smr_peer_addr_init(&smr_peer_addr(*smr)[i]);
 
@@ -197,8 +210,8 @@ void smr_map_to_endpoint(struct smr_region *region, int index)
 	local_peers = smr_peer_addr(region);
 
 	strncpy(smr_peer_addr(region)[index].name,
-		region->map->peers[index].peer.name, SMR_NAME_SIZE);
-	smr_peer_addr(region)[index].name[SMR_NAME_SIZE - 1] = '\0';
+		region->map->peers[index].peer.name, NAME_MAX - 1);
+	smr_peer_addr(region)[index].name[NAME_MAX - 1] = '\0';
 	if (region->map->peers[index].peer.addr == FI_ADDR_UNSPEC)
 		return;
 
@@ -207,7 +220,7 @@ void smr_map_to_endpoint(struct smr_region *region, int index)
 
 	for (peer_index = 0; peer_index < SMR_MAX_PEERS; peer_index++) {
 		if (!strncmp(smr_name(region),
-		    peer_peers[peer_index].name, SMR_NAME_SIZE))
+		    peer_peers[peer_index].name, NAME_MAX))
 			break;
 	}
 	if (peer_index != SMR_MAX_PEERS) {
@@ -224,7 +237,7 @@ void smr_unmap_from_endpoint(struct smr_region *region, int index)
 
 	local_peers = smr_peer_addr(region);
 
-	memset(local_peers[index].name, 0, SMR_NAME_SIZE);
+	memset(local_peers[index].name, 0, NAME_MAX);
 	peer_index = region->map->peers[index].peer.addr;
 	if (peer_index == FI_ADDR_UNSPEC)
 		return;
@@ -248,8 +261,8 @@ int smr_map_add(const struct fi_provider *prov, struct smr_map *map,
 	int ret = 0;
 
 	fastlock_acquire(&map->lock);
-	strncpy(map->peers[id].peer.name, name, SMR_NAME_SIZE);
-	map->peers[id].peer.name[SMR_NAME_SIZE - 1] = '\0';
+	strncpy(map->peers[id].peer.name, name, NAME_MAX);
+	map->peers[id].peer.name[NAME_MAX - 1] = '\0';
 	ret = smr_map_to_region(prov, &map->peers[id]);
 	if (!ret)
 		map->peers[id].peer.addr = id;
diff --git a/prov/verbs/configure.m4 b/prov/verbs/configure.m4
index 3ae5c6c..3d4c183 100644
--- a/prov/verbs/configure.m4
+++ b/prov/verbs/configure.m4
@@ -58,6 +58,17 @@ AC_DEFUN([FI_VERBS_CONFIGURE],[
 	AC_DEFINE_UNQUOTED([VERBS_HAVE_XRC],[$VERBS_HAVE_XRC],
 		[Whether infiniband/verbs.h has XRC support or not])
 
+	#See if we have rdma-core rdma_establish support
+	VERBS_HAVE_RDMA_ESTABLISH=0
+	AS_IF([test $verbs_ibverbs_happy -eq 1 && \
+	       test $verbs_rdmacm_ex_happy -eq 1],[
+		AC_CHECK_DECL([rdma_establish],
+			[VERBS_HAVE_RDMA_ESTABLISH=1],[],
+			[#include <rdma/rdma_cma.h>])
+		])
+	AC_DEFINE_UNQUOTED([VERBS_HAVE_RDMA_ESTABLISH],[$VERBS_HAVE_RDMA_ESTABLISH],
+		[Whether rdma/rdma_cma.h has rdma_establish() support or not])
+
 	# Technically, verbs_ibverbs_CPPFLAGS and
 	# verbs_rdmacm_CPPFLAGS could be different, but it is highly
 	# unlikely that they ever will be.  So only list
diff --git a/prov/verbs/src/fi_verbs.c b/prov/verbs/src/fi_verbs.c
index 5e3b9f0..6552349 100644
--- a/prov/verbs/src/fi_verbs.c
+++ b/prov/verbs/src/fi_verbs.c
@@ -78,7 +78,7 @@ struct fi_ibv_dev_preset {
 struct fi_provider fi_ibv_prov = {
 	.name = VERBS_PROV_NAME,
 	.version = VERBS_PROV_VERS,
-	.fi_version = FI_VERSION(1, 8),
+	.fi_version = OFI_VERSION_LATEST,
 	.getinfo = fi_ibv_getinfo,
 	.fabric = fi_ibv_fabric,
 	.cleanup = fi_ibv_fini
@@ -177,6 +177,8 @@ int fi_ibv_get_rai_id(const char *node, const char *service, uint64_t flags,
 		ret = rdma_bind_addr(*id, (*rai)->ai_src_addr);
 		if (ret) {
 			VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_bind_addr", errno);
+			ofi_straddr_log(&fi_ibv_prov, FI_LOG_INFO, FI_LOG_FABRIC,
+					"bind addr", (*rai)->ai_src_addr);
 			ret = -errno;
 			goto err2;
 		}
@@ -184,9 +186,13 @@ int fi_ibv_get_rai_id(const char *node, const char *service, uint64_t flags,
 	}
 
 	ret = rdma_resolve_addr(*id, (*rai)->ai_src_addr,
-				(*rai)->ai_dst_addr, 2000);
+				(*rai)->ai_dst_addr, VERBS_RESOLVE_TIMEOUT);
 	if (ret) {
 		VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_resolve_addr", errno);
+		ofi_straddr_log(&fi_ibv_prov, FI_LOG_INFO, FI_LOG_FABRIC,
+				"src addr", (*rai)->ai_src_addr);
+		ofi_straddr_log(&fi_ibv_prov, FI_LOG_INFO, FI_LOG_FABRIC,
+				"dst addr", (*rai)->ai_dst_addr);
 		ret = -errno;
 		goto err2;
 	}
@@ -227,8 +233,12 @@ int fi_ibv_create_ep(const struct fi_info *hints, struct rdma_cm_id **id)
 	if (rdma_resolve_addr(*id, rai->ai_src_addr, rai->ai_dst_addr,
 			      VERBS_RESOLVE_TIMEOUT)) {
 		ret = -errno;
-		FI_WARN(&fi_ibv_prov, FI_LOG_EP_CTRL, "rdma_resolve_addr failed: %s (%d)\n",
-			strerror(-ret), -ret);
+		FI_WARN(&fi_ibv_prov, FI_LOG_EP_CTRL, "rdma_resolve_addr failed: "
+			"%s (%d)\n", strerror(-ret), -ret);
+		ofi_straddr_log(&fi_ibv_prov, FI_LOG_WARN, FI_LOG_EP_CTRL,
+				"src addr", rai->ai_src_addr);
+		ofi_straddr_log(&fi_ibv_prov, FI_LOG_WARN, FI_LOG_EP_CTRL,
+				"dst addr", rai->ai_dst_addr);
 		goto err2;
 	}
 	return 0;
@@ -617,6 +627,23 @@ static int fi_ibv_read_params(void)
 	return FI_SUCCESS;
 }
 
+static void verbs_devs_free(void)
+{
+	struct verbs_dev_info *dev;
+	struct verbs_addr *addr;
+
+	while (!dlist_empty(&verbs_devs)) {
+		dlist_pop_front(&verbs_devs, struct verbs_dev_info, dev, entry);
+		while (!dlist_empty(&dev->addrs)) {
+			dlist_pop_front(&dev->addrs, struct verbs_addr, addr, entry);
+			rdma_freeaddrinfo(addr->rai);
+			free(addr);
+		}
+		free(dev->name);
+		free(dev);
+	}
+}
+
 static void fi_ibv_fini(void)
 {
 #if HAVE_VERBS_DL
@@ -624,6 +651,7 @@ static void fi_ibv_fini(void)
 	ofi_mem_fini();
 #endif
 	fi_freeinfo((void *)fi_ibv_util_prov.info);
+	verbs_devs_free();
 	fi_ibv_util_prov.info = NULL;
 }
 
diff --git a/prov/verbs/src/fi_verbs.h b/prov/verbs/src/fi_verbs.h
index 0dae282..81764f3 100644
--- a/prov/verbs/src/fi_verbs.h
+++ b/prov/verbs/src/fi_verbs.h
@@ -136,6 +136,7 @@
 
 extern struct fi_provider fi_ibv_prov;
 extern struct util_prov fi_ibv_util_prov;
+extern struct dlist_entry verbs_devs;
 
 extern struct fi_ibv_gl_data {
 	int	def_tx_size;
@@ -241,7 +242,11 @@ struct fi_ibv_eq_entry {
 	struct dlist_entry	item;
 	uint32_t		event;
 	size_t			len;
-	char 			eq_entry[0];
+	union {
+		char 			entry[0];
+		struct fi_eq_entry 	*eq_entry;
+		struct fi_eq_cm_entry	*cm_entry;
+	};
 };
 
 typedef int (*fi_ibv_trywait_func)(struct fid *fid);
@@ -288,6 +293,7 @@ struct fi_ibv_eq {
 int fi_ibv_eq_open(struct fid_fabric *fabric, struct fi_eq_attr *attr,
 		   struct fid_eq **eq, void *context);
 int fi_ibv_eq_trywait(struct fi_ibv_eq *eq);
+void fi_ibv_eq_remove_events(struct fi_ibv_eq *eq, struct fid *fid);
 
 int fi_ibv_av_open(struct fid_domain *domain, struct fi_av_attr *attr,
 		   struct fid_av **av, void *context);
@@ -324,8 +330,9 @@ struct fi_ibv_domain {
 
 		/* The domain maintains a RBTree for mapping an endpoint
 		 * destination addresses to physical XRC INI QP connected
-		 * to that host. */
-		fastlock_t		ini_mgmt_lock;
+		 * to that host. The map is protected using the EQ lock
+		 * bound to the domain to avoid the need for additional
+		 * locking. */
 		struct ofi_rbmap	*ini_conn_rbmap;
 	} xrc ;
 
@@ -462,7 +469,7 @@ enum fi_ibv_ini_qp_state {
  * An XRC transport INI QP connection can be shared within a process to
  * communicate with all the ranks on the same remote node. This structure is
  * only accessed during connection setup and tear down and should be
- * done while holding the domain:xrc:ini_mgmt_lock.
+ * done while holding the domain:eq:lock.
  */
 struct fi_ibv_ini_shared_conn {
 	/* To share, EP must have same remote peer host addr and TX CQ */
@@ -700,6 +707,11 @@ int fi_ibv_fi_to_rai(const struct fi_info *fi, uint64_t flags,
 		     struct rdma_addrinfo *rai);
 int fi_ibv_get_rdma_rai(const char *node, const char *service, uint64_t flags,
 			const struct fi_info *hints, struct rdma_addrinfo **rai);
+int fi_ibv_get_matching_info(uint32_t version, const struct fi_info *hints,
+			     struct fi_info **info, const struct fi_info *verbs_info,
+			     uint8_t passive);
+void fi_ibv_alter_info(const struct fi_info *hints, struct fi_info *info);
+
 struct verbs_ep_domain {
 	char			*suffix;
 	enum fi_ep_type		type;
@@ -886,24 +898,20 @@ static inline int fi_ibv_poll_reap_unsig_cq(struct fi_ibv_ep *ep)
 						    util_domain);
 
 	cq->util_cq.cq_fastlock_acquire(&cq->util_cq.cq_lock);
-	/* TODO: retrieve WCs as much as possible in a single
-	 * ibv_poll_cq call */
 	while (1) {
 		ret = domain->poll_cq(cq->cq, 10, wc);
-		if (ret <= 0) {
-			cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
-			return ret;
-		}
+		if (ret <= 0)
+			break;
+
 		for (i = 0; i < ret; i++) {
-			if (!fi_ibv_process_wc(cq, &wc[i]))
-				continue;
-			if (OFI_LIKELY(!fi_ibv_wc_2_wce(cq, &wc[i], &wce)))
+			if (fi_ibv_process_wc(cq, &wc[i]) &&
+			    (!fi_ibv_wc_2_wce(cq, &wc[i], &wce)))
 				slist_insert_tail(&wce->entry, &cq->wcq);
 		}
 	}
 
 	cq->util_cq.cq_fastlock_release(&cq->util_cq.cq_lock);
-	return FI_SUCCESS;
+	return ret;
 }
 
 /* WR must be filled out by now except for context */
diff --git a/prov/verbs/src/ofi_verbs_priv.h b/prov/verbs/src/ofi_verbs_priv.h
index c19a1f1..fdbdb52 100644
--- a/prov/verbs/src/ofi_verbs_priv.h
+++ b/prov/verbs/src/ofi_verbs_priv.h
@@ -60,4 +60,9 @@
 #define FI_VERBS_XRC_ONLY
 #endif /* VERBS_HAVE_XRC */
 
+#if !VERBS_HAVE_RDMA_ESTABLISH
+/* If older rdma-core this function does not exist/is not needed */
+#define rdma_establish(id) do { } while (0)
+#endif
+
 #endif /* OFI_VERBS_PRIV_H */
diff --git a/prov/verbs/src/verbs_cm.c b/prov/verbs/src/verbs_cm.c
index 98b71d4..69d08bc 100644
--- a/prov/verbs/src/verbs_cm.c
+++ b/prov/verbs/src/verbs_cm.c
@@ -489,11 +489,9 @@ static int fi_ibv_pep_listen(struct fid_pep *pep_fid)
 	pep = container_of(pep_fid, struct fi_ibv_pep, pep_fid);
 
 	addr = rdma_get_local_addr(pep->id);
-	if (addr) {
-		VERBS_INFO(FI_LOG_CORE, "Listening on %s:%d\n",
-			   inet_ntoa(((struct sockaddr_in *)addr)->sin_addr),
-			   ntohs(((struct sockaddr_in *)addr)->sin_port));
-	}
+	if (addr)
+		ofi_straddr_log(&fi_ibv_prov, FI_LOG_INFO,
+				FI_LOG_EP_CTRL, "listening on", addr);
 
 	return rdma_listen(pep->id, pep->backlog) ? -errno : 0;
 }
diff --git a/prov/verbs/src/verbs_cm_xrc.c b/prov/verbs/src/verbs_cm_xrc.c
index 40af6be..ecf6d11 100644
--- a/prov/verbs/src/verbs_cm_xrc.c
+++ b/prov/verbs/src/verbs_cm_xrc.c
@@ -203,10 +203,10 @@ void fi_ibv_free_xrc_conn_setup(struct fi_ibv_xrc_ep *ep, int disconnect)
 	}
 }
 
+/* Caller must hold the eq:lock */
 int fi_ibv_connect_xrc(struct fi_ibv_xrc_ep *ep, struct sockaddr *addr,
 		       int reciprocal, void *param, size_t paramlen)
 {
-	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
 	struct sockaddr *peer_addr;
 	int ret;
 
@@ -222,12 +222,10 @@ int fi_ibv_connect_xrc(struct fi_ibv_xrc_ep *ep, struct sockaddr *addr,
 		ofi_straddr_dbg(&fi_ibv_prov, FI_LOG_FABRIC,
 				"XRC connect dest_addr", peer_addr);
 
-	fastlock_acquire(&domain->xrc.ini_mgmt_lock);
 	ret = fi_ibv_get_shared_ini_conn(ep, &ep->ini_conn);
 	if (ret) {
 		VERBS_WARN(FI_LOG_EP_CTRL,
 			   "Get of shared XRC INI connection failed %d\n", ret);
-		fastlock_release(&domain->xrc.ini_mgmt_lock);
 		if (!reciprocal) {
 			free(ep->conn_setup);
 			ep->conn_setup = NULL;
@@ -236,20 +234,16 @@ int fi_ibv_connect_xrc(struct fi_ibv_xrc_ep *ep, struct sockaddr *addr,
 	}
 	fi_ibv_add_pending_ini_conn(ep, reciprocal, param, paramlen);
 	fi_ibv_sched_ini_conn(ep->ini_conn);
-	fastlock_release(&domain->xrc.ini_mgmt_lock);
 
 	return FI_SUCCESS;
 }
 
+/* Caller must hold the eq:lock */
 void fi_ibv_ep_ini_conn_done(struct fi_ibv_xrc_ep *ep, uint32_t peer_srqn,
 			     uint32_t tgt_qpn)
 {
-	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
-
 	assert(ep->base_ep.id && ep->ini_conn);
 
-	fastlock_acquire(&domain->xrc.ini_mgmt_lock);
-
 	assert(ep->ini_conn->state == FI_IBV_INI_QP_CONNECTING ||
 	       ep->ini_conn->state == FI_IBV_INI_QP_CONNECTED);
 
@@ -270,20 +264,16 @@ void fi_ibv_ep_ini_conn_done(struct fi_ibv_xrc_ep *ep, uint32_t peer_srqn,
 	ep->conn_setup->ini_connected = 1;
 	fi_ibv_log_ep_conn(ep, "INI Connection Done");
 	fi_ibv_sched_ini_conn(ep->ini_conn);
-	fastlock_release(&domain->xrc.ini_mgmt_lock);
 }
 
+/* Caller must hold the eq:lock */
 void fi_ibv_ep_ini_conn_rejected(struct fi_ibv_xrc_ep *ep)
 {
-	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
-
 	assert(ep->base_ep.id && ep->ini_conn);
 
-	fastlock_acquire(&domain->xrc.ini_mgmt_lock);
 	fi_ibv_log_ep_conn(ep, "INI Connection Rejected");
 	fi_ibv_put_shared_ini_conn(ep);
 	ep->conn_state = FI_IBV_XRC_ERROR;
-	fastlock_release(&domain->xrc.ini_mgmt_lock);
 }
 
 void fi_ibv_ep_tgt_conn_done(struct fi_ibv_xrc_ep *ep)
@@ -297,6 +287,7 @@ void fi_ibv_ep_tgt_conn_done(struct fi_ibv_xrc_ep *ep)
 	ep->conn_setup->tgt_connected = 1;
 }
 
+/* Caller must hold the eq:lock */
 int fi_ibv_accept_xrc(struct fi_ibv_xrc_ep *ep, int reciprocal,
 		      void *param, size_t paramlen)
 {
diff --git a/prov/verbs/src/verbs_domain_xrc.c b/prov/verbs/src/verbs_domain_xrc.c
index 5c9b868..0c49779 100644
--- a/prov/verbs/src/verbs_domain_xrc.c
+++ b/prov/verbs/src/verbs_domain_xrc.c
@@ -111,7 +111,7 @@ static inline void fi_ibv_set_ini_conn_key(struct fi_ibv_xrc_ep *ep,
 				  struct fi_ibv_cq, util_cq);
 }
 
-/* Caller must hold domain:xrc:ini_mgmt_lock */
+/* Caller must hold domain:eq:lock */
 int fi_ibv_get_shared_ini_conn(struct fi_ibv_xrc_ep *ep,
 			       struct fi_ibv_ini_shared_conn **ini_conn) {
 	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
@@ -168,13 +168,12 @@ insert_err:
 	return ret;
 }
 
-/* Caller must hold domain:xrc:ini_mgmt_lock */
+/* Caller must hold domain:eq:lock */
 void fi_ibv_put_shared_ini_conn(struct fi_ibv_xrc_ep *ep)
 {
 	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
 	struct fi_ibv_ini_shared_conn *ini_conn;
 	struct fi_ibv_ini_conn_key key;
-	struct ofi_rbnode *node;
 
 	if (!ep->ini_conn)
 		return;
@@ -206,9 +205,7 @@ void fi_ibv_put_shared_ini_conn(struct fi_ibv_xrc_ep *ep)
 
 		assert(dlist_empty(&ini_conn->pending_list));
 		fi_ibv_set_ini_conn_key(ep, &key);
-		node = ofi_rbmap_find(domain->xrc.ini_conn_rbmap, &key);
-		assert(node);
-		ofi_rbmap_delete(domain->xrc.ini_conn_rbmap, node);
+		ofi_rbmap_find_delete(domain->xrc.ini_conn_rbmap, &key);
 		free(ini_conn->peer_addr);
 		free(ini_conn);
 	} else {
@@ -216,7 +213,7 @@ void fi_ibv_put_shared_ini_conn(struct fi_ibv_xrc_ep *ep)
 	}
 }
 
-/* Caller must hold domain:xrc:ini_mgmt_lock */
+/* Caller must hold domain:eq:lock */
 void fi_ibv_add_pending_ini_conn(struct fi_ibv_xrc_ep *ep, int reciprocal,
 				 void *conn_param, size_t conn_paramlen)
 {
@@ -238,7 +235,7 @@ static void fi_ibv_create_shutdown_event(struct fi_ibv_xrc_ep *ep)
 			      &entry, sizeof(entry));
 }
 
-/* Caller must hold domain:xrc:ini_mgmt_lock */
+/* Caller must hold domain:eq:lock */
 void fi_ibv_sched_ini_conn(struct fi_ibv_ini_shared_conn *ini_conn)
 {
 	struct fi_ibv_xrc_ep *ep;
@@ -309,7 +306,7 @@ err:
 	}
 }
 
-/* Caller must hold domain:xrc:ini_mgmt_lock */
+/* Caller must hold domain:xrc:eq:lock */
 int fi_ibv_process_ini_conn(struct fi_ibv_xrc_ep *ep,int reciprocal,
 			    void *param, size_t paramlen)
 {
@@ -443,14 +440,11 @@ static int fi_ibv_put_tgt_qp(struct fi_ibv_xrc_ep *ep)
 	return FI_SUCCESS;
 }
 
+/* Caller must hold eq:lock */
 int fi_ibv_ep_destroy_xrc_qp(struct fi_ibv_xrc_ep *ep)
 {
-	struct fi_ibv_domain *domain = fi_ibv_ep_to_domain(&ep->base_ep);
-
 	if (ep->base_ep.ibv_qp) {
-		fastlock_acquire(&domain->xrc.ini_mgmt_lock);
 		fi_ibv_put_shared_ini_conn(ep);
-		fastlock_release(&domain->xrc.ini_mgmt_lock);
 	}
 	if (ep->base_ep.id) {
 		rdma_destroy_id(ep->base_ep.id);
@@ -544,8 +538,6 @@ int fi_ibv_domain_xrc_init(struct fi_ibv_domain *domain)
 		goto xrcd_err;
 	}
 
-	fastlock_init(&domain->xrc.ini_mgmt_lock);
-
 	domain->xrc.ini_conn_rbmap = ofi_rbmap_create(fi_ibv_ini_conn_compare);
 	if (!domain->xrc.ini_conn_rbmap) {
 		ret = -ENOMEM;
@@ -593,7 +585,6 @@ int fi_ibv_domain_xrc_cleanup(struct fi_ibv_domain *domain)
 	}
 
 	ofi_rbmap_destroy(domain->xrc.ini_conn_rbmap);
-	fastlock_destroy(&domain->xrc.ini_mgmt_lock);
 #endif /* VERBS_HAVE_XRC */
 	return 0;
 }
diff --git a/prov/verbs/src/verbs_ep.c b/prov/verbs/src/verbs_ep.c
index 3dca094..0c61266 100644
--- a/prov/verbs/src/verbs_ep.c
+++ b/prov/verbs/src/verbs_ep.c
@@ -242,8 +242,19 @@ static int fi_ibv_ep_close(fid_t fid)
 
 	switch (ep->util_ep.type) {
 	case FI_EP_MSG:
-		if (ep->eq)
+		if (ep->eq) {
 			fastlock_acquire(&ep->eq->lock);
+			if (ep->eq->err.err && ep->eq->err.fid == fid) {
+				if (ep->eq->err.err_data) {
+					free(ep->eq->err.err_data);
+					ep->eq->err.err_data = NULL;
+					ep->eq->err.err_data_size = 0;
+				}
+				ep->eq->err.err = 0;
+				ep->eq->err.prov_errno = 0;
+			}
+			fi_ibv_eq_remove_events(ep->eq, fid);
+		}
 
 		if (fi_ibv_is_xrc(ep->info))
 			fi_ibv_ep_xrc_close(ep);
@@ -718,13 +729,7 @@ static int fi_ibv_dgram_ep_setname(fid_t ep_fid, void *addr, size_t addrlen)
 	void *save_addr;
 	int ret = FI_SUCCESS;
 
-	if (ep_fid->fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
 	ep = container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid.fid);
-	if (!ep)
-		return -FI_EINVAL;
-
 	if (addrlen < ep->info->src_addrlen) {
 		VERBS_INFO(FI_LOG_EP_CTRL,
 			   "addrlen expected: %zu, got: %zu\n",
@@ -756,13 +761,7 @@ static int fi_ibv_dgram_ep_getname(fid_t ep_fid, void *addr, size_t *addrlen)
 {
 	struct fi_ibv_ep *ep;
 
-	if (ep_fid->fclass != FI_CLASS_EP)
-		return -FI_EINVAL;
-
 	ep = container_of(ep_fid, struct fi_ibv_ep, util_ep.ep_fid.fid);
-	if (!ep)
-		return -FI_EINVAL;
-
 	if (*addrlen < sizeof(ep->ep_name)) {
 		*addrlen = sizeof(ep->ep_name);
 		VERBS_INFO(FI_LOG_EP_CTRL,
diff --git a/prov/verbs/src/verbs_eq.c b/prov/verbs/src/verbs_eq.c
index 2e73b3d..d1f536b 100644
--- a/prov/verbs/src/verbs_eq.c
+++ b/prov/verbs/src/verbs_eq.c
@@ -192,7 +192,7 @@ fi_ibv_eq_cm_getinfo(struct rdma_cm_event *event, struct fi_info *pep_info,
 			goto err1;
 	} else {
 		if (fi_ibv_pep_dev_domain_match(hints, devname)) {
-			VERBS_WARN(FI_LOG_EQ, "Passive endpoint domain: %s does"
+			VERBS_WARN(FI_LOG_EQ, "passive endpoint domain: %s does"
 				   " not match device: %s where we got a "
 				   "connection request\n",
 				   hints->domain_attr->name, devname);
@@ -206,12 +206,16 @@ fi_ibv_eq_cm_getinfo(struct rdma_cm_event *event, struct fi_info *pep_info,
 		hints->fabric_attr->name = NULL;
 	}
 
-	if (fi_ibv_getinfo(hints->fabric_attr->api_version, NULL, NULL, 0,
-			   hints, info))
+	ret = fi_ibv_get_matching_info(hints->fabric_attr->api_version, hints,
+				       info, fi_ibv_util_prov.info, 0);
+	if (ret)
 		goto err1;
 
 	assert(!(*info)->dest_addr);
 
+	ofi_alter_info(*info, hints, hints->fabric_attr->api_version);
+	fi_ibv_alter_info(hints, *info);
+
 	free((*info)->src_addr);
 
 	(*info)->src_addrlen = fi_ibv_sockaddr_len(rdma_get_local_addr(event->id));
@@ -296,7 +300,6 @@ fi_ibv_eq_xrc_connreq_event(struct fi_ibv_eq *eq, struct fi_eq_cm_entry *entry,
 		return FI_SUCCESS;
 	}
 
-	fastlock_acquire(&eq->lock);
 	/*
 	 * Reciprocal connections are initiated and handled internally by
 	 * the provider, get the endpoint that issued the original connection
@@ -329,7 +332,6 @@ fi_ibv_eq_xrc_connreq_event(struct fi_ibv_eq *eq, struct fi_eq_cm_entry *entry,
 		goto send_reject;
 	}
 done:
-	fastlock_release(&eq->lock);
 
 	/* Event is handled internally and not passed to the application */
 	return -FI_EAGAIN;
@@ -337,11 +339,20 @@ done:
 send_reject:
 	if (rdma_reject(connreq->id, *priv_data, *priv_datalen))
 		VERBS_WARN(FI_LOG_EP_CTRL, "rdma_reject %d\n", -errno);
-	fastlock_release(&eq->lock);
 
 	return -FI_EAGAIN;
 }
 
+static void
+fi_ibv_eq_xrc_establish(struct rdma_cm_event *cma_event)
+{
+	/* For newer rdma-core, active side  must complete the
+	 * connect if rdma_cm is not managing the QP */
+	if (cma_event->event == RDMA_CM_EVENT_CONNECT_RESPONSE &&
+	    !cma_event->id->qp)
+		rdma_establish(cma_event->id);
+}
+
 static int
 fi_ibv_eq_xrc_conn_event(struct fi_ibv_xrc_ep *ep,
 			 struct rdma_cm_event *cma_event,
@@ -374,6 +385,7 @@ fi_ibv_eq_xrc_conn_event(struct fi_ibv_xrc_ep *ep,
 		fi_ibv_save_priv_data(ep, priv_data, priv_datalen);
 		fi_ibv_ep_ini_conn_done(ep, xrc_info.conn_data,
 					xrc_info.conn_param.qp_num);
+		fi_ibv_eq_xrc_establish(cma_event);
 	} else {
 		fi_ibv_ep_tgt_conn_done(ep);
 		ret = fi_ibv_connect_xrc(ep, NULL, FI_IBV_RECIP_CONN, &cm_data,
@@ -420,6 +432,7 @@ fi_ibv_eq_xrc_recip_conn_event(struct fi_ibv_eq *eq,
 		ep->peer_srqn = xrc_info.conn_data;
 		fi_ibv_ep_ini_conn_done(ep, xrc_info.conn_data,
 					xrc_info.conn_param.qp_num);
+		fi_ibv_eq_xrc_establish(cma_event);
 	} else {
 		fi_ibv_ep_tgt_conn_done(ep);
 	}
@@ -601,21 +614,18 @@ fi_ibv_eq_xrc_disconnect_event(struct fi_ibv_eq *eq,
 static ssize_t
 fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 	struct rdma_cm_event *cma_event, uint32_t *event,
-	struct fi_eq_cm_entry *entry, size_t len, int *acked)
+	struct fi_eq_cm_entry *entry, size_t len)
 {
 	const struct fi_ibv_cm_data_hdr *cm_hdr;
 	size_t datalen = 0;
 	size_t priv_datalen = cma_event->param.conn.private_data_len;
 	const void *priv_data = cma_event->param.conn.private_data;
-	int ret;
+	int ret, acked = 0;;
 	fid_t fid = cma_event->id->context;
 	struct fi_ibv_pep *pep =
 		container_of(fid, struct fi_ibv_pep, pep_fid);
 	struct fi_ibv_ep *ep;
 	struct fi_ibv_xrc_ep *xrc_ep;
-	struct fi_ibv_domain *domain;
-
-	*acked = 0;
 
 	switch (cma_event->event) {
 	case RDMA_CM_EVENT_ROUTE_RESOLVED:
@@ -628,14 +638,12 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 			if (fi_ibv_is_xrc(ep->info)) {
 				xrc_ep = container_of(fid, struct fi_ibv_xrc_ep,
 						      base_ep.util_ep.ep_fid);
-				domain = fi_ibv_ep_to_domain(ep);
-				fastlock_acquire(&domain->xrc.ini_mgmt_lock);
 				fi_ibv_put_shared_ini_conn(xrc_ep);
-				fastlock_release(&domain->xrc.ini_mgmt_lock);
 			}
-			return ret;
+		} else {
+			ret = -FI_EAGAIN;
 		}
-		return -FI_EAGAIN;
+		goto ack;
 	case RDMA_CM_EVENT_CONNECT_REQUEST:
 		*event = FI_CONNREQ;
 
@@ -643,7 +651,6 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 		if (ret) {
 			VERBS_WARN(FI_LOG_EP_CTRL,
 				   "CM getinfo error %d\n", ret);
-			fastlock_acquire(&eq->lock);
 			rdma_destroy_id(cma_event->id);
 			eq->err.err = -ret;
 			eq->err.prov_errno = ret;
@@ -654,9 +661,10 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 			ret = fi_ibv_eq_xrc_connreq_event(eq, entry, &priv_data,
 							  &priv_datalen);
 			if (ret == -FI_EAGAIN)
-				return ret;
+				goto ack;
 		}
 		break;
+	case RDMA_CM_EVENT_CONNECT_RESPONSE:
 	case RDMA_CM_EVENT_ESTABLISHED:
 		*event = FI_CONNECTED;
 
@@ -665,50 +673,42 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 		    IBV_TRANSPORT_IWARP) {
 			ret = fi_ibv_set_rnr_timer(cma_event->id->qp);
 			if (ret)
-				return ret;
+				goto ack;
 		}
 		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
 		if (fi_ibv_is_xrc(ep->info)) {
-			fastlock_acquire(&eq->lock);
 			ret = fi_ibv_eq_xrc_connected_event(eq, cma_event,
 							    entry, len);
-			fastlock_release(&eq->lock);
-			return ret;
+			goto ack;
 		}
 		entry->info = NULL;
 		break;
 	case RDMA_CM_EVENT_DISCONNECTED:
 		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
 		if (fi_ibv_is_xrc(ep->info)) {
-			fastlock_acquire(&eq->lock);
-			fi_ibv_eq_xrc_disconnect_event(eq, cma_event, acked);
-			fastlock_release(&eq->lock);
-			return -FI_EAGAIN;
+			fi_ibv_eq_xrc_disconnect_event(eq, cma_event, &acked);
+			ret = -FI_EAGAIN;
+			goto ack;
 		}
 		*event = FI_SHUTDOWN;
 		entry->info = NULL;
 		break;
 	case RDMA_CM_EVENT_TIMEWAIT_EXIT:
 		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
-		if (fi_ibv_is_xrc(ep->info)) {
-			fastlock_acquire(&eq->lock);
-			fi_ibv_eq_xrc_timewait_event(eq, cma_event, acked);
-			fastlock_release(&eq->lock);
-		}
-		return -FI_EAGAIN;
+		if (fi_ibv_is_xrc(ep->info))
+			fi_ibv_eq_xrc_timewait_event(eq, cma_event, &acked);
+		ret = -FI_EAGAIN;
+		goto ack;
 	case RDMA_CM_EVENT_ADDR_ERROR:
 	case RDMA_CM_EVENT_ROUTE_ERROR:
 	case RDMA_CM_EVENT_CONNECT_ERROR:
 	case RDMA_CM_EVENT_UNREACHABLE:
-		fastlock_acquire(&eq->lock);
 		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
 		assert(ep->info);
 		if (fi_ibv_is_xrc(ep->info)) {
 			ret = fi_ibv_eq_xrc_cm_err_event(eq, cma_event);
-			if (ret == -FI_EAGAIN) {
-				fastlock_release(&eq->lock);
-				return ret;
-			}
+			if (ret == -FI_EAGAIN)
+				goto ack;
 		}
 		eq->err.err = ETIMEDOUT;
 		eq->err.prov_errno = -cma_event->status;
@@ -721,14 +721,11 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 	case RDMA_CM_EVENT_REJECTED:
 		ep = container_of(fid, struct fi_ibv_ep, util_ep.ep_fid);
 		if (fi_ibv_is_xrc(ep->info)) {
-			fastlock_acquire(&eq->lock);
 			ret = fi_ibv_eq_xrc_rej_event(eq, cma_event);
-			fastlock_release(&eq->lock);
 			if (ret == -FI_EAGAIN)
-				return ret;
+				goto ack;
 			fi_ibv_eq_skip_xrc_cm_data(&priv_data, &priv_datalen);
 		}
-		fastlock_acquire(&eq->lock);
 		eq->err.err = ECONNREFUSED;
 		eq->err.prov_errno = -cma_event->status;
 		if (eq->err.err_data) {
@@ -746,15 +743,16 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 		}
 		goto err;
 	case RDMA_CM_EVENT_DEVICE_REMOVAL:
-		fastlock_acquire(&eq->lock);
 		eq->err.err = ENODEV;
 		goto err;
 	case RDMA_CM_EVENT_ADDR_CHANGE:
-		fastlock_acquire(&eq->lock);
 		eq->err.err = EADDRNOTAVAIL;
 		goto err;
 	default:
-		return 0;
+		VERBS_WARN(FI_LOG_EP_CTRL, "unknown rdmacm event received: %d\n",
+			   cma_event->event);
+		ret = -FI_EAGAIN;
+		goto ack;
 	}
 
 	entry->fid = fid;
@@ -763,11 +761,16 @@ fi_ibv_eq_cm_process_event(struct fi_ibv_eq *eq,
 	if (priv_datalen)
 		datalen = fi_ibv_eq_copy_event_data(entry, len, priv_data,
 						    priv_datalen);
+	if (!acked)
+		rdma_ack_cm_event(cma_event);
 	return sizeof(*entry) + datalen;
 err:
+	ret = -FI_EAVAIL;
 	eq->err.fid = fid;
-	fastlock_release(&eq->lock);
-	return -FI_EAVAIL;
+ack:
+	if (!acked)
+		rdma_ack_cm_event(cma_event);
+	return ret;
 }
 
 int fi_ibv_eq_trywait(struct fi_ibv_eq *eq)
@@ -779,6 +782,30 @@ int fi_ibv_eq_trywait(struct fi_ibv_eq *eq)
 	return ret ? 0 : -FI_EAGAIN;
 }
 
+int fi_ibv_eq_match_event(struct dlist_entry *item, const void *arg)
+{
+	struct fi_ibv_eq_entry *entry =
+		container_of(item, struct fi_ibv_eq_entry, item);
+	const struct fid *fid = arg;
+	return entry->eq_entry->fid == fid;
+}
+
+/* Caller must hold eq->lock */
+void fi_ibv_eq_remove_events(struct fi_ibv_eq *eq, struct fid *fid)
+{
+	struct dlist_entry *item;
+	struct fi_ibv_eq_entry *entry;
+
+	while ((item =
+		dlistfd_remove_first_match(&eq->list_head,
+					   fi_ibv_eq_match_event, fid))) {
+		entry = container_of(item, struct fi_ibv_eq_entry, item);
+		if (entry->event == FI_CONNREQ)
+			fi_freeinfo(entry->cm_entry->info);
+		free(entry);
+	}
+}
+
 ssize_t fi_ibv_eq_write_event(struct fi_ibv_eq *eq, uint32_t event,
 			      const void *buf, size_t len)
 {
@@ -792,7 +819,7 @@ ssize_t fi_ibv_eq_write_event(struct fi_ibv_eq *eq, uint32_t event,
 
 	entry->event = event;
 	entry->len = len;
-	memcpy(entry->eq_entry, buf, len);
+	memcpy(entry->entry, buf, len);
 
 	fastlock_acquire(&eq->lock);
 	dlistfd_insert_tail(&entry->item, &eq->list_head);
@@ -837,7 +864,7 @@ static size_t fi_ibv_eq_read_event(struct fi_ibv_eq *eq, uint32_t *event,
 
 	ret = entry->len;
 	*event = entry->event;
-	memcpy(buf, entry->eq_entry, entry->len);
+	memcpy(buf, entry->entry, entry->len);
 
 	if (!(flags & FI_PEEK)) {
 		dlistfd_remove(eq->list_head.list.next, &eq->list_head);
@@ -856,7 +883,9 @@ fi_ibv_eq_read(struct fid_eq *eq_fid, uint32_t *event,
 	struct fi_ibv_eq *eq;
 	struct rdma_cm_event *cma_event;
 	ssize_t ret = 0;
-	int acked;
+
+	if (len < sizeof(struct fi_eq_cm_entry))
+		return -FI_ETOOSMALL;
 
 	eq = container_of(eq_fid, struct fi_ibv_eq, eq_fid.fid);
 
@@ -864,29 +893,25 @@ fi_ibv_eq_read(struct fid_eq *eq_fid, uint32_t *event,
 		return ret;
 
 	if (eq->channel) {
+next_event:
 		fastlock_acquire(&eq->lock);
 		ret = rdma_get_cm_event(eq->channel, &cma_event);
-		fastlock_release(&eq->lock);
-
-		if (ret)
+		if (ret) {
+			fastlock_release(&eq->lock);
 			return -errno;
-
-		acked = 0;
-		if (len < sizeof(struct fi_eq_cm_entry)) {
-			ret = -FI_ETOOSMALL;
-			goto ack;
 		}
 
 		ret = fi_ibv_eq_cm_process_event(eq, cma_event, event,
-				(struct fi_eq_cm_entry *)buf, len, &acked);
-		if (ret < 0)
-			goto ack;
+						 (struct fi_eq_cm_entry *)buf,
+						 len);
+		fastlock_release(&eq->lock);
+		/* If the CM event was handled internally (e.g. XRC), continue
+		 * to process events. */
+		if (ret == -FI_EAGAIN)
+			goto next_event;
 
 		if (flags & FI_PEEK)
 			ret = fi_ibv_eq_write_event(eq, *event, buf, ret);
-ack:
-		if (!acked)
-			rdma_ack_cm_event(cma_event);
 
 		return ret;
 	}
diff --git a/prov/verbs/src/verbs_info.c b/prov/verbs/src/verbs_info.c
index 8c283d9..04c2576 100644
--- a/prov/verbs/src/verbs_info.c
+++ b/prov/verbs/src/verbs_info.c
@@ -153,6 +153,9 @@ const struct verbs_ep_domain verbs_dgram_domain = {
 	.caps			= VERBS_DGRAM_CAPS,
 };
 
+/* The list (not thread safe) is populated once when the provider is initialized */
+DEFINE_LIST(verbs_devs);
+
 int fi_ibv_check_ep_attr(const struct fi_info *hints,
 			 const struct fi_info *info)
 {
@@ -577,6 +580,9 @@ static int fi_ibv_get_device_attrs(struct ibv_context *ctx,
 	size_t max_sup_size;
 	int ret = 0, mtu_size;
 	uint8_t port_num;
+	enum fi_log_level level =
+		fi_ibv_gl_data.msg.prefer_xrc ? FI_LOG_WARN : FI_LOG_INFO;
+	const char *dev_name = ibv_get_device_name(ctx->device);
 
 	ret = ibv_query_device(ctx, &device_attr);
 	if (ret) {
@@ -587,7 +593,9 @@ static int fi_ibv_get_device_attrs(struct ibv_context *ctx,
 
 	if (protocol == FI_PROTO_RDMA_CM_IB_XRC) {
 		if (!(device_attr.device_cap_flags & IBV_DEVICE_XRC)) {
-			VERBS_WARN(FI_LOG_FABRIC, "XRC not supported\n");
+			FI_LOG(&fi_ibv_prov, level, FI_LOG_FABRIC,
+			       "XRC support unavailable in device: %s\n",
+			       dev_name);
 			return -FI_EINVAL;
 		}
 	}
@@ -637,21 +645,20 @@ static int fi_ibv_get_device_attrs(struct ibv_context *ctx,
 	}
 
 	if (port_num == device_attr.phys_port_cnt + 1) {
-		VERBS_INFO(FI_LOG_FABRIC, "There are no active ports\n");
+		FI_WARN(&fi_ibv_prov, FI_LOG_FABRIC, "device %s: there are no "
+			"active ports\n", dev_name);
 		return -FI_ENODATA;
 	} else {
-		VERBS_INFO(FI_LOG_FABRIC,
-			   "The first found active port is %"PRIu8"\n",
-			   port_num);
+		VERBS_INFO(FI_LOG_FABRIC, "device %s: first found active port "
+			   "is %"PRIu8"\n", dev_name, port_num);
 	}
 
 	if (info->ep_attr->type == FI_EP_DGRAM) {
 		ret = fi_ibv_mtu_type_to_len(port_attr.active_mtu);
 		if (ret < 0) {
-			VERBS_WARN(FI_LOG_FABRIC, "Device %s (port: %d) reports"
+			VERBS_WARN(FI_LOG_FABRIC, "device %s (port: %d) reports"
 				   " an unrecognized MTU (%d) \n",
-				   ibv_get_device_name(ctx->device), port_num,
-				   port_attr.active_mtu);
+				   dev_name, port_num, port_attr.active_mtu);
 			return ret;
 		}
 		max_sup_size = MIN(ret, port_attr.max_msg_sz);
@@ -749,6 +756,7 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 	struct fi_info *fi;
 	union ibv_gid gid;
 	size_t name_len;
+	const char *dev_name = ibv_get_device_name(ctx->device);
 	int ret;
 
 	if ((ctx->device->transport_type != IBV_TRANSPORT_IB) &&
@@ -794,7 +802,7 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 		goto err;
 	}
 
-	fi->nic->device_attr->name = strdup(ibv_get_device_name(ctx->device));
+	fi->nic->device_attr->name = strdup(dev_name);
 	if (!fi->nic->device_attr->name) {
 		ret = -FI_ENOMEM;
 		goto err;
@@ -857,7 +865,7 @@ static int fi_ibv_alloc_info(struct ibv_context *ctx, struct fi_info **info,
 		goto err;
 	}
 
-	name_len = strlen(ibv_get_device_name(ctx->device)) + strlen(ep_dom->suffix);
+	name_len = strlen(dev_name) + strlen(ep_dom->suffix);
 	fi->domain_attr->name = calloc(1, name_len + 2);
 	if (!fi->domain_attr->name) {
 		ret = -FI_ENOMEM;
@@ -875,36 +883,44 @@ err:
 	return ret;
 }
 
-static void fi_ibv_verbs_devs_free(struct dlist_entry *verbs_devs)
+static void verbs_devs_print(void)
 {
 	struct verbs_dev_info *dev;
 	struct verbs_addr *addr;
-
-	while (!dlist_empty(verbs_devs)) {
-		dlist_pop_front(verbs_devs, struct verbs_dev_info, dev, entry);
-		while (!dlist_empty(&dev->addrs)) {
-			dlist_pop_front(&dev->addrs, struct verbs_addr, addr, entry);
-			rdma_freeaddrinfo(addr->rai);
-			free(addr);
+	char addr_str[INET6_ADDRSTRLEN];
+	int i = 0;
+
+	FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+		"list of verbs devices found for FI_EP_MSG:\n");
+	dlist_foreach_container(&verbs_devs, struct verbs_dev_info,
+				dev, entry) {
+		FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+			"#%d %s - IPoIB addresses:\n", ++i, dev->name);
+		dlist_foreach_container(&dev->addrs, struct verbs_addr,
+					addr, entry) {
+			if (!inet_ntop(addr->rai->ai_family,
+				       ofi_get_ipaddr(addr->rai->ai_src_addr),
+				       addr_str, INET6_ADDRSTRLEN))
+				FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+					"unable to convert address to string\n");
+			else
+				FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+					"\t%s\n", addr_str);
 		}
-		free(dev->name);
-		free(dev);
 	}
 }
 
-static int fi_ibv_add_rai(struct dlist_entry *verbs_devs, struct rdma_cm_id *id,
-		struct rdma_addrinfo *rai)
+static int verbs_devs_add(struct dlist_entry *verbs_devs, char *dev_name,
+			  struct rdma_addrinfo *rai)
 {
 	struct verbs_dev_info *dev;
 	struct verbs_addr *addr;
-	const char *dev_name;
 
 	if (!(addr = malloc(sizeof(*addr))))
 		return -FI_ENOMEM;
 
 	addr->rai = rai;
 
-	dev_name = ibv_get_device_name(id->verbs->device);
 	dlist_foreach_container(verbs_devs, struct verbs_dev_info, dev, entry)
 		if (!strcmp(dev_name, dev->name))
 			goto add_rai;
@@ -912,29 +928,91 @@ static int fi_ibv_add_rai(struct dlist_entry *verbs_devs, struct rdma_cm_id *id,
 	if (!(dev = malloc(sizeof(*dev))))
 		goto err1;
 
-	if (!(dev->name = strdup(dev_name)))
-		goto err2;
-
+	dev->name = dev_name;
 	dlist_init(&dev->addrs);
 	dlist_insert_tail(&dev->entry, verbs_devs);
 add_rai:
 	dlist_insert_tail(&addr->entry, &dev->addrs);
 	return 0;
-err2:
-	free(dev);
 err1:
 	free(addr);
 	return -FI_ENOMEM;
 }
 
+#define IPV6_LINK_LOCAL_ADDR_PREFIX_STR "fe80"
+
+static int fi_ibv_ifa_rdma_info(const struct ifaddrs *ifa, char **dev_name,
+				struct rdma_addrinfo **rai)
+{
+	char name[INET6_ADDRSTRLEN];
+	struct rdma_addrinfo rai_hints = {
+		.ai_flags = RAI_PASSIVE | RAI_NUMERICHOST,
+	}, *rai_;
+	struct rdma_cm_id *id;
+	int ret;
+
+	if (!inet_ntop(ifa->ifa_addr->sa_family, ofi_get_ipaddr(ifa->ifa_addr),
+		       name, INET6_ADDRSTRLEN))
+		return -errno;
+
+	ret = rdma_create_id(NULL, &id, NULL, RDMA_PS_TCP);
+	if (ret)
+		return ret;
+
+	/* Detect if the IPv6 address is link local.
+	 * TODO should we do something similar for IPv4? */
+	if (!strncmp(name, IPV6_LINK_LOCAL_ADDR_PREFIX_STR,
+		     strlen(IPV6_LINK_LOCAL_ADDR_PREFIX_STR))) {
+		assert(strlen(name) + strlen(ifa->ifa_name) < INET6_ADDRSTRLEN);
+		strcat(name, "%");
+		strcat(name, ifa->ifa_name);
+	}
+
+	ret = rdma_getaddrinfo((char *) name, NULL, &rai_hints, &rai_);
+	if (ret) {
+		ret = -errno;
+		FI_DBG(&fi_ibv_prov, FI_LOG_FABRIC, "rdma_getaddrinfo failed "
+		       "with error code: %d (%s) for interface %s with address:"
+		       " %s\n", -ret, strerror(-ret), ifa->ifa_name, name);
+		goto err1;
+	}
+
+	ret = rdma_bind_addr(id, rai_->ai_src_addr);
+	if (ret) {
+		ret = -errno;
+		FI_DBG(&fi_ibv_prov, FI_LOG_FABRIC, "rdma_bind_addr failed "
+		       "with error code: %d (%s) for interface %s with address:"
+		       " %s\n", -ret, strerror(-ret), ifa->ifa_name, name);
+		goto err2;
+	}
+
+	if (!id->verbs) {
+		ret = -FI_EINVAL;
+		goto err2;
+	}
+
+	*dev_name = strdup(ibv_get_device_name(id->verbs->device));
+	if (!(*dev_name)) {
+		ret = -FI_ENOMEM;
+		goto err2;
+	}
+
+	rdma_destroy_id(id);
+	*rai = rai_;
+	return 0;
+err2:
+	rdma_freeaddrinfo(rai_);
+err1:
+	rdma_destroy_id(id);
+	return ret;
+}
+
 /* Builds a list of interfaces that correspond to active verbs devices */
 static int fi_ibv_getifaddrs(struct dlist_entry *verbs_devs)
 {
 	struct ifaddrs *ifaddr, *ifa;
-	char name[INET6_ADDRSTRLEN];
-	struct rdma_addrinfo *rai;
-	struct rdma_cm_id *id;
-	const char *ret_ptr;
+	struct rdma_addrinfo *rai = NULL;
+	char *dev_name = NULL;
 	char *iface = fi_ibv_gl_data.iface;
 	int ret, num_verbs_ifs = 0;
 	size_t iface_len = 0;
@@ -943,7 +1021,7 @@ static int fi_ibv_getifaddrs(struct dlist_entry *verbs_devs)
 	ret = ofi_getifaddrs(&ifaddr);
 	if (ret) {
 		VERBS_WARN(FI_LOG_FABRIC,
-			   "Unable to get interface addresses\n");
+			   "unable to get interface addresses\n");
 		return ret;
 	}
 
@@ -951,9 +1029,8 @@ static int fi_ibv_getifaddrs(struct dlist_entry *verbs_devs)
 	if (iface) {
 		iface_len = strlen(iface);
 		if (iface_len > IFNAMSIZ) {
-			VERBS_INFO(FI_LOG_EP_CTRL,
-				   "Too long iface name: %s, max: %d\n",
-				   iface, IFNAMSIZ);
+			VERBS_INFO(FI_LOG_FABRIC, "iface name: %s, too long "
+				   "max: %d\n", iface, IFNAMSIZ);
 
 		}
 		for (ifa = ifaddr; ifa && !exact_match; ifa = ifa->ifa_next)
@@ -967,144 +1044,93 @@ static int fi_ibv_getifaddrs(struct dlist_entry *verbs_devs)
 
 		if (iface) {
 			if (exact_match) {
-				if (strcmp(ifa->ifa_name, iface))
+				if (strcmp(ifa->ifa_name, iface)) {
+					FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+						"skipping interface: %s for FI_EP_MSG"
+						" as it doesn't match filter: %s\n",
+						ifa->ifa_name, iface);
 					continue;
+				}
 			} else {
-				if (strncmp(ifa->ifa_name, iface, iface_len))
+				if (strncmp(ifa->ifa_name, iface, iface_len)) {
+					FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+						"skipping interface: %s for FI_EP_MSG"
+						" as it doesn't match filter: %s\n",
+						ifa->ifa_name, iface);
 					continue;
+				}
 			}
 		}
 
-		switch (ifa->ifa_addr->sa_family) {
-		case AF_INET:
-			ret_ptr = inet_ntop(AF_INET, &ofi_sin_addr(ifa->ifa_addr),
-				name, INET6_ADDRSTRLEN);
-			break;
-		case AF_INET6:
-			ret_ptr = inet_ntop(AF_INET6, &ofi_sin6_addr(ifa->ifa_addr),
-				name, INET6_ADDRSTRLEN);
-			break;
-		default:
-			continue;
-		}
-		if (!ret_ptr) {
-			VERBS_WARN(FI_LOG_FABRIC,
-				   "inet_ntop failed: %s(%d)\n",
-				   strerror(errno), errno);
-			ret = -errno;
-			goto err1;
-		}
-
-		ret = fi_ibv_get_rai_id(name, NULL, FI_NUMERICHOST | FI_SOURCE,
-					NULL, &rai, &id);
+		ret = fi_ibv_ifa_rdma_info(ifa, &dev_name, &rai);
 		if (ret)
 			continue;
 
-		ret = fi_ibv_add_rai(verbs_devs, id, rai);
+		ret = verbs_devs_add(verbs_devs, dev_name, rai);
 		if (ret) {
+			free(dev_name);
 			rdma_freeaddrinfo(rai);
-			rdma_destroy_id(id);
-			goto err1;
+			continue;
 		}
-		VERBS_DBG(FI_LOG_FABRIC, "Found active interface for verbs device: "
-			  "%s with address: %s\n",
-			  ibv_get_device_name(id->verbs->device), name);
-		rdma_destroy_id(id);
 		num_verbs_ifs++;
 	}
+
+	verbs_devs_print();
+
 	freeifaddrs(ifaddr);
 	return num_verbs_ifs ? 0 : -FI_ENODATA;
-err1:
-	fi_ibv_verbs_devs_free(verbs_devs);
-	freeifaddrs(ifaddr);
-	return ret;
 }
 
-static int fi_ibv_get_srcaddr_devs(struct fi_info **info)
+static int
+fi_ibv_info_add_dev_addr(struct fi_info **info, struct verbs_dev_info *dev)
 {
-	struct fi_info *fi, *add_info;
-	struct fi_info *fi_unconf = NULL, *fi_prev = NULL;
-	struct verbs_dev_info *dev;
+	struct fi_info *add_info;
 	struct verbs_addr *addr;
-	int ret = 0;
-
-	DEFINE_LIST(verbs_devs);
+	int ret;
 
-	ret = fi_ibv_getifaddrs(&verbs_devs);
-	if (ret)
-		return ret;
+	dlist_foreach_container(&dev->addrs, struct verbs_addr, addr, entry) {
+		/* When a device has multiple interfaces/addresses configured
+		 * duplicate fi_info and add the address info. fi->src_addr
+		 * would have been set in the previous iteration */
+		if ((*info)->src_addr) {
+			if (!(add_info = fi_dupinfo(*info)))
+				return -FI_ENOMEM;
+
+			add_info->next = (*info)->next;
+			(*info)->next = add_info;
+			*info = add_info;
+		}
 
-	if (dlist_empty(&verbs_devs)) {
-		VERBS_WARN(FI_LOG_CORE, "No interface address found\n");
-		return 0;
+		ret = fi_ibv_rai_to_fi(addr->rai, *info);
+		if (ret)
+			return ret;
 	}
+	return 0;
+}
+
+static int fi_ibv_get_srcaddr_devs(struct fi_info **info)
+{
+	struct verbs_dev_info *dev;
+	struct fi_info *fi;
+	int ret;
 
 	for (fi = *info; fi; fi = fi->next) {
 		if (fi->ep_attr->type == FI_EP_DGRAM)
 			continue;
-		dlist_foreach_container(&verbs_devs, struct verbs_dev_info, dev, entry)
-			if (!strncmp(fi->domain_attr->name, dev->name, strlen(dev->name))) {
-				dlist_foreach_container(&dev->addrs, struct verbs_addr, addr, entry) {
-					/* When a device has multiple interfaces/addresses configured
-					 * duplicate fi_info and add the address info. fi->src_addr
-					 * would have been set in the previous iteration */
-					if (fi->src_addr) {
-						if (!(add_info = fi_dupinfo(fi))) {
-							ret = -FI_ENOMEM;
-							goto out;
-						}
-
-						add_info->next = fi->next;
-						fi->next = add_info;
-						fi = add_info;
-					}
-
-					ret = fi_ibv_rai_to_fi(addr->rai, fi);
-					if (ret)
-						goto out;
-				}
+		dlist_foreach_container(&verbs_devs, struct verbs_dev_info,
+					dev, entry) {
+			/* strncmp because we want to process XRC fi_info as
+			 * well which have a "-xrc" suffix in domain name */
+			if (!strncmp(fi->domain_attr->name, dev->name,
+				     strlen(dev->name))) {
+				ret = fi_ibv_info_add_dev_addr(&fi, dev);
+				if (ret)
+					return ret;
 				break;
 			}
-	}
-
-        /* re-order info: move info without src_addr to tail */
-	for (fi = *info; fi;) {
-		if (!fi->src_addr) {
-			/* re-link list - exclude current element */
-			if (fi == *info) {
-				*info = fi->next;
-				fi->next = fi_unconf;
-				fi_unconf = fi;
-				fi = *info;
-			} else {
-				assert(fi_prev);
-				fi_prev->next = fi->next;
-				fi->next = fi_unconf;
-				fi_unconf = fi;
-				fi = fi_prev->next;
-			}
-		} else {
-			fi_prev = fi;
-			fi = fi->next;
 		}
 	}
-
-	/* append excluded elements to tail of list */
-	if (fi_unconf) {
-		if (fi_prev) {
-			assert(!fi_prev->next);
-			fi_prev->next = fi_unconf;
-		} else if (*info) {
-			assert(!(*info)->next);
-			(*info)->next = fi_unconf;
-		} else /* !(*info) */ {
-			(*info) = fi_unconf;
-		}
-	}
-
-out:
-	fi_ibv_verbs_devs_free(&verbs_devs);
-	return ret;
+	return 0;
 }
 
 static void fi_ibv_sockaddr_set_port(struct sockaddr *sa, uint16_t port)
@@ -1199,6 +1225,17 @@ rai_to_fi:
 				     NULL, NULL);
 }
 
+static int fi_ibv_device_has_ipoib_addr(const char *dev_name)
+{
+	struct verbs_dev_info *dev;
+
+	dlist_foreach_container(&verbs_devs, struct verbs_dev_info, dev, entry) {
+		if (!strcmp(dev_name, dev->name))
+			return 1;
+	}
+	return 0;
+}
+
 #define VERBS_NUM_DOMAIN_TYPES		3
 
 int fi_ibv_init_info(const struct fi_info **all_infos)
@@ -1206,26 +1243,40 @@ int fi_ibv_init_info(const struct fi_info **all_infos)
 	struct ibv_context **ctx_list;
 	struct fi_info *fi = NULL, *tail = NULL;
 	const struct verbs_ep_domain *ep_type[VERBS_NUM_DOMAIN_TYPES];
-	int ret = 0, i, j, num_devices;
+	int ret = 0, i, j, num_devices, dom_count = 0;
 
 	*all_infos = NULL;
 
-	/* List XRC MSG_EP domain before default RC MSG_EP if requested */
-	if (fi_ibv_gl_data.msg.prefer_xrc) {
-		ep_type[0] = &verbs_msg_xrc_domain;
-		ep_type[1] = &verbs_msg_domain;
-	} else {
-		ep_type[0] = &verbs_msg_domain;
-		ep_type[1] = &verbs_msg_xrc_domain;
-	}
-	ep_type[2] = &verbs_dgram_domain;
-
 	if (!fi_ibv_have_device()) {
-		VERBS_INFO(FI_LOG_FABRIC, "No RDMA devices found\n");
+		VERBS_INFO(FI_LOG_FABRIC, "no RDMA devices found\n");
 		ret = -FI_ENODATA;
 		goto done;
 	}
 
+	/* List XRC MSG_EP domain before default RC MSG_EP if requested */
+	if (fi_ibv_gl_data.msg.prefer_xrc) {
+		if (VERBS_HAVE_XRC)
+			ep_type[dom_count++] = &verbs_msg_xrc_domain;
+		else
+			FI_WARN(&fi_ibv_prov, FI_LOG_FABRIC,
+				"XRC not built into provider, skip allocating "
+				"fi_info for XRC FI_EP_MSG endpoints\n");
+	}
+
+	fi_ibv_getifaddrs(&verbs_devs);
+
+	if (dlist_empty(&verbs_devs))
+		FI_WARN(&fi_ibv_prov, FI_LOG_FABRIC,
+			"no valid IPoIB interfaces found, FI_EP_MSG endpoint "
+			"type would not be available\n");
+	else
+		ep_type[dom_count++] = &verbs_msg_domain;
+
+	if (!fi_ibv_gl_data.msg.prefer_xrc && VERBS_HAVE_XRC)
+		ep_type[dom_count++] = &verbs_msg_xrc_domain;
+
+	ep_type[dom_count++] = &verbs_dgram_domain;
+
 	ctx_list = rdma_get_devices(&num_devices);
 	if (!num_devices) {
 		VERBS_INFO_ERRNO(FI_LOG_FABRIC, "rdma_get_devices", errno);
@@ -1234,7 +1285,18 @@ int fi_ibv_init_info(const struct fi_info **all_infos)
 	}
 
 	for (i = 0; i < num_devices; i++) {
-		for (j = 0; j < VERBS_NUM_DOMAIN_TYPES; j++) {
+		for (j = 0; j < dom_count; j++) {
+			if (ep_type[j]->type == FI_EP_MSG &&
+			    !fi_ibv_device_has_ipoib_addr(ctx_list[i]->device->name)) {
+				FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+					"skipping device: %s for FI_EP_MSG, "
+					"it may have a filtered IPoIB interface"
+					" (FI_VERBS_IFACE) or it may not have a"
+					" valid IP address configured\n",
+					ctx_list[i]->device->name);
+				continue;
+			}
+
 			ret = fi_ibv_alloc_info(ctx_list[i], &fi, ep_type[j]);
 			if (!ret) {
 				if (!*all_infos)
@@ -1254,58 +1316,33 @@ done:
 	return ret;
 }
 
-static int fi_ibv_set_default_attr(struct fi_info *info, size_t *attr,
-				   size_t default_attr, char *attr_str)
+static void fi_ibv_set_default_attr(size_t *attr, size_t default_attr)
 {
-	if (default_attr > *attr) {
-		VERBS_INFO(FI_LOG_FABRIC, "Ignoring provider default value "
-			   "for %s as it is greater than the value supported "
-			   "by domain: %s\n", attr_str, info->domain_attr->name);
-	} else {
+	if (default_attr <= *attr)
 		*attr = default_attr;
-	}
-	return 0;
 }
 
 /* Set default values for attributes. ofi_alter_info would change them if the
  * user has asked for a different value in hints */
-static int fi_ibv_set_default_info(struct fi_info *info)
+static void fi_ibv_set_default_info(struct fi_info *info)
 {
-	int ret;
+	fi_ibv_set_default_attr(&info->tx_attr->size,
+				fi_ibv_gl_data.def_tx_size);
 
-	ret = fi_ibv_set_default_attr(info, &info->tx_attr->size,
-				      fi_ibv_gl_data.def_tx_size,
-				      "tx context size");
-	if (ret)
-		return ret;
+	fi_ibv_set_default_attr(&info->rx_attr->size,
+				fi_ibv_gl_data.def_rx_size);
 
-	ret = fi_ibv_set_default_attr(info, &info->rx_attr->size,
-				      fi_ibv_gl_data.def_rx_size,
-				      "rx context size");
-	if (ret)
-		return ret;
-	ret = fi_ibv_set_default_attr(info, &info->tx_attr->iov_limit,
-				      fi_ibv_gl_data.def_tx_iov_limit,
-				      "tx iov_limit");
-	if (ret)
-		return ret;
-
-	ret = fi_ibv_set_default_attr(info, &info->rx_attr->iov_limit,
-				      fi_ibv_gl_data.def_rx_iov_limit,
-				      "rx iov_limit");
-	if (ret)
-		return ret;
+	fi_ibv_set_default_attr(&info->tx_attr->iov_limit,
+				fi_ibv_gl_data.def_tx_iov_limit);
+	fi_ibv_set_default_attr(&info->rx_attr->iov_limit,
+				fi_ibv_gl_data.def_rx_iov_limit);
 
 	if (info->ep_attr->type == FI_EP_MSG) {
 		/* For verbs iov limit is same for
 		 * both regular messages and RMA */
-		ret = fi_ibv_set_default_attr(info, &info->tx_attr->rma_iov_limit,
-					      fi_ibv_gl_data.def_tx_iov_limit,
-				"tx rma_iov_limit");
-		if (ret)
-			return ret;
+		fi_ibv_set_default_attr(&info->tx_attr->rma_iov_limit,
+					fi_ibv_gl_data.def_tx_iov_limit);
 	}
-	return 0;
 }
 
 static struct fi_info *fi_ibv_get_passive_info(const struct fi_info *prov_info,
@@ -1337,47 +1374,48 @@ static struct fi_info *fi_ibv_get_passive_info(const struct fi_info *prov_info,
 	return info;
 }
 
-static int fi_ibv_get_matching_info(uint32_t version,
-				    const struct fi_info *hints,
-				    struct fi_info **info,
-				    const struct fi_info *verbs_info,
-				    uint8_t passive)
+int fi_ibv_get_matching_info(uint32_t version, const struct fi_info *hints,
+			     struct fi_info **info, const struct fi_info *verbs_info,
+			     uint8_t passive)
 {
 	const struct fi_info *check_info = verbs_info;
 	struct fi_info *fi, *tail;
-	int ret;
+	int ret, i;
 	uint8_t got_passive_info = 0;
+	enum fi_log_level level =
+		fi_ibv_gl_data.msg.prefer_xrc ? FI_LOG_WARN : FI_LOG_INFO;
 
 	*info = tail = NULL;
 
-	for ( ; check_info; check_info = check_info->next) {
-		VERBS_DBG(FI_LOG_FABRIC, "Checking domain: %s\n",
-			  check_info->domain_attr->name);
-
+	for (i = 1; check_info; check_info = check_info->next, i++) {
 		if (hints) {
-			if ((check_info->ep_attr->protocol ==
-			     FI_PROTO_RDMA_CM_IB_XRC) &&
-			    (!hints->ep_attr ||
-			     (hints->ep_attr->rx_ctx_cnt != FI_SHARED_CONTEXT))) {
-				VERBS_INFO(FI_LOG_FABRIC,
-					   "hints->ep_attr->rx_ctx_cnt != "
-					   "FI_SHARED_CONTEXT. Skipping "
-					   "XRC FI_EP_MSG endpoints\n");
-				continue;
-			}
-			if ((check_info->ep_attr->protocol ==
-			    FI_PROTO_RDMA_CM_IB_XRC) && !VERBS_HAVE_XRC) {
-				VERBS_INFO(FI_LOG_FABRIC,
-					   "XRC not built into provider, "
-					   "skipping XRC FI_EP_MSG "
-					   "endpoints\n");
-				continue;
+			FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+				"checking domain: #%d %s\n",
+				i, check_info->domain_attr->name);
+
+			if (hints->ep_attr) {
+				/* check EP type first to avoid other unnecessary checks */
+				ret = ofi_check_ep_type(
+					&fi_ibv_prov, check_info->ep_attr, hints->ep_attr);
+				if (ret)
+					continue;
 			}
 
 			ret = fi_ibv_check_hints(version, hints,
 						 check_info);
 			if (ret)
 				continue;
+
+			if ((check_info->ep_attr->protocol ==
+			     FI_PROTO_RDMA_CM_IB_XRC) &&
+			    (!hints->ep_attr ||
+			     (hints->ep_attr->rx_ctx_cnt != FI_SHARED_CONTEXT))) {
+				FI_LOG(&fi_ibv_prov, level, FI_LOG_FABRIC,
+				       "hints->ep_attr->rx_ctx_cnt != "
+				       "FI_SHARED_CONTEXT. Skipping "
+				       "XRC FI_EP_MSG endpoints\n");
+				continue;
+			}
 		}
 
 		if ((check_info->ep_attr->type == FI_EP_MSG) && passive) {
@@ -1394,15 +1432,11 @@ static int fi_ibv_get_matching_info(uint32_t version,
 				ret = -FI_ENOMEM;
 				goto err;
 			}
-			ret = fi_ibv_set_default_info(fi);
-			if (ret) {
-				fi_freeinfo(fi);
-				continue;
-			}
+			fi_ibv_set_default_info(fi);
 		}
 
-		VERBS_DBG(FI_LOG_FABRIC, "Adding fi_info for domain: %s\n",
-			  fi->domain_attr->name);
+		FI_INFO(&fi_ibv_prov, FI_LOG_FABRIC,
+			"adding fi_info for domain: %s\n", fi->domain_attr->name);
 		if (!*info)
 			*info = fi;
 		else
@@ -1551,25 +1585,6 @@ fn2:
 	return ret;
 }
 
-static void fi_ibv_remove_nosrc_info(struct fi_info **info)
-{
-	struct fi_info **fi = info, *next;
-	while (*fi && ((*fi)->ep_attr->type == FI_EP_MSG)) {
-		if (!(*fi)->src_addr) {
-			VERBS_INFO(FI_LOG_FABRIC, "Not reporting fi_info "
-				   "corresponding to domain: %s as it has no IP"
-				   "address configured\n",
-				   (*fi)->domain_attr->name);
-			next = (*fi)->next;
-			(*fi)->next = NULL;
-			fi_freeinfo(*fi);
-			*fi = next;
-		} else {
-			fi = &(*fi)->next;
-		}
-	}
-}
-
 static int fi_ibv_handle_sock_addr(const char *node, const char *service,
 				   uint64_t flags, const struct fi_info *hints,
 				   struct fi_info **info)
@@ -1590,7 +1605,6 @@ static int fi_ibv_handle_sock_addr(const char *node, const char *service,
 	}
 
 	ret = fi_ibv_fill_addr(rai, info, id);
-	fi_ibv_remove_nosrc_info(info);
 out:
 	rdma_freeaddrinfo(rai);
 	if (rdma_destroy_id(id))
@@ -1598,30 +1612,13 @@ out:
 	return ret;
 }
 
-static inline int
-fi_ibv_hints_match_dgram_ep(const struct fi_info *hints)
-{
-	return (hints && ((hints->addr_format == FI_ADDR_IB_UD) ||
-			  (hints->ep_attr && (hints->ep_attr->type == FI_EP_DGRAM))));
-}
-
-static inline int
-fi_ibv_hints_match_msg_ep(const struct fi_info *hints)
-{
-	return (hints && ((hints->addr_format == FI_SOCKADDR) ||
-			  (hints->addr_format == FI_SOCKADDR_IN) ||
-			  (hints->addr_format == FI_SOCKADDR_IN6) ||
-			  (hints->addr_format == FI_SOCKADDR_IB) ||
-			  (hints->ep_attr && (hints->ep_attr->type == FI_EP_MSG))));
-}
-
 static int fi_ibv_get_match_infos(uint32_t version, const char *node,
 				  const char *service, uint64_t flags,
 				  const struct fi_info *hints,
 				  const struct fi_info **raw_info,
 				  struct fi_info **info)
 {
-	int ret, ret_sock_addr, ret_ib_ud_addr;
+	int ret, ret_sock_addr = -FI_ENODATA, ret_ib_ud_addr = -FI_ENODATA;
 
 	// TODO check for AF_IB addr
 	ret = fi_ibv_get_matching_info(version, hints, info, *raw_info,
@@ -1630,51 +1627,28 @@ static int fi_ibv_get_match_infos(uint32_t version, const char *node,
 	if (ret)
 		return ret;
 
-	/* Check if the user requested to support DGRAM EP type only */
-	if (fi_ibv_hints_match_dgram_ep(hints)) {
-		/* This is case when only IB UD addresses are passed */
-		ret = fi_ibv_handle_ib_ud_addr(node, service, flags, info);
-		if (ret) {
-			VERBS_INFO(FI_LOG_CORE,
-				   "Handling of the IB UD address fails - %d, "
-				   "support of this was requested thru the passed hints\n",
-				   ret);
-			fi_freeinfo(*info);
-		}
-		return ret;
-	}
-
-	/* Check if the user requested to support MSG EP type only */
-	if (fi_ibv_hints_match_msg_ep(hints)) {
-		ret = fi_ibv_handle_sock_addr(node, service, flags, hints, info);
-		if (ret) {
-			VERBS_INFO(FI_LOG_CORE,
-				   "Handling of the socket address fails - %d, but the "
-				   "support of this was requested thru the passed hints\n",
-				   ret);
-			if (*info)
-				fi_freeinfo(*info);
+	if (!hints || !hints->ep_attr || hints->ep_attr->type == FI_EP_MSG ||
+	    hints->ep_attr->type == FI_EP_UNSPEC) {
+		ret_sock_addr = fi_ibv_handle_sock_addr(node, service, flags, hints, info);
+		if (ret_sock_addr) {
+			VERBS_INFO(FI_LOG_FABRIC,
+				   "handling of the socket address fails - %d\n",
+				   ret_sock_addr);
 		} else {
 			if (!*info)
 				return -FI_ENODATA;
 		}
-		return ret;
 	}
 
-	ret_sock_addr = fi_ibv_handle_sock_addr(node, service, flags, hints, info);
-	if (ret_sock_addr) {
-		VERBS_INFO(FI_LOG_CORE, "Handling of the socket address fails - %d\n",
-			   ret_sock_addr);
-	} else {
-		if (!*info)
-			return -FI_ENODATA;
+	if (!hints || !hints->ep_attr || hints->ep_attr->type == FI_EP_DGRAM ||
+	    hints->ep_attr->type == FI_EP_UNSPEC) {
+		ret_ib_ud_addr = fi_ibv_handle_ib_ud_addr(node, service, flags, info);
+		if (ret_ib_ud_addr)
+			VERBS_INFO(FI_LOG_FABRIC,
+				   "handling of the IB ID address fails - %d\n",
+				   ret_ib_ud_addr);
 	}
 
-	ret_ib_ud_addr = fi_ibv_handle_ib_ud_addr(node, service, flags, info);
-	if (ret_ib_ud_addr)
-		VERBS_INFO(FI_LOG_CORE, "Handling of the IB ID address fails - %d\n",
-			   ret_ib_ud_addr);
-
 	if (ret_sock_addr && ret_ib_ud_addr) {
 		/* neither the sockaddr nor the ib_ud address wasn't
 		 * handled to satisfy the selection procedure */
@@ -1687,7 +1661,7 @@ static int fi_ibv_get_match_infos(uint32_t version, const char *node,
 	return FI_SUCCESS;
 }
 
-static void fi_ibv_alter_info(const struct fi_info *hints, struct fi_info *info)
+void fi_ibv_alter_info(const struct fi_info *hints, struct fi_info *info)
 {
 	struct fi_info *cur;
 
diff --git a/prov/verbs/src/verbs_mr.c b/prov/verbs/src/verbs_mr.c
index 6a88d71..2a1b4a7 100644
--- a/prov/verbs/src/verbs_mr.c
+++ b/prov/verbs/src/verbs_mr.c
@@ -159,7 +159,7 @@ fi_ibv_mr_reg(struct fid *fid, const void *buf, size_t len,
 	struct fi_ibv_mem_desc *md;
 	int ret;
 
-	if (OFI_UNLIKELY(flags))
+	if (OFI_UNLIKELY(flags & ~OFI_MR_NOCACHE))
 		return -FI_EBADFLAGS;
 
 	md = calloc(1, sizeof(*md));
@@ -241,7 +241,7 @@ fi_ibv_mr_cache_reg(struct fid *fid, const void *buf, size_t len,
 	struct iovec iov;
 	int ret;
 
-	if (OFI_UNLIKELY(flags))
+	if (flags & ~OFI_MR_NOCACHE)
 		return -FI_EBADFLAGS;
 
 	domain = container_of(fid, struct fi_ibv_domain,
@@ -257,7 +257,9 @@ fi_ibv_mr_cache_reg(struct fid *fid, const void *buf, size_t len,
 	attr.requested_key = requested_key;
 	attr.auth_key_size = 0;
 
-	ret = ofi_mr_cache_search(&domain->cache, &attr, &entry);
+	ret = (flags & OFI_MR_NOCACHE) ?
+	      ofi_mr_cache_reg(&domain->cache, &attr, &entry) :
+	      ofi_mr_cache_search(&domain->cache, &attr, &entry);
 	if (OFI_UNLIKELY(ret))
 		return ret;
 
diff --git a/src/abi_1_0.c b/src/abi_1_0.c
index c0fdd83..eb3bd0e 100644
--- a/src/abi_1_0.c
+++ b/src/abi_1_0.c
@@ -122,6 +122,81 @@ struct fi_info_1_1 {
 	struct fi_fabric_attr_1_0	*fabric_attr;
 };
 
+struct fi_tx_attr_1_2 {
+        uint64_t                caps;
+        uint64_t                mode;
+        uint64_t                op_flags;
+        uint64_t                msg_order;
+        uint64_t                comp_order;
+        size_t                  inject_size;
+        size_t                  size;
+        size_t                  iov_limit;
+        size_t                  rma_iov_limit;
+};
+
+struct fi_ep_attr_1_2 {
+        enum fi_ep_type         type;
+        uint32_t                protocol;
+        uint32_t                protocol_version;
+        size_t                  max_msg_size;
+        size_t                  msg_prefix_size;
+        size_t                  max_order_raw_size;
+        size_t                  max_order_war_size;
+        size_t                  max_order_waw_size;
+        uint64_t                mem_tag_format;
+        size_t                  tx_ctx_cnt;
+        size_t                  rx_ctx_cnt;
+        size_t                  auth_key_size;
+        uint8_t                 *auth_key;
+};
+
+struct fi_domain_attr_1_2 {
+        struct fid_domain       *domain;
+        char                    *name;
+        enum fi_threading       threading;
+        enum fi_progress        control_progress;
+        enum fi_progress        data_progress;
+        enum fi_resource_mgmt   resource_mgmt;
+        enum fi_av_type         av_type;
+        int                     mr_mode;
+        size_t                  mr_key_size;
+        size_t                  cq_data_size;
+        size_t                  cq_cnt;
+        size_t                  ep_cnt;
+        size_t                  tx_ctx_cnt;
+        size_t                  rx_ctx_cnt;
+        size_t                  max_ep_tx_ctx;
+        size_t                  max_ep_rx_ctx;
+        size_t                  max_ep_stx_ctx;
+        size_t                  max_ep_srx_ctx;
+        size_t                  cntr_cnt;
+        size_t                  mr_iov_limit;
+        uint64_t                caps;
+        uint64_t                mode;
+        uint8_t                 *auth_key;
+        size_t                  auth_key_size;
+        size_t                  max_err_data;
+        size_t                  mr_cnt;
+};
+
+struct fi_info_1_2 {
+        struct fi_info            *next;
+        uint64_t                  caps;
+        uint64_t                  mode;
+        uint32_t                  addr_format;
+        size_t                    src_addrlen;
+        size_t                    dest_addrlen;
+        void                      *src_addr;
+        void                      *dest_addr;
+        fid_t                     handle;
+        struct fi_tx_attr_1_2     *tx_attr;
+        struct fi_rx_attr         *rx_attr;
+        struct fi_ep_attr_1_2     *ep_attr;
+        struct fi_domain_attr_1_2 *domain_attr;
+        struct fi_fabric_attr     *fabric_attr;
+        struct fid_nic            *nic;
+};
+
 #define ofi_dup_attr(dst, src)				\
 	do {						\
 		dst = calloc(1, sizeof(*dst));		\
@@ -316,3 +391,55 @@ int fi_getinfo_1_1(uint32_t version, const char *node, const char *service,
 	return ret;
 }
 COMPAT_SYMVER(fi_getinfo_1_1, fi_getinfo, FABRIC_1.1);
+
+/*
+ * ABI 1.2
+ */
+__attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
+void fi_freeinfo_1_2(struct fi_info_1_2 *info)
+{
+	fi_freeinfo((struct fi_info *) info);
+}
+COMPAT_SYMVER(fi_freeinfo_1_2, fi_freeinfo, FABRIC_1.2);
+
+__attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
+struct fi_info_1_2 *fi_dupinfo_1_2(const struct fi_info_1_2 *info)
+{
+	struct fi_info *dup, *base;
+
+	if (!info)
+		return (struct fi_info_1_2 *) ofi_allocinfo_internal();
+
+	ofi_dup_attr(base, info);
+	if (base == NULL)
+		return NULL;
+
+	dup = fi_dupinfo(base);
+
+	free(base);
+	return (struct fi_info_1_2 *) dup;
+}
+COMPAT_SYMVER(fi_dupinfo_1_2, fi_dupinfo, FABRIC_1.2);
+
+__attribute__((visibility ("default"),EXTERNALLY_VISIBLE))
+int fi_getinfo_1_2(uint32_t version, const char *node, const char *service,
+		   uint64_t flags, const struct fi_info_1_2 *hints_1_2,
+		   struct fi_info_1_2 **info)
+{
+	struct fi_info *hints;
+	int ret;
+
+	if (hints_1_2) {
+		hints = (struct fi_info *) fi_dupinfo_1_2(hints_1_2);
+		if (!hints)
+			return -FI_ENOMEM;
+	} else {
+		hints = NULL;
+	}
+	ret = fi_getinfo(version, node, service, flags, hints,
+			 (struct fi_info **) info);
+	fi_freeinfo(hints);
+
+	return ret;
+}
+COMPAT_SYMVER(fi_getinfo_1_2, fi_getinfo, FABRIC_1.2);
diff --git a/src/common.c b/src/common.c
index 5e83341..ad7ff86 100644
--- a/src/common.c
+++ b/src/common.c
@@ -756,6 +756,8 @@ int ofi_is_wildcard_listen_addr(const char *node, const char *service,
 	/* else it's okay to call getaddrinfo, proceed with processing */
 
 	if (node) {
+		if (!(flags & FI_SOURCE))
+			return 0;
 		ret = getaddrinfo(node, service, NULL, &res);
 		if (ret) {
 			FI_WARN(&core_prov, FI_LOG_CORE,
@@ -1087,7 +1089,7 @@ void ofi_insert_loopback_addr(struct fi_provider *prov, struct slist *addr_list)
 		return;
 
 	addr_entry->ipaddr.sin.sin_family = AF_INET;
-	addr_entry->ipaddr.sin.sin_addr.s_addr = INADDR_LOOPBACK;
+	addr_entry->ipaddr.sin.sin_addr.s_addr = htonl(INADDR_LOOPBACK);
 	ofi_straddr_log(prov, FI_LOG_INFO, FI_LOG_CORE,
 			"available addr: ", &addr_entry->ipaddr);
 
@@ -1246,7 +1248,7 @@ void ofi_get_list_of_addr(struct fi_provider *prov, const char *env_name,
 
 	for (i = 0; i < iptbl->dwNumEntries; i++) {
 		if (iptbl->table[i].dwAddr &&
-		    (iptbl->table[i].dwAddr != ntohl(INADDR_LOOPBACK))) {
+		    (iptbl->table[i].dwAddr != htonl(INADDR_LOOPBACK))) {
 			addr_entry = calloc(1, sizeof(*addr_entry));
 			if (!addr_entry)
 				break;
diff --git a/src/enosys.c b/src/enosys.c
index 62348aa..cc253a0 100644
--- a/src/enosys.c
+++ b/src/enosys.c
@@ -588,3 +588,67 @@ int fi_no_av_remove(struct fid_av *av, fi_addr_t *fi_addr, size_t count,
 {
 	return -FI_ENOSYS;
 }
+
+ssize_t fi_coll_no_barrier(struct fid_ep *ep, fi_addr_t coll_addr, void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_broadcast(struct fid_ep *ep, void *buf, size_t count, void *desc,
+			     fi_addr_t coll_addr, fi_addr_t root_addr,
+			     enum fi_datatype datatype, uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_alltoall(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			    void *result, void *result_desc, fi_addr_t coll_addr,
+			    enum fi_datatype datatype, uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_allreduce(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			     void *result, void *result_desc, fi_addr_t coll_addr,
+			     enum fi_datatype datatype, enum fi_op op, uint64_t flags,
+			     void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_allgather(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			     void *result, void *result_desc, fi_addr_t coll_addr,
+			     enum fi_datatype datatype, uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_reduce_scatter(struct fid_ep *ep, const void *buf, size_t count,
+				  void *desc, void *result, void *result_desc,
+				  fi_addr_t coll_addr, enum fi_datatype datatype,
+				  enum fi_op op, uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_reduce(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			  void *result, void *result_desc, fi_addr_t coll_addr,
+			  fi_addr_t root_addr, enum fi_datatype datatype, enum fi_op op,
+			  uint64_t flags, void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_scatter(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			   void *result, void *result_desc, fi_addr_t coll_addr,
+			   fi_addr_t root_addr, enum fi_datatype datatype, uint64_t flags,
+			   void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_gather(struct fid_ep *ep, const void *buf, size_t count, void *desc,
+			  void *result, void *result_desc, fi_addr_t coll_addr,
+			  fi_addr_t root_addr, enum fi_datatype datatype, uint64_t flags,
+			  void *context)
+{
+	return -FI_ENOSYS;
+}
+ssize_t fi_coll_no_msg(struct fid_ep *ep, const struct fi_msg_collective *msg,
+		       struct fi_ioc *resultv, void **result_desc, size_t result_count,
+		       uint64_t flags)
+{
+	return -FI_ENOSYS;
+}
diff --git a/src/fabric.c b/src/fabric.c
index bd1ade9..177815f 100644
--- a/src/fabric.c
+++ b/src/fabric.c
@@ -101,6 +101,32 @@ static int ofi_find_core_name(char **names, const char *name)
 	return -1;
 }
 
+static void ofi_closest_prov_names(char *prov_name, char* miss_prov_name, int n)
+{
+	if (strncasecmp( prov_name, miss_prov_name, n ) == 0 ) {
+		FI_WARN(&core_prov, FI_LOG_CORE,
+			"Instead misspelled provider: %s, you may want: %s?\n",
+			miss_prov_name, prov_name);
+	}
+}
+
+static void ofi_suggest_prov_names(char *name_to_match)
+{
+	struct ofi_prov *prov;
+	for (prov = prov_head; prov; prov = prov->next) {
+		if (strlen(prov->prov_name) != strlen(name_to_match)
+		    && !strncasecmp(prov->prov_name, name_to_match,
+				    strlen(name_to_match))) {
+			if (strlen(name_to_match) > 5)
+				ofi_closest_prov_names(prov->prov_name,
+						       name_to_match, 5);
+			else
+				ofi_closest_prov_names(prov->prov_name,
+						       name_to_match, 2);
+		}
+	}
+}
+
 static enum ofi_prov_type ofi_prov_type(const struct fi_provider *provider)
 {
 	const struct fi_prov_context *ctx;
@@ -324,7 +350,7 @@ static void ofi_ordered_provs_init(void)
 {
 	char *ordered_prov_names[] = {
 		"psm2", "psm", "efa", "usnic", "gni", "bgq", "verbs",
-		"netdir", "ofi_rxm", "ofi_rxd", "shm", "mlx",
+		"netdir", "ofi_rxm", "ofi_rxd", "shm",
 		/* Initialize the socket based providers last of the
 		 * standard providers.  This will result in them being
 		 * the least preferred providers.
@@ -363,8 +389,8 @@ static int ofi_register_provider(struct fi_provider *provider, void *dlhandle)
 	int ret;
 
 	if (!provider || !provider->name) {
-		FI_WARN(&core_prov, FI_LOG_CORE,
-			"no provider structure or name\n");
+		FI_DBG(&core_prov, FI_LOG_CORE,
+		       "no provider structure or name\n");
 		ret = -FI_EINVAL;
 		goto cleanup;
 	}
@@ -469,6 +495,32 @@ static int lib_filter(const struct dirent *entry)
 }
 #endif
 
+static int verify_filter_names(char **names)
+{
+	int i, j;
+	char** split_names;
+	for (i = 0; names[i]; i++) {
+		split_names = ofi_split_and_alloc(names[i], ";", NULL);
+		if (!split_names) {
+			FI_WARN(&core_prov, FI_LOG_CORE,
+				"unable to parse given filter string\n");
+			return -FI_ENODATA;
+		}
+
+		for(j = 0; split_names[j]; j++) {
+			if(!ofi_getprov(split_names[j], strlen(split_names[j]))) {
+				FI_WARN(&core_prov, FI_LOG_CORE,
+					"provider %s is unknown, misspelled"
+					" or DL provider?\n", split_names[j]);
+				ofi_suggest_prov_names(split_names[j]);
+			}
+		}
+		ofi_free_string_array(split_names);
+	}
+
+	return FI_SUCCESS;
+}
+
 void ofi_free_filter(struct fi_filter *filter)
 {
 	ofi_free_string_array(filter->names);
@@ -485,10 +537,14 @@ void ofi_create_filter(struct fi_filter *filter, const char *raw_filter)
 		++raw_filter;
 	}
 
-	filter->names= ofi_split_and_alloc(raw_filter, ",", NULL);
+	filter->names = ofi_split_and_alloc(raw_filter, ",", NULL);
 	if (!filter->names)
 		FI_WARN(&core_prov, FI_LOG_CORE,
 			"unable to parse filter from: %s\n", raw_filter);
+
+	if(verify_filter_names(filter->names))
+		FI_WARN(&core_prov, FI_LOG_CORE,
+		        "unable to verify filter name\n");
 }
 
 #ifdef HAVE_LIBDL
@@ -606,7 +662,6 @@ libdl_done:
 	ofi_register_provider(PSM2_INIT, NULL);
 	ofi_register_provider(PSM_INIT, NULL);
 	ofi_register_provider(USNIC_INIT, NULL);
-	ofi_register_provider(MLX_INIT, NULL);
 	ofi_register_provider(GNI_INIT, NULL);
 	ofi_register_provider(BGQ_INIT, NULL);
 	ofi_register_provider(NETDIR_INIT, NULL);
@@ -817,9 +872,13 @@ static int ofi_layering_ok(const struct fi_provider *provider,
 			FI_INFO(&core_prov, FI_LOG_CORE,
 				"Sockets requested, skipping util layering\n");
 			return 0;
-		} else {
-			return 1;
 		}
+		if (!strcasecmp(prov_vec[0], "shm")) {
+			FI_INFO(&core_prov, FI_LOG_CORE,
+				"Shm requested, skipping util layering\n");
+			return 0;
+		}
+		return 1;
 	}
 
 	if ((count == 2) && ofi_has_util_prefix(prov_vec[0]) &&
@@ -840,6 +899,7 @@ int DEFAULT_SYMVER_PRE(fi_getinfo)(uint32_t version, const char *node,
 	struct fi_info *tail, *cur;
 	char **prov_vec = NULL;
 	size_t count = 0;
+	enum fi_log_level level;
 	int ret;
 
 	if (!ofi_init)
@@ -885,7 +945,11 @@ int DEFAULT_SYMVER_PRE(fi_getinfo)(uint32_t version, const char *node,
 		ret = prov->provider->getinfo(version, node, service, flags,
 					      hints, &cur);
 		if (ret) {
-			FI_WARN(&core_prov, FI_LOG_CORE,
+			level = ((hints && hints->fabric_attr &&
+				  hints->fabric_attr->prov_name) ?
+				 FI_LOG_WARN : FI_LOG_INFO);
+
+			FI_LOG(&core_prov, level, FI_LOG_CORE,
 			       "fi_getinfo: provider %s returned -%d (%s)\n",
 			       prov->provider->name, -ret, fi_strerror(-ret));
 			continue;
@@ -898,6 +962,9 @@ int DEFAULT_SYMVER_PRE(fi_getinfo)(uint32_t version, const char *node,
 			continue;
 		}
 
+		FI_DBG(&core_prov, FI_LOG_CORE, "fi_getinfo: provider %s "
+		       "returned success\n", prov->provider->name);
+
 		if (!*info)
 			*info = cur;
 		else
diff --git a/src/fi_tostr.c b/src/fi_tostr.c
index 8c99cb1..e9d9182 100644
--- a/src/fi_tostr.c
+++ b/src/fi_tostr.c
@@ -47,6 +47,8 @@
 #include <rdma/fi_domain.h>
 #include <rdma/fi_endpoint.h>
 #include <rdma/fi_trigger.h>
+#include <rdma/fi_collective.h>
+
 
 /* Print fi_info and related structs, enums, OR_able flags, addresses.
  *
@@ -221,6 +223,7 @@ static void ofi_tostr_caps(char *buf, uint64_t caps)
 	IFFLAGSTR(caps, FI_SOURCE);
 	IFFLAGSTR(caps, FI_NAMED_RX_CTX);
 	IFFLAGSTR(caps, FI_DIRECTED_RECV);
+	IFFLAGSTR(caps, FI_HMEM);
 
 	ofi_remove_comma(buf);
 }
@@ -435,6 +438,7 @@ static void ofi_tostr_mr_mode(char *buf, int mr_mode)
 	IFFLAGSTR(mr_mode, FI_MR_MMU_NOTIFY);
 	IFFLAGSTR(mr_mode, FI_MR_RMA_EVENT);
 	IFFLAGSTR(mr_mode, FI_MR_ENDPOINT);
+	IFFLAGSTR(mr_mode, FI_MR_HMEM);
 
 	ofi_remove_comma(buf);
 }
@@ -585,7 +589,6 @@ static void ofi_tostr_atomic_type(char *buf, enum fi_datatype type)
 	CASEENUMSTR(FI_DOUBLE_COMPLEX);
 	CASEENUMSTR(FI_LONG_DOUBLE);
 	CASEENUMSTR(FI_LONG_DOUBLE_COMPLEX);
-	CASEENUMSTR(FI_VOID);
 	default:
 		ofi_strcatf(buf, "Unknown");
 		break;
@@ -614,10 +617,24 @@ static void ofi_tostr_atomic_op(char *buf, enum fi_op op)
 	CASEENUMSTR(FI_CSWAP_GE);
 	CASEENUMSTR(FI_CSWAP_GT);
 	CASEENUMSTR(FI_MSWAP);
+	default:
+		ofi_strcatf(buf, "Unknown");
+		break;
+	}
+}
+
+static void ofi_tostr_collective_op(char *buf, enum fi_collective_op op)
+{
+	switch (op) {
 	CASEENUMSTR(FI_BARRIER);
 	CASEENUMSTR(FI_BROADCAST);
 	CASEENUMSTR(FI_ALLTOALL);
+	CASEENUMSTR(FI_ALLREDUCE);
 	CASEENUMSTR(FI_ALLGATHER);
+	CASEENUMSTR(FI_REDUCE_SCATTER);
+	CASEENUMSTR(FI_REDUCE);
+	CASEENUMSTR(FI_SCATTER);
+	CASEENUMSTR(FI_GATHER);
 	default:
 		ofi_strcatf(buf, "Unknown");
 		break;
@@ -761,6 +778,9 @@ char *DEFAULT_SYMVER_PRE(fi_tostr)(const void *data, enum fi_type datatype)
 	case FI_TYPE_FID:
 		ofi_tostr_fid("fid: ", buf, data);
 		break;
+	case FI_TYPE_COLLECTIVE_OP:
+		ofi_tostr_collective_op(buf, *enumval);
+		break;
 	default:
 		ofi_strcatf(buf, "Unknown type");
 		break;
diff --git a/src/mem.c b/src/mem.c
index 23617a0..6cd5f48 100644
--- a/src/mem.c
+++ b/src/mem.c
@@ -1,5 +1,5 @@
 /*
- * Copyright 2014-2018, Intel Corporation
+ * Copyright 2014-2019, Intel Corporation
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions
@@ -104,6 +104,24 @@ void ofi_mem_fini(void)
 	free(page_sizes);
 }
 
+size_t ofi_get_mem_size(void)
+{
+	long page_cnt, page_size;
+	size_t mem_size;
+
+	page_cnt = ofi_sysconf(_SC_PHYS_PAGES);
+	page_size = ofi_get_page_size();
+
+	if (page_cnt <= 0 || page_size <= 0)
+		return 0;
+
+	mem_size = (size_t) page_cnt * (size_t) page_size;
+	if (mem_size < page_cnt || mem_size < page_size)
+		return 0;
+
+	return mem_size;
+}
+
 
 uint64_t OFI_RMA_PMEM;
 void (*ofi_pmem_commit)(const void *addr, size_t len);
diff --git a/src/tree.c b/src/tree.c
index 77e2937..d613474 100644
--- a/src/tree.c
+++ b/src/tree.c
@@ -293,22 +293,43 @@ static void ofi_delete_rebalance(struct ofi_rbmap *map, struct ofi_rbnode *node)
 	node->color = BLACK;
 }
 
+static void ofi_rbmap_replace_node_ptr(struct ofi_rbmap *map,
+		struct ofi_rbnode *old_node, struct ofi_rbnode *new_node)
+{
+	if (new_node == old_node)
+		return;
+
+	*new_node = *old_node;
+
+	if (!old_node->parent)
+		map->root = new_node;
+	else if (old_node == old_node->parent->left)
+		old_node->parent->left = new_node;
+	else
+		old_node->parent->right = new_node;
+
+	if (old_node->left != &map->sentinel)
+		old_node->left->parent = new_node;
+	if (old_node->right != &map->sentinel)
+		old_node->right->parent = new_node;
+}
+
 void ofi_rbmap_delete(struct ofi_rbmap *map, struct ofi_rbnode *node)
 {
 	struct ofi_rbnode *x, *y;
 
-	if (node->left == &map->sentinel || node->right == &map->sentinel) {
+	if (node->left == &map->sentinel) {
+		y = node;
+		x = y->right;
+	} else if (node->right == &map->sentinel) {
 		y = node;
+		x = y->left;
 	} else {
 		y = node->right;
 		while (y->left != &map->sentinel)
 			y = y->left;
-	}
-
-	if (y->left != &map->sentinel)
-		x = y->left;
-	else
 		x = y->right;
+	}
 
 	x->parent = y->parent;
 	if (y->parent) {
@@ -326,7 +347,9 @@ void ofi_rbmap_delete(struct ofi_rbmap *map, struct ofi_rbnode *node)
 	if (y->color == BLACK)
 		ofi_delete_rebalance(map, x);
 
-	free (y);
+	/* swap y in for node, so we can free node */
+	ofi_rbmap_replace_node_ptr(map, node, y);
+	free(node);
 }
 
 struct ofi_rbnode *ofi_rbmap_find(struct ofi_rbmap *map, void *key)
@@ -345,6 +368,18 @@ struct ofi_rbnode *ofi_rbmap_find(struct ofi_rbmap *map, void *key)
 	return NULL;
 }
 
+int ofi_rbmap_find_delete(struct ofi_rbmap *map, void *key)
+{
+	struct ofi_rbnode *node;
+
+	node = ofi_rbmap_find(map, key);
+	if (!node)
+		return -FI_ENODATA;
+
+	ofi_rbmap_delete(map, node);
+	return 0;
+}
+
 struct ofi_rbnode *ofi_rbmap_search(struct ofi_rbmap *map, void *key,
 		int (*compare)(struct ofi_rbmap *map, void *key, void *data))
 {
diff --git a/src/var.c b/src/var.c
index ee43ff9..6103db1 100644
--- a/src/var.c
+++ b/src/var.c
@@ -228,7 +228,7 @@ int DEFAULT_SYMVER_PRE(fi_param_define)(const struct fi_provider *provider,
 
 	dlist_insert_tail(&v->entry, &param_list);
 
-	FI_INFO(provider, FI_LOG_CORE, "registered var %s\n", param_name);
+	FI_DBG(provider, FI_LOG_CORE, "registered var %s\n", param_name);
 	return FI_SUCCESS;
 }
 DEFAULT_SYMVER(fi_param_define_, fi_param_define, FABRIC_1.0);
diff --git a/src/windows/osd.c b/src/windows/osd.c
index a8d4efb..5a05d8f 100644
--- a/src/windows/osd.c
+++ b/src/windows/osd.c
@@ -465,7 +465,7 @@ int getifaddrs(struct ifaddrs **ifap)
 								&fa->in_netmasks;
 				netmask4->sin_family = pSockAddr->sa_family;
 				addr4->sin_family = pSockAddr->sa_family;
-				netmask4->sin_addr.S_un.S_addr = mask;
+				netmask4->sin_addr.S_un.S_addr = *mask;
 				pInAddr = (struct sockaddr_in *) pSockAddr;
 				addr4->sin_addr = pInAddr->sin_addr;
 			} else {
diff --git a/util/info.c b/util/info.c
index 8703392..26b35eb 100644
--- a/util/info.c
+++ b/util/info.c
@@ -139,6 +139,7 @@ static int str2cap(char *inputstr, uint64_t *value)
 	ORCASE(FI_SOURCE);
 	ORCASE(FI_NAMED_RX_CTX);
 	ORCASE(FI_DIRECTED_RECV);
+	ORCASE(FI_HMEM);
 
 	fprintf(stderr, "error: Unrecognized capability: %s\n", inputstr);
 
